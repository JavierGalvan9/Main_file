{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd77124d",
   "metadata": {},
   "source": [
    "## Load librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99ecb623",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T16:43:57.693458Z",
     "start_time": "2022-08-15T16:43:36.740325Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 17:03:05.315592: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from numpy.random import seed\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_curve, auc\n",
    "from collections import Counter\n",
    "\n",
    "parentDir = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "sys.path.append(os.path.join(parentDir, \"general_utils\"))\n",
    "import file_management\n",
    "from data_preprocessing import data_preprocessing\n",
    "\n",
    "seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9393971f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cluster_id           C           B           G           Y           R  \\\n",
      "314        1398   99.720984   82.710320   70.930293   78.311811   54.853197   \n",
      "178        1149  139.402345  113.234367   99.685817  133.694488   79.205065   \n",
      "437        1653  134.916626  114.219013  101.815856  114.645669   82.894742   \n",
      "327        1429  118.353971   99.121098   87.757600   94.009449   71.579732   \n",
      "558        1895  104.551759   86.320691   72.847328   76.371654   57.558960   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "275        1330   93.164933   76.474224   64.114169   47.798425   34.682963   \n",
      "427        1627  101.791316   87.305338   72.421320   76.724409   58.296895   \n",
      "331        1434  121.804524   99.121098   83.071515   95.067717   63.462443   \n",
      "593        2026  144.233119  119.470462  103.732891  113.234646   84.862569   \n",
      "144        1071  151.479280  134.568378  131.849404  144.982677  102.573018   \n",
      "\n",
      "             RE           N         N2    NDVI_1  ...    NPQI_3    NPQI_4  \\\n",
      "314   78.335401   79.768105  53.318979  0.185074  ...  0.139484  0.162509   \n",
      "178  124.396616  119.405451  80.793388  0.202408  ...  0.155062  0.180728   \n",
      "437  114.369685  127.628967  84.053063  0.212490  ...  0.124367  0.144950   \n",
      "327   97.292567  108.221470  70.665110  0.203790  ...  0.132351  0.154233   \n",
      "558   80.842133   91.445497  59.489080  0.227420  ...  0.142897  0.166496   \n",
      "..          ...         ...        ...       ...  ...       ...       ...   \n",
      "275   79.588767  115.951575  72.877033  0.539508  ...  0.147151  0.171424   \n",
      "427   74.418630   87.662680  50.524972  0.201191  ...  0.114606  0.133531   \n",
      "331   91.025735   93.419141  60.769666  0.190951  ...  0.153664  0.179072   \n",
      "593  110.139573  126.148734  81.375473  0.195659  ...  0.140589  0.163865   \n",
      "144  142.727100  150.819282  91.503751  0.190401  ...  0.088524  0.103188   \n",
      "\n",
      "       NPQI_5       CLR       CLG     BNDVI      CTR1       Lats     Longs  \\\n",
      "314  0.185472  0.018289  0.124599 -0.018108  0.550067  39.616315  2.585089   \n",
      "178  0.206342 -0.040123  0.197818  0.026526  0.568176  39.616700  2.585466   \n",
      "437  0.165491  0.115934  0.253527  0.055448  0.614415  39.615861  2.585193   \n",
      "327  0.176065  0.112330  0.233186  0.043891  0.604794  39.616260  2.585309   \n",
      "558  0.190033  0.131161  0.255303  0.028829  0.550531  39.615444  2.584909   \n",
      "..        ...       ...       ...       ...       ...        ...       ...   \n",
      "275  0.195626  0.456884  0.808517  0.205156  0.372275  39.616419  2.583939   \n",
      "427  0.152406  0.177967  0.210454  0.002042  0.572710  39.615907  2.584438   \n",
      "331  0.204424  0.026294  0.124563 -0.029614  0.521019  39.616265  2.584037   \n",
      "593  0.187097  0.145353  0.216092  0.027190  0.588371  39.615272  2.585129   \n",
      "144  0.117826  0.056697  0.143875  0.056943  0.677142  39.616832  2.585844   \n",
      "\n",
      "     PCR  \n",
      "314  0.0  \n",
      "178  0.0  \n",
      "437  0.0  \n",
      "327  0.0  \n",
      "558  1.0  \n",
      "..   ...  \n",
      "275  0.0  \n",
      "427  1.0  \n",
      "331  0.0  \n",
      "593  1.0  \n",
      "144  0.0  \n",
      "\n",
      "[564 rows x 39 columns]\n",
      "     cluster_id           C           B           G           Y          R  \\\n",
      "455        1686   91.094601   83.038536   70.717289   62.614173  54.361240   \n",
      "222        1218  103.861648   85.007829   64.114169   82.897638  47.719822   \n",
      "98          977  104.896814   87.633553   70.078278   62.966929  52.393412   \n",
      "29          741  128.015520  119.798678  109.057988  104.768504  91.258009   \n",
      "27          724  124.564966   98.464667   82.858511  103.533858  67.152120   \n",
      "..          ...         ...         ...         ...         ...        ...   \n",
      "293        1362  112.833086  101.746822   90.739654   82.368504  73.301582   \n",
      "406        1588  121.459469  103.387900   92.017678   91.892913  70.595818   \n",
      "389        1556  118.699026   97.808236   84.775546  100.888189  63.954400   \n",
      "198        1179  134.226515  122.424402  110.549016  117.644094  92.979858   \n",
      "69          914  125.600132  104.700762   87.118588  103.004724  67.890055   \n",
      "\n",
      "             RE           N         N2    NDVI_1  ...    NPQI_3    NPQI_4  \\\n",
      "455   70.658531   93.583611  57.975659  0.265115  ...  0.069197  0.080614   \n",
      "222   76.298680   71.873529  50.292138  0.201965  ...  0.149342  0.174002   \n",
      "98    62.668320   78.781283  52.620477  0.201166  ...  0.134149  0.156305   \n",
      "29   113.586331  132.234136  88.593326  0.183345  ...  0.049636  0.057850   \n",
      "27    93.532468   99.669013  66.124848  0.194921  ...  0.175147  0.204109   \n",
      "..          ...         ...        ...       ...  ...       ...       ...   \n",
      "293   94.315822  112.662168  73.226284  0.211657  ...  0.077317  0.090099   \n",
      "406   90.869065  105.754415  66.939767  0.199368  ...  0.120291  0.140184   \n",
      "389   99.015946   96.708547  67.638269  0.203869  ...  0.144402  0.168275   \n",
      "198  120.949858  133.714369  87.778407  0.179689  ...  0.068844  0.080239   \n",
      "69    99.642629  101.149246  71.363612  0.196754  ...  0.135827  0.158294   \n",
      "\n",
      "       NPQI_5       CLR       CLG     BNDVI      CTR1       Lats     Longs  \\\n",
      "455  0.091999  0.324449  0.323348  0.059704  0.596756  39.615784  2.584101   \n",
      "222  0.198598 -0.057998  0.121024 -0.083721  0.459456  39.616591  2.582556   \n",
      "98   0.178404  0.257115  0.124190 -0.053194  0.499476  39.617004  2.582475   \n",
      "29   0.066048  0.164173  0.212512  0.049341  0.712867  39.617349  2.582963   \n",
      "27   0.233008  0.065609  0.202882  0.006078  0.539093  39.617376  2.583038   \n",
      "..        ...       ...       ...       ...       ...        ...       ...   \n",
      "293  0.102851  0.194520  0.241598  0.050909  0.649646  39.616387  2.585484   \n",
      "406  0.160033  0.163811  0.149284  0.011315  0.581229  39.615979  2.581633   \n",
      "389  0.192093 -0.023303  0.140760 -0.005653  0.538795  39.616043  2.582556   \n",
      "198  0.091613  0.105536  0.209548  0.044078  0.692709  39.616655  2.584334   \n",
      "69   0.180712  0.015120  0.161052 -0.017253  0.540525  39.617090  2.584949   \n",
      "\n",
      "     PCR  \n",
      "455  0.0  \n",
      "222  0.0  \n",
      "98   0.0  \n",
      "29   0.0  \n",
      "27   0.0  \n",
      "..   ...  \n",
      "293  1.0  \n",
      "406  1.0  \n",
      "389  0.0  \n",
      "198  0.0  \n",
      "69   0.0  \n",
      "\n",
      "[63 rows x 39 columns]\n",
      "Index(['C', 'B', 'G', 'Y', 'R', 'RE', 'N', 'N2', 'NDVI_1', 'NDVI_2', 'ENDVI_1',\n",
      "       'ENDVI_2', 'ratio_nir_red_1', 'ratio_nir_red_2', 'ratio_red_NDVI1',\n",
      "       'ratio_red_NDVI2', 'BR3', 'BR4', 'GNDVI_1', 'GNDVI_2', 'SAVI_1',\n",
      "       'SAVI_2', 'SAVI_3', 'SAVI_4', 'SAVI_5', 'SAVI_6', 'NPQI_1', 'NPQI_2',\n",
      "       'NPQI_3', 'NPQI_4', 'NPQI_5', 'CLR', 'CLG', 'BNDVI', 'CTR1',\n",
      "       'cluster_id', 'Lats', 'Longs', 'PCR'],\n",
      "      dtype='object')\n",
      "Index(['C', 'B', 'G', 'Y', 'R', 'RE', 'N', 'N2', 'NDVI_1', 'NDVI_2', 'ENDVI_1',\n",
      "       'ENDVI_2', 'ratio_nir_red_1', 'ratio_nir_red_2', 'ratio_red_NDVI1',\n",
      "       'ratio_red_NDVI2', 'BR3', 'BR4', 'GNDVI_1', 'GNDVI_2', 'SAVI_1',\n",
      "       'SAVI_2', 'SAVI_3', 'SAVI_4', 'SAVI_5', 'SAVI_6', 'NPQI_1', 'NPQI_2',\n",
      "       'NPQI_3', 'NPQI_4', 'NPQI_5', 'CLR', 'CLG', 'BNDVI', 'CTR1'],\n",
      "      dtype='object')\n",
      "Training set size:  24221\n",
      "Test set size:  2594\n",
      "Original dataset proportions:  {0.0: 0.7508856983031885, 1.0: 0.24911430169681148}\n",
      "Training set proportions:  {0.0: 0.7461706783369803, 1.0: 0.2538293216630197}\n",
      "Test set proportions:  {0.0: 0.79491133384734, 1.0: 0.20508866615265997}\n",
      "Number of unique cluster_id in the original dataset:  627\n",
      "Number of unique cluster_id in the training set:  564\n",
      "Number of unique cluster_id in the test set:  63\n"
     ]
    }
   ],
   "source": [
    "train_test_path = os.path.join('Classification datasets', 'Train and test sets')\n",
    "X_train, X_test, y_train, y_test, std_scale, cluster_id_train, cluster_id_test = data_preprocessing(train_test_path, use_spectral_bands=True, use_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fabe1e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.99409447,  1.91919073,  1.43853778, ..., -0.96036431,\n",
       "        -1.33780135,  0.38178907],\n",
       "       [ 2.67398756,  2.63385914,  2.03426804, ..., -0.90583642,\n",
       "        -1.26425913,  0.52263915],\n",
       "       [-0.54172301, -0.30207597, -0.23695359, ..., -1.24322284,\n",
       "        -1.43437222,  0.59871539],\n",
       "       ...,\n",
       "       [-0.79897986, -0.16686843,  0.07332259, ..., -0.6214711 ,\n",
       "        -0.28816756,  2.09445771],\n",
       "       [-0.68872692, -0.10892234,  0.12296678, ..., -0.46227922,\n",
       "        -0.09202701,  1.8443753 ],\n",
       "       [-0.5600985 , -0.01234553,  0.24707725, ..., -0.45991858,\n",
       "        -0.03415089,  1.85664153]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d67b01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "K = 5\n",
    "kfold = StratifiedKFold(n_splits=K, shuffle=True, random_state=0) #fix the divisions of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39b0543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trees_set = set(cluster_id_test)\n",
    "trees_label = {tree: label for tree, label in zip(cluster_id_test, y_test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c57fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lists of trees and labels\n",
    "trees = list(trees_set)\n",
    "labels = [trees_label[tree] for tree in trees]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd810072",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "kfold = StratifiedKFold(n_splits=K, shuffle=True, random_state=0) #fix the divisions of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7291556a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  5  6  7  9 10 11 12 13 14 15 16 17 19 20 21 22 23 24 25 26\n",
      " 27 28 29 31 33 34 36 37 38 39 41 42 44 45 46 47 48 49 50 52 54 55 56 58\n",
      " 59 62] [ 4  8 18 30 32 35 40 43 51 53 57 60 61]\n"
     ]
    }
   ],
   "source": [
    "for train, validate in kfold.split(trees, labels):\n",
    "    print(train, validate)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d155286d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2594,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mask = np.isin(cluster_id_test, np.array(trees)[train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcabef59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.06095947, -1.52389024, -1.55644798, ...,  2.13646192,\n",
       "         1.6776804 , -1.65720489],\n",
       "       [ 0.52034057,  0.09743728, -0.02021897, ...,  0.17571513,\n",
       "         0.15807483, -0.07834646],\n",
       "       [-0.27030945, -0.55881433, -0.6272772 , ..., -0.25173985,\n",
       "        -0.43248375, -0.2752477 ],\n",
       "       ...,\n",
       "       [ 0.35485568,  0.15534184,  0.09128153, ..., -0.2648523 ,\n",
       "        -0.25460927, -0.23597692],\n",
       "       [ 1.55002432,  1.23622685,  1.56556582, ..., -0.95765505,\n",
       "        -0.45231523,  0.58883662],\n",
       "       [ 0.66743825,  0.71508586,  0.3390604 , ..., -0.76252772,\n",
       "        -1.21279918,  0.23349832]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5c2225d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature1  feature2  target\n",
      "0         0        50       0\n",
      "1         1       487       1\n",
      "2         0        70       0\n",
      "3         0       479       1\n",
      "4         0        47       0\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate random dataset with 1000 rows and 2 features\n",
    "feature1 = np.random.randint(low=0, high=2, size=10000)\n",
    "feature2 = np.random.randint(low=0, high=500, size=10000)\n",
    "\n",
    "# Generate random binary target variable\n",
    "# all rows with same feature2 value will have the same target value\n",
    "target = np.where(feature2 > 250, 1, 0)\n",
    "\n",
    "# Combine features and target into a pandas DataFrame\n",
    "df = pd.DataFrame({'feature1': feature1, 'feature2': feature2, 'target': target})\n",
    "\n",
    "# Print the first few rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b3e3392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby feature_2 and train test split on each group\n",
    "def groupby_split(df, feature_1, feature_2, test_size):\n",
    "    # Given df and feature_2, groupby feature_2 and split each group into train and test sets\n",
    "    # feature_1 is the feature to stratify the split\n",
    "    # test_size is the size of the test set\n",
    "    # Return a list of tuples (train, test) where train and test are dataframes\n",
    "    \n",
    "    # Create new dataframe with the first row for each unique value of feature_2\n",
    "    df_new = df.groupby(feature_2).first().reset_index()\n",
    "    # Stratify the split on feature_1\n",
    "    train, test = train_test_split(df_new, test_size=test_size, stratify=df_new[feature_1])\n",
    "    # From the original dataframe, select the rows that have the same values of feature_2 as the train and test dataframes\n",
    "    train_df = df[df[feature_2].isin(train[feature_2])]\n",
    "    test_df = df[df[feature_2].isin(test[feature_2])]\n",
    "    # Return a list of tuples (train, test) where train and test are dataframes\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f9039cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = groupby_split(df, 'target', 'feature2', 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cbe76485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size:  8015\n",
      "Test set size:  1985\n",
      "Original dataset proportions:  {0: 0.5013, 1: 0.4987}\n",
      "Training set proportions:  {0: 0.5010605115408608, 1: 0.4989394884591391}\n",
      "Test set proportions:  {0: 0.5022670025188917, 1: 0.49773299748110833}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "feature = 'feature1'\n",
    "\n",
    "# Print the number of samples in each set\n",
    "print('Training set size: ', len(train_df))\n",
    "print('Test set size: ', len(test_df))\n",
    "\n",
    "# Ensure that the proportion of samples in each set is the same as the original dataset\n",
    "# Print the proportion samples in each set by dividing the counter by the total number of samples\n",
    "print('Original dataset proportions: ', get_class_proportions(df, feature))\n",
    "print('Training set proportions: ', get_class_proportions(train_df, feature) )\n",
    "print('Test set proportions: ', get_class_proportions(test_df, feature) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "26adf8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9964</th>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>1</td>\n",
       "      <td>209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>1</td>\n",
       "      <td>327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1985 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature1  feature2  target\n",
       "2            0        70       0\n",
       "6            0       261       1\n",
       "7            0        83       0\n",
       "10           0       106       0\n",
       "12           0       303       1\n",
       "...        ...       ...     ...\n",
       "9964         0        96       0\n",
       "9973         1       209       0\n",
       "9977         1       327       1\n",
       "9982         1       181       0\n",
       "9993         1        45       0\n",
       "\n",
       "[1985 rows x 3 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e581c184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that, given a counter, returns the proportion of each class\n",
    "def get_class_proportions(df, feature):\n",
    "    counter = Counter(df[feature])\n",
    "    total = sum(counter.values())\n",
    "    new_dict = {cl: count / total for cl, count in counter.items()}\n",
    "    # Sort the dictionary by key\n",
    "    new_dict = {k: new_dict[k] for k in sorted(new_dict)}\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9307840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Specify the features you want to use for stratification\n",
    "stratify_cols = ['feature1', 'target']\n",
    "\n",
    "# Split the dataset into a training set and a test set, stratifying based on the specified features\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[stratify_cols], random_state=42)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "feature = 'feature2'\n",
    "\n",
    "# Print the number of samples in each set\n",
    "print('Training set size: ', len(train_df))\n",
    "print('Test set size: ', len(test_df))\n",
    "\n",
    "# Ensure that the proportion of samples in each set is the same as the original dataset\n",
    "# Print the proportion samples in each set by dividing the counter by the total number of samples\n",
    "print('Original dataset proportions: ', get_class_proportions(df, feature))\n",
    "print('Training set proportions: ', get_class_proportions(train_df, feature) )\n",
    "print('Test set proportions: ', get_class_proportions(test_df, feature) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1155ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size:  80\n",
      "Test set size:  20\n",
      "Original dataset proportions:  {0: 0.56, 1: 0.44}\n",
      "Training set proportions:  {0: 0.5375, 1: 0.4625}\n",
      "Test set proportions:  {0: 0.65, 1: 0.35}\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9369127a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T16:44:15.740330Z",
     "start_time": "2022-08-15T16:44:15.736699Z"
    }
   },
   "outputs": [],
   "source": [
    "## Create dir to save figures\n",
    "classification_path = 'Classification figures'\n",
    "os.makedirs(classification_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99207867",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "089cdb2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T16:44:19.009056Z",
     "start_time": "2022-08-15T16:44:16.591080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>G</th>\n",
       "      <th>Y</th>\n",
       "      <th>R</th>\n",
       "      <th>RE</th>\n",
       "      <th>N</th>\n",
       "      <th>N2</th>\n",
       "      <th>NDVI_1</th>\n",
       "      <th>NDVI_2</th>\n",
       "      <th>...</th>\n",
       "      <th>NPQI_4</th>\n",
       "      <th>NPQI_5</th>\n",
       "      <th>CLR</th>\n",
       "      <th>CLG</th>\n",
       "      <th>BNDVI</th>\n",
       "      <th>CTR1</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>Lats</th>\n",
       "      <th>Longs</th>\n",
       "      <th>PCR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66182</th>\n",
       "      <td>89.024270</td>\n",
       "      <td>82.382104</td>\n",
       "      <td>72.421320</td>\n",
       "      <td>72.491339</td>\n",
       "      <td>60.264723</td>\n",
       "      <td>70.815202</td>\n",
       "      <td>76.478698</td>\n",
       "      <td>46.799628</td>\n",
       "      <td>0.118572</td>\n",
       "      <td>-0.125766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067519</td>\n",
       "      <td>0.077052</td>\n",
       "      <td>0.079976</td>\n",
       "      <td>0.056025</td>\n",
       "      <td>-0.037161</td>\n",
       "      <td>0.676947</td>\n",
       "      <td>285</td>\n",
       "      <td>39.618106</td>\n",
       "      <td>2.583509</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66183</th>\n",
       "      <td>119.044081</td>\n",
       "      <td>106.998271</td>\n",
       "      <td>92.017678</td>\n",
       "      <td>94.714961</td>\n",
       "      <td>74.777452</td>\n",
       "      <td>95.569189</td>\n",
       "      <td>103.451830</td>\n",
       "      <td>65.193512</td>\n",
       "      <td>0.160885</td>\n",
       "      <td>-0.068471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092949</td>\n",
       "      <td>0.106111</td>\n",
       "      <td>0.082481</td>\n",
       "      <td>0.124260</td>\n",
       "      <td>-0.016852</td>\n",
       "      <td>0.628149</td>\n",
       "      <td>285</td>\n",
       "      <td>39.618106</td>\n",
       "      <td>2.583515</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66184</th>\n",
       "      <td>143.888064</td>\n",
       "      <td>126.691204</td>\n",
       "      <td>106.714946</td>\n",
       "      <td>112.529134</td>\n",
       "      <td>85.846483</td>\n",
       "      <td>116.719747</td>\n",
       "      <td>126.477675</td>\n",
       "      <td>82.306809</td>\n",
       "      <td>0.191364</td>\n",
       "      <td>-0.021050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110915</td>\n",
       "      <td>0.126643</td>\n",
       "      <td>0.083601</td>\n",
       "      <td>0.185192</td>\n",
       "      <td>-0.000843</td>\n",
       "      <td>0.596620</td>\n",
       "      <td>285</td>\n",
       "      <td>39.618106</td>\n",
       "      <td>2.583520</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66185</th>\n",
       "      <td>156.655110</td>\n",
       "      <td>138.835180</td>\n",
       "      <td>116.939132</td>\n",
       "      <td>124.875591</td>\n",
       "      <td>95.931600</td>\n",
       "      <td>128.783398</td>\n",
       "      <td>139.964241</td>\n",
       "      <td>92.551503</td>\n",
       "      <td>0.186661</td>\n",
       "      <td>-0.017933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105269</td>\n",
       "      <td>0.120206</td>\n",
       "      <td>0.086819</td>\n",
       "      <td>0.196898</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>0.612375</td>\n",
       "      <td>285</td>\n",
       "      <td>39.618106</td>\n",
       "      <td>2.583526</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66186</th>\n",
       "      <td>160.450719</td>\n",
       "      <td>148.025216</td>\n",
       "      <td>129.719365</td>\n",
       "      <td>135.987402</td>\n",
       "      <td>112.166178</td>\n",
       "      <td>134.893560</td>\n",
       "      <td>146.378584</td>\n",
       "      <td>96.044013</td>\n",
       "      <td>0.132327</td>\n",
       "      <td>-0.077432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070320</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.085141</td>\n",
       "      <td>0.128425</td>\n",
       "      <td>-0.005593</td>\n",
       "      <td>0.699069</td>\n",
       "      <td>285</td>\n",
       "      <td>39.618106</td>\n",
       "      <td>2.583532</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778154</th>\n",
       "      <td>99.375929</td>\n",
       "      <td>95.838942</td>\n",
       "      <td>82.858511</td>\n",
       "      <td>66.847244</td>\n",
       "      <td>71.825711</td>\n",
       "      <td>79.745438</td>\n",
       "      <td>98.517721</td>\n",
       "      <td>67.638269</td>\n",
       "      <td>0.156695</td>\n",
       "      <td>-0.030025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031586</td>\n",
       "      <td>0.036052</td>\n",
       "      <td>0.235403</td>\n",
       "      <td>0.188987</td>\n",
       "      <td>0.013783</td>\n",
       "      <td>0.722768</td>\n",
       "      <td>2685</td>\n",
       "      <td>39.614768</td>\n",
       "      <td>2.585019</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778155</th>\n",
       "      <td>98.340763</td>\n",
       "      <td>97.480020</td>\n",
       "      <td>85.414557</td>\n",
       "      <td>71.962205</td>\n",
       "      <td>77.483215</td>\n",
       "      <td>78.022059</td>\n",
       "      <td>94.899374</td>\n",
       "      <td>63.680091</td>\n",
       "      <td>0.101032</td>\n",
       "      <td>-0.097781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007663</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>0.216315</td>\n",
       "      <td>0.111044</td>\n",
       "      <td>-0.013414</td>\n",
       "      <td>0.787905</td>\n",
       "      <td>2685</td>\n",
       "      <td>39.614768</td>\n",
       "      <td>2.585025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778156</th>\n",
       "      <td>92.474823</td>\n",
       "      <td>92.885002</td>\n",
       "      <td>82.219499</td>\n",
       "      <td>71.785827</td>\n",
       "      <td>76.745280</td>\n",
       "      <td>73.008593</td>\n",
       "      <td>87.827150</td>\n",
       "      <td>57.742825</td>\n",
       "      <td>0.067337</td>\n",
       "      <td>-0.141295</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003857</td>\n",
       "      <td>-0.004402</td>\n",
       "      <td>0.202970</td>\n",
       "      <td>0.068203</td>\n",
       "      <td>-0.027988</td>\n",
       "      <td>0.829905</td>\n",
       "      <td>2685</td>\n",
       "      <td>39.614768</td>\n",
       "      <td>2.585031</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779120</th>\n",
       "      <td>95.580320</td>\n",
       "      <td>91.900356</td>\n",
       "      <td>79.237445</td>\n",
       "      <td>61.379528</td>\n",
       "      <td>69.857883</td>\n",
       "      <td>75.358655</td>\n",
       "      <td>88.649502</td>\n",
       "      <td>64.727844</td>\n",
       "      <td>0.118554</td>\n",
       "      <td>-0.038117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034213</td>\n",
       "      <td>0.039049</td>\n",
       "      <td>0.176368</td>\n",
       "      <td>0.118783</td>\n",
       "      <td>-0.018005</td>\n",
       "      <td>0.730881</td>\n",
       "      <td>2685</td>\n",
       "      <td>39.614764</td>\n",
       "      <td>2.585013</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779121</th>\n",
       "      <td>108.002312</td>\n",
       "      <td>107.326487</td>\n",
       "      <td>93.508705</td>\n",
       "      <td>74.255118</td>\n",
       "      <td>85.600505</td>\n",
       "      <td>83.975549</td>\n",
       "      <td>97.859840</td>\n",
       "      <td>70.315859</td>\n",
       "      <td>0.066823</td>\n",
       "      <td>-0.098031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005473</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.165337</td>\n",
       "      <td>0.046532</td>\n",
       "      <td>-0.046137</td>\n",
       "      <td>0.792580</td>\n",
       "      <td>2685</td>\n",
       "      <td>39.614764</td>\n",
       "      <td>2.585019</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40332 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 C           B           G           Y           R  \\\n",
       "66182    89.024270   82.382104   72.421320   72.491339   60.264723   \n",
       "66183   119.044081  106.998271   92.017678   94.714961   74.777452   \n",
       "66184   143.888064  126.691204  106.714946  112.529134   85.846483   \n",
       "66185   156.655110  138.835180  116.939132  124.875591   95.931600   \n",
       "66186   160.450719  148.025216  129.719365  135.987402  112.166178   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "778154   99.375929   95.838942   82.858511   66.847244   71.825711   \n",
       "778155   98.340763   97.480020   85.414557   71.962205   77.483215   \n",
       "778156   92.474823   92.885002   82.219499   71.785827   76.745280   \n",
       "779120   95.580320   91.900356   79.237445   61.379528   69.857883   \n",
       "779121  108.002312  107.326487   93.508705   74.255118   85.600505   \n",
       "\n",
       "                RE           N         N2    NDVI_1    NDVI_2  ...    NPQI_4  \\\n",
       "66182    70.815202   76.478698  46.799628  0.118572 -0.125766  ...  0.067519   \n",
       "66183    95.569189  103.451830  65.193512  0.160885 -0.068471  ...  0.092949   \n",
       "66184   116.719747  126.477675  82.306809  0.191364 -0.021050  ...  0.110915   \n",
       "66185   128.783398  139.964241  92.551503  0.186661 -0.017933  ...  0.105269   \n",
       "66186   134.893560  146.378584  96.044013  0.132327 -0.077432  ...  0.070320   \n",
       "...            ...         ...        ...       ...       ...  ...       ...   \n",
       "778154   79.745438   98.517721  67.638269  0.156695 -0.030025  ...  0.031586   \n",
       "778155   78.022059   94.899374  63.680091  0.101032 -0.097781  ...  0.007663   \n",
       "778156   73.008593   87.827150  57.742825  0.067337 -0.141295  ... -0.003857   \n",
       "779120   75.358655   88.649502  64.727844  0.118554 -0.038117  ...  0.034213   \n",
       "779121   83.975549   97.859840  70.315859  0.066823 -0.098031  ...  0.005473   \n",
       "\n",
       "          NPQI_5       CLR       CLG     BNDVI      CTR1  cluster_id  \\\n",
       "66182   0.077052  0.079976  0.056025 -0.037161  0.676947         285   \n",
       "66183   0.106111  0.082481  0.124260 -0.016852  0.628149         285   \n",
       "66184   0.126643  0.083601  0.185192 -0.000843  0.596620         285   \n",
       "66185   0.120206  0.086819  0.196898  0.004050  0.612375         285   \n",
       "66186   0.080300  0.085141  0.128425 -0.005593  0.699069         285   \n",
       "...          ...       ...       ...       ...       ...         ...   \n",
       "778154  0.036052  0.235403  0.188987  0.013783  0.722768        2685   \n",
       "778155  0.008746  0.216315  0.111044 -0.013414  0.787905        2685   \n",
       "778156 -0.004402  0.202970  0.068203 -0.027988  0.829905        2685   \n",
       "779120  0.039049  0.176368  0.118783 -0.018005  0.730881        2685   \n",
       "779121  0.006248  0.165337  0.046532 -0.046137  0.792580        2685   \n",
       "\n",
       "             Lats     Longs  PCR  \n",
       "66182   39.618106  2.583509  1.0  \n",
       "66183   39.618106  2.583515  1.0  \n",
       "66184   39.618106  2.583520  1.0  \n",
       "66185   39.618106  2.583526  1.0  \n",
       "66186   39.618106  2.583532  1.0  \n",
       "...           ...       ...  ...  \n",
       "778154  39.614768  2.585019  0.0  \n",
       "778155  39.614768  2.585025  0.0  \n",
       "778156  39.614768  2.585031  0.0  \n",
       "779120  39.614764  2.585013  0.0  \n",
       "779121  39.614764  2.585019  0.0  \n",
       "\n",
       "[40332 rows x 39 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = file_management.load_lzma('Processed Data/QPCR_labelled_df.lzma')\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769dbb77",
   "metadata": {},
   "source": [
    "## Save real data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a55e5057",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=42)\n",
    "n_test = int(len(df)*0.05) # 5% of tree pixels for testing\n",
    "n_train = len(df) - n_test\n",
    "test_df = df.iloc[:n_test]\n",
    "train_df = df.iloc[n_test:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd0dfec",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9fd5357",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T16:44:29.270934Z",
     "start_time": "2022-08-15T16:44:29.222782Z"
    }
   },
   "outputs": [],
   "source": [
    "#Data preprocessing: Normalization of spectral bands\n",
    "# spectral_bands = ['C', 'B', 'G', 'Y', 'R', 'RE', 'N', 'N2']\n",
    "# X_train = train_df.loc[:, spectral_bands] # only spectral bands\n",
    "X_train = train_df.iloc[:, :-4] # spectral bands + indices\n",
    "#X_train = train_df.iloc[:, 8:-4] # indices\n",
    "X_test = test_df.iloc[:, :-4] \n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "Y_train = train_df['PCR'].values\n",
    "Y_test = test_df['PCR'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0481dea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 28731, 1.0: 9585})\n"
     ]
    }
   ],
   "source": [
    "n_features = X_train.shape[1]\n",
    "\n",
    "print(Counter(Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adfb35c",
   "metadata": {},
   "source": [
    "## SVC with penalization for the minority class"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e796a7d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T16:51:16.777445Z",
     "start_time": "2022-08-10T16:15:18.567555Z"
    }
   },
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# we can add class_weight='balanced' to add panalize mistake\n",
    "svc_model = SVC(class_weight='balanced', probability=True)\n",
    "svc_model.fit(X, Y)\n",
    "svc_predict = svc_model.predict(X)# check performance"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e59ce2fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T16:51:16.874860Z",
     "start_time": "2022-08-10T16:51:16.781267Z"
    }
   },
   "source": [
    "cm=confusion_matrix(Y, svc_predict)\n",
    "print(cm)\n",
    "\n",
    "print('Accuracy score:',accuracy_score(Y, svc_predict))\n",
    "print('F1 score:',f1_score(Y, svc_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681b72e2",
   "metadata": {},
   "source": [
    "## Balance the dataset using oversampling techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a302aeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T17:48:35.931999Z",
     "start_time": "2022-08-11T17:48:35.660277Z"
    }
   },
   "outputs": [],
   "source": [
    "#random.seed(42)\n",
    "#\n",
    "#c = list(zip(X_train, Y_train))\n",
    "#random.shuffle(c)\n",
    "#X_train, Y_train = zip(*c)\n",
    "#X_train = np.array(X_train)\n",
    "#Y_train = np.array(Y_train)\n",
    "\n",
    "file_management.save_lzma(X_train, 'X_train.lzma', '')\n",
    "file_management.save_lzma(Y_train, 'Y_train.lzma', '')\n",
    "file_management.save_lzma(X_test, 'X_test.lzma', '')\n",
    "file_management.save_lzma(Y_test, 'Y_test.lzma', '')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "233fd26b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T12:57:30.919773Z",
     "start_time": "2022-08-11T12:57:30.816545Z"
    }
   },
   "source": [
    "X.shape\n",
    "pca = PCA(n_components=8)\n",
    "X1 = pca.fit_transform(X)\n",
    "X1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d86d93",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec8d5ae1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T21:51:42.935613Z",
     "start_time": "2022-08-11T21:51:35.428857Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jgalvan/.conda/envs/xylella_tf/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2b8b57e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T21:52:10.060042Z",
     "start_time": "2022-08-11T21:52:10.052063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15833, 27)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = X[5000:, :]\n",
    "Y1 = Y[5000:]\n",
    "\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c416870d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-12T10:21:42.217903Z",
     "start_time": "2022-08-12T10:21:39.275627Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualization\n",
    "import plotly.express as px # for data visualization\n",
    "import matplotlib.pyplot as plt # for showing handwritten digits\n",
    "\n",
    "def chart(X, y):\n",
    "    #--------------------------------------------------------------------------#\n",
    "    # This section is not mandatory as its purpose is to sort the data by label \n",
    "    # so, we can maintain consistent colors for digits across multiple graphs\n",
    "    \n",
    "    # Concatenate X and y arrays\n",
    "    arr_concat=np.concatenate((X, y.reshape(y.shape[0],1)), axis=1)\n",
    "    # Create a Pandas dataframe using the above array\n",
    "    df=pd.DataFrame(arr_concat, columns=['x', 'y', 'z', 'label'])\n",
    "    # Convert label data type from float to integer\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    # Finally, sort the dataframe by label\n",
    "    df.sort_values(by='label', axis=0, ascending=True, inplace=True)\n",
    "    #--------------------------------------------------------------------------#\n",
    "    \n",
    "    # Create a 3D graph\n",
    "    fig = px.scatter_3d(df, x='x', y='y', z='z', color=df['label'].astype(str), height=900, width=950)\n",
    "\n",
    "    # Update chart looks\n",
    "    fig.update_layout(title_text='UMAP',\n",
    "                      showlegend=True,\n",
    "                      legend=dict(orientation=\"h\", yanchor=\"top\", y=0, xanchor=\"center\", x=0.5),\n",
    "                      scene_camera=dict(up=dict(x=0, y=0, z=1), \n",
    "                                            center=dict(x=0, y=0, z=-0.1),\n",
    "                                            eye=dict(x=1.5, y=-1.4, z=0.5)),\n",
    "                                            margin=dict(l=0, r=0, b=0, t=0),\n",
    "                      scene = dict(xaxis=dict(backgroundcolor='white',\n",
    "                                              color='black',\n",
    "                                              gridcolor='#f0f0f0',\n",
    "                                              title_font=dict(size=10),\n",
    "                                              tickfont=dict(size=10),\n",
    "                                             ),\n",
    "                                   yaxis=dict(backgroundcolor='white',\n",
    "                                              color='black',\n",
    "                                              gridcolor='#f0f0f0',\n",
    "                                              title_font=dict(size=10),\n",
    "                                              tickfont=dict(size=10),\n",
    "                                              ),\n",
    "                                   zaxis=dict(backgroundcolor='lightgrey',\n",
    "                                              color='black', \n",
    "                                              gridcolor='#f0f0f0',\n",
    "                                              title_font=dict(size=10),\n",
    "                                              tickfont=dict(size=10),\n",
    "                                             )))\n",
    "    # Update marker size\n",
    "    fig.update_traces(marker=dict(size=3, line=dict(color='black', width=0.1)))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba2530ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T22:27:19.863963Z",
     "start_time": "2022-08-11T22:24:57.113480Z"
    }
   },
   "source": [
    "reducer = UMAP(n_neighbors=5, # default 15, The size of local neighborhood (in terms of number of neighboring sample points) used for manifold approximation.\n",
    "               n_components=3, # default 2, The dimension of the space to embed into.\n",
    "               metric='euclidean', # default 'euclidean', The metric to use to compute distances in high dimensional space.\n",
    "               n_epochs=1000, # default None, The number of training epochs to be used in optimizing the low dimensional embedding. Larger values result in more accurate embeddings. \n",
    "               learning_rate=1.0, # default 1.0, The initial learning rate for the embedding optimization.\n",
    "               init='spectral', # default 'spectral', How to initialize the low dimensional embedding. Options are: {'spectral', 'random', A numpy array of initial embedding positions}.\n",
    "               min_dist=0.1, # default 0.1, The effective minimum distance between embedded points.\n",
    "               spread=1.0, # default 1.0, The effective scale of embedded points. In combination with ``min_dist`` this determines how clustered/clumped the embedded points are.\n",
    "               low_memory=False, # default False, For some datasets the nearest neighbor computation can consume a lot of memory. If you find that UMAP is failing due to memory constraints consider setting this option to True.\n",
    "               set_op_mix_ratio=1.0, # default 1.0, The value of this parameter should be between 0.0 and 1.0; a value of 1.0 will use a pure fuzzy union, while 0.0 will use a pure fuzzy intersection.\n",
    "               local_connectivity=1, # default 1, The local connectivity required -- i.e. the number of nearest neighbors that should be assumed to be connected at a local level.\n",
    "               repulsion_strength=1.0, # default 1.0, Weighting applied to negative samples in low dimensional embedding optimization.\n",
    "               negative_sample_rate=5, # default 5, Increasing this value will result in greater repulsive force being applied, greater optimization cost, but slightly more accuracy.\n",
    "               transform_queue_size=4.0, # default 4.0, Larger values will result in slower performance but more accurate nearest neighbor evaluation.\n",
    "               a=None, # default None, More specific parameters controlling the embedding. If None these values are set automatically as determined by ``min_dist`` and ``spread``.\n",
    "               b=None, # default None, More specific parameters controlling the embedding. If None these values are set automatically as determined by ``min_dist`` and ``spread``.\n",
    "               random_state=42, # default: None, If int, random_state is the seed used by the random number generator;\n",
    "               metric_kwds=None, # default None) Arguments to pass on to the metric, such as the ``p`` value for Minkowski distance.\n",
    "               angular_rp_forest=False, # default False, Whether to use an angular random projection forest to initialise the approximate nearest neighbor search.\n",
    "               target_n_neighbors=-1, # default -1, The number of nearest neighbors to use to construct the target simplcial set. If set to -1 use the ``n_neighbors`` value.\n",
    "               #target_metric='categorical', # default 'categorical', The metric used to measure distance for a target array is using supervised dimension reduction. By default this is 'categorical' which will measure distance in terms of whether categories match or are different. \n",
    "               #target_metric_kwds=None, # dict, default None, Keyword argument to pass to the target metric when performing supervised dimension reduction. If None then no arguments are passed on.\n",
    "               #target_weight=0.5, # default 0.5, weighting factor between data topology and target topology.\n",
    "               transform_seed=42, # default 42, Random seed used for the stochastic aspects of the transform operation.\n",
    "               verbose=False, # default False, Controls verbosity of logging.\n",
    "               unique=False, # default False, Controls if the rows of your data should be uniqued before being embedded. \n",
    "              )\n",
    "\n",
    "# Fit and transform the data\n",
    "X3 = reducer.fit_transform(X)\n",
    "X_trans = reducer.transform(X1)\n",
    "#X_trans = reducer.fit_transform(X1, Y1)\n",
    "\n",
    "# Check the shape of the new data\n",
    "print('Shape of X_trans: ', X_trans.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1ae8195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T22:27:20.426937Z",
     "start_time": "2022-08-11T22:27:19.867963Z"
    },
    "scrolled": true
   },
   "source": [
    "chart(X_trans, Y1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a8ddeee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T16:22:30.302793Z",
     "start_time": "2022-08-11T16:21:48.617930Z"
    }
   },
   "source": [
    "X2 = X[:5000, :]\n",
    "Y2 = Y[:5000]\n",
    "\n",
    "X_test = reducer.transform(X2)\n",
    "print('Shape of X_test: ', X_test.shape)\n",
    "\n",
    "chart(X_test, Y2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75cf2a67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T16:22:30.620338Z",
     "start_time": "2022-08-11T16:22:30.307172Z"
    }
   },
   "source": [
    "# =============================================================================\n",
    "# KNN\n",
    "# =============================================================================\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier().fit(X_trans, Y1)\n",
    "\n",
    "y_pred = np.round(knn.predict(X_test))\n",
    "\n",
    "print(confusion_matrix(Y2,y_pred))\n",
    "#### OJO CON COMO DEFINE LA MATRIZ DE CONFUSION PYTHON ####\n",
    "accuracy = accuracy_score(Y2, y_pred)\n",
    "recall = recall_score(Y2, y_pred)\n",
    "precision = precision_score(Y2, y_pred)\n",
    "f1score = f1_score(Y2, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy*100))\n",
    "print(\"Recall: %.2f%%\" % (recall*100))\n",
    "print(\"Precision: %.2f%%\" % (precision*100))\n",
    "print(\"F1-score: %.2f%%\" % (f1score*100))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5131de57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T16:22:30.903697Z",
     "start_time": "2022-08-11T16:22:30.623121Z"
    }
   },
   "source": [
    "chart(X_test, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "64af5d9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T16:22:31.182586Z",
     "start_time": "2022-08-11T16:22:30.906453Z"
    }
   },
   "source": [
    "chart(X_test, Y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb12489a",
   "metadata": {},
   "source": [
    "## Explore the differences between the two classes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e420cb41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T12:57:41.872253Z",
     "start_time": "2022-08-11T12:57:41.486817Z"
    }
   },
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents2 = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "512a770d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T12:57:44.420999Z",
     "start_time": "2022-08-11T12:57:41.942991Z"
    }
   },
   "source": [
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "for label in [0, 1]:\n",
    "    ax.scatter(principalComponents2[Y==label, 0], principalComponents2[Y==label, 1], s = 2, alpha=0.2, label=label)\n",
    "# ax.scatter(principalComponents2[original_labels==0, 0], principalComponents2[original_labels==0, 1], s = 2, c='k', alpha=0.5, label='Joan trees')\n",
    "ax.legend()\n",
    "path = 'Classification figures'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "plt.savefig(os.path.join(path, 'positive_vs_negative_smote.png'), dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005683a3",
   "metadata": {},
   "source": [
    "## Train a simple neural network usign 7-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ac06948",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T17:48:34.091925Z",
     "start_time": "2022-08-11T17:48:33.491774Z"
    }
   },
   "outputs": [],
   "source": [
    "## Since there exist an unbalance in the dataset we perform some \n",
    "# over_sampling techniques (SMOTE)\n",
    "from imblearn.over_sampling import ADASYN, RandomOverSampler\n",
    "\n",
    "#ros = RandomOverSampler(random_state=42, ratio=1.0)\n",
    "#X_train, Y_train = ros.fit_resample(X_train, Y_train)\n",
    "\n",
    "adasyn = ADASYN(random_state=42)\n",
    "# X_train, Y_train = adasyn.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee85d619",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T18:29:35.336333Z",
     "start_time": "2022-08-11T18:29:35.323010Z"
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ANN: 1 pixel = 1 tree\n",
    "# =============================================================================\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "num_folds = 7\n",
    "#n_features = 27\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=0) #fix the divition\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "#Set the training parameters\n",
    "num_epochs = 15000\n",
    "verbosity = 1 #0:silent, 1:to show a progress bar during the training, 2:show results after each epoch\n",
    "\n",
    "#initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1.)\n",
    "initializer = tf.keras.initializers.GlorotNormal(seed=42)\n",
    "\n",
    "# Define the model architecture\n",
    "def model():\n",
    "    classifier = Sequential()\n",
    "    # First layer\n",
    "    classifier.add(Dense(units = 128, input_dim = n_features, kernel_initializer = initializer,  activation = \"relu\"))\n",
    "    # Second layer\n",
    "    classifier.add(Dense(units = 64, kernel_initializer = initializer,  activation = \"relu\"))\n",
    "    #classifier.add(Dropout(rate = 0.2))\n",
    "    # Third layer\n",
    "    classifier.add(Dense(units = 32, kernel_initializer = initializer,  activation = \"relu\"))\n",
    "    #classifier.add(Dropout(rate = 0.2))\n",
    "    \n",
    "    classifier.add(Dense(units = 8, kernel_initializer = initializer,  activation = \"relu\"))\n",
    "\n",
    "    # Output layer\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = initializer,  activation = \"sigmoid\"))\n",
    "\n",
    "    # Compilar la RNA\n",
    "    classifier.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "    return classifier\n",
    "\n",
    "# def model():\n",
    "#     classifier = Sequential()\n",
    "#     # First layer\n",
    "#     classifier.add(Dense(units = 1, input_dim = n_bands, kernel_initializer = \"uniform\",  activation = \"sigmoid\"))\n",
    "    \n",
    "#     # Compilar la RNA\n",
    "#     classifier.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "#     return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ce324db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T21:34:05.005748Z",
     "start_time": "2022-08-11T18:29:46.066951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 19:07:59.538688: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /common/amd/aocl/2.1/amd-fftw/lib:/common/amd/aocl/2.1/libs:/opt/AMD/aocc-compiler-2.1.0/lib:/opt/AMD/aocc-compiler-2.1.0/lib32:/usr/lib/x86_64-linux-gnu:/usr/lib64:/usr/lib32:/usr/lib:/common/opt_intel/oneapi/vpl/2021.2.2/lib:/common/opt_intel/oneapi/tbb/2021.2.0/env/../lib/intel64/gcc4.8:/common/opt_intel/oneapi/mkl/latest/lib/intel64:/common/opt_intel/oneapi/itac/2021.2.0/slib:/common/opt_intel/oneapi/ipp/2021.2.0/lib/intel64:/common/opt_intel/oneapi/ippcp/2021.2.0/lib/intel64:/common/opt_intel/oneapi/ipp/2021.2.0/lib/intel64:/common/opt_intel/oneapi/dnnl/2021.2.0/cpu_dpcpp_gpu_dpcpp/lib:/common/opt_intel/oneapi/debugger/10.1.1/dep/lib:/common/opt_intel/oneapi/debugger/10.1.1/libipt/intel64/lib:/common/opt_intel/oneapi/debugger/10.1.1/gdb/intel64/lib:/common/opt_intel/oneapi/dal/2021.2.0/lib/intel64:/common/opt_intel/oneapi/compiler/2021.2.0/linux/lib:/common/opt_intel/oneapi/compiler/2021.2.0/linux/lib/x64:/common/opt_intel/oneapi/compiler/2021.2.0/linux/lib/emu:/common/opt_intel/oneapi/compiler/2021.2.0/linux/lib/oclfpga/host/linux64/lib:/common/opt_intel/oneapi/compiler/2021.2.0/linux/lib/oclfpga/linux64/lib:/common/opt_intel/oneapi/compiler/2021.2.0/linux/compiler/lib/intel64_lin:/common/opt_intel/oneapi/compiler/2021.2.0/linux/compiler/lib:/common/opt_intel/oneapi/ccl/2021.2.0/lib/cpu_gpu_dpcpp:/common/amd/aocl/2.1/amd-fftw/lib:/common/amd/aocl/2.1/libs:/opt/AMD/aocc-compiler-2.1.0/lib:/opt/AMD/aocc-compiler-2.1.0/lib32:/usr/lib/x86_64-linux-gnu:/usr/lib64:/usr/lib32:/usr/lib::/common/MATLAB/MATLAB_Runtime/v910/runtime/glnxa64:/common/MATLAB/MATLAB_Runtime/v910/bin/glnxa64:/common/MATLAB/MATLAB_Runtime/v910/sys/os/glnxa64:/common/MATLAB/MATLAB_Runtime/v910/extern/bin/glnxa64:/common/MATLAB/MATLAB_Runtime/v910/runtime/glnxa64:/common/MATLAB/MATLAB_Runtime/v910/bin/glnxa64:/common/MATLAB/MATLAB_Runtime/v910/sys/os/glnxa64:/common/MATLAB/MATLAB_Runtime/v910/extern/bin/glnxa64\n",
      "2023-03-06 19:07:59.538760: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-06 19:07:59.538827: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (salmunia): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6933 - accuracy: 0.4789 - val_loss: 0.6910 - val_accuracy: 0.6293\n",
      "Epoch 2/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6928 - accuracy: 0.5157 - val_loss: 0.6900 - val_accuracy: 0.6213\n",
      "Epoch 3/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6924 - accuracy: 0.5319 - val_loss: 0.6867 - val_accuracy: 0.6944\n",
      "Epoch 4/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6922 - accuracy: 0.5211 - val_loss: 0.6831 - val_accuracy: 0.7280\n",
      "Epoch 5/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6920 - accuracy: 0.5091 - val_loss: 0.6803 - val_accuracy: 0.7340\n",
      "Epoch 6/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6918 - accuracy: 0.5061 - val_loss: 0.6791 - val_accuracy: 0.7256\n",
      "Epoch 7/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6915 - accuracy: 0.5097 - val_loss: 0.6790 - val_accuracy: 0.7119\n",
      "Epoch 8/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6913 - accuracy: 0.5164 - val_loss: 0.6797 - val_accuracy: 0.6810\n",
      "Epoch 9/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6910 - accuracy: 0.5256 - val_loss: 0.6803 - val_accuracy: 0.6474\n",
      "Epoch 10/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6908 - accuracy: 0.5340 - val_loss: 0.6803 - val_accuracy: 0.6240\n",
      "Epoch 11/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6905 - accuracy: 0.5366 - val_loss: 0.6796 - val_accuracy: 0.6195\n",
      "Epoch 12/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6903 - accuracy: 0.5384 - val_loss: 0.6782 - val_accuracy: 0.6255\n",
      "Epoch 13/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6900 - accuracy: 0.5393 - val_loss: 0.6769 - val_accuracy: 0.6281\n",
      "Epoch 14/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6898 - accuracy: 0.5385 - val_loss: 0.6761 - val_accuracy: 0.6222\n",
      "Epoch 15/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6895 - accuracy: 0.5385 - val_loss: 0.6759 - val_accuracy: 0.6085\n",
      "Epoch 16/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6893 - accuracy: 0.5421 - val_loss: 0.6760 - val_accuracy: 0.5955\n",
      "Epoch 17/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6890 - accuracy: 0.5443 - val_loss: 0.6759 - val_accuracy: 0.5820\n",
      "Epoch 18/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6887 - accuracy: 0.5446 - val_loss: 0.6752 - val_accuracy: 0.5791\n",
      "Epoch 19/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6885 - accuracy: 0.5447 - val_loss: 0.6742 - val_accuracy: 0.5798\n",
      "Epoch 20/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6882 - accuracy: 0.5435 - val_loss: 0.6733 - val_accuracy: 0.5780\n",
      "Epoch 21/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6879 - accuracy: 0.5433 - val_loss: 0.6733 - val_accuracy: 0.5670\n",
      "Epoch 22/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6876 - accuracy: 0.5445 - val_loss: 0.6739 - val_accuracy: 0.5528\n",
      "Epoch 23/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6873 - accuracy: 0.5466 - val_loss: 0.6736 - val_accuracy: 0.5477\n",
      "Epoch 24/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6871 - accuracy: 0.5469 - val_loss: 0.6725 - val_accuracy: 0.5493\n",
      "Epoch 25/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6868 - accuracy: 0.5469 - val_loss: 0.6719 - val_accuracy: 0.5462\n",
      "Epoch 26/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6865 - accuracy: 0.5474 - val_loss: 0.6720 - val_accuracy: 0.5406\n",
      "Epoch 27/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6862 - accuracy: 0.5489 - val_loss: 0.6725 - val_accuracy: 0.5300\n",
      "Epoch 28/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6859 - accuracy: 0.5493 - val_loss: 0.6722 - val_accuracy: 0.5269\n",
      "Epoch 29/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6857 - accuracy: 0.5494 - val_loss: 0.6713 - val_accuracy: 0.5303\n",
      "Epoch 30/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6854 - accuracy: 0.5496 - val_loss: 0.6714 - val_accuracy: 0.5263\n",
      "Epoch 31/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6851 - accuracy: 0.5503 - val_loss: 0.6725 - val_accuracy: 0.5183\n",
      "Epoch 32/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6848 - accuracy: 0.5532 - val_loss: 0.6728 - val_accuracy: 0.5174\n",
      "Epoch 33/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6845 - accuracy: 0.5546 - val_loss: 0.6722 - val_accuracy: 0.5183\n",
      "Epoch 34/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6842 - accuracy: 0.5549 - val_loss: 0.6728 - val_accuracy: 0.5139\n",
      "Epoch 35/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6839 - accuracy: 0.5546 - val_loss: 0.6735 - val_accuracy: 0.5097\n",
      "Epoch 36/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6836 - accuracy: 0.5551 - val_loss: 0.6726 - val_accuracy: 0.5119\n",
      "Epoch 37/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6833 - accuracy: 0.5553 - val_loss: 0.6731 - val_accuracy: 0.5066\n",
      "Epoch 38/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6831 - accuracy: 0.5554 - val_loss: 0.6746 - val_accuracy: 0.4998\n",
      "Epoch 39/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6828 - accuracy: 0.5555 - val_loss: 0.6734 - val_accuracy: 0.5035\n",
      "Epoch 40/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6825 - accuracy: 0.5564 - val_loss: 0.6745 - val_accuracy: 0.4980\n",
      "Epoch 41/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6823 - accuracy: 0.5557 - val_loss: 0.6754 - val_accuracy: 0.4962\n",
      "Epoch 42/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6821 - accuracy: 0.5556 - val_loss: 0.6743 - val_accuracy: 0.5004\n",
      "Epoch 43/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6819 - accuracy: 0.5557 - val_loss: 0.6781 - val_accuracy: 0.4868\n",
      "Epoch 44/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6817 - accuracy: 0.5563 - val_loss: 0.6740 - val_accuracy: 0.5037\n",
      "Epoch 45/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6815 - accuracy: 0.5561 - val_loss: 0.6815 - val_accuracy: 0.4720\n",
      "Epoch 46/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6814 - accuracy: 0.5551 - val_loss: 0.6754 - val_accuracy: 0.4998\n",
      "Epoch 47/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6812 - accuracy: 0.5569 - val_loss: 0.6795 - val_accuracy: 0.4848\n",
      "Epoch 48/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6811 - accuracy: 0.5561 - val_loss: 0.6814 - val_accuracy: 0.4797\n",
      "Epoch 49/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6810 - accuracy: 0.5562 - val_loss: 0.6776 - val_accuracy: 0.4947\n",
      "Epoch 50/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6809 - accuracy: 0.5567 - val_loss: 0.6849 - val_accuracy: 0.4697\n",
      "Epoch 51/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6808 - accuracy: 0.5552 - val_loss: 0.6790 - val_accuracy: 0.4903\n",
      "Epoch 52/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6807 - accuracy: 0.5572 - val_loss: 0.6829 - val_accuracy: 0.4795\n",
      "Epoch 53/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6805 - accuracy: 0.5559 - val_loss: 0.6835 - val_accuracy: 0.4784\n",
      "Epoch 54/15000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6805 - accuracy: 0.5563 - val_loss: 0.6801 - val_accuracy: 0.4896\n",
      "Epoch 55/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6804 - accuracy: 0.5576 - val_loss: 0.6863 - val_accuracy: 0.4713\n",
      "Epoch 56/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6803 - accuracy: 0.5559 - val_loss: 0.6800 - val_accuracy: 0.4914\n",
      "Epoch 57/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6802 - accuracy: 0.5582 - val_loss: 0.6848 - val_accuracy: 0.4763\n",
      "Epoch 58/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6801 - accuracy: 0.5571 - val_loss: 0.6828 - val_accuracy: 0.4828\n",
      "Epoch 59/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6800 - accuracy: 0.5582 - val_loss: 0.6803 - val_accuracy: 0.4914\n",
      "Epoch 60/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6800 - accuracy: 0.5586 - val_loss: 0.6862 - val_accuracy: 0.4719\n",
      "Epoch 61/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6799 - accuracy: 0.5577 - val_loss: 0.6767 - val_accuracy: 0.4996\n",
      "Epoch 62/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6798 - accuracy: 0.5590 - val_loss: 0.6863 - val_accuracy: 0.4720\n",
      "Epoch 63/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6797 - accuracy: 0.5575 - val_loss: 0.6790 - val_accuracy: 0.4945\n",
      "Epoch 64/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6796 - accuracy: 0.5588 - val_loss: 0.6799 - val_accuracy: 0.4912\n",
      "Epoch 65/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6794 - accuracy: 0.5584 - val_loss: 0.6840 - val_accuracy: 0.4799\n",
      "Epoch 66/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6794 - accuracy: 0.5581 - val_loss: 0.6758 - val_accuracy: 0.5024\n",
      "Epoch 67/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6793 - accuracy: 0.5598 - val_loss: 0.6828 - val_accuracy: 0.4839\n",
      "Epoch 68/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6792 - accuracy: 0.5583 - val_loss: 0.6786 - val_accuracy: 0.4932\n",
      "Epoch 69/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6790 - accuracy: 0.5596 - val_loss: 0.6765 - val_accuracy: 0.5013\n",
      "Epoch 70/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6789 - accuracy: 0.5610 - val_loss: 0.6822 - val_accuracy: 0.4865\n",
      "Epoch 71/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6788 - accuracy: 0.5598 - val_loss: 0.6733 - val_accuracy: 0.5122\n",
      "Epoch 72/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6787 - accuracy: 0.5623 - val_loss: 0.6806 - val_accuracy: 0.4898\n",
      "Epoch 73/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6785 - accuracy: 0.5608 - val_loss: 0.6746 - val_accuracy: 0.5095\n",
      "Epoch 74/15000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6784 - accuracy: 0.5637 - val_loss: 0.6753 - val_accuracy: 0.5084\n",
      "Epoch 75/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6782 - accuracy: 0.5639 - val_loss: 0.6776 - val_accuracy: 0.5004\n",
      "Epoch 76/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6781 - accuracy: 0.5643 - val_loss: 0.6710 - val_accuracy: 0.5230\n",
      "Epoch 77/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6779 - accuracy: 0.5631 - val_loss: 0.6822 - val_accuracy: 0.4900\n",
      "Epoch 78/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6779 - accuracy: 0.5634 - val_loss: 0.6644 - val_accuracy: 0.5459\n",
      "Epoch 79/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6778 - accuracy: 0.5653 - val_loss: 0.6883 - val_accuracy: 0.4717\n",
      "Epoch 80/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6779 - accuracy: 0.5619 - val_loss: 0.6682 - val_accuracy: 0.5343\n",
      "Epoch 81/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6774 - accuracy: 0.5667 - val_loss: 0.6694 - val_accuracy: 0.5323\n",
      "Epoch 82/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6772 - accuracy: 0.5669 - val_loss: 0.6853 - val_accuracy: 0.4836\n",
      "Epoch 83/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6773 - accuracy: 0.5638 - val_loss: 0.6664 - val_accuracy: 0.5433\n",
      "Epoch 84/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6770 - accuracy: 0.5674 - val_loss: 0.6719 - val_accuracy: 0.5290\n",
      "Epoch 85/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6767 - accuracy: 0.5681 - val_loss: 0.6826 - val_accuracy: 0.4967\n",
      "Epoch 86/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6767 - accuracy: 0.5652 - val_loss: 0.6653 - val_accuracy: 0.5486\n",
      "Epoch 87/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6766 - accuracy: 0.5674 - val_loss: 0.6764 - val_accuracy: 0.5197\n",
      "Epoch 88/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6763 - accuracy: 0.5666 - val_loss: 0.6772 - val_accuracy: 0.5181\n",
      "Epoch 89/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6762 - accuracy: 0.5669 - val_loss: 0.6659 - val_accuracy: 0.5486\n",
      "Epoch 90/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6762 - accuracy: 0.5680 - val_loss: 0.6804 - val_accuracy: 0.5079\n",
      "Epoch 91/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6760 - accuracy: 0.5669 - val_loss: 0.6710 - val_accuracy: 0.5389\n",
      "Epoch 92/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6758 - accuracy: 0.5675 - val_loss: 0.6698 - val_accuracy: 0.5420\n",
      "Epoch 93/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6757 - accuracy: 0.5684 - val_loss: 0.6802 - val_accuracy: 0.5093\n",
      "Epoch 94/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6756 - accuracy: 0.5674 - val_loss: 0.6656 - val_accuracy: 0.5564\n",
      "Epoch 95/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6755 - accuracy: 0.5698 - val_loss: 0.6793 - val_accuracy: 0.5121\n",
      "Epoch 96/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6753 - accuracy: 0.5681 - val_loss: 0.6701 - val_accuracy: 0.5449\n",
      "Epoch 97/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6751 - accuracy: 0.5700 - val_loss: 0.6720 - val_accuracy: 0.5398\n",
      "Epoch 98/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6750 - accuracy: 0.5699 - val_loss: 0.6774 - val_accuracy: 0.5230\n",
      "Epoch 99/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6749 - accuracy: 0.5691 - val_loss: 0.6658 - val_accuracy: 0.5590\n",
      "Epoch 100/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6749 - accuracy: 0.5707 - val_loss: 0.6836 - val_accuracy: 0.5047\n",
      "Epoch 101/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6749 - accuracy: 0.5692 - val_loss: 0.6620 - val_accuracy: 0.5676\n",
      "Epoch 102/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6748 - accuracy: 0.5707 - val_loss: 0.6838 - val_accuracy: 0.5046\n",
      "Epoch 103/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6747 - accuracy: 0.5698 - val_loss: 0.6674 - val_accuracy: 0.5568\n",
      "Epoch 104/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6744 - accuracy: 0.5717 - val_loss: 0.6730 - val_accuracy: 0.5418\n",
      "Epoch 105/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6742 - accuracy: 0.5714 - val_loss: 0.6785 - val_accuracy: 0.5252\n",
      "Epoch 106/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6741 - accuracy: 0.5709 - val_loss: 0.6642 - val_accuracy: 0.5672\n",
      "Epoch 107/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6742 - accuracy: 0.5716 - val_loss: 0.6852 - val_accuracy: 0.5042\n",
      "Epoch 108/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6742 - accuracy: 0.5707 - val_loss: 0.6635 - val_accuracy: 0.5685\n",
      "Epoch 109/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6740 - accuracy: 0.5722 - val_loss: 0.6799 - val_accuracy: 0.5237\n",
      "Epoch 110/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6738 - accuracy: 0.5723 - val_loss: 0.6734 - val_accuracy: 0.5435\n",
      "Epoch 111/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6736 - accuracy: 0.5731 - val_loss: 0.6683 - val_accuracy: 0.5575\n",
      "Epoch 112/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6736 - accuracy: 0.5733 - val_loss: 0.6835 - val_accuracy: 0.5163\n",
      "Epoch 113/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6736 - accuracy: 0.5722 - val_loss: 0.6631 - val_accuracy: 0.5692\n",
      "Epoch 114/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6736 - accuracy: 0.5741 - val_loss: 0.6839 - val_accuracy: 0.5144\n",
      "Epoch 115/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6735 - accuracy: 0.5726 - val_loss: 0.6684 - val_accuracy: 0.5574\n",
      "Epoch 116/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6732 - accuracy: 0.5737 - val_loss: 0.6738 - val_accuracy: 0.5446\n",
      "Epoch 117/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6731 - accuracy: 0.5734 - val_loss: 0.6791 - val_accuracy: 0.5305\n",
      "Epoch 118/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6730 - accuracy: 0.5744 - val_loss: 0.6654 - val_accuracy: 0.5634\n",
      "Epoch 119/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6731 - accuracy: 0.5750 - val_loss: 0.6845 - val_accuracy: 0.5157\n",
      "Epoch 120/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6731 - accuracy: 0.5730 - val_loss: 0.6644 - val_accuracy: 0.5663\n",
      "Epoch 121/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6730 - accuracy: 0.5753 - val_loss: 0.6804 - val_accuracy: 0.5263\n",
      "Epoch 122/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6728 - accuracy: 0.5747 - val_loss: 0.6724 - val_accuracy: 0.5493\n",
      "Epoch 123/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6726 - accuracy: 0.5751 - val_loss: 0.6706 - val_accuracy: 0.5539\n",
      "Epoch 124/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6725 - accuracy: 0.5752 - val_loss: 0.6812 - val_accuracy: 0.5254\n",
      "Epoch 125/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6726 - accuracy: 0.5745 - val_loss: 0.6645 - val_accuracy: 0.5658\n",
      "Epoch 126/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6726 - accuracy: 0.5759 - val_loss: 0.6847 - val_accuracy: 0.5183\n",
      "Epoch 127/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6726 - accuracy: 0.5741 - val_loss: 0.6652 - val_accuracy: 0.5650\n",
      "Epoch 128/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6724 - accuracy: 0.5762 - val_loss: 0.6799 - val_accuracy: 0.5292\n",
      "Epoch 129/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6722 - accuracy: 0.5757 - val_loss: 0.6718 - val_accuracy: 0.5504\n",
      "Epoch 130/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6721 - accuracy: 0.5768 - val_loss: 0.6720 - val_accuracy: 0.5502\n",
      "Epoch 131/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6720 - accuracy: 0.5771 - val_loss: 0.6792 - val_accuracy: 0.5325\n",
      "Epoch 132/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6720 - accuracy: 0.5754 - val_loss: 0.6663 - val_accuracy: 0.5627\n",
      "Epoch 133/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6720 - accuracy: 0.5764 - val_loss: 0.6840 - val_accuracy: 0.5216\n",
      "Epoch 134/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6720 - accuracy: 0.5755 - val_loss: 0.6634 - val_accuracy: 0.5694\n",
      "Epoch 135/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6720 - accuracy: 0.5765 - val_loss: 0.6855 - val_accuracy: 0.5174\n",
      "Epoch 136/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6719 - accuracy: 0.5751 - val_loss: 0.6647 - val_accuracy: 0.5658\n",
      "Epoch 137/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6717 - accuracy: 0.5769 - val_loss: 0.6794 - val_accuracy: 0.5331\n",
      "Epoch 138/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6715 - accuracy: 0.5769 - val_loss: 0.6727 - val_accuracy: 0.5473\n",
      "Epoch 139/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6714 - accuracy: 0.5783 - val_loss: 0.6705 - val_accuracy: 0.5530\n",
      "Epoch 140/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6713 - accuracy: 0.5782 - val_loss: 0.6806 - val_accuracy: 0.5309\n",
      "Epoch 141/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6714 - accuracy: 0.5771 - val_loss: 0.6644 - val_accuracy: 0.5658\n",
      "Epoch 142/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6714 - accuracy: 0.5774 - val_loss: 0.6861 - val_accuracy: 0.5185\n",
      "Epoch 143/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6715 - accuracy: 0.5769 - val_loss: 0.6623 - val_accuracy: 0.5692\n",
      "Epoch 144/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6713 - accuracy: 0.5776 - val_loss: 0.6840 - val_accuracy: 0.5225\n",
      "Epoch 145/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6712 - accuracy: 0.5775 - val_loss: 0.6678 - val_accuracy: 0.5579\n",
      "Epoch 146/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6710 - accuracy: 0.5776 - val_loss: 0.6739 - val_accuracy: 0.5427\n",
      "Epoch 147/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6708 - accuracy: 0.5785 - val_loss: 0.6775 - val_accuracy: 0.5356\n",
      "Epoch 148/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6708 - accuracy: 0.5786 - val_loss: 0.6660 - val_accuracy: 0.5614\n",
      "Epoch 149/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6708 - accuracy: 0.5783 - val_loss: 0.6842 - val_accuracy: 0.5225\n",
      "Epoch 150/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6709 - accuracy: 0.5780 - val_loss: 0.6630 - val_accuracy: 0.5672\n",
      "Epoch 151/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6708 - accuracy: 0.5778 - val_loss: 0.6842 - val_accuracy: 0.5232\n",
      "Epoch 152/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6707 - accuracy: 0.5782 - val_loss: 0.6660 - val_accuracy: 0.5596\n",
      "Epoch 153/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6705 - accuracy: 0.5789 - val_loss: 0.6772 - val_accuracy: 0.5360\n",
      "Epoch 154/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6703 - accuracy: 0.5791 - val_loss: 0.6737 - val_accuracy: 0.5459\n",
      "Epoch 155/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6702 - accuracy: 0.5789 - val_loss: 0.6696 - val_accuracy: 0.5533\n",
      "Epoch 156/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6702 - accuracy: 0.5798 - val_loss: 0.6809 - val_accuracy: 0.5292\n",
      "Epoch 157/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6702 - accuracy: 0.5790 - val_loss: 0.6638 - val_accuracy: 0.5645\n",
      "Epoch 158/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6703 - accuracy: 0.5784 - val_loss: 0.6869 - val_accuracy: 0.5168\n",
      "Epoch 159/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6704 - accuracy: 0.5797 - val_loss: 0.6602 - val_accuracy: 0.5734\n",
      "Epoch 160/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6703 - accuracy: 0.5776 - val_loss: 0.6880 - val_accuracy: 0.5146\n",
      "Epoch 161/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6703 - accuracy: 0.5801 - val_loss: 0.6634 - val_accuracy: 0.5661\n",
      "Epoch 162/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6700 - accuracy: 0.5787 - val_loss: 0.6778 - val_accuracy: 0.5371\n",
      "Epoch 163/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6697 - accuracy: 0.5799 - val_loss: 0.6739 - val_accuracy: 0.5449\n",
      "Epoch 164/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6696 - accuracy: 0.5801 - val_loss: 0.6675 - val_accuracy: 0.5603\n",
      "Epoch 165/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6696 - accuracy: 0.5794 - val_loss: 0.6830 - val_accuracy: 0.5247\n",
      "Epoch 166/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6697 - accuracy: 0.5798 - val_loss: 0.6625 - val_accuracy: 0.5669\n",
      "Epoch 167/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6697 - accuracy: 0.5792 - val_loss: 0.6848 - val_accuracy: 0.5205\n",
      "Epoch 168/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6696 - accuracy: 0.5801 - val_loss: 0.6647 - val_accuracy: 0.5643\n",
      "Epoch 169/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6694 - accuracy: 0.5796 - val_loss: 0.6786 - val_accuracy: 0.5345\n",
      "Epoch 170/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6692 - accuracy: 0.5798 - val_loss: 0.6713 - val_accuracy: 0.5497\n",
      "Epoch 171/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6691 - accuracy: 0.5808 - val_loss: 0.6715 - val_accuracy: 0.5484\n",
      "Epoch 172/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6690 - accuracy: 0.5806 - val_loss: 0.6780 - val_accuracy: 0.5358\n",
      "Epoch 173/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6690 - accuracy: 0.5807 - val_loss: 0.6654 - val_accuracy: 0.5625\n",
      "Epoch 174/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6690 - accuracy: 0.5803 - val_loss: 0.6852 - val_accuracy: 0.5192\n",
      "Epoch 175/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6691 - accuracy: 0.5812 - val_loss: 0.6601 - val_accuracy: 0.5734\n",
      "Epoch 176/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6692 - accuracy: 0.5790 - val_loss: 0.6893 - val_accuracy: 0.5086\n",
      "Epoch 177/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6693 - accuracy: 0.5800 - val_loss: 0.6615 - val_accuracy: 0.5700\n",
      "Epoch 178/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6689 - accuracy: 0.5799 - val_loss: 0.6807 - val_accuracy: 0.5292\n",
      "Epoch 179/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6687 - accuracy: 0.5811 - val_loss: 0.6711 - val_accuracy: 0.5486\n",
      "Epoch 180/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6685 - accuracy: 0.5813 - val_loss: 0.6697 - val_accuracy: 0.5526\n",
      "Epoch 181/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6684 - accuracy: 0.5812 - val_loss: 0.6809 - val_accuracy: 0.5289\n",
      "Epoch 182/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6685 - accuracy: 0.5817 - val_loss: 0.6631 - val_accuracy: 0.5665\n",
      "Epoch 183/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6685 - accuracy: 0.5804 - val_loss: 0.6854 - val_accuracy: 0.5186\n",
      "Epoch 184/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6685 - accuracy: 0.5819 - val_loss: 0.6629 - val_accuracy: 0.5669\n",
      "Epoch 185/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6684 - accuracy: 0.5801 - val_loss: 0.6811 - val_accuracy: 0.5287\n",
      "Epoch 186/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6682 - accuracy: 0.5826 - val_loss: 0.6690 - val_accuracy: 0.5532\n",
      "Epoch 187/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6680 - accuracy: 0.5820 - val_loss: 0.6730 - val_accuracy: 0.5451\n",
      "Epoch 188/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6679 - accuracy: 0.5823 - val_loss: 0.6768 - val_accuracy: 0.5382\n",
      "Epoch 189/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6679 - accuracy: 0.5827 - val_loss: 0.6661 - val_accuracy: 0.5596\n",
      "Epoch 190/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6679 - accuracy: 0.5815 - val_loss: 0.6836 - val_accuracy: 0.5217\n",
      "Epoch 191/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6680 - accuracy: 0.5823 - val_loss: 0.6614 - val_accuracy: 0.5705\n",
      "Epoch 192/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6680 - accuracy: 0.5799 - val_loss: 0.6883 - val_accuracy: 0.5079\n",
      "Epoch 193/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6681 - accuracy: 0.5833 - val_loss: 0.6603 - val_accuracy: 0.5729\n",
      "Epoch 194/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6680 - accuracy: 0.5799 - val_loss: 0.6851 - val_accuracy: 0.5179\n",
      "Epoch 195/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6678 - accuracy: 0.5830 - val_loss: 0.6660 - val_accuracy: 0.5585\n",
      "Epoch 196/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6675 - accuracy: 0.5820 - val_loss: 0.6750 - val_accuracy: 0.5404\n",
      "Epoch 197/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6674 - accuracy: 0.5831 - val_loss: 0.6751 - val_accuracy: 0.5400\n",
      "Epoch 198/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6673 - accuracy: 0.5832 - val_loss: 0.6666 - val_accuracy: 0.5575\n",
      "Epoch 199/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6673 - accuracy: 0.5825 - val_loss: 0.6837 - val_accuracy: 0.5197\n",
      "Epoch 200/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6674 - accuracy: 0.5830 - val_loss: 0.6608 - val_accuracy: 0.5712\n",
      "Epoch 201/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6675 - accuracy: 0.5810 - val_loss: 0.6886 - val_accuracy: 0.5088\n",
      "Epoch 202/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6676 - accuracy: 0.5840 - val_loss: 0.6612 - val_accuracy: 0.5694\n",
      "Epoch 203/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6673 - accuracy: 0.5813 - val_loss: 0.6824 - val_accuracy: 0.5236\n",
      "Epoch 204/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6671 - accuracy: 0.5834 - val_loss: 0.6687 - val_accuracy: 0.5535\n",
      "Epoch 205/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6669 - accuracy: 0.5840 - val_loss: 0.6722 - val_accuracy: 0.5453\n",
      "Epoch 206/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6668 - accuracy: 0.5838 - val_loss: 0.6778 - val_accuracy: 0.5325\n",
      "Epoch 207/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6668 - accuracy: 0.5843 - val_loss: 0.6646 - val_accuracy: 0.5617\n",
      "Epoch 208/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6668 - accuracy: 0.5824 - val_loss: 0.6865 - val_accuracy: 0.5137\n",
      "Epoch 209/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6670 - accuracy: 0.5847 - val_loss: 0.6588 - val_accuracy: 0.5711\n",
      "Epoch 210/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6670 - accuracy: 0.5816 - val_loss: 0.6914 - val_accuracy: 0.5004\n",
      "Epoch 211/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6672 - accuracy: 0.5856 - val_loss: 0.6599 - val_accuracy: 0.5692\n",
      "Epoch 212/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6668 - accuracy: 0.5824 - val_loss: 0.6824 - val_accuracy: 0.5230\n",
      "Epoch 213/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6665 - accuracy: 0.5850 - val_loss: 0.6702 - val_accuracy: 0.5484\n",
      "Epoch 214/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6663 - accuracy: 0.5851 - val_loss: 0.6692 - val_accuracy: 0.5504\n",
      "Epoch 215/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6662 - accuracy: 0.5850 - val_loss: 0.6826 - val_accuracy: 0.5217\n",
      "Epoch 216/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6663 - accuracy: 0.5854 - val_loss: 0.6605 - val_accuracy: 0.5663\n",
      "Epoch 217/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6664 - accuracy: 0.5832 - val_loss: 0.6889 - val_accuracy: 0.5064\n",
      "Epoch 218/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6666 - accuracy: 0.5868 - val_loss: 0.6609 - val_accuracy: 0.5661\n",
      "Epoch 219/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6663 - accuracy: 0.5832 - val_loss: 0.6815 - val_accuracy: 0.5245\n",
      "Epoch 220/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6660 - accuracy: 0.5858 - val_loss: 0.6707 - val_accuracy: 0.5486\n",
      "Epoch 221/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6658 - accuracy: 0.5852 - val_loss: 0.6699 - val_accuracy: 0.5497\n",
      "Epoch 222/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6658 - accuracy: 0.5855 - val_loss: 0.6812 - val_accuracy: 0.5241\n",
      "Epoch 223/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6658 - accuracy: 0.5864 - val_loss: 0.6625 - val_accuracy: 0.5612\n",
      "Epoch 224/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6659 - accuracy: 0.5834 - val_loss: 0.6856 - val_accuracy: 0.5133\n",
      "Epoch 225/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6659 - accuracy: 0.5873 - val_loss: 0.6624 - val_accuracy: 0.5612\n",
      "Epoch 226/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6658 - accuracy: 0.5836 - val_loss: 0.6810 - val_accuracy: 0.5237\n",
      "Epoch 227/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6656 - accuracy: 0.5869 - val_loss: 0.6690 - val_accuracy: 0.5499\n",
      "Epoch 228/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6654 - accuracy: 0.5858 - val_loss: 0.6729 - val_accuracy: 0.5417\n",
      "Epoch 229/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6653 - accuracy: 0.5861 - val_loss: 0.6766 - val_accuracy: 0.5334\n",
      "Epoch 230/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6652 - accuracy: 0.5873 - val_loss: 0.6660 - val_accuracy: 0.5568\n",
      "Epoch 231/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6653 - accuracy: 0.5846 - val_loss: 0.6830 - val_accuracy: 0.5188\n",
      "Epoch 232/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6653 - accuracy: 0.5876 - val_loss: 0.6614 - val_accuracy: 0.5627\n",
      "Epoch 233/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6654 - accuracy: 0.5842 - val_loss: 0.6866 - val_accuracy: 0.5100\n",
      "Epoch 234/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6654 - accuracy: 0.5878 - val_loss: 0.6599 - val_accuracy: 0.5652\n",
      "Epoch 235/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6653 - accuracy: 0.5851 - val_loss: 0.6859 - val_accuracy: 0.5121\n",
      "Epoch 236/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6652 - accuracy: 0.5884 - val_loss: 0.6635 - val_accuracy: 0.5594\n",
      "Epoch 237/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6650 - accuracy: 0.5850 - val_loss: 0.6788 - val_accuracy: 0.5280\n",
      "Epoch 238/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6648 - accuracy: 0.5886 - val_loss: 0.6708 - val_accuracy: 0.5451\n",
      "Epoch 239/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6646 - accuracy: 0.5872 - val_loss: 0.6705 - val_accuracy: 0.5460\n",
      "Epoch 240/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6646 - accuracy: 0.5869 - val_loss: 0.6778 - val_accuracy: 0.5309\n",
      "Epoch 241/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6646 - accuracy: 0.5886 - val_loss: 0.6651 - val_accuracy: 0.5561\n",
      "Epoch 242/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6646 - accuracy: 0.5859 - val_loss: 0.6829 - val_accuracy: 0.5205\n",
      "Epoch 243/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6646 - accuracy: 0.5893 - val_loss: 0.6607 - val_accuracy: 0.5619\n",
      "Epoch 244/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6647 - accuracy: 0.5848 - val_loss: 0.6876 - val_accuracy: 0.5095\n",
      "Epoch 245/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6648 - accuracy: 0.5892 - val_loss: 0.6585 - val_accuracy: 0.5650\n",
      "Epoch 246/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6647 - accuracy: 0.5845 - val_loss: 0.6873 - val_accuracy: 0.5104\n",
      "Epoch 247/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6647 - accuracy: 0.5894 - val_loss: 0.6616 - val_accuracy: 0.5612\n",
      "Epoch 248/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6644 - accuracy: 0.5858 - val_loss: 0.6795 - val_accuracy: 0.5265\n",
      "Epoch 249/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6641 - accuracy: 0.5898 - val_loss: 0.6697 - val_accuracy: 0.5462\n",
      "Epoch 250/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6639 - accuracy: 0.5875 - val_loss: 0.6710 - val_accuracy: 0.5418\n",
      "Epoch 251/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6639 - accuracy: 0.5886 - val_loss: 0.6770 - val_accuracy: 0.5305\n",
      "Epoch 252/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6639 - accuracy: 0.5901 - val_loss: 0.6644 - val_accuracy: 0.5564\n",
      "Epoch 253/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6639 - accuracy: 0.5869 - val_loss: 0.6831 - val_accuracy: 0.5186\n",
      "Epoch 254/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6640 - accuracy: 0.5908 - val_loss: 0.6600 - val_accuracy: 0.5630\n",
      "Epoch 255/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6640 - accuracy: 0.5852 - val_loss: 0.6871 - val_accuracy: 0.5084\n",
      "Epoch 256/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6641 - accuracy: 0.5900 - val_loss: 0.6588 - val_accuracy: 0.5639\n",
      "Epoch 257/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6640 - accuracy: 0.5852 - val_loss: 0.6858 - val_accuracy: 0.5110\n",
      "Epoch 258/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6639 - accuracy: 0.5904 - val_loss: 0.6619 - val_accuracy: 0.5596\n",
      "Epoch 259/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6636 - accuracy: 0.5866 - val_loss: 0.6785 - val_accuracy: 0.5261\n",
      "Epoch 260/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6634 - accuracy: 0.5908 - val_loss: 0.6697 - val_accuracy: 0.5464\n",
      "Epoch 261/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6633 - accuracy: 0.5896 - val_loss: 0.6697 - val_accuracy: 0.5469\n",
      "Epoch 262/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6632 - accuracy: 0.5895 - val_loss: 0.6780 - val_accuracy: 0.5272\n",
      "Epoch 263/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6632 - accuracy: 0.5909 - val_loss: 0.6626 - val_accuracy: 0.5592\n",
      "Epoch 264/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6633 - accuracy: 0.5875 - val_loss: 0.6852 - val_accuracy: 0.5115\n",
      "Epoch 265/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6635 - accuracy: 0.5912 - val_loss: 0.6582 - val_accuracy: 0.5667\n",
      "Epoch 266/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6635 - accuracy: 0.5870 - val_loss: 0.6877 - val_accuracy: 0.5058\n",
      "Epoch 267/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6635 - accuracy: 0.5901 - val_loss: 0.6600 - val_accuracy: 0.5627\n",
      "Epoch 268/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6632 - accuracy: 0.5879 - val_loss: 0.6800 - val_accuracy: 0.5234\n",
      "Epoch 269/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6629 - accuracy: 0.5920 - val_loss: 0.6683 - val_accuracy: 0.5468\n",
      "Epoch 270/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6627 - accuracy: 0.5901 - val_loss: 0.6697 - val_accuracy: 0.5417\n",
      "Epoch 271/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6627 - accuracy: 0.5903 - val_loss: 0.6773 - val_accuracy: 0.5263\n",
      "Epoch 272/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6627 - accuracy: 0.5928 - val_loss: 0.6627 - val_accuracy: 0.5575\n",
      "Epoch 273/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6627 - accuracy: 0.5888 - val_loss: 0.6847 - val_accuracy: 0.5095\n",
      "Epoch 274/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6629 - accuracy: 0.5914 - val_loss: 0.6578 - val_accuracy: 0.5661\n",
      "Epoch 275/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6629 - accuracy: 0.5879 - val_loss: 0.6884 - val_accuracy: 0.5058\n",
      "Epoch 276/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6630 - accuracy: 0.5913 - val_loss: 0.6590 - val_accuracy: 0.5621\n",
      "Epoch 277/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6627 - accuracy: 0.5890 - val_loss: 0.6814 - val_accuracy: 0.5157\n",
      "Epoch 278/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6625 - accuracy: 0.5922 - val_loss: 0.6662 - val_accuracy: 0.5488\n",
      "Epoch 279/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6622 - accuracy: 0.5906 - val_loss: 0.6711 - val_accuracy: 0.5353\n",
      "Epoch 280/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6621 - accuracy: 0.5917 - val_loss: 0.6747 - val_accuracy: 0.5287\n",
      "Epoch 281/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6620 - accuracy: 0.5938 - val_loss: 0.6641 - val_accuracy: 0.5541\n",
      "Epoch 282/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6621 - accuracy: 0.5905 - val_loss: 0.6809 - val_accuracy: 0.5157\n",
      "Epoch 283/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6622 - accuracy: 0.5923 - val_loss: 0.6602 - val_accuracy: 0.5597\n",
      "Epoch 284/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6621 - accuracy: 0.5903 - val_loss: 0.6840 - val_accuracy: 0.5091\n",
      "Epoch 285/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6622 - accuracy: 0.5918 - val_loss: 0.6600 - val_accuracy: 0.5588\n",
      "Epoch 286/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6620 - accuracy: 0.5906 - val_loss: 0.6806 - val_accuracy: 0.5157\n",
      "Epoch 287/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6619 - accuracy: 0.5923 - val_loss: 0.6642 - val_accuracy: 0.5502\n",
      "Epoch 288/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6617 - accuracy: 0.5908 - val_loss: 0.6727 - val_accuracy: 0.5323\n",
      "Epoch 289/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6615 - accuracy: 0.5929 - val_loss: 0.6710 - val_accuracy: 0.5343\n",
      "Epoch 290/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6615 - accuracy: 0.5931 - val_loss: 0.6663 - val_accuracy: 0.5446\n",
      "Epoch 291/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6615 - accuracy: 0.5922 - val_loss: 0.6770 - val_accuracy: 0.5232\n",
      "Epoch 292/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6615 - accuracy: 0.5935 - val_loss: 0.6619 - val_accuracy: 0.5544\n",
      "Epoch 293/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6615 - accuracy: 0.5913 - val_loss: 0.6812 - val_accuracy: 0.5146\n",
      "Epoch 294/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6616 - accuracy: 0.5928 - val_loss: 0.6595 - val_accuracy: 0.5581\n",
      "Epoch 295/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6615 - accuracy: 0.5913 - val_loss: 0.6822 - val_accuracy: 0.5117\n",
      "Epoch 296/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6615 - accuracy: 0.5926 - val_loss: 0.6605 - val_accuracy: 0.5554\n",
      "Epoch 297/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6613 - accuracy: 0.5914 - val_loss: 0.6789 - val_accuracy: 0.5190\n",
      "Epoch 298/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6612 - accuracy: 0.5930 - val_loss: 0.6638 - val_accuracy: 0.5482\n",
      "Epoch 299/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6610 - accuracy: 0.5924 - val_loss: 0.6744 - val_accuracy: 0.5281\n",
      "Epoch 300/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6609 - accuracy: 0.5934 - val_loss: 0.6669 - val_accuracy: 0.5407\n",
      "Epoch 301/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6608 - accuracy: 0.5939 - val_loss: 0.6712 - val_accuracy: 0.5340\n",
      "Epoch 302/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6607 - accuracy: 0.5944 - val_loss: 0.6695 - val_accuracy: 0.5365\n",
      "Epoch 303/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6606 - accuracy: 0.5945 - val_loss: 0.6693 - val_accuracy: 0.5374\n",
      "Epoch 304/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6606 - accuracy: 0.5945 - val_loss: 0.6716 - val_accuracy: 0.5311\n",
      "Epoch 305/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6605 - accuracy: 0.5943 - val_loss: 0.6669 - val_accuracy: 0.5402\n",
      "Epoch 306/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6604 - accuracy: 0.5937 - val_loss: 0.6750 - val_accuracy: 0.5254\n",
      "Epoch 307/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6604 - accuracy: 0.5942 - val_loss: 0.6604 - val_accuracy: 0.5541\n",
      "Epoch 308/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6605 - accuracy: 0.5928 - val_loss: 0.6882 - val_accuracy: 0.4984\n",
      "Epoch 309/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6611 - accuracy: 0.5930 - val_loss: 0.6418 - val_accuracy: 0.5890\n",
      "Epoch 310/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6625 - accuracy: 0.5879 - val_loss: 0.7242 - val_accuracy: 0.4357\n",
      "Epoch 311/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6669 - accuracy: 0.5842 - val_loss: 0.6534 - val_accuracy: 0.5683\n",
      "Epoch 312/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6609 - accuracy: 0.5925 - val_loss: 0.6487 - val_accuracy: 0.5751\n",
      "Epoch 313/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6613 - accuracy: 0.5910 - val_loss: 0.7163 - val_accuracy: 0.4426\n",
      "Epoch 314/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6653 - accuracy: 0.5859 - val_loss: 0.6603 - val_accuracy: 0.5568\n",
      "Epoch 315/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6604 - accuracy: 0.5942 - val_loss: 0.6382 - val_accuracy: 0.5939\n",
      "Epoch 316/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6627 - accuracy: 0.5886 - val_loss: 0.7173 - val_accuracy: 0.4454\n",
      "Epoch 317/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6659 - accuracy: 0.5855 - val_loss: 0.6782 - val_accuracy: 0.5214\n",
      "Epoch 318/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6609 - accuracy: 0.5940 - val_loss: 0.6197 - val_accuracy: 0.6312\n",
      "Epoch 319/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6693 - accuracy: 0.5721 - val_loss: 0.7209 - val_accuracy: 0.4306\n",
      "Epoch 320/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6666 - accuracy: 0.5847 - val_loss: 0.7176 - val_accuracy: 0.4326\n",
      "Epoch 321/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6660 - accuracy: 0.5838 - val_loss: 0.6336 - val_accuracy: 0.6007\n",
      "Epoch 322/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6654 - accuracy: 0.5857 - val_loss: 0.6529 - val_accuracy: 0.5661\n",
      "Epoch 323/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6608 - accuracy: 0.5943 - val_loss: 0.6953 - val_accuracy: 0.4790\n",
      "Epoch 324/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6631 - accuracy: 0.5907 - val_loss: 0.6825 - val_accuracy: 0.5066\n",
      "Epoch 325/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6622 - accuracy: 0.5908 - val_loss: 0.6417 - val_accuracy: 0.5871\n",
      "Epoch 326/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6626 - accuracy: 0.5881 - val_loss: 0.6539 - val_accuracy: 0.5564\n",
      "Epoch 327/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6605 - accuracy: 0.5928 - val_loss: 0.6817 - val_accuracy: 0.4956\n",
      "Epoch 328/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6613 - accuracy: 0.5920 - val_loss: 0.6766 - val_accuracy: 0.5047\n",
      "Epoch 329/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6612 - accuracy: 0.5933 - val_loss: 0.6525 - val_accuracy: 0.5585\n",
      "Epoch 330/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6610 - accuracy: 0.5922 - val_loss: 0.6630 - val_accuracy: 0.5415\n",
      "Epoch 331/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6602 - accuracy: 0.5942 - val_loss: 0.6788 - val_accuracy: 0.5064\n",
      "Epoch 332/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6606 - accuracy: 0.5933 - val_loss: 0.6665 - val_accuracy: 0.5327\n",
      "Epoch 333/15000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6601 - accuracy: 0.5945 - val_loss: 0.6550 - val_accuracy: 0.5581\n",
      "Epoch 334/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6603 - accuracy: 0.5926 - val_loss: 0.6717 - val_accuracy: 0.5267\n",
      "Epoch 335/15000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6598 - accuracy: 0.5958 - val_loss: 0.6772 - val_accuracy: 0.5119\n",
      "Epoch 336/15000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6600 - accuracy: 0.5945 - val_loss: 0.6634 - val_accuracy: 0.5451\n",
      "Epoch 337/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6596 - accuracy: 0.5943 - val_loss: 0.6628 - val_accuracy: 0.5431\n",
      "Epoch 338/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6593 - accuracy: 0.5936 - val_loss: 0.6745 - val_accuracy: 0.5177\n",
      "Epoch 339/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6597 - accuracy: 0.5934 - val_loss: 0.6707 - val_accuracy: 0.5263\n",
      "Epoch 340/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6595 - accuracy: 0.5945 - val_loss: 0.6616 - val_accuracy: 0.5490\n",
      "Epoch 341/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6590 - accuracy: 0.5944 - val_loss: 0.6686 - val_accuracy: 0.5349\n",
      "Epoch 342/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6590 - accuracy: 0.5960 - val_loss: 0.6742 - val_accuracy: 0.5256\n",
      "Epoch 343/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6593 - accuracy: 0.5957 - val_loss: 0.6670 - val_accuracy: 0.5391\n",
      "Epoch 344/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6590 - accuracy: 0.5965 - val_loss: 0.6649 - val_accuracy: 0.5413\n",
      "Epoch 345/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6588 - accuracy: 0.5965 - val_loss: 0.6720 - val_accuracy: 0.5267\n",
      "Epoch 346/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6589 - accuracy: 0.5956 - val_loss: 0.6701 - val_accuracy: 0.5314\n",
      "Epoch 347/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6588 - accuracy: 0.5951 - val_loss: 0.6647 - val_accuracy: 0.5446\n",
      "Epoch 348/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6586 - accuracy: 0.5951 - val_loss: 0.6703 - val_accuracy: 0.5338\n",
      "Epoch 349/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6586 - accuracy: 0.5963 - val_loss: 0.6711 - val_accuracy: 0.5338\n",
      "Epoch 350/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6585 - accuracy: 0.5965 - val_loss: 0.6650 - val_accuracy: 0.5451\n",
      "Epoch 351/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6584 - accuracy: 0.5957 - val_loss: 0.6701 - val_accuracy: 0.5329\n",
      "Epoch 352/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6584 - accuracy: 0.5965 - val_loss: 0.6727 - val_accuracy: 0.5283\n",
      "Epoch 353/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6584 - accuracy: 0.5968 - val_loss: 0.6661 - val_accuracy: 0.5440\n",
      "Epoch 354/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6582 - accuracy: 0.5972 - val_loss: 0.6700 - val_accuracy: 0.5358\n",
      "Epoch 355/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6582 - accuracy: 0.5979 - val_loss: 0.6701 - val_accuracy: 0.5353\n",
      "Epoch 356/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6581 - accuracy: 0.5972 - val_loss: 0.6658 - val_accuracy: 0.5415\n",
      "Epoch 357/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6580 - accuracy: 0.5967 - val_loss: 0.6699 - val_accuracy: 0.5342\n",
      "Epoch 358/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6580 - accuracy: 0.5968 - val_loss: 0.6694 - val_accuracy: 0.5351\n",
      "Epoch 359/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6579 - accuracy: 0.5973 - val_loss: 0.6652 - val_accuracy: 0.5446\n",
      "Epoch 360/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6578 - accuracy: 0.5978 - val_loss: 0.6696 - val_accuracy: 0.5354\n",
      "Epoch 361/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6578 - accuracy: 0.5986 - val_loss: 0.6685 - val_accuracy: 0.5371\n",
      "Epoch 362/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6577 - accuracy: 0.5985 - val_loss: 0.6662 - val_accuracy: 0.5396\n",
      "Epoch 363/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6576 - accuracy: 0.5976 - val_loss: 0.6700 - val_accuracy: 0.5307\n",
      "Epoch 364/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6576 - accuracy: 0.5979 - val_loss: 0.6672 - val_accuracy: 0.5384\n",
      "Epoch 365/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6575 - accuracy: 0.5980 - val_loss: 0.6651 - val_accuracy: 0.5424\n",
      "Epoch 366/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6575 - accuracy: 0.5983 - val_loss: 0.6705 - val_accuracy: 0.5340\n",
      "Epoch 367/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6574 - accuracy: 0.5981 - val_loss: 0.6655 - val_accuracy: 0.5417\n",
      "Epoch 368/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6573 - accuracy: 0.5976 - val_loss: 0.6682 - val_accuracy: 0.5353\n",
      "Epoch 369/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6572 - accuracy: 0.5980 - val_loss: 0.6688 - val_accuracy: 0.5356\n",
      "Epoch 370/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6572 - accuracy: 0.5984 - val_loss: 0.6650 - val_accuracy: 0.5442\n",
      "Epoch 371/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6571 - accuracy: 0.5985 - val_loss: 0.6700 - val_accuracy: 0.5325\n",
      "Epoch 372/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6571 - accuracy: 0.5979 - val_loss: 0.6661 - val_accuracy: 0.5420\n",
      "Epoch 373/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6570 - accuracy: 0.5976 - val_loss: 0.6673 - val_accuracy: 0.5384\n",
      "Epoch 374/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6569 - accuracy: 0.5979 - val_loss: 0.6693 - val_accuracy: 0.5347\n",
      "Epoch 375/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6569 - accuracy: 0.5980 - val_loss: 0.6650 - val_accuracy: 0.5449\n",
      "Epoch 376/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6568 - accuracy: 0.5990 - val_loss: 0.6691 - val_accuracy: 0.5347\n",
      "Epoch 377/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6568 - accuracy: 0.5985 - val_loss: 0.6662 - val_accuracy: 0.5415\n",
      "Epoch 378/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6567 - accuracy: 0.5990 - val_loss: 0.6671 - val_accuracy: 0.5387\n",
      "Epoch 379/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6566 - accuracy: 0.5987 - val_loss: 0.6681 - val_accuracy: 0.5364\n",
      "Epoch 380/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6566 - accuracy: 0.5987 - val_loss: 0.6651 - val_accuracy: 0.5435\n",
      "Epoch 381/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6565 - accuracy: 0.5992 - val_loss: 0.6693 - val_accuracy: 0.5345\n",
      "Epoch 382/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6565 - accuracy: 0.5988 - val_loss: 0.6642 - val_accuracy: 0.5471\n",
      "Epoch 383/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6564 - accuracy: 0.5993 - val_loss: 0.6694 - val_accuracy: 0.5343\n",
      "Epoch 384/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6564 - accuracy: 0.5991 - val_loss: 0.6642 - val_accuracy: 0.5448\n",
      "Epoch 385/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6563 - accuracy: 0.5990 - val_loss: 0.6688 - val_accuracy: 0.5360\n",
      "Epoch 386/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6562 - accuracy: 0.5994 - val_loss: 0.6644 - val_accuracy: 0.5442\n",
      "Epoch 387/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6562 - accuracy: 0.5996 - val_loss: 0.6681 - val_accuracy: 0.5360\n",
      "Epoch 388/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6561 - accuracy: 0.5996 - val_loss: 0.6646 - val_accuracy: 0.5426\n",
      "Epoch 389/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6560 - accuracy: 0.5999 - val_loss: 0.6688 - val_accuracy: 0.5354\n",
      "Epoch 390/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6560 - accuracy: 0.6001 - val_loss: 0.6637 - val_accuracy: 0.5444\n",
      "Epoch 391/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6559 - accuracy: 0.6006 - val_loss: 0.6697 - val_accuracy: 0.5338\n",
      "Epoch 392/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6559 - accuracy: 0.6006 - val_loss: 0.6617 - val_accuracy: 0.5466\n",
      "Epoch 393/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6558 - accuracy: 0.6005 - val_loss: 0.6727 - val_accuracy: 0.5280\n",
      "Epoch 394/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6558 - accuracy: 0.6011 - val_loss: 0.6587 - val_accuracy: 0.5535\n",
      "Epoch 395/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6558 - accuracy: 0.6002 - val_loss: 0.6771 - val_accuracy: 0.5186\n",
      "Epoch 396/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6559 - accuracy: 0.6015 - val_loss: 0.6533 - val_accuracy: 0.5599\n",
      "Epoch 397/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6561 - accuracy: 0.5992 - val_loss: 0.6849 - val_accuracy: 0.5009\n",
      "Epoch 398/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6565 - accuracy: 0.6000 - val_loss: 0.6495 - val_accuracy: 0.5663\n",
      "Epoch 399/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6563 - accuracy: 0.5998 - val_loss: 0.6849 - val_accuracy: 0.5016\n",
      "Epoch 400/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6564 - accuracy: 0.6000 - val_loss: 0.6537 - val_accuracy: 0.5605\n",
      "Epoch 401/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6557 - accuracy: 0.5994 - val_loss: 0.6713 - val_accuracy: 0.5289\n",
      "Epoch 402/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6553 - accuracy: 0.6022 - val_loss: 0.6649 - val_accuracy: 0.5418\n",
      "Epoch 403/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6551 - accuracy: 0.6017 - val_loss: 0.6596 - val_accuracy: 0.5473\n",
      "Epoch 404/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6551 - accuracy: 0.6013 - val_loss: 0.6753 - val_accuracy: 0.5203\n",
      "Epoch 405/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6554 - accuracy: 0.6021 - val_loss: 0.6516 - val_accuracy: 0.5658\n",
      "Epoch 406/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6555 - accuracy: 0.6000 - val_loss: 0.6846 - val_accuracy: 0.5004\n",
      "Epoch 407/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6560 - accuracy: 0.6009 - val_loss: 0.6487 - val_accuracy: 0.5689\n",
      "Epoch 408/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6558 - accuracy: 0.6011 - val_loss: 0.6835 - val_accuracy: 0.5037\n",
      "Epoch 409/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6558 - accuracy: 0.6012 - val_loss: 0.6549 - val_accuracy: 0.5559\n",
      "Epoch 410/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6550 - accuracy: 0.6009 - val_loss: 0.6668 - val_accuracy: 0.5364\n",
      "Epoch 411/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6546 - accuracy: 0.6029 - val_loss: 0.6692 - val_accuracy: 0.5327\n",
      "Epoch 412/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6547 - accuracy: 0.6040 - val_loss: 0.6531 - val_accuracy: 0.5592\n",
      "Epoch 413/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6549 - accuracy: 0.6013 - val_loss: 0.6847 - val_accuracy: 0.5016\n",
      "Epoch 414/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6557 - accuracy: 0.6016 - val_loss: 0.6451 - val_accuracy: 0.5744\n",
      "Epoch 415/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6557 - accuracy: 0.6008 - val_loss: 0.6884 - val_accuracy: 0.4949\n",
      "Epoch 416/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6560 - accuracy: 0.6010 - val_loss: 0.6528 - val_accuracy: 0.5616\n",
      "Epoch 417/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6548 - accuracy: 0.6021 - val_loss: 0.6669 - val_accuracy: 0.5345\n",
      "Epoch 418/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6543 - accuracy: 0.6040 - val_loss: 0.6702 - val_accuracy: 0.5294\n",
      "Epoch 419/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6543 - accuracy: 0.6040 - val_loss: 0.6515 - val_accuracy: 0.5639\n",
      "Epoch 420/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6546 - accuracy: 0.6015 - val_loss: 0.6841 - val_accuracy: 0.5015\n",
      "Epoch 421/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6552 - accuracy: 0.6020 - val_loss: 0.6463 - val_accuracy: 0.5742\n",
      "Epoch 422/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6550 - accuracy: 0.6016 - val_loss: 0.6841 - val_accuracy: 0.5002\n",
      "Epoch 423/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6551 - accuracy: 0.6027 - val_loss: 0.6536 - val_accuracy: 0.5568\n",
      "Epoch 424/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6542 - accuracy: 0.6024 - val_loss: 0.6672 - val_accuracy: 0.5329\n",
      "Epoch 425/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6538 - accuracy: 0.6049 - val_loss: 0.6689 - val_accuracy: 0.5294\n",
      "Epoch 426/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6538 - accuracy: 0.6052 - val_loss: 0.6522 - val_accuracy: 0.5596\n",
      "Epoch 427/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6541 - accuracy: 0.6022 - val_loss: 0.6842 - val_accuracy: 0.5015\n",
      "Epoch 428/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6548 - accuracy: 0.6033 - val_loss: 0.6438 - val_accuracy: 0.5776\n",
      "Epoch 429/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6549 - accuracy: 0.6011 - val_loss: 0.6898 - val_accuracy: 0.4889\n",
      "Epoch 430/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6554 - accuracy: 0.6020 - val_loss: 0.6485 - val_accuracy: 0.5672\n",
      "Epoch 431/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6542 - accuracy: 0.6028 - val_loss: 0.6740 - val_accuracy: 0.5208\n",
      "Epoch 432/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6537 - accuracy: 0.6060 - val_loss: 0.6629 - val_accuracy: 0.5404\n",
      "Epoch 433/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6533 - accuracy: 0.6054 - val_loss: 0.6537 - val_accuracy: 0.5574\n",
      "Epoch 434/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6534 - accuracy: 0.6029 - val_loss: 0.6811 - val_accuracy: 0.5064\n",
      "Epoch 435/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6541 - accuracy: 0.6042 - val_loss: 0.6436 - val_accuracy: 0.5798\n",
      "Epoch 436/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6544 - accuracy: 0.6016 - val_loss: 0.6903 - val_accuracy: 0.4901\n",
      "Epoch 437/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6551 - accuracy: 0.6029 - val_loss: 0.6479 - val_accuracy: 0.5681\n",
      "Epoch 438/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6539 - accuracy: 0.6030 - val_loss: 0.6703 - val_accuracy: 0.5256\n",
      "Epoch 439/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6531 - accuracy: 0.6067 - val_loss: 0.6685 - val_accuracy: 0.5292\n",
      "Epoch 440/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6530 - accuracy: 0.6070 - val_loss: 0.6489 - val_accuracy: 0.5659\n",
      "Epoch 441/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6535 - accuracy: 0.6030 - val_loss: 0.6871 - val_accuracy: 0.4958\n",
      "Epoch 442/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6546 - accuracy: 0.6032 - val_loss: 0.6423 - val_accuracy: 0.5802\n",
      "Epoch 443/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6542 - accuracy: 0.6008 - val_loss: 0.6796 - val_accuracy: 0.5097\n",
      "Epoch 444/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6535 - accuracy: 0.6054 - val_loss: 0.6571 - val_accuracy: 0.5519\n",
      "Epoch 445/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6528 - accuracy: 0.6058 - val_loss: 0.6606 - val_accuracy: 0.5451\n",
      "Epoch 446/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6526 - accuracy: 0.6059 - val_loss: 0.6730 - val_accuracy: 0.5219\n",
      "Epoch 447/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6528 - accuracy: 0.6072 - val_loss: 0.6491 - val_accuracy: 0.5661\n",
      "Epoch 448/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6530 - accuracy: 0.6037 - val_loss: 0.6783 - val_accuracy: 0.5102\n",
      "Epoch 449/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6531 - accuracy: 0.6066 - val_loss: 0.6493 - val_accuracy: 0.5676\n",
      "Epoch 450/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6529 - accuracy: 0.6047 - val_loss: 0.6758 - val_accuracy: 0.5153\n",
      "Epoch 451/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6527 - accuracy: 0.6074 - val_loss: 0.6538 - val_accuracy: 0.5585\n",
      "Epoch 452/15000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6525 - accuracy: 0.6059 - val_loss: 0.6687 - val_accuracy: 0.5272\n",
      "Epoch 453/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6522 - accuracy: 0.6078 - val_loss: 0.6612 - val_accuracy: 0.5435\n",
      "Epoch 454/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6520 - accuracy: 0.6076 - val_loss: 0.6593 - val_accuracy: 0.5475\n",
      "Epoch 455/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6520 - accuracy: 0.6082 - val_loss: 0.6694 - val_accuracy: 0.5267\n",
      "Epoch 456/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6520 - accuracy: 0.6086 - val_loss: 0.6506 - val_accuracy: 0.5628\n",
      "Epoch 457/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6523 - accuracy: 0.6058 - val_loss: 0.6832 - val_accuracy: 0.5040\n",
      "Epoch 458/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6530 - accuracy: 0.6070 - val_loss: 0.6424 - val_accuracy: 0.5822\n",
      "Epoch 459/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6532 - accuracy: 0.6039 - val_loss: 0.6922 - val_accuracy: 0.4879\n",
      "Epoch 460/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6541 - accuracy: 0.6048 - val_loss: 0.6449 - val_accuracy: 0.5762\n",
      "Epoch 461/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6528 - accuracy: 0.6045 - val_loss: 0.6752 - val_accuracy: 0.5177\n",
      "Epoch 462/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6521 - accuracy: 0.6084 - val_loss: 0.6600 - val_accuracy: 0.5482\n",
      "Epoch 463/15000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6515 - accuracy: 0.6077 - val_loss: 0.6550 - val_accuracy: 0.5575\n",
      "Epoch 464/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6516 - accuracy: 0.6068 - val_loss: 0.6790 - val_accuracy: 0.5106\n",
      "Epoch 465/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6523 - accuracy: 0.6080 - val_loss: 0.6392 - val_accuracy: 0.5888\n",
      "Epoch 466/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6531 - accuracy: 0.6033 - val_loss: 0.6982 - val_accuracy: 0.4794\n",
      "Epoch 467/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6549 - accuracy: 0.6038 - val_loss: 0.6447 - val_accuracy: 0.5744\n",
      "Epoch 468/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6526 - accuracy: 0.6049 - val_loss: 0.6665 - val_accuracy: 0.5331\n",
      "Epoch 469/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6513 - accuracy: 0.6085 - val_loss: 0.6725 - val_accuracy: 0.5197\n",
      "Epoch 470/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6516 - accuracy: 0.6101 - val_loss: 0.6425 - val_accuracy: 0.5815\n",
      "Epoch 471/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6525 - accuracy: 0.6038 - val_loss: 0.6932 - val_accuracy: 0.4863\n",
      "Epoch 472/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6542 - accuracy: 0.6048 - val_loss: 0.6420 - val_accuracy: 0.5798\n",
      "Epoch 473/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6526 - accuracy: 0.6030 - val_loss: 0.6669 - val_accuracy: 0.5309\n",
      "Epoch 474/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6511 - accuracy: 0.6097 - val_loss: 0.6686 - val_accuracy: 0.5265\n",
      "Epoch 475/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6513 - accuracy: 0.6100 - val_loss: 0.6473 - val_accuracy: 0.5703\n",
      "Epoch 476/15000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6520 - accuracy: 0.6054 - val_loss: 0.6885 - val_accuracy: 0.4942\n",
      "Epoch 477/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6530 - accuracy: 0.6069 - val_loss: 0.6425 - val_accuracy: 0.5817\n",
      "Epoch 478/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6524 - accuracy: 0.6045 - val_loss: 0.6690 - val_accuracy: 0.5296\n",
      "Epoch 479/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6511 - accuracy: 0.6097 - val_loss: 0.6633 - val_accuracy: 0.5365\n",
      "Epoch 480/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6508 - accuracy: 0.6095 - val_loss: 0.6487 - val_accuracy: 0.5689\n",
      "Epoch 481/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6515 - accuracy: 0.6058 - val_loss: 0.6878 - val_accuracy: 0.4934\n",
      "Epoch 482/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6526 - accuracy: 0.6075 - val_loss: 0.6389 - val_accuracy: 0.5849\n",
      "Epoch 483/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6525 - accuracy: 0.6033 - val_loss: 0.6812 - val_accuracy: 0.5079\n",
      "Epoch 484/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6518 - accuracy: 0.6095 - val_loss: 0.6566 - val_accuracy: 0.5532\n",
      "Epoch 485/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6506 - accuracy: 0.6081 - val_loss: 0.6496 - val_accuracy: 0.5685\n",
      "Epoch 486/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6509 - accuracy: 0.6073 - val_loss: 0.6894 - val_accuracy: 0.4901\n",
      "Epoch 487/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6526 - accuracy: 0.6078 - val_loss: 0.6379 - val_accuracy: 0.5891\n",
      "Epoch 488/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6523 - accuracy: 0.6037 - val_loss: 0.6841 - val_accuracy: 0.5033\n",
      "Epoch 489/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6519 - accuracy: 0.6095 - val_loss: 0.6530 - val_accuracy: 0.5616\n",
      "Epoch 490/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6505 - accuracy: 0.6086 - val_loss: 0.6523 - val_accuracy: 0.5628\n",
      "Epoch 491/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6505 - accuracy: 0.6073 - val_loss: 0.6833 - val_accuracy: 0.5002\n",
      "Epoch 492/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6515 - accuracy: 0.6096 - val_loss: 0.6418 - val_accuracy: 0.5824\n",
      "Epoch 493/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6516 - accuracy: 0.6060 - val_loss: 0.6830 - val_accuracy: 0.5046\n",
      "Epoch 494/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6515 - accuracy: 0.6099 - val_loss: 0.6492 - val_accuracy: 0.5709\n",
      "Epoch 495/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6505 - accuracy: 0.6085 - val_loss: 0.6579 - val_accuracy: 0.5491\n",
      "Epoch 496/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6500 - accuracy: 0.6098 - val_loss: 0.6739 - val_accuracy: 0.5172\n",
      "Epoch 497/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6504 - accuracy: 0.6114 - val_loss: 0.6449 - val_accuracy: 0.5776\n",
      "Epoch 498/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6511 - accuracy: 0.6070 - val_loss: 0.6878 - val_accuracy: 0.4940\n",
      "Epoch 499/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6518 - accuracy: 0.6094 - val_loss: 0.6434 - val_accuracy: 0.5806\n",
      "Epoch 500/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6509 - accuracy: 0.6063 - val_loss: 0.6681 - val_accuracy: 0.5311\n",
      "Epoch 501/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6500 - accuracy: 0.6109 - val_loss: 0.6651 - val_accuracy: 0.5365\n",
      "Epoch 502/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6497 - accuracy: 0.6122 - val_loss: 0.6470 - val_accuracy: 0.5754\n",
      "Epoch 503/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6504 - accuracy: 0.6077 - val_loss: 0.6884 - val_accuracy: 0.4931\n",
      "Epoch 504/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6517 - accuracy: 0.6098 - val_loss: 0.6380 - val_accuracy: 0.5899\n",
      "Epoch 505/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6513 - accuracy: 0.6058 - val_loss: 0.6806 - val_accuracy: 0.5095\n",
      "Epoch 506/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6507 - accuracy: 0.6112 - val_loss: 0.6546 - val_accuracy: 0.5586\n",
      "Epoch 507/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6496 - accuracy: 0.6099 - val_loss: 0.6533 - val_accuracy: 0.5603\n",
      "Epoch 508/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6496 - accuracy: 0.6092 - val_loss: 0.6812 - val_accuracy: 0.5060\n",
      "Epoch 509/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6505 - accuracy: 0.6112 - val_loss: 0.6396 - val_accuracy: 0.5868\n",
      "Epoch 510/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6508 - accuracy: 0.6071 - val_loss: 0.6857 - val_accuracy: 0.5009\n",
      "Epoch 511/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6512 - accuracy: 0.6097 - val_loss: 0.6460 - val_accuracy: 0.5765\n",
      "Epoch 512/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6499 - accuracy: 0.6084 - val_loss: 0.6616 - val_accuracy: 0.5418\n",
      "Epoch 513/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6491 - accuracy: 0.6116 - val_loss: 0.6710 - val_accuracy: 0.5259\n",
      "Epoch 514/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6494 - accuracy: 0.6134 - val_loss: 0.6445 - val_accuracy: 0.5775\n",
      "Epoch 515/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6501 - accuracy: 0.6083 - val_loss: 0.6877 - val_accuracy: 0.4962\n",
      "Epoch 516/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6512 - accuracy: 0.6099 - val_loss: 0.6398 - val_accuracy: 0.5886\n",
      "Epoch 517/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6504 - accuracy: 0.6066 - val_loss: 0.6725 - val_accuracy: 0.5241\n",
      "Epoch 518/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6494 - accuracy: 0.6129 - val_loss: 0.6600 - val_accuracy: 0.5475\n",
      "Epoch 519/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6489 - accuracy: 0.6115 - val_loss: 0.6517 - val_accuracy: 0.5639\n",
      "Epoch 520/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6493 - accuracy: 0.6098 - val_loss: 0.6824 - val_accuracy: 0.5060\n",
      "Epoch 521/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6503 - accuracy: 0.6125 - val_loss: 0.6365 - val_accuracy: 0.5926\n",
      "Epoch 522/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6506 - accuracy: 0.6061 - val_loss: 0.6850 - val_accuracy: 0.5027\n",
      "Epoch 523/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6507 - accuracy: 0.6108 - val_loss: 0.6487 - val_accuracy: 0.5689\n",
      "Epoch 524/15000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6491 - accuracy: 0.6093 - val_loss: 0.6603 - val_accuracy: 0.5469\n",
      "Epoch 525/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6487 - accuracy: 0.6112 - val_loss: 0.6721 - val_accuracy: 0.5248\n",
      "Epoch 526/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6490 - accuracy: 0.6134 - val_loss: 0.6417 - val_accuracy: 0.5831\n",
      "Epoch 527/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6496 - accuracy: 0.6077 - val_loss: 0.6853 - val_accuracy: 0.5022\n",
      "Epoch 528/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6505 - accuracy: 0.6112 - val_loss: 0.6419 - val_accuracy: 0.5828\n",
      "Epoch 529/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6495 - accuracy: 0.6078 - val_loss: 0.6716 - val_accuracy: 0.5261\n",
      "Epoch 530/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6488 - accuracy: 0.6139 - val_loss: 0.6596 - val_accuracy: 0.5499\n",
      "Epoch 531/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6484 - accuracy: 0.6118 - val_loss: 0.6524 - val_accuracy: 0.5634\n",
      "Epoch 532/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6485 - accuracy: 0.6102 - val_loss: 0.6759 - val_accuracy: 0.5166\n",
      "Epoch 533/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6491 - accuracy: 0.6135 - val_loss: 0.6408 - val_accuracy: 0.5866\n",
      "Epoch 534/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6494 - accuracy: 0.6076 - val_loss: 0.6821 - val_accuracy: 0.5071\n",
      "Epoch 535/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6497 - accuracy: 0.6124 - val_loss: 0.6443 - val_accuracy: 0.5764\n",
      "Epoch 536/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6491 - accuracy: 0.6090 - val_loss: 0.6741 - val_accuracy: 0.5201\n",
      "Epoch 537/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6487 - accuracy: 0.6136 - val_loss: 0.6545 - val_accuracy: 0.5588\n",
      "Epoch 538/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6482 - accuracy: 0.6114 - val_loss: 0.6573 - val_accuracy: 0.5539\n",
      "Epoch 539/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6481 - accuracy: 0.6132 - val_loss: 0.6683 - val_accuracy: 0.5318\n",
      "Epoch 540/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6483 - accuracy: 0.6140 - val_loss: 0.6459 - val_accuracy: 0.5775\n",
      "Epoch 541/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6486 - accuracy: 0.6091 - val_loss: 0.6822 - val_accuracy: 0.5064\n",
      "Epoch 542/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6495 - accuracy: 0.6127 - val_loss: 0.6385 - val_accuracy: 0.5891\n",
      "Epoch 543/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6495 - accuracy: 0.6082 - val_loss: 0.6859 - val_accuracy: 0.5027\n",
      "Epoch 544/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6499 - accuracy: 0.6122 - val_loss: 0.6466 - val_accuracy: 0.5731\n",
      "Epoch 545/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6485 - accuracy: 0.6103 - val_loss: 0.6632 - val_accuracy: 0.5426\n",
      "Epoch 546/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6479 - accuracy: 0.6144 - val_loss: 0.6662 - val_accuracy: 0.5367\n",
      "Epoch 547/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6479 - accuracy: 0.6139 - val_loss: 0.6448 - val_accuracy: 0.5809\n",
      "Epoch 548/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6485 - accuracy: 0.6098 - val_loss: 0.6857 - val_accuracy: 0.5018\n",
      "Epoch 549/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6498 - accuracy: 0.6118 - val_loss: 0.6355 - val_accuracy: 0.5972\n",
      "Epoch 550/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6497 - accuracy: 0.6075 - val_loss: 0.6864 - val_accuracy: 0.5015\n",
      "Epoch 551/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6497 - accuracy: 0.6124 - val_loss: 0.6499 - val_accuracy: 0.5674\n",
      "Epoch 552/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6481 - accuracy: 0.6108 - val_loss: 0.6581 - val_accuracy: 0.5530\n",
      "Epoch 553/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6477 - accuracy: 0.6129 - val_loss: 0.6740 - val_accuracy: 0.5186\n",
      "Epoch 554/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6482 - accuracy: 0.6146 - val_loss: 0.6383 - val_accuracy: 0.5904\n",
      "Epoch 555/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6490 - accuracy: 0.6084 - val_loss: 0.6895 - val_accuracy: 0.4947\n",
      "Epoch 556/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6503 - accuracy: 0.6105 - val_loss: 0.6388 - val_accuracy: 0.5901\n",
      "Epoch 557/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6488 - accuracy: 0.6084 - val_loss: 0.6721 - val_accuracy: 0.5228\n",
      "Epoch 558/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6479 - accuracy: 0.6148 - val_loss: 0.6601 - val_accuracy: 0.5495\n",
      "Epoch 559/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6475 - accuracy: 0.6130 - val_loss: 0.6495 - val_accuracy: 0.5701\n",
      "Epoch 560/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6477 - accuracy: 0.6111 - val_loss: 0.6797 - val_accuracy: 0.5110\n",
      "Epoch 561/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6487 - accuracy: 0.6140 - val_loss: 0.6381 - val_accuracy: 0.5919\n",
      "Epoch 562/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6487 - accuracy: 0.6084 - val_loss: 0.6792 - val_accuracy: 0.5115\n",
      "Epoch 563/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6485 - accuracy: 0.6140 - val_loss: 0.6494 - val_accuracy: 0.5705\n",
      "Epoch 564/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6476 - accuracy: 0.6115 - val_loss: 0.6630 - val_accuracy: 0.5427\n",
      "Epoch 565/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6472 - accuracy: 0.6146 - val_loss: 0.6641 - val_accuracy: 0.5406\n",
      "Epoch 566/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6472 - accuracy: 0.6155 - val_loss: 0.6480 - val_accuracy: 0.5729\n",
      "Epoch 567/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6475 - accuracy: 0.6114 - val_loss: 0.6755 - val_accuracy: 0.5185\n",
      "Epoch 568/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6480 - accuracy: 0.6148 - val_loss: 0.6413 - val_accuracy: 0.5853\n",
      "Epoch 569/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6481 - accuracy: 0.6105 - val_loss: 0.6821 - val_accuracy: 0.5084\n",
      "Epoch 570/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6486 - accuracy: 0.6143 - val_loss: 0.6432 - val_accuracy: 0.5798\n",
      "Epoch 571/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6479 - accuracy: 0.6107 - val_loss: 0.6717 - val_accuracy: 0.5237\n",
      "Epoch 572/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6474 - accuracy: 0.6151 - val_loss: 0.6567 - val_accuracy: 0.5566\n",
      "Epoch 573/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6470 - accuracy: 0.6140 - val_loss: 0.6551 - val_accuracy: 0.5579\n",
      "Epoch 574/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6469 - accuracy: 0.6137 - val_loss: 0.6711 - val_accuracy: 0.5252\n",
      "Epoch 575/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6473 - accuracy: 0.6156 - val_loss: 0.6416 - val_accuracy: 0.5851\n",
      "Epoch 576/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6478 - accuracy: 0.6105 - val_loss: 0.6844 - val_accuracy: 0.5055\n",
      "Epoch 577/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6487 - accuracy: 0.6136 - val_loss: 0.6397 - val_accuracy: 0.5868\n",
      "Epoch 578/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6481 - accuracy: 0.6100 - val_loss: 0.6775 - val_accuracy: 0.5168\n",
      "Epoch 579/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6477 - accuracy: 0.6147 - val_loss: 0.6522 - val_accuracy: 0.5645\n",
      "Epoch 580/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6469 - accuracy: 0.6126 - val_loss: 0.6590 - val_accuracy: 0.5541\n",
      "Epoch 581/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6467 - accuracy: 0.6153 - val_loss: 0.6669 - val_accuracy: 0.5343\n",
      "Epoch 582/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6469 - accuracy: 0.6159 - val_loss: 0.6439 - val_accuracy: 0.5782\n",
      "Epoch 583/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6473 - accuracy: 0.6111 - val_loss: 0.6825 - val_accuracy: 0.5088\n",
      "Epoch 584/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6482 - accuracy: 0.6143 - val_loss: 0.6386 - val_accuracy: 0.5897\n",
      "Epoch 585/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6481 - accuracy: 0.6096 - val_loss: 0.6831 - val_accuracy: 0.5082\n",
      "Epoch 586/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6482 - accuracy: 0.6147 - val_loss: 0.6477 - val_accuracy: 0.5714\n",
      "Epoch 587/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6470 - accuracy: 0.6115 - val_loss: 0.6603 - val_accuracy: 0.5504\n",
      "Epoch 588/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6465 - accuracy: 0.6159 - val_loss: 0.6675 - val_accuracy: 0.5316\n",
      "Epoch 589/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6467 - accuracy: 0.6159 - val_loss: 0.6412 - val_accuracy: 0.5842\n",
      "Epoch 590/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6475 - accuracy: 0.6109 - val_loss: 0.6880 - val_accuracy: 0.4991\n",
      "Epoch 591/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6490 - accuracy: 0.6130 - val_loss: 0.6366 - val_accuracy: 0.5934\n",
      "Epoch 592/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6482 - accuracy: 0.6092 - val_loss: 0.6781 - val_accuracy: 0.5161\n",
      "Epoch 593/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6474 - accuracy: 0.6151 - val_loss: 0.6551 - val_accuracy: 0.5588\n",
      "Epoch 594/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6465 - accuracy: 0.6139 - val_loss: 0.6536 - val_accuracy: 0.5616\n",
      "Epoch 595/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6464 - accuracy: 0.6141 - val_loss: 0.6738 - val_accuracy: 0.5230\n",
      "Epoch 596/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6471 - accuracy: 0.6151 - val_loss: 0.6376 - val_accuracy: 0.5904\n",
      "Epoch 597/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6477 - accuracy: 0.6098 - val_loss: 0.6847 - val_accuracy: 0.5027\n",
      "Epoch 598/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6482 - accuracy: 0.6140 - val_loss: 0.6425 - val_accuracy: 0.5776\n",
      "Epoch 599/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6473 - accuracy: 0.6111 - val_loss: 0.6721 - val_accuracy: 0.5243\n",
      "Epoch 600/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6467 - accuracy: 0.6155 - val_loss: 0.6564 - val_accuracy: 0.5566\n",
      "Epoch 601/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6462 - accuracy: 0.6151 - val_loss: 0.6513 - val_accuracy: 0.5639\n",
      "Epoch 602/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6462 - accuracy: 0.6140 - val_loss: 0.6746 - val_accuracy: 0.5177\n",
      "Epoch 603/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6469 - accuracy: 0.6157 - val_loss: 0.6381 - val_accuracy: 0.5875\n",
      "Epoch 604/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6475 - accuracy: 0.6102 - val_loss: 0.6872 - val_accuracy: 0.5009\n",
      "Epoch 605/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6485 - accuracy: 0.6128 - val_loss: 0.6407 - val_accuracy: 0.5853\n",
      "Epoch 606/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6473 - accuracy: 0.6103 - val_loss: 0.6667 - val_accuracy: 0.5349\n",
      "Epoch 607/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6462 - accuracy: 0.6166 - val_loss: 0.6658 - val_accuracy: 0.5364\n",
      "Epoch 608/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6462 - accuracy: 0.6151 - val_loss: 0.6449 - val_accuracy: 0.5762\n",
      "Epoch 609/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6467 - accuracy: 0.6125 - val_loss: 0.6828 - val_accuracy: 0.5088\n",
      "Epoch 610/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6480 - accuracy: 0.6143 - val_loss: 0.6360 - val_accuracy: 0.5954\n",
      "Epoch 611/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6477 - accuracy: 0.6089 - val_loss: 0.6750 - val_accuracy: 0.5208\n",
      "Epoch 612/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6466 - accuracy: 0.6163 - val_loss: 0.6547 - val_accuracy: 0.5596\n",
      "Epoch 613/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6463 - accuracy: 0.6140 - val_loss: 0.6623 - val_accuracy: 0.5418\n",
      "Epoch 614/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6459 - accuracy: 0.6161 - val_loss: 0.6614 - val_accuracy: 0.5442\n",
      "Epoch 615/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6459 - accuracy: 0.6164 - val_loss: 0.6489 - val_accuracy: 0.5650\n",
      "Epoch 616/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6461 - accuracy: 0.6138 - val_loss: 0.6689 - val_accuracy: 0.5278\n",
      "Epoch 617/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6461 - accuracy: 0.6165 - val_loss: 0.6477 - val_accuracy: 0.5718\n",
      "Epoch 618/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6464 - accuracy: 0.6127 - val_loss: 0.6789 - val_accuracy: 0.5113\n",
      "Epoch 619/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6468 - accuracy: 0.6164 - val_loss: 0.6389 - val_accuracy: 0.5864\n",
      "Epoch 620/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6471 - accuracy: 0.6103 - val_loss: 0.6801 - val_accuracy: 0.5152\n",
      "Epoch 621/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6471 - accuracy: 0.6159 - val_loss: 0.6499 - val_accuracy: 0.5689\n",
      "Epoch 622/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6458 - accuracy: 0.6145 - val_loss: 0.6577 - val_accuracy: 0.5561\n",
      "Epoch 623/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6456 - accuracy: 0.6157 - val_loss: 0.6717 - val_accuracy: 0.5237\n",
      "Epoch 624/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6460 - accuracy: 0.6168 - val_loss: 0.6374 - val_accuracy: 0.5890\n",
      "Epoch 625/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6470 - accuracy: 0.6104 - val_loss: 0.6905 - val_accuracy: 0.4982\n",
      "Epoch 626/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6486 - accuracy: 0.6125 - val_loss: 0.6398 - val_accuracy: 0.5851\n",
      "Epoch 627/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6469 - accuracy: 0.6104 - val_loss: 0.6657 - val_accuracy: 0.5389\n",
      "Epoch 628/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6456 - accuracy: 0.6169 - val_loss: 0.6675 - val_accuracy: 0.5338\n",
      "Epoch 629/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6457 - accuracy: 0.6162 - val_loss: 0.6440 - val_accuracy: 0.5754\n",
      "Epoch 630/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6462 - accuracy: 0.6126 - val_loss: 0.6828 - val_accuracy: 0.5110\n",
      "Epoch 631/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6476 - accuracy: 0.6145 - val_loss: 0.6367 - val_accuracy: 0.5913\n",
      "Epoch 632/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6472 - accuracy: 0.6101 - val_loss: 0.6728 - val_accuracy: 0.5210\n",
      "Epoch 633/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6459 - accuracy: 0.6171 - val_loss: 0.6568 - val_accuracy: 0.5574\n",
      "Epoch 634/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6460 - accuracy: 0.6148 - val_loss: 0.6630 - val_accuracy: 0.5409\n",
      "Epoch 635/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6454 - accuracy: 0.6164 - val_loss: 0.6587 - val_accuracy: 0.5510\n",
      "Epoch 636/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6454 - accuracy: 0.6173 - val_loss: 0.6492 - val_accuracy: 0.5649\n",
      "Epoch 637/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6457 - accuracy: 0.6149 - val_loss: 0.6680 - val_accuracy: 0.5314\n",
      "Epoch 638/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6455 - accuracy: 0.6170 - val_loss: 0.6464 - val_accuracy: 0.5718\n",
      "Epoch 639/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6462 - accuracy: 0.6125 - val_loss: 0.6846 - val_accuracy: 0.5027\n",
      "Epoch 640/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6470 - accuracy: 0.6148 - val_loss: 0.6364 - val_accuracy: 0.5888\n",
      "Epoch 641/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6471 - accuracy: 0.6109 - val_loss: 0.6798 - val_accuracy: 0.5142\n",
      "Epoch 642/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6467 - accuracy: 0.6162 - val_loss: 0.6531 - val_accuracy: 0.5641\n",
      "Epoch 643/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6452 - accuracy: 0.6162 - val_loss: 0.6479 - val_accuracy: 0.5714\n",
      "Epoch 644/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6456 - accuracy: 0.6139 - val_loss: 0.6887 - val_accuracy: 0.4954\n",
      "Epoch 645/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6476 - accuracy: 0.6139 - val_loss: 0.6298 - val_accuracy: 0.6007\n",
      "Epoch 646/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6479 - accuracy: 0.6083 - val_loss: 0.6917 - val_accuracy: 0.4969\n",
      "Epoch 647/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6485 - accuracy: 0.6130 - val_loss: 0.6507 - val_accuracy: 0.5643\n",
      "Epoch 648/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6457 - accuracy: 0.6154 - val_loss: 0.6415 - val_accuracy: 0.5787\n",
      "Epoch 649/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6462 - accuracy: 0.6121 - val_loss: 0.6989 - val_accuracy: 0.4788\n",
      "Epoch 650/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6493 - accuracy: 0.6104 - val_loss: 0.6385 - val_accuracy: 0.5835\n",
      "Epoch 651/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6472 - accuracy: 0.6101 - val_loss: 0.6681 - val_accuracy: 0.5329\n",
      "Epoch 652/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6455 - accuracy: 0.6164 - val_loss: 0.6571 - val_accuracy: 0.5519\n",
      "Epoch 653/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6457 - accuracy: 0.6154 - val_loss: 0.6459 - val_accuracy: 0.5722\n",
      "Epoch 654/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6455 - accuracy: 0.6135 - val_loss: 0.6737 - val_accuracy: 0.5164\n",
      "Epoch 655/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6457 - accuracy: 0.6167 - val_loss: 0.6507 - val_accuracy: 0.5623\n",
      "Epoch 656/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6461 - accuracy: 0.6137 - val_loss: 0.6703 - val_accuracy: 0.5243\n",
      "Epoch 657/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6453 - accuracy: 0.6172 - val_loss: 0.6446 - val_accuracy: 0.5751\n",
      "Epoch 658/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6457 - accuracy: 0.6132 - val_loss: 0.6634 - val_accuracy: 0.5438\n",
      "Epoch 659/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6452 - accuracy: 0.6170 - val_loss: 0.6588 - val_accuracy: 0.5519\n",
      "Epoch 660/15000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.6447 - accuracy: 0.6169 - val_loss: 0.6536 - val_accuracy: 0.5597\n",
      "Epoch 661/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6453 - accuracy: 0.6151 - val_loss: 0.6753 - val_accuracy: 0.5155\n",
      "Epoch 662/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6455 - accuracy: 0.6173 - val_loss: 0.6400 - val_accuracy: 0.5846\n",
      "Epoch 663/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6458 - accuracy: 0.6122 - val_loss: 0.6738 - val_accuracy: 0.5230\n",
      "Epoch 664/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6456 - accuracy: 0.6169 - val_loss: 0.6528 - val_accuracy: 0.5638\n",
      "Epoch 665/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6447 - accuracy: 0.6159 - val_loss: 0.6532 - val_accuracy: 0.5634\n",
      "Epoch 666/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6448 - accuracy: 0.6147 - val_loss: 0.6765 - val_accuracy: 0.5146\n",
      "Epoch 667/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6455 - accuracy: 0.6173 - val_loss: 0.6377 - val_accuracy: 0.5868\n",
      "Epoch 668/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6460 - accuracy: 0.6118 - val_loss: 0.6808 - val_accuracy: 0.5108\n",
      "Epoch 669/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6462 - accuracy: 0.6161 - val_loss: 0.6483 - val_accuracy: 0.5676\n",
      "Epoch 670/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6449 - accuracy: 0.6150 - val_loss: 0.6542 - val_accuracy: 0.5605\n",
      "Epoch 671/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6446 - accuracy: 0.6162 - val_loss: 0.6773 - val_accuracy: 0.5133\n",
      "Epoch 672/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6455 - accuracy: 0.6172 - val_loss: 0.6376 - val_accuracy: 0.5860\n",
      "Epoch 673/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6461 - accuracy: 0.6111 - val_loss: 0.6854 - val_accuracy: 0.5042\n",
      "Epoch 674/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6469 - accuracy: 0.6153 - val_loss: 0.6450 - val_accuracy: 0.5769\n",
      "Epoch 675/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6454 - accuracy: 0.6137 - val_loss: 0.6542 - val_accuracy: 0.5599\n",
      "Epoch 676/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6445 - accuracy: 0.6170 - val_loss: 0.6786 - val_accuracy: 0.5128\n",
      "Epoch 677/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6456 - accuracy: 0.6168 - val_loss: 0.6398 - val_accuracy: 0.5813\n",
      "Epoch 678/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6465 - accuracy: 0.6110 - val_loss: 0.6875 - val_accuracy: 0.5018\n",
      "Epoch 679/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6471 - accuracy: 0.6147 - val_loss: 0.6401 - val_accuracy: 0.5853\n",
      "Epoch 680/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6464 - accuracy: 0.6115 - val_loss: 0.6579 - val_accuracy: 0.5524\n",
      "Epoch 681/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6445 - accuracy: 0.6177 - val_loss: 0.6730 - val_accuracy: 0.5225\n",
      "Epoch 682/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6452 - accuracy: 0.6167 - val_loss: 0.6454 - val_accuracy: 0.5716\n",
      "Epoch 683/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6463 - accuracy: 0.6121 - val_loss: 0.6855 - val_accuracy: 0.5024\n",
      "Epoch 684/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6465 - accuracy: 0.6153 - val_loss: 0.6360 - val_accuracy: 0.5890\n",
      "Epoch 685/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6468 - accuracy: 0.6107 - val_loss: 0.6661 - val_accuracy: 0.5385\n",
      "Epoch 686/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6448 - accuracy: 0.6174 - val_loss: 0.6652 - val_accuracy: 0.5365\n",
      "Epoch 687/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6445 - accuracy: 0.6177 - val_loss: 0.6446 - val_accuracy: 0.5723\n",
      "Epoch 688/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6460 - accuracy: 0.6124 - val_loss: 0.6908 - val_accuracy: 0.4931\n",
      "Epoch 689/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6472 - accuracy: 0.6136 - val_loss: 0.6357 - val_accuracy: 0.5901\n",
      "Epoch 690/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6462 - accuracy: 0.6114 - val_loss: 0.6617 - val_accuracy: 0.5433\n",
      "Epoch 691/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6446 - accuracy: 0.6175 - val_loss: 0.6709 - val_accuracy: 0.5239\n",
      "Epoch 692/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6446 - accuracy: 0.6182 - val_loss: 0.6378 - val_accuracy: 0.5824\n",
      "Epoch 693/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6466 - accuracy: 0.6107 - val_loss: 0.6955 - val_accuracy: 0.4896\n",
      "Epoch 694/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6480 - accuracy: 0.6129 - val_loss: 0.6418 - val_accuracy: 0.5815\n",
      "Epoch 695/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6453 - accuracy: 0.6133 - val_loss: 0.6460 - val_accuracy: 0.5736\n",
      "Epoch 696/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6447 - accuracy: 0.6143 - val_loss: 0.6876 - val_accuracy: 0.4980\n",
      "Epoch 697/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6465 - accuracy: 0.6151 - val_loss: 0.6388 - val_accuracy: 0.5813\n",
      "Epoch 698/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6464 - accuracy: 0.6110 - val_loss: 0.6761 - val_accuracy: 0.5141\n",
      "Epoch 699/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6450 - accuracy: 0.6178 - val_loss: 0.6526 - val_accuracy: 0.5590\n",
      "Epoch 700/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6444 - accuracy: 0.6172 - val_loss: 0.6453 - val_accuracy: 0.5747\n",
      "Epoch 701/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6446 - accuracy: 0.6144 - val_loss: 0.6777 - val_accuracy: 0.5122\n",
      "Epoch 702/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6450 - accuracy: 0.6175 - val_loss: 0.6465 - val_accuracy: 0.5689\n",
      "Epoch 703/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6451 - accuracy: 0.6136 - val_loss: 0.6682 - val_accuracy: 0.5294\n",
      "Epoch 704/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6442 - accuracy: 0.6187 - val_loss: 0.6544 - val_accuracy: 0.5585\n",
      "Epoch 705/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6440 - accuracy: 0.6175 - val_loss: 0.6498 - val_accuracy: 0.5649\n",
      "Epoch 706/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6442 - accuracy: 0.6161 - val_loss: 0.6698 - val_accuracy: 0.5265\n",
      "Epoch 707/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6442 - accuracy: 0.6189 - val_loss: 0.6481 - val_accuracy: 0.5680\n",
      "Epoch 708/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6446 - accuracy: 0.6153 - val_loss: 0.6726 - val_accuracy: 0.5223\n",
      "Epoch 709/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6443 - accuracy: 0.6189 - val_loss: 0.6496 - val_accuracy: 0.5676\n",
      "Epoch 710/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6440 - accuracy: 0.6166 - val_loss: 0.6583 - val_accuracy: 0.5519\n",
      "Epoch 711/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6438 - accuracy: 0.6184 - val_loss: 0.6634 - val_accuracy: 0.5418\n",
      "Epoch 712/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6438 - accuracy: 0.6190 - val_loss: 0.6491 - val_accuracy: 0.5676\n",
      "Epoch 713/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6441 - accuracy: 0.6158 - val_loss: 0.6738 - val_accuracy: 0.5208\n",
      "Epoch 714/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6443 - accuracy: 0.6189 - val_loss: 0.6457 - val_accuracy: 0.5733\n",
      "Epoch 715/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6441 - accuracy: 0.6152 - val_loss: 0.6654 - val_accuracy: 0.5380\n",
      "Epoch 716/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6439 - accuracy: 0.6180 - val_loss: 0.6582 - val_accuracy: 0.5521\n",
      "Epoch 717/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6436 - accuracy: 0.6189 - val_loss: 0.6518 - val_accuracy: 0.5634\n",
      "Epoch 718/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6438 - accuracy: 0.6166 - val_loss: 0.6736 - val_accuracy: 0.5212\n",
      "Epoch 719/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6442 - accuracy: 0.6197 - val_loss: 0.6435 - val_accuracy: 0.5762\n",
      "Epoch 720/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6443 - accuracy: 0.6149 - val_loss: 0.6729 - val_accuracy: 0.5265\n",
      "Epoch 721/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6443 - accuracy: 0.6182 - val_loss: 0.6502 - val_accuracy: 0.5685\n",
      "Epoch 722/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6437 - accuracy: 0.6167 - val_loss: 0.6590 - val_accuracy: 0.5526\n",
      "Epoch 723/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6434 - accuracy: 0.6186 - val_loss: 0.6668 - val_accuracy: 0.5364\n",
      "Epoch 724/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6436 - accuracy: 0.6198 - val_loss: 0.6473 - val_accuracy: 0.5696\n",
      "Epoch 725/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6438 - accuracy: 0.6162 - val_loss: 0.6729 - val_accuracy: 0.5254\n",
      "Epoch 726/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6442 - accuracy: 0.6185 - val_loss: 0.6449 - val_accuracy: 0.5742\n",
      "Epoch 727/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6440 - accuracy: 0.6156 - val_loss: 0.6671 - val_accuracy: 0.5354\n",
      "Epoch 728/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6435 - accuracy: 0.6188 - val_loss: 0.6569 - val_accuracy: 0.5572\n",
      "Epoch 729/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6434 - accuracy: 0.6176 - val_loss: 0.6577 - val_accuracy: 0.5550\n",
      "Epoch 730/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6433 - accuracy: 0.6180 - val_loss: 0.6635 - val_accuracy: 0.5431\n",
      "Epoch 731/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6434 - accuracy: 0.6186 - val_loss: 0.6487 - val_accuracy: 0.5691\n",
      "Epoch 732/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6435 - accuracy: 0.6168 - val_loss: 0.6684 - val_accuracy: 0.5323\n",
      "Epoch 733/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6435 - accuracy: 0.6191 - val_loss: 0.6500 - val_accuracy: 0.5669\n",
      "Epoch 734/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6436 - accuracy: 0.6166 - val_loss: 0.6694 - val_accuracy: 0.5305\n",
      "Epoch 735/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6435 - accuracy: 0.6194 - val_loss: 0.6499 - val_accuracy: 0.5681\n",
      "Epoch 736/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6434 - accuracy: 0.6169 - val_loss: 0.6643 - val_accuracy: 0.5406\n",
      "Epoch 737/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6433 - accuracy: 0.6190 - val_loss: 0.6543 - val_accuracy: 0.5590\n",
      "Epoch 738/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6431 - accuracy: 0.6180 - val_loss: 0.6602 - val_accuracy: 0.5515\n",
      "Epoch 739/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6431 - accuracy: 0.6186 - val_loss: 0.6601 - val_accuracy: 0.5499\n",
      "Epoch 740/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6431 - accuracy: 0.6186 - val_loss: 0.6554 - val_accuracy: 0.5566\n",
      "Epoch 741/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6431 - accuracy: 0.6183 - val_loss: 0.6630 - val_accuracy: 0.5429\n",
      "Epoch 742/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6431 - accuracy: 0.6192 - val_loss: 0.6527 - val_accuracy: 0.5627\n",
      "Epoch 743/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6431 - accuracy: 0.6172 - val_loss: 0.6664 - val_accuracy: 0.5371\n",
      "Epoch 744/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6431 - accuracy: 0.6196 - val_loss: 0.6501 - val_accuracy: 0.5654\n",
      "Epoch 745/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6432 - accuracy: 0.6170 - val_loss: 0.6696 - val_accuracy: 0.5312\n",
      "Epoch 746/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6433 - accuracy: 0.6188 - val_loss: 0.6463 - val_accuracy: 0.5723\n",
      "Epoch 747/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6434 - accuracy: 0.6169 - val_loss: 0.6725 - val_accuracy: 0.5243\n",
      "Epoch 748/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6435 - accuracy: 0.6193 - val_loss: 0.6461 - val_accuracy: 0.5720\n",
      "Epoch 749/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6435 - accuracy: 0.6168 - val_loss: 0.6738 - val_accuracy: 0.5223\n",
      "Epoch 750/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6435 - accuracy: 0.6196 - val_loss: 0.6447 - val_accuracy: 0.5738\n",
      "Epoch 751/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6435 - accuracy: 0.6163 - val_loss: 0.6721 - val_accuracy: 0.5254\n",
      "Epoch 752/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6434 - accuracy: 0.6193 - val_loss: 0.6477 - val_accuracy: 0.5687\n",
      "Epoch 753/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6432 - accuracy: 0.6172 - val_loss: 0.6689 - val_accuracy: 0.5318\n",
      "Epoch 754/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6431 - accuracy: 0.6191 - val_loss: 0.6504 - val_accuracy: 0.5659\n",
      "Epoch 755/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6429 - accuracy: 0.6175 - val_loss: 0.6644 - val_accuracy: 0.5404\n",
      "Epoch 756/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6428 - accuracy: 0.6187 - val_loss: 0.6541 - val_accuracy: 0.5607\n",
      "Epoch 757/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6427 - accuracy: 0.6182 - val_loss: 0.6616 - val_accuracy: 0.5466\n",
      "Epoch 758/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6427 - accuracy: 0.6187 - val_loss: 0.6570 - val_accuracy: 0.5559\n",
      "Epoch 759/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6426 - accuracy: 0.6191 - val_loss: 0.6604 - val_accuracy: 0.5493\n",
      "Epoch 760/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6426 - accuracy: 0.6193 - val_loss: 0.6564 - val_accuracy: 0.5554\n",
      "Epoch 761/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6426 - accuracy: 0.6187 - val_loss: 0.6610 - val_accuracy: 0.5479\n",
      "Epoch 762/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6426 - accuracy: 0.6188 - val_loss: 0.6548 - val_accuracy: 0.5585\n",
      "Epoch 763/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6426 - accuracy: 0.6184 - val_loss: 0.6645 - val_accuracy: 0.5384\n",
      "Epoch 764/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6426 - accuracy: 0.6194 - val_loss: 0.6501 - val_accuracy: 0.5652\n",
      "Epoch 765/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6427 - accuracy: 0.6178 - val_loss: 0.6720 - val_accuracy: 0.5248\n",
      "Epoch 766/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6430 - accuracy: 0.6193 - val_loss: 0.6418 - val_accuracy: 0.5775\n",
      "Epoch 767/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6434 - accuracy: 0.6168 - val_loss: 0.6852 - val_accuracy: 0.5031\n",
      "Epoch 768/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6445 - accuracy: 0.6180 - val_loss: 0.6352 - val_accuracy: 0.5868\n",
      "Epoch 769/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6444 - accuracy: 0.6137 - val_loss: 0.6873 - val_accuracy: 0.5000\n",
      "Epoch 770/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6448 - accuracy: 0.6174 - val_loss: 0.6417 - val_accuracy: 0.5780\n",
      "Epoch 771/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6434 - accuracy: 0.6166 - val_loss: 0.6685 - val_accuracy: 0.5320\n",
      "Epoch 772/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6427 - accuracy: 0.6193 - val_loss: 0.6559 - val_accuracy: 0.5561\n",
      "Epoch 773/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6423 - accuracy: 0.6189 - val_loss: 0.6521 - val_accuracy: 0.5623\n",
      "Epoch 774/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6424 - accuracy: 0.6188 - val_loss: 0.6706 - val_accuracy: 0.5278\n",
      "Epoch 775/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6428 - accuracy: 0.6195 - val_loss: 0.6400 - val_accuracy: 0.5820\n",
      "Epoch 776/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6434 - accuracy: 0.6165 - val_loss: 0.6857 - val_accuracy: 0.4996\n",
      "Epoch 777/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6445 - accuracy: 0.6180 - val_loss: 0.6384 - val_accuracy: 0.5837\n",
      "Epoch 778/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6438 - accuracy: 0.6151 - val_loss: 0.6766 - val_accuracy: 0.5146\n",
      "Epoch 779/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6432 - accuracy: 0.6197 - val_loss: 0.6497 - val_accuracy: 0.5643\n",
      "Epoch 780/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6424 - accuracy: 0.6187 - val_loss: 0.6590 - val_accuracy: 0.5490\n",
      "Epoch 781/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6421 - accuracy: 0.6195 - val_loss: 0.6616 - val_accuracy: 0.5435\n",
      "Epoch 782/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6422 - accuracy: 0.6199 - val_loss: 0.6479 - val_accuracy: 0.5669\n",
      "Epoch 783/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6424 - accuracy: 0.6176 - val_loss: 0.6729 - val_accuracy: 0.5217\n",
      "Epoch 784/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6428 - accuracy: 0.6199 - val_loss: 0.6419 - val_accuracy: 0.5765\n",
      "Epoch 785/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6430 - accuracy: 0.6170 - val_loss: 0.6797 - val_accuracy: 0.5111\n",
      "Epoch 786/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6435 - accuracy: 0.6189 - val_loss: 0.6413 - val_accuracy: 0.5784\n",
      "Epoch 787/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6430 - accuracy: 0.6176 - val_loss: 0.6727 - val_accuracy: 0.5223\n",
      "Epoch 788/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6426 - accuracy: 0.6201 - val_loss: 0.6506 - val_accuracy: 0.5627\n",
      "Epoch 789/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6422 - accuracy: 0.6192 - val_loss: 0.6624 - val_accuracy: 0.5429\n",
      "Epoch 790/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6420 - accuracy: 0.6196 - val_loss: 0.6560 - val_accuracy: 0.5555\n",
      "Epoch 791/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6419 - accuracy: 0.6193 - val_loss: 0.6554 - val_accuracy: 0.5570\n",
      "Epoch 792/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6419 - accuracy: 0.6190 - val_loss: 0.6635 - val_accuracy: 0.5418\n",
      "Epoch 793/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6419 - accuracy: 0.6200 - val_loss: 0.6505 - val_accuracy: 0.5632\n",
      "Epoch 794/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6421 - accuracy: 0.6187 - val_loss: 0.6721 - val_accuracy: 0.5247\n",
      "Epoch 795/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6424 - accuracy: 0.6201 - val_loss: 0.6411 - val_accuracy: 0.5789\n",
      "Epoch 796/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6428 - accuracy: 0.6172 - val_loss: 0.6833 - val_accuracy: 0.5046\n",
      "Epoch 797/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6436 - accuracy: 0.6187 - val_loss: 0.6370 - val_accuracy: 0.5855\n",
      "Epoch 798/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6435 - accuracy: 0.6150 - val_loss: 0.6861 - val_accuracy: 0.4991\n",
      "Epoch 799/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6440 - accuracy: 0.6182 - val_loss: 0.6404 - val_accuracy: 0.5813\n",
      "Epoch 800/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6429 - accuracy: 0.6169 - val_loss: 0.6708 - val_accuracy: 0.5272\n",
      "Epoch 801/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6422 - accuracy: 0.6205 - val_loss: 0.6532 - val_accuracy: 0.5599\n",
      "Epoch 802/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6417 - accuracy: 0.6191 - val_loss: 0.6562 - val_accuracy: 0.5543\n",
      "Epoch 803/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6416 - accuracy: 0.6203 - val_loss: 0.6648 - val_accuracy: 0.5374\n",
      "Epoch 804/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6418 - accuracy: 0.6208 - val_loss: 0.6448 - val_accuracy: 0.5705\n",
      "Epoch 805/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6421 - accuracy: 0.6183 - val_loss: 0.6781 - val_accuracy: 0.5137\n",
      "Epoch 806/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6428 - accuracy: 0.6203 - val_loss: 0.6389 - val_accuracy: 0.5828\n",
      "Epoch 807/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6429 - accuracy: 0.6159 - val_loss: 0.6830 - val_accuracy: 0.5037\n",
      "Epoch 808/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6435 - accuracy: 0.6190 - val_loss: 0.6390 - val_accuracy: 0.5824\n",
      "Epoch 809/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6427 - accuracy: 0.6170 - val_loss: 0.6733 - val_accuracy: 0.5205\n",
      "Epoch 810/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6422 - accuracy: 0.6208 - val_loss: 0.6503 - val_accuracy: 0.5617\n",
      "Epoch 811/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6417 - accuracy: 0.6188 - val_loss: 0.6612 - val_accuracy: 0.5442\n",
      "Epoch 812/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6414 - accuracy: 0.6207 - val_loss: 0.6573 - val_accuracy: 0.5533\n",
      "Epoch 813/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6414 - accuracy: 0.6197 - val_loss: 0.6528 - val_accuracy: 0.5603\n",
      "Epoch 814/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6414 - accuracy: 0.6197 - val_loss: 0.6650 - val_accuracy: 0.5384\n",
      "Epoch 815/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6415 - accuracy: 0.6214 - val_loss: 0.6484 - val_accuracy: 0.5661\n",
      "Epoch 816/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6416 - accuracy: 0.6191 - val_loss: 0.6723 - val_accuracy: 0.5228\n",
      "Epoch 817/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6419 - accuracy: 0.6206 - val_loss: 0.6417 - val_accuracy: 0.5767\n",
      "Epoch 818/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6421 - accuracy: 0.6182 - val_loss: 0.6783 - val_accuracy: 0.5128\n",
      "Epoch 819/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6425 - accuracy: 0.6207 - val_loss: 0.6402 - val_accuracy: 0.5817\n",
      "Epoch 820/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6424 - accuracy: 0.6172 - val_loss: 0.6806 - val_accuracy: 0.5079\n",
      "Epoch 821/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6427 - accuracy: 0.6196 - val_loss: 0.6400 - val_accuracy: 0.5820\n",
      "Epoch 822/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6423 - accuracy: 0.6178 - val_loss: 0.6746 - val_accuracy: 0.5206\n",
      "Epoch 823/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6420 - accuracy: 0.6212 - val_loss: 0.6469 - val_accuracy: 0.5683\n",
      "Epoch 824/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6415 - accuracy: 0.6185 - val_loss: 0.6654 - val_accuracy: 0.5367\n",
      "Epoch 825/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6413 - accuracy: 0.6218 - val_loss: 0.6526 - val_accuracy: 0.5614\n",
      "Epoch 826/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6411 - accuracy: 0.6203 - val_loss: 0.6591 - val_accuracy: 0.5495\n",
      "Epoch 827/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6410 - accuracy: 0.6206 - val_loss: 0.6578 - val_accuracy: 0.5519\n",
      "Epoch 828/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6410 - accuracy: 0.6208 - val_loss: 0.6555 - val_accuracy: 0.5554\n",
      "Epoch 829/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6410 - accuracy: 0.6207 - val_loss: 0.6622 - val_accuracy: 0.5422\n",
      "Epoch 830/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6410 - accuracy: 0.6212 - val_loss: 0.6503 - val_accuracy: 0.5630\n",
      "Epoch 831/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6411 - accuracy: 0.6197 - val_loss: 0.6692 - val_accuracy: 0.5292\n",
      "Epoch 832/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6413 - accuracy: 0.6218 - val_loss: 0.6431 - val_accuracy: 0.5762\n",
      "Epoch 833/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6417 - accuracy: 0.6178 - val_loss: 0.6817 - val_accuracy: 0.5064\n",
      "Epoch 834/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6426 - accuracy: 0.6201 - val_loss: 0.6335 - val_accuracy: 0.5908\n",
      "Epoch 835/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6431 - accuracy: 0.6146 - val_loss: 0.6928 - val_accuracy: 0.4909\n",
      "Epoch 836/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6444 - accuracy: 0.6166 - val_loss: 0.6359 - val_accuracy: 0.5877\n",
      "Epoch 837/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6426 - accuracy: 0.6165 - val_loss: 0.6720 - val_accuracy: 0.5267\n",
      "Epoch 838/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6415 - accuracy: 0.6215 - val_loss: 0.6547 - val_accuracy: 0.5561\n",
      "Epoch 839/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6409 - accuracy: 0.6205 - val_loss: 0.6509 - val_accuracy: 0.5619\n",
      "Epoch 840/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6409 - accuracy: 0.6205 - val_loss: 0.6714 - val_accuracy: 0.5274\n",
      "Epoch 841/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6415 - accuracy: 0.6204 - val_loss: 0.6366 - val_accuracy: 0.5848\n",
      "Epoch 842/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6422 - accuracy: 0.6172 - val_loss: 0.6863 - val_accuracy: 0.4978\n",
      "Epoch 843/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6432 - accuracy: 0.6188 - val_loss: 0.6372 - val_accuracy: 0.5844\n",
      "Epoch 844/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6424 - accuracy: 0.6155 - val_loss: 0.6783 - val_accuracy: 0.5121\n",
      "Epoch 845/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6421 - accuracy: 0.6212 - val_loss: 0.6461 - val_accuracy: 0.5701\n",
      "Epoch 846/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6411 - accuracy: 0.6200 - val_loss: 0.6575 - val_accuracy: 0.5495\n",
      "Epoch 847/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6406 - accuracy: 0.6214 - val_loss: 0.6652 - val_accuracy: 0.5351\n",
      "Epoch 848/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6409 - accuracy: 0.6217 - val_loss: 0.6413 - val_accuracy: 0.5773\n",
      "Epoch 849/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6415 - accuracy: 0.6180 - val_loss: 0.6838 - val_accuracy: 0.5027\n",
      "Epoch 850/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6429 - accuracy: 0.6188 - val_loss: 0.6338 - val_accuracy: 0.5908\n",
      "Epoch 851/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6428 - accuracy: 0.6163 - val_loss: 0.6796 - val_accuracy: 0.5091\n",
      "Epoch 852/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6420 - accuracy: 0.6209 - val_loss: 0.6494 - val_accuracy: 0.5627\n",
      "Epoch 853/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6411 - accuracy: 0.6192 - val_loss: 0.6580 - val_accuracy: 0.5480\n",
      "Epoch 854/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6405 - accuracy: 0.6218 - val_loss: 0.6615 - val_accuracy: 0.5418\n",
      "Epoch 855/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6407 - accuracy: 0.6211 - val_loss: 0.6441 - val_accuracy: 0.5731\n",
      "Epoch 856/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6410 - accuracy: 0.6197 - val_loss: 0.6738 - val_accuracy: 0.5179\n",
      "Epoch 857/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6413 - accuracy: 0.6213 - val_loss: 0.6420 - val_accuracy: 0.5756\n",
      "Epoch 858/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6416 - accuracy: 0.6170 - val_loss: 0.6800 - val_accuracy: 0.5080\n",
      "Epoch 859/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6420 - accuracy: 0.6205 - val_loss: 0.6387 - val_accuracy: 0.5809\n",
      "Epoch 860/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6418 - accuracy: 0.6179 - val_loss: 0.6710 - val_accuracy: 0.5237\n",
      "Epoch 861/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6410 - accuracy: 0.6222 - val_loss: 0.6522 - val_accuracy: 0.5583\n",
      "Epoch 862/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6407 - accuracy: 0.6205 - val_loss: 0.6599 - val_accuracy: 0.5457\n",
      "Epoch 863/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6403 - accuracy: 0.6220 - val_loss: 0.6567 - val_accuracy: 0.5513\n",
      "Epoch 864/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6403 - accuracy: 0.6206 - val_loss: 0.6515 - val_accuracy: 0.5596\n",
      "Epoch 865/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6404 - accuracy: 0.6199 - val_loss: 0.6647 - val_accuracy: 0.5378\n",
      "Epoch 866/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6404 - accuracy: 0.6225 - val_loss: 0.6482 - val_accuracy: 0.5658\n",
      "Epoch 867/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6407 - accuracy: 0.6202 - val_loss: 0.6742 - val_accuracy: 0.5197\n",
      "Epoch 868/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6410 - accuracy: 0.6214 - val_loss: 0.6383 - val_accuracy: 0.5809\n",
      "Epoch 869/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6415 - accuracy: 0.6186 - val_loss: 0.6814 - val_accuracy: 0.5049\n",
      "Epoch 870/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6418 - accuracy: 0.6204 - val_loss: 0.6393 - val_accuracy: 0.5800\n",
      "Epoch 871/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6414 - accuracy: 0.6175 - val_loss: 0.6785 - val_accuracy: 0.5108\n",
      "Epoch 872/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6414 - accuracy: 0.6215 - val_loss: 0.6419 - val_accuracy: 0.5771\n",
      "Epoch 873/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6408 - accuracy: 0.6192 - val_loss: 0.6682 - val_accuracy: 0.5298\n",
      "Epoch 874/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6404 - accuracy: 0.6221 - val_loss: 0.6500 - val_accuracy: 0.5623\n",
      "Epoch 875/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6401 - accuracy: 0.6209 - val_loss: 0.6607 - val_accuracy: 0.5438\n",
      "Epoch 876/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6400 - accuracy: 0.6225 - val_loss: 0.6569 - val_accuracy: 0.5512\n",
      "Epoch 877/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6399 - accuracy: 0.6227 - val_loss: 0.6554 - val_accuracy: 0.5535\n",
      "Epoch 878/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6399 - accuracy: 0.6217 - val_loss: 0.6604 - val_accuracy: 0.5433\n",
      "Epoch 879/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6399 - accuracy: 0.6227 - val_loss: 0.6511 - val_accuracy: 0.5601\n",
      "Epoch 880/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6399 - accuracy: 0.6210 - val_loss: 0.6664 - val_accuracy: 0.5314\n",
      "Epoch 881/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6401 - accuracy: 0.6223 - val_loss: 0.6452 - val_accuracy: 0.5709\n",
      "Epoch 882/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6403 - accuracy: 0.6199 - val_loss: 0.6765 - val_accuracy: 0.5152\n",
      "Epoch 883/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6409 - accuracy: 0.6216 - val_loss: 0.6369 - val_accuracy: 0.5848\n",
      "Epoch 884/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6413 - accuracy: 0.6179 - val_loss: 0.6852 - val_accuracy: 0.4989\n",
      "Epoch 885/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6420 - accuracy: 0.6194 - val_loss: 0.6363 - val_accuracy: 0.5862\n",
      "Epoch 886/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6414 - accuracy: 0.6175 - val_loss: 0.6804 - val_accuracy: 0.5060\n",
      "Epoch 887/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6414 - accuracy: 0.6208 - val_loss: 0.6422 - val_accuracy: 0.5769\n",
      "Epoch 888/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6404 - accuracy: 0.6199 - val_loss: 0.6656 - val_accuracy: 0.5356\n",
      "Epoch 889/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6399 - accuracy: 0.6227 - val_loss: 0.6539 - val_accuracy: 0.5548\n",
      "Epoch 890/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6397 - accuracy: 0.6218 - val_loss: 0.6541 - val_accuracy: 0.5543\n",
      "Epoch 891/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6396 - accuracy: 0.6222 - val_loss: 0.6631 - val_accuracy: 0.5398\n",
      "Epoch 892/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6397 - accuracy: 0.6226 - val_loss: 0.6458 - val_accuracy: 0.5698\n",
      "Epoch 893/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6400 - accuracy: 0.6202 - val_loss: 0.6744 - val_accuracy: 0.5163\n",
      "Epoch 894/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6404 - accuracy: 0.6223 - val_loss: 0.6392 - val_accuracy: 0.5807\n",
      "Epoch 895/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6407 - accuracy: 0.6184 - val_loss: 0.6837 - val_accuracy: 0.5000\n",
      "Epoch 896/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6417 - accuracy: 0.6200 - val_loss: 0.6338 - val_accuracy: 0.5886\n",
      "Epoch 897/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6415 - accuracy: 0.6170 - val_loss: 0.6823 - val_accuracy: 0.5020\n",
      "Epoch 898/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6414 - accuracy: 0.6207 - val_loss: 0.6420 - val_accuracy: 0.5747\n",
      "Epoch 899/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6403 - accuracy: 0.6194 - val_loss: 0.6663 - val_accuracy: 0.5331\n",
      "Epoch 900/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6397 - accuracy: 0.6231 - val_loss: 0.6530 - val_accuracy: 0.5555\n",
      "Epoch 901/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6394 - accuracy: 0.6219 - val_loss: 0.6520 - val_accuracy: 0.5574\n",
      "Epoch 902/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6394 - accuracy: 0.6220 - val_loss: 0.6660 - val_accuracy: 0.5329\n",
      "Epoch 903/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6396 - accuracy: 0.6225 - val_loss: 0.6428 - val_accuracy: 0.5740\n",
      "Epoch 904/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6400 - accuracy: 0.6198 - val_loss: 0.6800 - val_accuracy: 0.5055\n",
      "Epoch 905/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6410 - accuracy: 0.6214 - val_loss: 0.6342 - val_accuracy: 0.5875\n",
      "Epoch 906/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6413 - accuracy: 0.6180 - val_loss: 0.6853 - val_accuracy: 0.4980\n",
      "Epoch 907/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6417 - accuracy: 0.6201 - val_loss: 0.6390 - val_accuracy: 0.5818\n",
      "Epoch 908/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6405 - accuracy: 0.6183 - val_loss: 0.6714 - val_accuracy: 0.5236\n",
      "Epoch 909/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6399 - accuracy: 0.6232 - val_loss: 0.6491 - val_accuracy: 0.5627\n",
      "Epoch 910/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6394 - accuracy: 0.6217 - val_loss: 0.6549 - val_accuracy: 0.5519\n",
      "Epoch 911/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6391 - accuracy: 0.6230 - val_loss: 0.6634 - val_accuracy: 0.5378\n",
      "Epoch 912/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6394 - accuracy: 0.6228 - val_loss: 0.6436 - val_accuracy: 0.5722\n",
      "Epoch 913/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6397 - accuracy: 0.6204 - val_loss: 0.6777 - val_accuracy: 0.5121\n",
      "Epoch 914/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6406 - accuracy: 0.6216 - val_loss: 0.6356 - val_accuracy: 0.5857\n",
      "Epoch 915/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6409 - accuracy: 0.6192 - val_loss: 0.6829 - val_accuracy: 0.5035\n",
      "Epoch 916/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6410 - accuracy: 0.6212 - val_loss: 0.6412 - val_accuracy: 0.5765\n",
      "Epoch 917/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6402 - accuracy: 0.6196 - val_loss: 0.6712 - val_accuracy: 0.5245\n",
      "Epoch 918/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6397 - accuracy: 0.6230 - val_loss: 0.6469 - val_accuracy: 0.5667\n",
      "Epoch 919/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6394 - accuracy: 0.6214 - val_loss: 0.6587 - val_accuracy: 0.5460\n",
      "Epoch 920/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6390 - accuracy: 0.6240 - val_loss: 0.6582 - val_accuracy: 0.5473\n",
      "Epoch 921/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6391 - accuracy: 0.6232 - val_loss: 0.6517 - val_accuracy: 0.5575\n",
      "Epoch 922/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6390 - accuracy: 0.6220 - val_loss: 0.6644 - val_accuracy: 0.5353\n",
      "Epoch 923/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6392 - accuracy: 0.6234 - val_loss: 0.6453 - val_accuracy: 0.5714\n",
      "Epoch 924/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6394 - accuracy: 0.6220 - val_loss: 0.6717 - val_accuracy: 0.5234\n",
      "Epoch 925/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6395 - accuracy: 0.6235 - val_loss: 0.6424 - val_accuracy: 0.5762\n",
      "Epoch 926/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6398 - accuracy: 0.6199 - val_loss: 0.6799 - val_accuracy: 0.5090\n",
      "Epoch 927/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6405 - accuracy: 0.6217 - val_loss: 0.6328 - val_accuracy: 0.5871\n",
      "Epoch 928/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6411 - accuracy: 0.6183 - val_loss: 0.6877 - val_accuracy: 0.4954\n",
      "Epoch 929/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6416 - accuracy: 0.6203 - val_loss: 0.6364 - val_accuracy: 0.5868\n",
      "Epoch 930/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6407 - accuracy: 0.6174 - val_loss: 0.6769 - val_accuracy: 0.5139\n",
      "Epoch 931/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6401 - accuracy: 0.6221 - val_loss: 0.6450 - val_accuracy: 0.5705\n",
      "Epoch 932/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6393 - accuracy: 0.6223 - val_loss: 0.6572 - val_accuracy: 0.5471\n",
      "Epoch 933/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6387 - accuracy: 0.6245 - val_loss: 0.6623 - val_accuracy: 0.5398\n",
      "Epoch 934/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6389 - accuracy: 0.6235 - val_loss: 0.6447 - val_accuracy: 0.5714\n",
      "Epoch 935/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6392 - accuracy: 0.6213 - val_loss: 0.6764 - val_accuracy: 0.5161\n",
      "Epoch 936/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6401 - accuracy: 0.6219 - val_loss: 0.6349 - val_accuracy: 0.5864\n",
      "Epoch 937/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6405 - accuracy: 0.6193 - val_loss: 0.6824 - val_accuracy: 0.5038\n",
      "Epoch 938/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6406 - accuracy: 0.6219 - val_loss: 0.6404 - val_accuracy: 0.5786\n",
      "Epoch 939/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6400 - accuracy: 0.6193 - val_loss: 0.6724 - val_accuracy: 0.5192\n",
      "Epoch 940/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6394 - accuracy: 0.6234 - val_loss: 0.6456 - val_accuracy: 0.5700\n",
      "Epoch 941/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6392 - accuracy: 0.6214 - val_loss: 0.6589 - val_accuracy: 0.5440\n",
      "Epoch 942/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6385 - accuracy: 0.6244 - val_loss: 0.6590 - val_accuracy: 0.5442\n",
      "Epoch 943/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6387 - accuracy: 0.6233 - val_loss: 0.6506 - val_accuracy: 0.5601\n",
      "Epoch 944/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6387 - accuracy: 0.6225 - val_loss: 0.6653 - val_accuracy: 0.5332\n",
      "Epoch 945/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6388 - accuracy: 0.6236 - val_loss: 0.6443 - val_accuracy: 0.5712\n",
      "Epoch 946/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6391 - accuracy: 0.6218 - val_loss: 0.6696 - val_accuracy: 0.5256\n",
      "Epoch 947/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6389 - accuracy: 0.6240 - val_loss: 0.6458 - val_accuracy: 0.5696\n",
      "Epoch 948/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6391 - accuracy: 0.6207 - val_loss: 0.6717 - val_accuracy: 0.5208\n",
      "Epoch 949/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6391 - accuracy: 0.6236 - val_loss: 0.6402 - val_accuracy: 0.5789\n",
      "Epoch 950/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6393 - accuracy: 0.6210 - val_loss: 0.6738 - val_accuracy: 0.5201\n",
      "Epoch 951/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6393 - accuracy: 0.6234 - val_loss: 0.6413 - val_accuracy: 0.5767\n",
      "Epoch 952/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6393 - accuracy: 0.6200 - val_loss: 0.6777 - val_accuracy: 0.5111\n",
      "Epoch 953/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6396 - accuracy: 0.6229 - val_loss: 0.6379 - val_accuracy: 0.5833\n",
      "Epoch 954/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6395 - accuracy: 0.6205 - val_loss: 0.6778 - val_accuracy: 0.5124\n",
      "Epoch 955/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6397 - accuracy: 0.6226 - val_loss: 0.6412 - val_accuracy: 0.5762\n",
      "Epoch 956/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6390 - accuracy: 0.6212 - val_loss: 0.6692 - val_accuracy: 0.5285\n",
      "Epoch 957/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6387 - accuracy: 0.6244 - val_loss: 0.6490 - val_accuracy: 0.5603\n",
      "Epoch 958/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6383 - accuracy: 0.6236 - val_loss: 0.6587 - val_accuracy: 0.5453\n",
      "Epoch 959/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6381 - accuracy: 0.6244 - val_loss: 0.6553 - val_accuracy: 0.5493\n",
      "Epoch 960/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6381 - accuracy: 0.6245 - val_loss: 0.6530 - val_accuracy: 0.5537\n",
      "Epoch 961/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6381 - accuracy: 0.6244 - val_loss: 0.6624 - val_accuracy: 0.5387\n",
      "Epoch 962/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6381 - accuracy: 0.6252 - val_loss: 0.6489 - val_accuracy: 0.5592\n",
      "Epoch 963/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6382 - accuracy: 0.6229 - val_loss: 0.6668 - val_accuracy: 0.5298\n",
      "Epoch 964/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6384 - accuracy: 0.6245 - val_loss: 0.6439 - val_accuracy: 0.5705\n",
      "Epoch 965/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6385 - accuracy: 0.6221 - val_loss: 0.6735 - val_accuracy: 0.5183\n",
      "Epoch 966/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6388 - accuracy: 0.6240 - val_loss: 0.6390 - val_accuracy: 0.5806\n",
      "Epoch 967/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6392 - accuracy: 0.6205 - val_loss: 0.6839 - val_accuracy: 0.5018\n",
      "Epoch 968/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6403 - accuracy: 0.6219 - val_loss: 0.6302 - val_accuracy: 0.5917\n",
      "Epoch 969/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6405 - accuracy: 0.6169 - val_loss: 0.6898 - val_accuracy: 0.4940\n",
      "Epoch 970/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6412 - accuracy: 0.6206 - val_loss: 0.6367 - val_accuracy: 0.5846\n",
      "Epoch 971/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6395 - accuracy: 0.6189 - val_loss: 0.6703 - val_accuracy: 0.5239\n",
      "Epoch 972/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6385 - accuracy: 0.6241 - val_loss: 0.6522 - val_accuracy: 0.5530\n",
      "Epoch 973/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6379 - accuracy: 0.6237 - val_loss: 0.6475 - val_accuracy: 0.5619\n",
      "Epoch 974/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6380 - accuracy: 0.6230 - val_loss: 0.6734 - val_accuracy: 0.5170\n",
      "Epoch 975/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6389 - accuracy: 0.6241 - val_loss: 0.6334 - val_accuracy: 0.5919\n",
      "Epoch 976/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6397 - accuracy: 0.6190 - val_loss: 0.6920 - val_accuracy: 0.4901\n",
      "Epoch 977/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6418 - accuracy: 0.6189 - val_loss: 0.6338 - val_accuracy: 0.5848\n",
      "Epoch 978/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6402 - accuracy: 0.6194 - val_loss: 0.6695 - val_accuracy: 0.5239\n",
      "Epoch 979/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6383 - accuracy: 0.6249 - val_loss: 0.6581 - val_accuracy: 0.5433\n",
      "Epoch 980/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6382 - accuracy: 0.6243 - val_loss: 0.6442 - val_accuracy: 0.5685\n",
      "Epoch 981/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6381 - accuracy: 0.6237 - val_loss: 0.6728 - val_accuracy: 0.5201\n",
      "Epoch 982/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6393 - accuracy: 0.6219 - val_loss: 0.6356 - val_accuracy: 0.5826\n",
      "Epoch 983/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6394 - accuracy: 0.6201 - val_loss: 0.6771 - val_accuracy: 0.5113\n",
      "Epoch 984/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6391 - accuracy: 0.6231 - val_loss: 0.6449 - val_accuracy: 0.5709\n",
      "Epoch 985/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6391 - accuracy: 0.6210 - val_loss: 0.6687 - val_accuracy: 0.5254\n",
      "Epoch 986/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6382 - accuracy: 0.6240 - val_loss: 0.6432 - val_accuracy: 0.5701\n",
      "Epoch 987/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6388 - accuracy: 0.6210 - val_loss: 0.6627 - val_accuracy: 0.5356\n",
      "Epoch 988/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6378 - accuracy: 0.6252 - val_loss: 0.6527 - val_accuracy: 0.5550\n",
      "Epoch 989/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6381 - accuracy: 0.6239 - val_loss: 0.6629 - val_accuracy: 0.5349\n",
      "Epoch 990/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6378 - accuracy: 0.6249 - val_loss: 0.6490 - val_accuracy: 0.5603\n",
      "Epoch 991/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6377 - accuracy: 0.6234 - val_loss: 0.6588 - val_accuracy: 0.5435\n",
      "Epoch 992/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6378 - accuracy: 0.6242 - val_loss: 0.6531 - val_accuracy: 0.5519\n",
      "Epoch 993/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6374 - accuracy: 0.6243 - val_loss: 0.6593 - val_accuracy: 0.5422\n",
      "Epoch 994/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6377 - accuracy: 0.6251 - val_loss: 0.6589 - val_accuracy: 0.5426\n",
      "Epoch 995/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6374 - accuracy: 0.6255 - val_loss: 0.6499 - val_accuracy: 0.5594\n",
      "Epoch 996/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6376 - accuracy: 0.6237 - val_loss: 0.6627 - val_accuracy: 0.5378\n",
      "Epoch 997/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6376 - accuracy: 0.6250 - val_loss: 0.6456 - val_accuracy: 0.5665\n",
      "Epoch 998/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6377 - accuracy: 0.6228 - val_loss: 0.6733 - val_accuracy: 0.5181\n",
      "Epoch 999/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6381 - accuracy: 0.6251 - val_loss: 0.6376 - val_accuracy: 0.5795\n",
      "Epoch 1000/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6387 - accuracy: 0.6213 - val_loss: 0.6863 - val_accuracy: 0.4989\n",
      "Epoch 1001/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6402 - accuracy: 0.6214 - val_loss: 0.6292 - val_accuracy: 0.5948\n",
      "Epoch 1002/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6402 - accuracy: 0.6168 - val_loss: 0.6895 - val_accuracy: 0.4958\n",
      "Epoch 1003/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6404 - accuracy: 0.6205 - val_loss: 0.6393 - val_accuracy: 0.5802\n",
      "Epoch 1004/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6387 - accuracy: 0.6203 - val_loss: 0.6684 - val_accuracy: 0.5294\n",
      "Epoch 1005/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6377 - accuracy: 0.6254 - val_loss: 0.6498 - val_accuracy: 0.5592\n",
      "Epoch 1006/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6374 - accuracy: 0.6236 - val_loss: 0.6499 - val_accuracy: 0.5575\n",
      "Epoch 1007/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6372 - accuracy: 0.6241 - val_loss: 0.6676 - val_accuracy: 0.5267\n",
      "Epoch 1008/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6377 - accuracy: 0.6252 - val_loss: 0.6411 - val_accuracy: 0.5744\n",
      "Epoch 1009/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6381 - accuracy: 0.6220 - val_loss: 0.6806 - val_accuracy: 0.5090\n",
      "Epoch 1010/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6392 - accuracy: 0.6225 - val_loss: 0.6335 - val_accuracy: 0.5839\n",
      "Epoch 1011/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6393 - accuracy: 0.6193 - val_loss: 0.6797 - val_accuracy: 0.5058\n",
      "Epoch 1012/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6388 - accuracy: 0.6236 - val_loss: 0.6408 - val_accuracy: 0.5791\n",
      "Epoch 1013/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6386 - accuracy: 0.6219 - val_loss: 0.6742 - val_accuracy: 0.5161\n",
      "Epoch 1014/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6382 - accuracy: 0.6243 - val_loss: 0.6376 - val_accuracy: 0.5780\n",
      "Epoch 1015/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6386 - accuracy: 0.6206 - val_loss: 0.6717 - val_accuracy: 0.5239\n",
      "Epoch 1016/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6379 - accuracy: 0.6247 - val_loss: 0.6449 - val_accuracy: 0.5711\n",
      "Epoch 1017/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6378 - accuracy: 0.6220 - val_loss: 0.6680 - val_accuracy: 0.5278\n",
      "Epoch 1018/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6374 - accuracy: 0.6250 - val_loss: 0.6437 - val_accuracy: 0.5692\n",
      "Epoch 1019/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6375 - accuracy: 0.6231 - val_loss: 0.6636 - val_accuracy: 0.5338\n",
      "Epoch 1020/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6372 - accuracy: 0.6255 - val_loss: 0.6506 - val_accuracy: 0.5546\n",
      "Epoch 1021/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6370 - accuracy: 0.6245 - val_loss: 0.6590 - val_accuracy: 0.5415\n",
      "Epoch 1022/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6369 - accuracy: 0.6263 - val_loss: 0.6555 - val_accuracy: 0.5464\n",
      "Epoch 1023/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6368 - accuracy: 0.6259 - val_loss: 0.6515 - val_accuracy: 0.5550\n",
      "Epoch 1024/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6368 - accuracy: 0.6249 - val_loss: 0.6599 - val_accuracy: 0.5429\n",
      "Epoch 1025/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6368 - accuracy: 0.6260 - val_loss: 0.6488 - val_accuracy: 0.5586\n",
      "Epoch 1026/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6369 - accuracy: 0.6243 - val_loss: 0.6687 - val_accuracy: 0.5270\n",
      "Epoch 1027/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6372 - accuracy: 0.6252 - val_loss: 0.6411 - val_accuracy: 0.5744\n",
      "Epoch 1028/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6375 - accuracy: 0.6230 - val_loss: 0.6784 - val_accuracy: 0.5102\n",
      "Epoch 1029/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6383 - accuracy: 0.6240 - val_loss: 0.6322 - val_accuracy: 0.5935\n",
      "Epoch 1030/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6389 - accuracy: 0.6193 - val_loss: 0.6924 - val_accuracy: 0.4909\n",
      "Epoch 1031/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6405 - accuracy: 0.6207 - val_loss: 0.6301 - val_accuracy: 0.5930\n",
      "Epoch 1032/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6396 - accuracy: 0.6185 - val_loss: 0.6845 - val_accuracy: 0.5029\n",
      "Epoch 1033/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6392 - accuracy: 0.6222 - val_loss: 0.6429 - val_accuracy: 0.5727\n",
      "Epoch 1034/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6373 - accuracy: 0.6227 - val_loss: 0.6531 - val_accuracy: 0.5515\n",
      "Epoch 1035/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6366 - accuracy: 0.6255 - val_loss: 0.6700 - val_accuracy: 0.5212\n",
      "Epoch 1036/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6373 - accuracy: 0.6258 - val_loss: 0.6329 - val_accuracy: 0.5904\n",
      "Epoch 1037/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6385 - accuracy: 0.6212 - val_loss: 0.6945 - val_accuracy: 0.4881\n",
      "Epoch 1038/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6412 - accuracy: 0.6201 - val_loss: 0.6302 - val_accuracy: 0.5919\n",
      "Epoch 1039/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6395 - accuracy: 0.6164 - val_loss: 0.6756 - val_accuracy: 0.5133\n",
      "Epoch 1040/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6378 - accuracy: 0.6242 - val_loss: 0.6535 - val_accuracy: 0.5491\n",
      "Epoch 1041/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6368 - accuracy: 0.6255 - val_loss: 0.6437 - val_accuracy: 0.5663\n",
      "Epoch 1042/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6369 - accuracy: 0.6243 - val_loss: 0.6748 - val_accuracy: 0.5155\n",
      "Epoch 1043/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6384 - accuracy: 0.6241 - val_loss: 0.6317 - val_accuracy: 0.5879\n",
      "Epoch 1044/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6386 - accuracy: 0.6190 - val_loss: 0.6809 - val_accuracy: 0.5046\n",
      "Epoch 1045/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6385 - accuracy: 0.6230 - val_loss: 0.6445 - val_accuracy: 0.5714\n",
      "Epoch 1046/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6377 - accuracy: 0.6228 - val_loss: 0.6611 - val_accuracy: 0.5380\n",
      "Epoch 1047/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6365 - accuracy: 0.6259 - val_loss: 0.6546 - val_accuracy: 0.5491\n",
      "Epoch 1048/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6368 - accuracy: 0.6249 - val_loss: 0.6476 - val_accuracy: 0.5603\n",
      "Epoch 1049/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6366 - accuracy: 0.6248 - val_loss: 0.6660 - val_accuracy: 0.5252\n",
      "Epoch 1050/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6369 - accuracy: 0.6264 - val_loss: 0.6450 - val_accuracy: 0.5680\n",
      "Epoch 1051/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6370 - accuracy: 0.6239 - val_loss: 0.6699 - val_accuracy: 0.5247\n",
      "Epoch 1052/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6372 - accuracy: 0.6248 - val_loss: 0.6402 - val_accuracy: 0.5751\n",
      "Epoch 1053/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6375 - accuracy: 0.6222 - val_loss: 0.6697 - val_accuracy: 0.5250\n",
      "Epoch 1054/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6368 - accuracy: 0.6264 - val_loss: 0.6467 - val_accuracy: 0.5654\n",
      "Epoch 1055/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6372 - accuracy: 0.6239 - val_loss: 0.6694 - val_accuracy: 0.5234\n",
      "Epoch 1056/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6368 - accuracy: 0.6264 - val_loss: 0.6398 - val_accuracy: 0.5758\n",
      "Epoch 1057/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6372 - accuracy: 0.6229 - val_loss: 0.6729 - val_accuracy: 0.5225\n",
      "Epoch 1058/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6373 - accuracy: 0.6255 - val_loss: 0.6416 - val_accuracy: 0.5751\n",
      "Epoch 1059/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6371 - accuracy: 0.6225 - val_loss: 0.6744 - val_accuracy: 0.5135\n",
      "Epoch 1060/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6371 - accuracy: 0.6257 - val_loss: 0.6394 - val_accuracy: 0.5762\n",
      "Epoch 1061/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6370 - accuracy: 0.6233 - val_loss: 0.6712 - val_accuracy: 0.5237\n",
      "Epoch 1062/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6370 - accuracy: 0.6259 - val_loss: 0.6433 - val_accuracy: 0.5705\n",
      "Epoch 1063/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6365 - accuracy: 0.6232 - val_loss: 0.6661 - val_accuracy: 0.5314\n",
      "Epoch 1064/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6363 - accuracy: 0.6259 - val_loss: 0.6503 - val_accuracy: 0.5570\n",
      "Epoch 1065/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6362 - accuracy: 0.6256 - val_loss: 0.6590 - val_accuracy: 0.5440\n",
      "Epoch 1066/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6360 - accuracy: 0.6261 - val_loss: 0.6526 - val_accuracy: 0.5530\n",
      "Epoch 1067/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6360 - accuracy: 0.6260 - val_loss: 0.6561 - val_accuracy: 0.5491\n",
      "Epoch 1068/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6359 - accuracy: 0.6265 - val_loss: 0.6573 - val_accuracy: 0.5449\n",
      "Epoch 1069/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6359 - accuracy: 0.6263 - val_loss: 0.6535 - val_accuracy: 0.5528\n",
      "Epoch 1070/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6359 - accuracy: 0.6263 - val_loss: 0.6585 - val_accuracy: 0.5444\n",
      "Epoch 1071/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6359 - accuracy: 0.6268 - val_loss: 0.6496 - val_accuracy: 0.5574\n",
      "Epoch 1072/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6359 - accuracy: 0.6250 - val_loss: 0.6641 - val_accuracy: 0.5343\n",
      "Epoch 1073/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6360 - accuracy: 0.6271 - val_loss: 0.6444 - val_accuracy: 0.5698\n",
      "Epoch 1074/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6363 - accuracy: 0.6234 - val_loss: 0.6747 - val_accuracy: 0.5174\n",
      "Epoch 1075/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6369 - accuracy: 0.6261 - val_loss: 0.6331 - val_accuracy: 0.5882\n",
      "Epoch 1076/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6378 - accuracy: 0.6209 - val_loss: 0.6941 - val_accuracy: 0.4912\n",
      "Epoch 1077/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6400 - accuracy: 0.6209 - val_loss: 0.6277 - val_accuracy: 0.5979\n",
      "Epoch 1078/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6392 - accuracy: 0.6185 - val_loss: 0.6904 - val_accuracy: 0.4929\n",
      "Epoch 1079/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6395 - accuracy: 0.6221 - val_loss: 0.6374 - val_accuracy: 0.5806\n",
      "Epoch 1080/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6370 - accuracy: 0.6221 - val_loss: 0.6576 - val_accuracy: 0.5448\n",
      "Epoch 1081/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6358 - accuracy: 0.6266 - val_loss: 0.6662 - val_accuracy: 0.5303\n",
      "Epoch 1082/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6361 - accuracy: 0.6271 - val_loss: 0.6350 - val_accuracy: 0.5866\n",
      "Epoch 1083/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6373 - accuracy: 0.6223 - val_loss: 0.6905 - val_accuracy: 0.4929\n",
      "Epoch 1084/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6397 - accuracy: 0.6213 - val_loss: 0.6291 - val_accuracy: 0.5910\n",
      "Epoch 1085/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6387 - accuracy: 0.6183 - val_loss: 0.6802 - val_accuracy: 0.5057\n",
      "Epoch 1086/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6375 - accuracy: 0.6245 - val_loss: 0.6479 - val_accuracy: 0.5608\n",
      "Epoch 1087/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6363 - accuracy: 0.6248 - val_loss: 0.6511 - val_accuracy: 0.5532\n",
      "Epoch 1088/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6357 - accuracy: 0.6269 - val_loss: 0.6647 - val_accuracy: 0.5318\n",
      "Epoch 1089/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6363 - accuracy: 0.6261 - val_loss: 0.6380 - val_accuracy: 0.5754\n",
      "Epoch 1090/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6365 - accuracy: 0.6228 - val_loss: 0.6746 - val_accuracy: 0.5130\n",
      "Epoch 1091/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6368 - accuracy: 0.6262 - val_loss: 0.6401 - val_accuracy: 0.5740\n",
      "Epoch 1092/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6369 - accuracy: 0.6221 - val_loss: 0.6740 - val_accuracy: 0.5166\n",
      "Epoch 1093/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6368 - accuracy: 0.6253 - val_loss: 0.6402 - val_accuracy: 0.5731\n",
      "Epoch 1094/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6366 - accuracy: 0.6237 - val_loss: 0.6644 - val_accuracy: 0.5314\n",
      "Epoch 1095/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6358 - accuracy: 0.6274 - val_loss: 0.6523 - val_accuracy: 0.5512\n",
      "Epoch 1096/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6359 - accuracy: 0.6264 - val_loss: 0.6562 - val_accuracy: 0.5446\n",
      "Epoch 1097/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6354 - accuracy: 0.6270 - val_loss: 0.6537 - val_accuracy: 0.5491\n",
      "Epoch 1098/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6356 - accuracy: 0.6262 - val_loss: 0.6512 - val_accuracy: 0.5533\n",
      "Epoch 1099/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6355 - accuracy: 0.6260 - val_loss: 0.6598 - val_accuracy: 0.5407\n",
      "Epoch 1100/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6354 - accuracy: 0.6278 - val_loss: 0.6514 - val_accuracy: 0.5544\n",
      "Epoch 1101/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6356 - accuracy: 0.6259 - val_loss: 0.6643 - val_accuracy: 0.5331\n",
      "Epoch 1102/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6356 - accuracy: 0.6264 - val_loss: 0.6433 - val_accuracy: 0.5701\n",
      "Epoch 1103/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6359 - accuracy: 0.6242 - val_loss: 0.6706 - val_accuracy: 0.5241\n",
      "Epoch 1104/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6360 - accuracy: 0.6268 - val_loss: 0.6411 - val_accuracy: 0.5753\n",
      "Epoch 1105/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6363 - accuracy: 0.6231 - val_loss: 0.6801 - val_accuracy: 0.5071\n",
      "Epoch 1106/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6371 - accuracy: 0.6255 - val_loss: 0.6298 - val_accuracy: 0.5901\n",
      "Epoch 1107/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6378 - accuracy: 0.6209 - val_loss: 0.6920 - val_accuracy: 0.4914\n",
      "Epoch 1108/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6392 - accuracy: 0.6226 - val_loss: 0.6322 - val_accuracy: 0.5908\n",
      "Epoch 1109/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6377 - accuracy: 0.6201 - val_loss: 0.6786 - val_accuracy: 0.5104\n",
      "Epoch 1110/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6369 - accuracy: 0.6249 - val_loss: 0.6452 - val_accuracy: 0.5654\n",
      "Epoch 1111/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6357 - accuracy: 0.6252 - val_loss: 0.6520 - val_accuracy: 0.5532\n",
      "Epoch 1112/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6351 - accuracy: 0.6266 - val_loss: 0.6680 - val_accuracy: 0.5274\n",
      "Epoch 1113/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6358 - accuracy: 0.6278 - val_loss: 0.6348 - val_accuracy: 0.5859\n",
      "Epoch 1114/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6366 - accuracy: 0.6230 - val_loss: 0.6886 - val_accuracy: 0.4976\n",
      "Epoch 1115/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6387 - accuracy: 0.6219 - val_loss: 0.6317 - val_accuracy: 0.5866\n",
      "Epoch 1116/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6379 - accuracy: 0.6193 - val_loss: 0.6789 - val_accuracy: 0.5095\n",
      "Epoch 1117/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6368 - accuracy: 0.6255 - val_loss: 0.6480 - val_accuracy: 0.5634\n",
      "Epoch 1118/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6360 - accuracy: 0.6251 - val_loss: 0.6535 - val_accuracy: 0.5482\n",
      "Epoch 1119/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6350 - accuracy: 0.6283 - val_loss: 0.6592 - val_accuracy: 0.5404\n",
      "Epoch 1120/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6357 - accuracy: 0.6264 - val_loss: 0.6454 - val_accuracy: 0.5647\n",
      "Epoch 1121/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6353 - accuracy: 0.6251 - val_loss: 0.6662 - val_accuracy: 0.5287\n",
      "Epoch 1122/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6357 - accuracy: 0.6268 - val_loss: 0.6479 - val_accuracy: 0.5608\n",
      "Epoch 1123/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6354 - accuracy: 0.6250 - val_loss: 0.6611 - val_accuracy: 0.5374\n",
      "Epoch 1124/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6353 - accuracy: 0.6275 - val_loss: 0.6501 - val_accuracy: 0.5557\n",
      "Epoch 1125/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6353 - accuracy: 0.6260 - val_loss: 0.6563 - val_accuracy: 0.5464\n",
      "Epoch 1126/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6350 - accuracy: 0.6287 - val_loss: 0.6577 - val_accuracy: 0.5444\n",
      "Epoch 1127/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6352 - accuracy: 0.6278 - val_loss: 0.6530 - val_accuracy: 0.5501\n",
      "Epoch 1128/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6348 - accuracy: 0.6281 - val_loss: 0.6540 - val_accuracy: 0.5504\n",
      "Epoch 1129/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6351 - accuracy: 0.6270 - val_loss: 0.6547 - val_accuracy: 0.5486\n",
      "Epoch 1130/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6348 - accuracy: 0.6279 - val_loss: 0.6545 - val_accuracy: 0.5497\n",
      "Epoch 1131/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6349 - accuracy: 0.6275 - val_loss: 0.6605 - val_accuracy: 0.5391\n",
      "Epoch 1132/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6348 - accuracy: 0.6284 - val_loss: 0.6490 - val_accuracy: 0.5583\n",
      "Epoch 1133/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6349 - accuracy: 0.6270 - val_loss: 0.6624 - val_accuracy: 0.5382\n",
      "Epoch 1134/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6349 - accuracy: 0.6281 - val_loss: 0.6461 - val_accuracy: 0.5649\n",
      "Epoch 1135/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6350 - accuracy: 0.6251 - val_loss: 0.6701 - val_accuracy: 0.5245\n",
      "Epoch 1136/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6352 - accuracy: 0.6276 - val_loss: 0.6400 - val_accuracy: 0.5776\n",
      "Epoch 1137/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6356 - accuracy: 0.6239 - val_loss: 0.6797 - val_accuracy: 0.5104\n",
      "Epoch 1138/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6366 - accuracy: 0.6257 - val_loss: 0.6295 - val_accuracy: 0.5915\n",
      "Epoch 1139/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6372 - accuracy: 0.6213 - val_loss: 0.6952 - val_accuracy: 0.4883\n",
      "Epoch 1140/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6391 - accuracy: 0.6228 - val_loss: 0.6311 - val_accuracy: 0.5926\n",
      "Epoch 1141/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6374 - accuracy: 0.6203 - val_loss: 0.6786 - val_accuracy: 0.5100\n",
      "Epoch 1142/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6364 - accuracy: 0.6248 - val_loss: 0.6468 - val_accuracy: 0.5623\n",
      "Epoch 1143/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6348 - accuracy: 0.6258 - val_loss: 0.6461 - val_accuracy: 0.5654\n",
      "Epoch 1144/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6347 - accuracy: 0.6260 - val_loss: 0.6778 - val_accuracy: 0.5075\n",
      "Epoch 1145/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6363 - accuracy: 0.6267 - val_loss: 0.6261 - val_accuracy: 0.5968\n",
      "Epoch 1146/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6381 - accuracy: 0.6201 - val_loss: 0.7034 - val_accuracy: 0.4766\n",
      "Epoch 1147/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6415 - accuracy: 0.6196 - val_loss: 0.6361 - val_accuracy: 0.5791\n",
      "Epoch 1148/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6368 - accuracy: 0.6211 - val_loss: 0.6507 - val_accuracy: 0.5544\n",
      "Epoch 1149/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6348 - accuracy: 0.6270 - val_loss: 0.6837 - val_accuracy: 0.4971\n",
      "Epoch 1150/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6373 - accuracy: 0.6254 - val_loss: 0.6245 - val_accuracy: 0.5961\n",
      "Epoch 1151/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6384 - accuracy: 0.6190 - val_loss: 0.6914 - val_accuracy: 0.4929\n",
      "Epoch 1152/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6400 - accuracy: 0.6210 - val_loss: 0.6391 - val_accuracy: 0.5692\n",
      "Epoch 1153/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6376 - accuracy: 0.6196 - val_loss: 0.6499 - val_accuracy: 0.5544\n",
      "Epoch 1154/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6349 - accuracy: 0.6264 - val_loss: 0.6749 - val_accuracy: 0.5139\n",
      "Epoch 1155/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6371 - accuracy: 0.6246 - val_loss: 0.6460 - val_accuracy: 0.5596\n",
      "Epoch 1156/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6367 - accuracy: 0.6245 - val_loss: 0.6613 - val_accuracy: 0.5340\n",
      "Epoch 1157/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6355 - accuracy: 0.6257 - val_loss: 0.6408 - val_accuracy: 0.5691\n",
      "Epoch 1158/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6374 - accuracy: 0.6213 - val_loss: 0.6677 - val_accuracy: 0.5252\n",
      "Epoch 1159/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6356 - accuracy: 0.6266 - val_loss: 0.6441 - val_accuracy: 0.5639\n",
      "Epoch 1160/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6364 - accuracy: 0.6238 - val_loss: 0.6762 - val_accuracy: 0.5091\n",
      "Epoch 1161/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6362 - accuracy: 0.6259 - val_loss: 0.6419 - val_accuracy: 0.5687\n",
      "Epoch 1162/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6351 - accuracy: 0.6258 - val_loss: 0.6521 - val_accuracy: 0.5532\n",
      "Epoch 1163/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6349 - accuracy: 0.6259 - val_loss: 0.6639 - val_accuracy: 0.5329\n",
      "Epoch 1164/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6349 - accuracy: 0.6280 - val_loss: 0.6385 - val_accuracy: 0.5742\n",
      "Epoch 1165/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6359 - accuracy: 0.6233 - val_loss: 0.6853 - val_accuracy: 0.4963\n",
      "Epoch 1166/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6372 - accuracy: 0.6231 - val_loss: 0.6317 - val_accuracy: 0.5868\n",
      "Epoch 1167/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6363 - accuracy: 0.6213 - val_loss: 0.6700 - val_accuracy: 0.5258\n",
      "Epoch 1168/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6354 - accuracy: 0.6263 - val_loss: 0.6531 - val_accuracy: 0.5513\n",
      "Epoch 1169/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6345 - accuracy: 0.6281 - val_loss: 0.6441 - val_accuracy: 0.5667\n",
      "Epoch 1170/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6347 - accuracy: 0.6262 - val_loss: 0.6811 - val_accuracy: 0.5004\n",
      "Epoch 1171/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6364 - accuracy: 0.6253 - val_loss: 0.6317 - val_accuracy: 0.5873\n",
      "Epoch 1172/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6362 - accuracy: 0.6233 - val_loss: 0.6779 - val_accuracy: 0.5119\n",
      "Epoch 1173/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6361 - accuracy: 0.6266 - val_loss: 0.6427 - val_accuracy: 0.5714\n",
      "Epoch 1174/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6349 - accuracy: 0.6236 - val_loss: 0.6543 - val_accuracy: 0.5495\n",
      "Epoch 1175/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6340 - accuracy: 0.6294 - val_loss: 0.6679 - val_accuracy: 0.5234\n",
      "Epoch 1176/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6347 - accuracy: 0.6279 - val_loss: 0.6387 - val_accuracy: 0.5773\n",
      "Epoch 1177/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6351 - accuracy: 0.6250 - val_loss: 0.6791 - val_accuracy: 0.5075\n",
      "Epoch 1178/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6362 - accuracy: 0.6262 - val_loss: 0.6335 - val_accuracy: 0.5849\n",
      "Epoch 1179/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6358 - accuracy: 0.6228 - val_loss: 0.6755 - val_accuracy: 0.5117\n",
      "Epoch 1180/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6353 - accuracy: 0.6269 - val_loss: 0.6467 - val_accuracy: 0.5614\n",
      "Epoch 1181/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6348 - accuracy: 0.6262 - val_loss: 0.6575 - val_accuracy: 0.5449\n",
      "Epoch 1182/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6338 - accuracy: 0.6296 - val_loss: 0.6599 - val_accuracy: 0.5407\n",
      "Epoch 1183/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6343 - accuracy: 0.6285 - val_loss: 0.6412 - val_accuracy: 0.5725\n",
      "Epoch 1184/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6344 - accuracy: 0.6258 - val_loss: 0.6706 - val_accuracy: 0.5205\n",
      "Epoch 1185/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6348 - accuracy: 0.6274 - val_loss: 0.6421 - val_accuracy: 0.5703\n",
      "Epoch 1186/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6348 - accuracy: 0.6249 - val_loss: 0.6705 - val_accuracy: 0.5230\n",
      "Epoch 1187/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6345 - accuracy: 0.6280 - val_loss: 0.6460 - val_accuracy: 0.5659\n",
      "Epoch 1188/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6343 - accuracy: 0.6246 - val_loss: 0.6592 - val_accuracy: 0.5415\n",
      "Epoch 1189/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6338 - accuracy: 0.6293 - val_loss: 0.6549 - val_accuracy: 0.5460\n",
      "Epoch 1190/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6340 - accuracy: 0.6285 - val_loss: 0.6510 - val_accuracy: 0.5539\n",
      "Epoch 1191/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6337 - accuracy: 0.6281 - val_loss: 0.6624 - val_accuracy: 0.5391\n",
      "Epoch 1192/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6340 - accuracy: 0.6296 - val_loss: 0.6453 - val_accuracy: 0.5663\n",
      "Epoch 1193/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6341 - accuracy: 0.6248 - val_loss: 0.6659 - val_accuracy: 0.5329\n",
      "Epoch 1194/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6340 - accuracy: 0.6287 - val_loss: 0.6468 - val_accuracy: 0.5617\n",
      "Epoch 1195/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6340 - accuracy: 0.6276 - val_loss: 0.6647 - val_accuracy: 0.5343\n",
      "Epoch 1196/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6338 - accuracy: 0.6298 - val_loss: 0.6473 - val_accuracy: 0.5641\n",
      "Epoch 1197/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6338 - accuracy: 0.6262 - val_loss: 0.6613 - val_accuracy: 0.5417\n",
      "Epoch 1198/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6336 - accuracy: 0.6293 - val_loss: 0.6513 - val_accuracy: 0.5535\n",
      "Epoch 1199/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6336 - accuracy: 0.6281 - val_loss: 0.6576 - val_accuracy: 0.5464\n",
      "Epoch 1200/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6335 - accuracy: 0.6299 - val_loss: 0.6543 - val_accuracy: 0.5515\n",
      "Epoch 1201/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6335 - accuracy: 0.6286 - val_loss: 0.6530 - val_accuracy: 0.5517\n",
      "Epoch 1202/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6334 - accuracy: 0.6287 - val_loss: 0.6575 - val_accuracy: 0.5444\n",
      "Epoch 1203/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6334 - accuracy: 0.6290 - val_loss: 0.6529 - val_accuracy: 0.5490\n",
      "Epoch 1204/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6334 - accuracy: 0.6294 - val_loss: 0.6603 - val_accuracy: 0.5424\n",
      "Epoch 1205/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6334 - accuracy: 0.6299 - val_loss: 0.6482 - val_accuracy: 0.5610\n",
      "Epoch 1206/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6335 - accuracy: 0.6272 - val_loss: 0.6634 - val_accuracy: 0.5378\n",
      "Epoch 1207/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6336 - accuracy: 0.6292 - val_loss: 0.6454 - val_accuracy: 0.5670\n",
      "Epoch 1208/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6336 - accuracy: 0.6261 - val_loss: 0.6701 - val_accuracy: 0.5258\n",
      "Epoch 1209/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6339 - accuracy: 0.6293 - val_loss: 0.6397 - val_accuracy: 0.5775\n",
      "Epoch 1210/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6342 - accuracy: 0.6259 - val_loss: 0.6782 - val_accuracy: 0.5108\n",
      "Epoch 1211/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6350 - accuracy: 0.6273 - val_loss: 0.6328 - val_accuracy: 0.5842\n",
      "Epoch 1212/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6353 - accuracy: 0.6231 - val_loss: 0.6847 - val_accuracy: 0.5002\n",
      "Epoch 1213/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6358 - accuracy: 0.6268 - val_loss: 0.6345 - val_accuracy: 0.5859\n",
      "Epoch 1214/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6353 - accuracy: 0.6230 - val_loss: 0.6796 - val_accuracy: 0.5088\n",
      "Epoch 1215/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6353 - accuracy: 0.6263 - val_loss: 0.6382 - val_accuracy: 0.5751\n",
      "Epoch 1216/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6345 - accuracy: 0.6250 - val_loss: 0.6633 - val_accuracy: 0.5362\n",
      "Epoch 1217/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6334 - accuracy: 0.6298 - val_loss: 0.6540 - val_accuracy: 0.5532\n",
      "Epoch 1218/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6336 - accuracy: 0.6285 - val_loss: 0.6523 - val_accuracy: 0.5513\n",
      "Epoch 1219/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6331 - accuracy: 0.6297 - val_loss: 0.6590 - val_accuracy: 0.5406\n",
      "Epoch 1220/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6335 - accuracy: 0.6274 - val_loss: 0.6468 - val_accuracy: 0.5627\n",
      "Epoch 1221/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6333 - accuracy: 0.6279 - val_loss: 0.6640 - val_accuracy: 0.5331\n",
      "Epoch 1222/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6335 - accuracy: 0.6302 - val_loss: 0.6476 - val_accuracy: 0.5612\n",
      "Epoch 1223/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6334 - accuracy: 0.6270 - val_loss: 0.6659 - val_accuracy: 0.5289\n",
      "Epoch 1224/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6336 - accuracy: 0.6286 - val_loss: 0.6418 - val_accuracy: 0.5685\n",
      "Epoch 1225/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6337 - accuracy: 0.6266 - val_loss: 0.6691 - val_accuracy: 0.5270\n",
      "Epoch 1226/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6337 - accuracy: 0.6293 - val_loss: 0.6411 - val_accuracy: 0.5738\n",
      "Epoch 1227/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6341 - accuracy: 0.6252 - val_loss: 0.6767 - val_accuracy: 0.5122\n",
      "Epoch 1228/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6346 - accuracy: 0.6269 - val_loss: 0.6329 - val_accuracy: 0.5840\n",
      "Epoch 1229/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6352 - accuracy: 0.6233 - val_loss: 0.6841 - val_accuracy: 0.5024\n",
      "Epoch 1230/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6356 - accuracy: 0.6269 - val_loss: 0.6342 - val_accuracy: 0.5849\n",
      "Epoch 1231/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6355 - accuracy: 0.6228 - val_loss: 0.6816 - val_accuracy: 0.5044\n",
      "Epoch 1232/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6352 - accuracy: 0.6264 - val_loss: 0.6364 - val_accuracy: 0.5784\n",
      "Epoch 1233/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6350 - accuracy: 0.6252 - val_loss: 0.6681 - val_accuracy: 0.5296\n",
      "Epoch 1234/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6335 - accuracy: 0.6292 - val_loss: 0.6492 - val_accuracy: 0.5634\n",
      "Epoch 1235/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6338 - accuracy: 0.6267 - val_loss: 0.6582 - val_accuracy: 0.5437\n",
      "Epoch 1236/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6328 - accuracy: 0.6300 - val_loss: 0.6511 - val_accuracy: 0.5528\n",
      "Epoch 1237/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6335 - accuracy: 0.6278 - val_loss: 0.6569 - val_accuracy: 0.5449\n",
      "Epoch 1238/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6328 - accuracy: 0.6290 - val_loss: 0.6534 - val_accuracy: 0.5530\n",
      "Epoch 1239/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6332 - accuracy: 0.6285 - val_loss: 0.6601 - val_accuracy: 0.5400\n",
      "Epoch 1240/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6329 - accuracy: 0.6306 - val_loss: 0.6486 - val_accuracy: 0.5585\n",
      "Epoch 1241/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6330 - accuracy: 0.6289 - val_loss: 0.6620 - val_accuracy: 0.5384\n",
      "Epoch 1242/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6331 - accuracy: 0.6290 - val_loss: 0.6470 - val_accuracy: 0.5619\n",
      "Epoch 1243/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6329 - accuracy: 0.6268 - val_loss: 0.6663 - val_accuracy: 0.5323\n",
      "Epoch 1244/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6332 - accuracy: 0.6303 - val_loss: 0.6427 - val_accuracy: 0.5716\n",
      "Epoch 1245/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6331 - accuracy: 0.6272 - val_loss: 0.6712 - val_accuracy: 0.5221\n",
      "Epoch 1246/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6337 - accuracy: 0.6287 - val_loss: 0.6380 - val_accuracy: 0.5775\n",
      "Epoch 1247/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6336 - accuracy: 0.6256 - val_loss: 0.6776 - val_accuracy: 0.5133\n",
      "Epoch 1248/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6341 - accuracy: 0.6290 - val_loss: 0.6364 - val_accuracy: 0.5817\n",
      "Epoch 1249/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6341 - accuracy: 0.6244 - val_loss: 0.6811 - val_accuracy: 0.5077\n",
      "Epoch 1250/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6348 - accuracy: 0.6270 - val_loss: 0.6337 - val_accuracy: 0.5820\n",
      "Epoch 1251/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6345 - accuracy: 0.6242 - val_loss: 0.6776 - val_accuracy: 0.5133\n",
      "Epoch 1252/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6342 - accuracy: 0.6290 - val_loss: 0.6398 - val_accuracy: 0.5762\n",
      "Epoch 1253/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6340 - accuracy: 0.6242 - val_loss: 0.6718 - val_accuracy: 0.5210\n",
      "Epoch 1254/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6335 - accuracy: 0.6286 - val_loss: 0.6407 - val_accuracy: 0.5718\n",
      "Epoch 1255/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6338 - accuracy: 0.6267 - val_loss: 0.6680 - val_accuracy: 0.5296\n",
      "Epoch 1256/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6330 - accuracy: 0.6302 - val_loss: 0.6432 - val_accuracy: 0.5714\n",
      "Epoch 1257/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6336 - accuracy: 0.6256 - val_loss: 0.6745 - val_accuracy: 0.5168\n",
      "Epoch 1258/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6336 - accuracy: 0.6289 - val_loss: 0.6329 - val_accuracy: 0.5826\n",
      "Epoch 1259/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6349 - accuracy: 0.6239 - val_loss: 0.6880 - val_accuracy: 0.4963\n",
      "Epoch 1260/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6357 - accuracy: 0.6262 - val_loss: 0.6308 - val_accuracy: 0.5891\n",
      "Epoch 1261/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6353 - accuracy: 0.6239 - val_loss: 0.6828 - val_accuracy: 0.5058\n",
      "Epoch 1262/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6349 - accuracy: 0.6272 - val_loss: 0.6385 - val_accuracy: 0.5738\n",
      "Epoch 1263/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6337 - accuracy: 0.6265 - val_loss: 0.6582 - val_accuracy: 0.5431\n",
      "Epoch 1264/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6323 - accuracy: 0.6313 - val_loss: 0.6612 - val_accuracy: 0.5402\n",
      "Epoch 1265/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6328 - accuracy: 0.6301 - val_loss: 0.6405 - val_accuracy: 0.5740\n",
      "Epoch 1266/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6330 - accuracy: 0.6277 - val_loss: 0.6775 - val_accuracy: 0.5126\n",
      "Epoch 1267/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6344 - accuracy: 0.6269 - val_loss: 0.6340 - val_accuracy: 0.5818\n",
      "Epoch 1268/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6346 - accuracy: 0.6243 - val_loss: 0.6808 - val_accuracy: 0.5075\n",
      "Epoch 1269/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6343 - accuracy: 0.6282 - val_loss: 0.6394 - val_accuracy: 0.5764\n",
      "Epoch 1270/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6345 - accuracy: 0.6233 - val_loss: 0.6732 - val_accuracy: 0.5179\n",
      "Epoch 1271/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6335 - accuracy: 0.6281 - val_loss: 0.6387 - val_accuracy: 0.5711\n",
      "Epoch 1272/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6342 - accuracy: 0.6258 - val_loss: 0.6647 - val_accuracy: 0.5327\n",
      "Epoch 1273/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6326 - accuracy: 0.6299 - val_loss: 0.6484 - val_accuracy: 0.5638\n",
      "Epoch 1274/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6334 - accuracy: 0.6267 - val_loss: 0.6645 - val_accuracy: 0.5309\n",
      "Epoch 1275/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6324 - accuracy: 0.6309 - val_loss: 0.6433 - val_accuracy: 0.5647\n",
      "Epoch 1276/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6330 - accuracy: 0.6279 - val_loss: 0.6668 - val_accuracy: 0.5307\n",
      "Epoch 1277/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6328 - accuracy: 0.6288 - val_loss: 0.6439 - val_accuracy: 0.5687\n",
      "Epoch 1278/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6327 - accuracy: 0.6276 - val_loss: 0.6700 - val_accuracy: 0.5243\n",
      "Epoch 1279/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6328 - accuracy: 0.6305 - val_loss: 0.6419 - val_accuracy: 0.5718\n",
      "Epoch 1280/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6327 - accuracy: 0.6276 - val_loss: 0.6681 - val_accuracy: 0.5280\n",
      "Epoch 1281/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6328 - accuracy: 0.6290 - val_loss: 0.6427 - val_accuracy: 0.5687\n",
      "Epoch 1282/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6325 - accuracy: 0.6280 - val_loss: 0.6642 - val_accuracy: 0.5342\n",
      "Epoch 1283/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6323 - accuracy: 0.6310 - val_loss: 0.6496 - val_accuracy: 0.5605\n",
      "Epoch 1284/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6321 - accuracy: 0.6287 - val_loss: 0.6607 - val_accuracy: 0.5406\n",
      "Epoch 1285/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6320 - accuracy: 0.6308 - val_loss: 0.6484 - val_accuracy: 0.5592\n",
      "Epoch 1286/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6320 - accuracy: 0.6304 - val_loss: 0.6610 - val_accuracy: 0.5415\n",
      "Epoch 1287/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6320 - accuracy: 0.6306 - val_loss: 0.6494 - val_accuracy: 0.5592\n",
      "Epoch 1288/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6320 - accuracy: 0.6285 - val_loss: 0.6657 - val_accuracy: 0.5318\n",
      "Epoch 1289/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6322 - accuracy: 0.6308 - val_loss: 0.6423 - val_accuracy: 0.5705\n",
      "Epoch 1290/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6324 - accuracy: 0.6275 - val_loss: 0.6731 - val_accuracy: 0.5227\n",
      "Epoch 1291/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6329 - accuracy: 0.6293 - val_loss: 0.6346 - val_accuracy: 0.5835\n",
      "Epoch 1292/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6335 - accuracy: 0.6256 - val_loss: 0.6885 - val_accuracy: 0.4996\n",
      "Epoch 1293/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6351 - accuracy: 0.6257 - val_loss: 0.6290 - val_accuracy: 0.5908\n",
      "Epoch 1294/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6349 - accuracy: 0.6248 - val_loss: 0.6895 - val_accuracy: 0.4962\n",
      "Epoch 1295/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6354 - accuracy: 0.6260 - val_loss: 0.6341 - val_accuracy: 0.5826\n",
      "Epoch 1296/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6336 - accuracy: 0.6255 - val_loss: 0.6685 - val_accuracy: 0.5272\n",
      "Epoch 1297/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6323 - accuracy: 0.6301 - val_loss: 0.6514 - val_accuracy: 0.5535\n",
      "Epoch 1298/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6319 - accuracy: 0.6304 - val_loss: 0.6487 - val_accuracy: 0.5572\n",
      "Epoch 1299/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6317 - accuracy: 0.6296 - val_loss: 0.6689 - val_accuracy: 0.5274\n",
      "Epoch 1300/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6325 - accuracy: 0.6304 - val_loss: 0.6345 - val_accuracy: 0.5820\n",
      "Epoch 1301/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6332 - accuracy: 0.6272 - val_loss: 0.6880 - val_accuracy: 0.4973\n",
      "Epoch 1302/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6351 - accuracy: 0.6257 - val_loss: 0.6304 - val_accuracy: 0.5877\n",
      "Epoch 1303/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6346 - accuracy: 0.6245 - val_loss: 0.6828 - val_accuracy: 0.5057\n",
      "Epoch 1304/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6341 - accuracy: 0.6281 - val_loss: 0.6413 - val_accuracy: 0.5723\n",
      "Epoch 1305/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6328 - accuracy: 0.6261 - val_loss: 0.6556 - val_accuracy: 0.5486\n",
      "Epoch 1306/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6317 - accuracy: 0.6311 - val_loss: 0.6603 - val_accuracy: 0.5376\n",
      "Epoch 1307/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6321 - accuracy: 0.6300 - val_loss: 0.6399 - val_accuracy: 0.5731\n",
      "Epoch 1308/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6323 - accuracy: 0.6284 - val_loss: 0.6784 - val_accuracy: 0.5104\n",
      "Epoch 1309/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6336 - accuracy: 0.6292 - val_loss: 0.6324 - val_accuracy: 0.5884\n",
      "Epoch 1310/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6339 - accuracy: 0.6264 - val_loss: 0.6851 - val_accuracy: 0.5029\n",
      "Epoch 1311/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6346 - accuracy: 0.6261 - val_loss: 0.6374 - val_accuracy: 0.5773\n",
      "Epoch 1312/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6334 - accuracy: 0.6268 - val_loss: 0.6624 - val_accuracy: 0.5343\n",
      "Epoch 1313/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6319 - accuracy: 0.6311 - val_loss: 0.6563 - val_accuracy: 0.5490\n",
      "Epoch 1314/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6322 - accuracy: 0.6301 - val_loss: 0.6438 - val_accuracy: 0.5680\n",
      "Epoch 1315/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6317 - accuracy: 0.6291 - val_loss: 0.6682 - val_accuracy: 0.5261\n",
      "Epoch 1316/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6326 - accuracy: 0.6288 - val_loss: 0.6433 - val_accuracy: 0.5685\n",
      "Epoch 1317/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6322 - accuracy: 0.6280 - val_loss: 0.6693 - val_accuracy: 0.5261\n",
      "Epoch 1318/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6323 - accuracy: 0.6310 - val_loss: 0.6453 - val_accuracy: 0.5685\n",
      "Epoch 1319/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6322 - accuracy: 0.6290 - val_loss: 0.6654 - val_accuracy: 0.5314\n",
      "Epoch 1320/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6319 - accuracy: 0.6295 - val_loss: 0.6433 - val_accuracy: 0.5669\n",
      "Epoch 1321/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6324 - accuracy: 0.6289 - val_loss: 0.6680 - val_accuracy: 0.5294\n",
      "Epoch 1322/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6319 - accuracy: 0.6316 - val_loss: 0.6431 - val_accuracy: 0.5731\n",
      "Epoch 1323/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6326 - accuracy: 0.6266 - val_loss: 0.6724 - val_accuracy: 0.5223\n",
      "Epoch 1324/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6324 - accuracy: 0.6299 - val_loss: 0.6361 - val_accuracy: 0.5789\n",
      "Epoch 1325/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6333 - accuracy: 0.6267 - val_loss: 0.6794 - val_accuracy: 0.5100\n",
      "Epoch 1326/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6331 - accuracy: 0.6292 - val_loss: 0.6357 - val_accuracy: 0.5828\n",
      "Epoch 1327/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6335 - accuracy: 0.6263 - val_loss: 0.6846 - val_accuracy: 0.5046\n",
      "Epoch 1328/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6339 - accuracy: 0.6277 - val_loss: 0.6318 - val_accuracy: 0.5864\n",
      "Epoch 1329/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6338 - accuracy: 0.6259 - val_loss: 0.6769 - val_accuracy: 0.5126\n",
      "Epoch 1330/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6328 - accuracy: 0.6296 - val_loss: 0.6424 - val_accuracy: 0.5734\n",
      "Epoch 1331/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6321 - accuracy: 0.6286 - val_loss: 0.6614 - val_accuracy: 0.5382\n",
      "Epoch 1332/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6313 - accuracy: 0.6314 - val_loss: 0.6526 - val_accuracy: 0.5502\n",
      "Epoch 1333/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6313 - accuracy: 0.6314 - val_loss: 0.6516 - val_accuracy: 0.5530\n",
      "Epoch 1334/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6311 - accuracy: 0.6313 - val_loss: 0.6622 - val_accuracy: 0.5382\n",
      "Epoch 1335/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6314 - accuracy: 0.6316 - val_loss: 0.6452 - val_accuracy: 0.5685\n",
      "Epoch 1336/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6316 - accuracy: 0.6292 - val_loss: 0.6708 - val_accuracy: 0.5227\n",
      "Epoch 1337/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6319 - accuracy: 0.6303 - val_loss: 0.6375 - val_accuracy: 0.5762\n",
      "Epoch 1338/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6325 - accuracy: 0.6276 - val_loss: 0.6792 - val_accuracy: 0.5102\n",
      "Epoch 1339/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6329 - accuracy: 0.6298 - val_loss: 0.6346 - val_accuracy: 0.5828\n",
      "Epoch 1340/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6330 - accuracy: 0.6267 - val_loss: 0.6805 - val_accuracy: 0.5104\n",
      "Epoch 1341/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6333 - accuracy: 0.6286 - val_loss: 0.6355 - val_accuracy: 0.5786\n",
      "Epoch 1342/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6327 - accuracy: 0.6270 - val_loss: 0.6677 - val_accuracy: 0.5285\n",
      "Epoch 1343/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6315 - accuracy: 0.6311 - val_loss: 0.6502 - val_accuracy: 0.5579\n",
      "Epoch 1344/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6314 - accuracy: 0.6305 - val_loss: 0.6552 - val_accuracy: 0.5482\n",
      "Epoch 1345/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6309 - accuracy: 0.6315 - val_loss: 0.6564 - val_accuracy: 0.5453\n",
      "Epoch 1346/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6311 - accuracy: 0.6316 - val_loss: 0.6493 - val_accuracy: 0.5574\n",
      "Epoch 1347/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6310 - accuracy: 0.6314 - val_loss: 0.6639 - val_accuracy: 0.5364\n",
      "Epoch 1348/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6312 - accuracy: 0.6310 - val_loss: 0.6456 - val_accuracy: 0.5685\n",
      "Epoch 1349/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6313 - accuracy: 0.6298 - val_loss: 0.6697 - val_accuracy: 0.5245\n",
      "Epoch 1350/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6317 - accuracy: 0.6304 - val_loss: 0.6360 - val_accuracy: 0.5786\n",
      "Epoch 1351/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6322 - accuracy: 0.6288 - val_loss: 0.6789 - val_accuracy: 0.5106\n",
      "Epoch 1352/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6327 - accuracy: 0.6293 - val_loss: 0.6361 - val_accuracy: 0.5842\n",
      "Epoch 1353/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6327 - accuracy: 0.6265 - val_loss: 0.6812 - val_accuracy: 0.5088\n",
      "Epoch 1354/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6330 - accuracy: 0.6283 - val_loss: 0.6360 - val_accuracy: 0.5787\n",
      "Epoch 1355/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6325 - accuracy: 0.6276 - val_loss: 0.6696 - val_accuracy: 0.5267\n",
      "Epoch 1356/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6315 - accuracy: 0.6314 - val_loss: 0.6456 - val_accuracy: 0.5681\n",
      "Epoch 1357/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6314 - accuracy: 0.6299 - val_loss: 0.6616 - val_accuracy: 0.5376\n",
      "Epoch 1358/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6308 - accuracy: 0.6320 - val_loss: 0.6483 - val_accuracy: 0.5579\n",
      "Epoch 1359/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6312 - accuracy: 0.6309 - val_loss: 0.6611 - val_accuracy: 0.5404\n",
      "Epoch 1360/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6308 - accuracy: 0.6318 - val_loss: 0.6489 - val_accuracy: 0.5617\n",
      "Epoch 1361/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6310 - accuracy: 0.6306 - val_loss: 0.6633 - val_accuracy: 0.5349\n",
      "Epoch 1362/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6309 - accuracy: 0.6315 - val_loss: 0.6443 - val_accuracy: 0.5661\n",
      "Epoch 1363/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6311 - accuracy: 0.6303 - val_loss: 0.6677 - val_accuracy: 0.5285\n",
      "Epoch 1364/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6312 - accuracy: 0.6310 - val_loss: 0.6417 - val_accuracy: 0.5727\n",
      "Epoch 1365/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6313 - accuracy: 0.6295 - val_loss: 0.6737 - val_accuracy: 0.5210\n",
      "Epoch 1366/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6317 - accuracy: 0.6312 - val_loss: 0.6367 - val_accuracy: 0.5780\n",
      "Epoch 1367/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6319 - accuracy: 0.6283 - val_loss: 0.6804 - val_accuracy: 0.5084\n",
      "Epoch 1368/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6326 - accuracy: 0.6294 - val_loss: 0.6331 - val_accuracy: 0.5839\n",
      "Epoch 1369/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6325 - accuracy: 0.6278 - val_loss: 0.6831 - val_accuracy: 0.5058\n",
      "Epoch 1370/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6330 - accuracy: 0.6290 - val_loss: 0.6351 - val_accuracy: 0.5804\n",
      "Epoch 1371/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6321 - accuracy: 0.6279 - val_loss: 0.6733 - val_accuracy: 0.5201\n",
      "Epoch 1372/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6316 - accuracy: 0.6306 - val_loss: 0.6431 - val_accuracy: 0.5692\n",
      "Epoch 1373/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6309 - accuracy: 0.6297 - val_loss: 0.6582 - val_accuracy: 0.5433\n",
      "Epoch 1374/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6305 - accuracy: 0.6324 - val_loss: 0.6568 - val_accuracy: 0.5451\n",
      "Epoch 1375/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6304 - accuracy: 0.6323 - val_loss: 0.6472 - val_accuracy: 0.5623\n",
      "Epoch 1376/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6306 - accuracy: 0.6312 - val_loss: 0.6691 - val_accuracy: 0.5267\n",
      "Epoch 1377/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6311 - accuracy: 0.6312 - val_loss: 0.6370 - val_accuracy: 0.5796\n",
      "Epoch 1378/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6316 - accuracy: 0.6292 - val_loss: 0.6823 - val_accuracy: 0.5079\n",
      "Epoch 1379/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6327 - accuracy: 0.6290 - val_loss: 0.6312 - val_accuracy: 0.5877\n",
      "Epoch 1380/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6327 - accuracy: 0.6274 - val_loss: 0.6861 - val_accuracy: 0.5009\n",
      "Epoch 1381/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6335 - accuracy: 0.6276 - val_loss: 0.6337 - val_accuracy: 0.5828\n",
      "Epoch 1382/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6319 - accuracy: 0.6282 - val_loss: 0.6673 - val_accuracy: 0.5280\n",
      "Epoch 1383/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6309 - accuracy: 0.6318 - val_loss: 0.6519 - val_accuracy: 0.5550\n",
      "Epoch 1384/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6303 - accuracy: 0.6316 - val_loss: 0.6470 - val_accuracy: 0.5628\n",
      "Epoch 1385/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6304 - accuracy: 0.6315 - val_loss: 0.6718 - val_accuracy: 0.5212\n",
      "Epoch 1386/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6313 - accuracy: 0.6304 - val_loss: 0.6309 - val_accuracy: 0.5884\n",
      "Epoch 1387/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6325 - accuracy: 0.6287 - val_loss: 0.6949 - val_accuracy: 0.4859\n",
      "Epoch 1388/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6350 - accuracy: 0.6255 - val_loss: 0.6282 - val_accuracy: 0.5926\n",
      "Epoch 1389/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6337 - accuracy: 0.6259 - val_loss: 0.6835 - val_accuracy: 0.5049\n",
      "Epoch 1390/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6330 - accuracy: 0.6284 - val_loss: 0.6426 - val_accuracy: 0.5676\n",
      "Epoch 1391/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6308 - accuracy: 0.6310 - val_loss: 0.6463 - val_accuracy: 0.5632\n",
      "Epoch 1392/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6304 - accuracy: 0.6314 - val_loss: 0.6749 - val_accuracy: 0.5137\n",
      "Epoch 1393/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6317 - accuracy: 0.6313 - val_loss: 0.6301 - val_accuracy: 0.5886\n",
      "Epoch 1394/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6327 - accuracy: 0.6280 - val_loss: 0.6911 - val_accuracy: 0.4938\n",
      "Epoch 1395/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6345 - accuracy: 0.6270 - val_loss: 0.6343 - val_accuracy: 0.5802\n",
      "Epoch 1396/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6324 - accuracy: 0.6267 - val_loss: 0.6646 - val_accuracy: 0.5332\n",
      "Epoch 1397/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6305 - accuracy: 0.6319 - val_loss: 0.6591 - val_accuracy: 0.5387\n",
      "Epoch 1398/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6306 - accuracy: 0.6323 - val_loss: 0.6393 - val_accuracy: 0.5734\n",
      "Epoch 1399/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6309 - accuracy: 0.6311 - val_loss: 0.6752 - val_accuracy: 0.5175\n",
      "Epoch 1400/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6322 - accuracy: 0.6280 - val_loss: 0.6332 - val_accuracy: 0.5820\n",
      "Epoch 1401/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6322 - accuracy: 0.6274 - val_loss: 0.6756 - val_accuracy: 0.5170\n",
      "Epoch 1402/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6315 - accuracy: 0.6314 - val_loss: 0.6466 - val_accuracy: 0.5638\n",
      "Epoch 1403/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6313 - accuracy: 0.6294 - val_loss: 0.6608 - val_accuracy: 0.5389\n",
      "Epoch 1404/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6302 - accuracy: 0.6326 - val_loss: 0.6492 - val_accuracy: 0.5546\n",
      "Epoch 1405/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6307 - accuracy: 0.6315 - val_loss: 0.6536 - val_accuracy: 0.5506\n",
      "Epoch 1406/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6301 - accuracy: 0.6334 - val_loss: 0.6567 - val_accuracy: 0.5453\n",
      "Epoch 1407/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6303 - accuracy: 0.6313 - val_loss: 0.6556 - val_accuracy: 0.5477\n",
      "Epoch 1408/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6302 - accuracy: 0.6311 - val_loss: 0.6554 - val_accuracy: 0.5469\n",
      "Epoch 1409/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6301 - accuracy: 0.6320 - val_loss: 0.6507 - val_accuracy: 0.5543\n",
      "Epoch 1410/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6302 - accuracy: 0.6320 - val_loss: 0.6580 - val_accuracy: 0.5462\n",
      "Epoch 1411/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6299 - accuracy: 0.6330 - val_loss: 0.6506 - val_accuracy: 0.5570\n",
      "Epoch 1412/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6302 - accuracy: 0.6324 - val_loss: 0.6645 - val_accuracy: 0.5327\n",
      "Epoch 1413/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6302 - accuracy: 0.6322 - val_loss: 0.6419 - val_accuracy: 0.5691\n",
      "Epoch 1414/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6305 - accuracy: 0.6306 - val_loss: 0.6714 - val_accuracy: 0.5247\n",
      "Epoch 1415/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6309 - accuracy: 0.6316 - val_loss: 0.6386 - val_accuracy: 0.5771\n",
      "Epoch 1416/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6310 - accuracy: 0.6303 - val_loss: 0.6813 - val_accuracy: 0.5088\n",
      "Epoch 1417/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6318 - accuracy: 0.6305 - val_loss: 0.6328 - val_accuracy: 0.5840\n",
      "Epoch 1418/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6319 - accuracy: 0.6289 - val_loss: 0.6856 - val_accuracy: 0.5037\n",
      "Epoch 1419/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6329 - accuracy: 0.6288 - val_loss: 0.6309 - val_accuracy: 0.5910\n",
      "Epoch 1420/15000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.6321 - accuracy: 0.6276 - val_loss: 0.6793 - val_accuracy: 0.5104\n",
      "Epoch 1421/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6316 - accuracy: 0.6304 - val_loss: 0.6428 - val_accuracy: 0.5681\n",
      "Epoch 1422/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6307 - accuracy: 0.6305 - val_loss: 0.6606 - val_accuracy: 0.5407\n",
      "Epoch 1423/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6299 - accuracy: 0.6326 - val_loss: 0.6519 - val_accuracy: 0.5555\n",
      "Epoch 1424/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6299 - accuracy: 0.6326 - val_loss: 0.6508 - val_accuracy: 0.5548\n",
      "Epoch 1425/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6297 - accuracy: 0.6333 - val_loss: 0.6645 - val_accuracy: 0.5332\n",
      "Epoch 1426/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6300 - accuracy: 0.6325 - val_loss: 0.6469 - val_accuracy: 0.5647\n",
      "Epoch 1427/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6300 - accuracy: 0.6319 - val_loss: 0.6678 - val_accuracy: 0.5269\n",
      "Epoch 1428/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6303 - accuracy: 0.6321 - val_loss: 0.6382 - val_accuracy: 0.5751\n",
      "Epoch 1429/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6305 - accuracy: 0.6309 - val_loss: 0.6749 - val_accuracy: 0.5181\n",
      "Epoch 1430/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6310 - accuracy: 0.6319 - val_loss: 0.6372 - val_accuracy: 0.5786\n",
      "Epoch 1431/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6312 - accuracy: 0.6301 - val_loss: 0.6797 - val_accuracy: 0.5095\n",
      "Epoch 1432/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6316 - accuracy: 0.6306 - val_loss: 0.6351 - val_accuracy: 0.5822\n",
      "Epoch 1433/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6312 - accuracy: 0.6289 - val_loss: 0.6728 - val_accuracy: 0.5212\n",
      "Epoch 1434/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6307 - accuracy: 0.6316 - val_loss: 0.6426 - val_accuracy: 0.5685\n",
      "Epoch 1435/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6303 - accuracy: 0.6322 - val_loss: 0.6646 - val_accuracy: 0.5340\n",
      "Epoch 1436/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6298 - accuracy: 0.6328 - val_loss: 0.6482 - val_accuracy: 0.5627\n",
      "Epoch 1437/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6298 - accuracy: 0.6320 - val_loss: 0.6581 - val_accuracy: 0.5446\n",
      "Epoch 1438/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6295 - accuracy: 0.6333 - val_loss: 0.6527 - val_accuracy: 0.5517\n",
      "Epoch 1439/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6296 - accuracy: 0.6331 - val_loss: 0.6555 - val_accuracy: 0.5477\n",
      "Epoch 1440/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6294 - accuracy: 0.6327 - val_loss: 0.6550 - val_accuracy: 0.5495\n",
      "Epoch 1441/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6295 - accuracy: 0.6331 - val_loss: 0.6525 - val_accuracy: 0.5530\n",
      "Epoch 1442/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6294 - accuracy: 0.6327 - val_loss: 0.6571 - val_accuracy: 0.5435\n",
      "Epoch 1443/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6294 - accuracy: 0.6334 - val_loss: 0.6522 - val_accuracy: 0.5530\n",
      "Epoch 1444/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6293 - accuracy: 0.6327 - val_loss: 0.6598 - val_accuracy: 0.5422\n",
      "Epoch 1445/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6294 - accuracy: 0.6330 - val_loss: 0.6489 - val_accuracy: 0.5592\n",
      "Epoch 1446/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6294 - accuracy: 0.6328 - val_loss: 0.6639 - val_accuracy: 0.5353\n",
      "Epoch 1447/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6295 - accuracy: 0.6325 - val_loss: 0.6438 - val_accuracy: 0.5683\n",
      "Epoch 1448/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6298 - accuracy: 0.6320 - val_loss: 0.6735 - val_accuracy: 0.5188\n",
      "Epoch 1449/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6304 - accuracy: 0.6325 - val_loss: 0.6326 - val_accuracy: 0.5891\n",
      "Epoch 1450/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6313 - accuracy: 0.6292 - val_loss: 0.6929 - val_accuracy: 0.4936\n",
      "Epoch 1451/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6337 - accuracy: 0.6273 - val_loss: 0.6254 - val_accuracy: 0.5992\n",
      "Epoch 1452/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6335 - accuracy: 0.6251 - val_loss: 0.6948 - val_accuracy: 0.4905\n",
      "Epoch 1453/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6340 - accuracy: 0.6275 - val_loss: 0.6352 - val_accuracy: 0.5849\n",
      "Epoch 1454/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6314 - accuracy: 0.6285 - val_loss: 0.6635 - val_accuracy: 0.5349\n",
      "Epoch 1455/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6297 - accuracy: 0.6328 - val_loss: 0.6555 - val_accuracy: 0.5473\n",
      "Epoch 1456/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6297 - accuracy: 0.6330 - val_loss: 0.6436 - val_accuracy: 0.5681\n",
      "Epoch 1457/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6296 - accuracy: 0.6316 - val_loss: 0.6746 - val_accuracy: 0.5172\n",
      "Epoch 1458/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6308 - accuracy: 0.6319 - val_loss: 0.6339 - val_accuracy: 0.5853\n",
      "Epoch 1459/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6311 - accuracy: 0.6301 - val_loss: 0.6865 - val_accuracy: 0.4998\n",
      "Epoch 1460/15000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6327 - accuracy: 0.6279 - val_loss: 0.6336 - val_accuracy: 0.5809\n",
      "Epoch 1461/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6318 - accuracy: 0.6283 - val_loss: 0.6713 - val_accuracy: 0.5237\n",
      "Epoch 1462/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6303 - accuracy: 0.6327 - val_loss: 0.6480 - val_accuracy: 0.5597\n",
      "Epoch 1463/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6304 - accuracy: 0.6311 - val_loss: 0.6569 - val_accuracy: 0.5437\n",
      "Epoch 1464/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6293 - accuracy: 0.6337 - val_loss: 0.6516 - val_accuracy: 0.5524\n",
      "Epoch 1465/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6299 - accuracy: 0.6323 - val_loss: 0.6540 - val_accuracy: 0.5519\n",
      "Epoch 1466/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6293 - accuracy: 0.6329 - val_loss: 0.6561 - val_accuracy: 0.5475\n",
      "Epoch 1467/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6296 - accuracy: 0.6327 - val_loss: 0.6584 - val_accuracy: 0.5409\n",
      "Epoch 1468/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6292 - accuracy: 0.6334 - val_loss: 0.6510 - val_accuracy: 0.5526\n",
      "Epoch 1469/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6294 - accuracy: 0.6331 - val_loss: 0.6581 - val_accuracy: 0.5418\n",
      "Epoch 1470/15000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6293 - accuracy: 0.6331 - val_loss: 0.6467 - val_accuracy: 0.5628\n",
      "Epoch 1471/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6294 - accuracy: 0.6323 - val_loss: 0.6646 - val_accuracy: 0.5342\n",
      "Epoch 1472/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6293 - accuracy: 0.6334 - val_loss: 0.6462 - val_accuracy: 0.5617\n",
      "Epoch 1473/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6296 - accuracy: 0.6321 - val_loss: 0.6686 - val_accuracy: 0.5298\n",
      "Epoch 1474/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6296 - accuracy: 0.6322 - val_loss: 0.6370 - val_accuracy: 0.5782\n",
      "Epoch 1475/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6303 - accuracy: 0.6301 - val_loss: 0.6811 - val_accuracy: 0.5095\n",
      "Epoch 1476/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6310 - accuracy: 0.6311 - val_loss: 0.6309 - val_accuracy: 0.5884\n",
      "Epoch 1477/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6321 - accuracy: 0.6279 - val_loss: 0.6982 - val_accuracy: 0.4863\n",
      "Epoch 1478/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6344 - accuracy: 0.6261 - val_loss: 0.6262 - val_accuracy: 0.5972\n",
      "Epoch 1479/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6326 - accuracy: 0.6264 - val_loss: 0.6791 - val_accuracy: 0.5126\n",
      "Epoch 1480/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6308 - accuracy: 0.6320 - val_loss: 0.6472 - val_accuracy: 0.5634\n",
      "Epoch 1481/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6294 - accuracy: 0.6331 - val_loss: 0.6502 - val_accuracy: 0.5544\n",
      "Epoch 1482/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6289 - accuracy: 0.6346 - val_loss: 0.6669 - val_accuracy: 0.5320\n",
      "Epoch 1483/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6296 - accuracy: 0.6313 - val_loss: 0.6345 - val_accuracy: 0.5842\n",
      "Epoch 1484/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6305 - accuracy: 0.6303 - val_loss: 0.6874 - val_accuracy: 0.4976\n",
      "Epoch 1485/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6320 - accuracy: 0.6302 - val_loss: 0.6313 - val_accuracy: 0.5897\n",
      "Epoch 1486/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6320 - accuracy: 0.6275 - val_loss: 0.6866 - val_accuracy: 0.5004\n",
      "Epoch 1487/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6322 - accuracy: 0.6282 - val_loss: 0.6349 - val_accuracy: 0.5806\n",
      "Epoch 1488/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6308 - accuracy: 0.6294 - val_loss: 0.6618 - val_accuracy: 0.5376\n",
      "Epoch 1489/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6290 - accuracy: 0.6336 - val_loss: 0.6577 - val_accuracy: 0.5446\n",
      "Epoch 1490/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6294 - accuracy: 0.6332 - val_loss: 0.6473 - val_accuracy: 0.5617\n",
      "Epoch 1491/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6290 - accuracy: 0.6338 - val_loss: 0.6641 - val_accuracy: 0.5358\n",
      "Epoch 1492/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6295 - accuracy: 0.6317 - val_loss: 0.6407 - val_accuracy: 0.5701\n",
      "Epoch 1493/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6298 - accuracy: 0.6308 - val_loss: 0.6714 - val_accuracy: 0.5214\n",
      "Epoch 1494/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6295 - accuracy: 0.6318 - val_loss: 0.6416 - val_accuracy: 0.5714\n",
      "Epoch 1495/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6304 - accuracy: 0.6309 - val_loss: 0.6781 - val_accuracy: 0.5115\n",
      "Epoch 1496/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6306 - accuracy: 0.6308 - val_loss: 0.6307 - val_accuracy: 0.5877\n",
      "Epoch 1497/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6314 - accuracy: 0.6286 - val_loss: 0.6794 - val_accuracy: 0.5102\n",
      "Epoch 1498/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6309 - accuracy: 0.6318 - val_loss: 0.6383 - val_accuracy: 0.5798\n",
      "Epoch 1499/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6306 - accuracy: 0.6307 - val_loss: 0.6727 - val_accuracy: 0.5185\n",
      "Epoch 1500/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6297 - accuracy: 0.6328 - val_loss: 0.6420 - val_accuracy: 0.5672\n",
      "Epoch 1501/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6295 - accuracy: 0.6318 - val_loss: 0.6619 - val_accuracy: 0.5395\n",
      "Epoch 1502/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6289 - accuracy: 0.6334 - val_loss: 0.6507 - val_accuracy: 0.5572\n",
      "Epoch 1503/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6289 - accuracy: 0.6341 - val_loss: 0.6588 - val_accuracy: 0.5413\n",
      "Epoch 1504/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6286 - accuracy: 0.6339 - val_loss: 0.6529 - val_accuracy: 0.5512\n",
      "Epoch 1505/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6286 - accuracy: 0.6338 - val_loss: 0.6539 - val_accuracy: 0.5499\n",
      "Epoch 1506/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6285 - accuracy: 0.6335 - val_loss: 0.6545 - val_accuracy: 0.5499\n",
      "Epoch 1507/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6286 - accuracy: 0.6335 - val_loss: 0.6554 - val_accuracy: 0.5466\n",
      "Epoch 1508/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6284 - accuracy: 0.6344 - val_loss: 0.6563 - val_accuracy: 0.5460\n",
      "Epoch 1509/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6285 - accuracy: 0.6351 - val_loss: 0.6546 - val_accuracy: 0.5495\n",
      "Epoch 1510/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6283 - accuracy: 0.6349 - val_loss: 0.6538 - val_accuracy: 0.5528\n",
      "Epoch 1511/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6284 - accuracy: 0.6343 - val_loss: 0.6560 - val_accuracy: 0.5460\n",
      "Epoch 1512/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6283 - accuracy: 0.6345 - val_loss: 0.6543 - val_accuracy: 0.5482\n",
      "Epoch 1513/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6284 - accuracy: 0.6350 - val_loss: 0.6578 - val_accuracy: 0.5446\n",
      "Epoch 1514/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6282 - accuracy: 0.6346 - val_loss: 0.6513 - val_accuracy: 0.5550\n",
      "Epoch 1515/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6283 - accuracy: 0.6342 - val_loss: 0.6611 - val_accuracy: 0.5409\n",
      "Epoch 1516/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6283 - accuracy: 0.6346 - val_loss: 0.6462 - val_accuracy: 0.5638\n",
      "Epoch 1517/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6285 - accuracy: 0.6338 - val_loss: 0.6712 - val_accuracy: 0.5254\n",
      "Epoch 1518/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6291 - accuracy: 0.6329 - val_loss: 0.6339 - val_accuracy: 0.5881\n",
      "Epoch 1519/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6299 - accuracy: 0.6305 - val_loss: 0.6926 - val_accuracy: 0.4932\n",
      "Epoch 1520/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6326 - accuracy: 0.6290 - val_loss: 0.6230 - val_accuracy: 0.6056\n",
      "Epoch 1521/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6329 - accuracy: 0.6263 - val_loss: 0.7041 - val_accuracy: 0.4797\n",
      "Epoch 1522/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6351 - accuracy: 0.6253 - val_loss: 0.6346 - val_accuracy: 0.5839\n",
      "Epoch 1523/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6302 - accuracy: 0.6298 - val_loss: 0.6546 - val_accuracy: 0.5491\n",
      "Epoch 1524/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6283 - accuracy: 0.6345 - val_loss: 0.6721 - val_accuracy: 0.5221\n",
      "Epoch 1525/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6295 - accuracy: 0.6327 - val_loss: 0.6243 - val_accuracy: 0.6038\n",
      "Epoch 1526/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6318 - accuracy: 0.6279 - val_loss: 0.7069 - val_accuracy: 0.4735\n",
      "Epoch 1527/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6363 - accuracy: 0.6234 - val_loss: 0.6319 - val_accuracy: 0.5855\n",
      "Epoch 1528/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6312 - accuracy: 0.6282 - val_loss: 0.6603 - val_accuracy: 0.5404\n",
      "Epoch 1529/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6285 - accuracy: 0.6331 - val_loss: 0.6686 - val_accuracy: 0.5259\n",
      "Epoch 1530/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6292 - accuracy: 0.6337 - val_loss: 0.6264 - val_accuracy: 0.5974\n",
      "Epoch 1531/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6310 - accuracy: 0.6297 - val_loss: 0.6928 - val_accuracy: 0.4883\n",
      "Epoch 1532/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6336 - accuracy: 0.6253 - val_loss: 0.6345 - val_accuracy: 0.5776\n",
      "Epoch 1533/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6304 - accuracy: 0.6285 - val_loss: 0.6574 - val_accuracy: 0.5444\n",
      "Epoch 1534/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6285 - accuracy: 0.6326 - val_loss: 0.6695 - val_accuracy: 0.5216\n",
      "Epoch 1535/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6295 - accuracy: 0.6334 - val_loss: 0.6332 - val_accuracy: 0.5831\n",
      "Epoch 1536/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6299 - accuracy: 0.6311 - val_loss: 0.6785 - val_accuracy: 0.5095\n",
      "Epoch 1537/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6310 - accuracy: 0.6294 - val_loss: 0.6387 - val_accuracy: 0.5723\n",
      "Epoch 1538/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6298 - accuracy: 0.6312 - val_loss: 0.6612 - val_accuracy: 0.5384\n",
      "Epoch 1539/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6284 - accuracy: 0.6335 - val_loss: 0.6581 - val_accuracy: 0.5435\n",
      "Epoch 1540/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6289 - accuracy: 0.6331 - val_loss: 0.6473 - val_accuracy: 0.5594\n",
      "Epoch 1541/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6284 - accuracy: 0.6341 - val_loss: 0.6588 - val_accuracy: 0.5398\n",
      "Epoch 1542/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6287 - accuracy: 0.6330 - val_loss: 0.6472 - val_accuracy: 0.5616\n",
      "Epoch 1543/15000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.6285 - accuracy: 0.6335 - val_loss: 0.6596 - val_accuracy: 0.5396\n",
      "Epoch 1544/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6282 - accuracy: 0.6338 - val_loss: 0.6554 - val_accuracy: 0.5468\n",
      "Epoch 1545/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6284 - accuracy: 0.6340 - val_loss: 0.6559 - val_accuracy: 0.5464\n",
      "Epoch 1546/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6281 - accuracy: 0.6353 - val_loss: 0.6493 - val_accuracy: 0.5581\n",
      "Epoch 1547/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6282 - accuracy: 0.6339 - val_loss: 0.6587 - val_accuracy: 0.5420\n",
      "Epoch 1548/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6281 - accuracy: 0.6353 - val_loss: 0.6508 - val_accuracy: 0.5561\n",
      "Epoch 1549/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6281 - accuracy: 0.6343 - val_loss: 0.6680 - val_accuracy: 0.5274\n",
      "Epoch 1550/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6285 - accuracy: 0.6332 - val_loss: 0.6406 - val_accuracy: 0.5733\n",
      "Epoch 1551/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6285 - accuracy: 0.6330 - val_loss: 0.6731 - val_accuracy: 0.5247\n",
      "Epoch 1552/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6293 - accuracy: 0.6331 - val_loss: 0.6346 - val_accuracy: 0.5899\n",
      "Epoch 1553/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6295 - accuracy: 0.6307 - val_loss: 0.6853 - val_accuracy: 0.5029\n",
      "Epoch 1554/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6305 - accuracy: 0.6305 - val_loss: 0.6348 - val_accuracy: 0.5842\n",
      "Epoch 1555/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6303 - accuracy: 0.6298 - val_loss: 0.6806 - val_accuracy: 0.5124\n",
      "Epoch 1556/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6301 - accuracy: 0.6321 - val_loss: 0.6345 - val_accuracy: 0.5901\n",
      "Epoch 1557/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6297 - accuracy: 0.6298 - val_loss: 0.6706 - val_accuracy: 0.5259\n",
      "Epoch 1558/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6285 - accuracy: 0.6341 - val_loss: 0.6470 - val_accuracy: 0.5621\n",
      "Epoch 1559/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6287 - accuracy: 0.6339 - val_loss: 0.6643 - val_accuracy: 0.5362\n",
      "Epoch 1560/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6278 - accuracy: 0.6348 - val_loss: 0.6482 - val_accuracy: 0.5658\n",
      "Epoch 1561/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6281 - accuracy: 0.6341 - val_loss: 0.6598 - val_accuracy: 0.5433\n",
      "Epoch 1562/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6278 - accuracy: 0.6350 - val_loss: 0.6492 - val_accuracy: 0.5570\n",
      "Epoch 1563/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6279 - accuracy: 0.6345 - val_loss: 0.6641 - val_accuracy: 0.5349\n",
      "Epoch 1564/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6278 - accuracy: 0.6343 - val_loss: 0.6472 - val_accuracy: 0.5649\n",
      "Epoch 1565/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6280 - accuracy: 0.6345 - val_loss: 0.6665 - val_accuracy: 0.5305\n",
      "Epoch 1566/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6282 - accuracy: 0.6344 - val_loss: 0.6398 - val_accuracy: 0.5742\n",
      "Epoch 1567/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6284 - accuracy: 0.6334 - val_loss: 0.6753 - val_accuracy: 0.5185\n",
      "Epoch 1568/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6288 - accuracy: 0.6341 - val_loss: 0.6366 - val_accuracy: 0.5842\n",
      "Epoch 1569/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6293 - accuracy: 0.6314 - val_loss: 0.6839 - val_accuracy: 0.5073\n",
      "Epoch 1570/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6302 - accuracy: 0.6313 - val_loss: 0.6300 - val_accuracy: 0.5921\n",
      "Epoch 1571/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6303 - accuracy: 0.6297 - val_loss: 0.6846 - val_accuracy: 0.5046\n",
      "Epoch 1572/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6303 - accuracy: 0.6311 - val_loss: 0.6351 - val_accuracy: 0.5862\n",
      "Epoch 1573/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6297 - accuracy: 0.6311 - val_loss: 0.6741 - val_accuracy: 0.5201\n",
      "Epoch 1574/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6288 - accuracy: 0.6331 - val_loss: 0.6413 - val_accuracy: 0.5711\n",
      "Epoch 1575/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6284 - accuracy: 0.6324 - val_loss: 0.6595 - val_accuracy: 0.5418\n",
      "Epoch 1576/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6274 - accuracy: 0.6359 - val_loss: 0.6555 - val_accuracy: 0.5486\n",
      "Epoch 1577/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6277 - accuracy: 0.6350 - val_loss: 0.6524 - val_accuracy: 0.5533\n",
      "Epoch 1578/15000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6274 - accuracy: 0.6359 - val_loss: 0.6591 - val_accuracy: 0.5417\n",
      "Epoch 1579/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6276 - accuracy: 0.6351 - val_loss: 0.6472 - val_accuracy: 0.5625\n",
      "Epoch 1580/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6277 - accuracy: 0.6339 - val_loss: 0.6663 - val_accuracy: 0.5322\n",
      "Epoch 1581/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6277 - accuracy: 0.6346 - val_loss: 0.6429 - val_accuracy: 0.5700\n",
      "Epoch 1582/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6283 - accuracy: 0.6341 - val_loss: 0.6749 - val_accuracy: 0.5190\n",
      "Epoch 1583/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6288 - accuracy: 0.6328 - val_loss: 0.6304 - val_accuracy: 0.5904\n",
      "Epoch 1584/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6297 - accuracy: 0.6299 - val_loss: 0.6883 - val_accuracy: 0.4998\n",
      "Epoch 1585/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6308 - accuracy: 0.6305 - val_loss: 0.6319 - val_accuracy: 0.5917\n",
      "Epoch 1586/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6303 - accuracy: 0.6292 - val_loss: 0.6836 - val_accuracy: 0.5040\n",
      "Epoch 1587/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6299 - accuracy: 0.6312 - val_loss: 0.6382 - val_accuracy: 0.5725\n",
      "Epoch 1588/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6286 - accuracy: 0.6324 - val_loss: 0.6581 - val_accuracy: 0.5424\n",
      "Epoch 1589/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6274 - accuracy: 0.6360 - val_loss: 0.6578 - val_accuracy: 0.5453\n",
      "Epoch 1590/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6276 - accuracy: 0.6355 - val_loss: 0.6454 - val_accuracy: 0.5650\n",
      "Epoch 1591/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6277 - accuracy: 0.6352 - val_loss: 0.6725 - val_accuracy: 0.5232\n",
      "Epoch 1592/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6284 - accuracy: 0.6325 - val_loss: 0.6357 - val_accuracy: 0.5813\n",
      "Epoch 1593/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6289 - accuracy: 0.6313 - val_loss: 0.6805 - val_accuracy: 0.5084\n",
      "Epoch 1594/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6293 - accuracy: 0.6329 - val_loss: 0.6344 - val_accuracy: 0.5868\n",
      "Epoch 1595/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6295 - accuracy: 0.6316 - val_loss: 0.6827 - val_accuracy: 0.5075\n",
      "Epoch 1596/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6299 - accuracy: 0.6315 - val_loss: 0.6334 - val_accuracy: 0.5818\n",
      "Epoch 1597/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6294 - accuracy: 0.6307 - val_loss: 0.6713 - val_accuracy: 0.5237\n",
      "Epoch 1598/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6282 - accuracy: 0.6340 - val_loss: 0.6466 - val_accuracy: 0.5619\n",
      "Epoch 1599/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6280 - accuracy: 0.6345 - val_loss: 0.6607 - val_accuracy: 0.5378\n",
      "Epoch 1600/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6273 - accuracy: 0.6354 - val_loss: 0.6511 - val_accuracy: 0.5530\n",
      "Epoch 1601/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6275 - accuracy: 0.6343 - val_loss: 0.6538 - val_accuracy: 0.5502\n",
      "Epoch 1602/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6272 - accuracy: 0.6352 - val_loss: 0.6569 - val_accuracy: 0.5453\n",
      "Epoch 1603/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6273 - accuracy: 0.6358 - val_loss: 0.6536 - val_accuracy: 0.5519\n",
      "Epoch 1604/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6272 - accuracy: 0.6356 - val_loss: 0.6582 - val_accuracy: 0.5440\n",
      "Epoch 1605/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6272 - accuracy: 0.6361 - val_loss: 0.6483 - val_accuracy: 0.5607\n",
      "Epoch 1606/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6271 - accuracy: 0.6352 - val_loss: 0.6596 - val_accuracy: 0.5422\n",
      "Epoch 1607/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6272 - accuracy: 0.6365 - val_loss: 0.6504 - val_accuracy: 0.5550\n",
      "Epoch 1608/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6271 - accuracy: 0.6364 - val_loss: 0.6645 - val_accuracy: 0.5351\n",
      "Epoch 1609/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6273 - accuracy: 0.6353 - val_loss: 0.6448 - val_accuracy: 0.5680\n",
      "Epoch 1610/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6272 - accuracy: 0.6352 - val_loss: 0.6683 - val_accuracy: 0.5294\n",
      "Epoch 1611/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6276 - accuracy: 0.6351 - val_loss: 0.6385 - val_accuracy: 0.5795\n",
      "Epoch 1612/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6280 - accuracy: 0.6330 - val_loss: 0.6831 - val_accuracy: 0.5073\n",
      "Epoch 1613/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6293 - accuracy: 0.6323 - val_loss: 0.6304 - val_accuracy: 0.5928\n",
      "Epoch 1614/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6297 - accuracy: 0.6305 - val_loss: 0.6906 - val_accuracy: 0.5002\n",
      "Epoch 1615/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6311 - accuracy: 0.6300 - val_loss: 0.6286 - val_accuracy: 0.5972\n",
      "Epoch 1616/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6297 - accuracy: 0.6290 - val_loss: 0.6784 - val_accuracy: 0.5157\n",
      "Epoch 1617/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6288 - accuracy: 0.6329 - val_loss: 0.6449 - val_accuracy: 0.5643\n",
      "Epoch 1618/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6278 - accuracy: 0.6343 - val_loss: 0.6563 - val_accuracy: 0.5473\n",
      "Epoch 1619/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6269 - accuracy: 0.6363 - val_loss: 0.6602 - val_accuracy: 0.5433\n",
      "Epoch 1620/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6273 - accuracy: 0.6364 - val_loss: 0.6418 - val_accuracy: 0.5720\n",
      "Epoch 1621/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6273 - accuracy: 0.6351 - val_loss: 0.6771 - val_accuracy: 0.5174\n",
      "Epoch 1622/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6285 - accuracy: 0.6323 - val_loss: 0.6350 - val_accuracy: 0.5835\n",
      "Epoch 1623/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6286 - accuracy: 0.6319 - val_loss: 0.6850 - val_accuracy: 0.5046\n",
      "Epoch 1624/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6298 - accuracy: 0.6323 - val_loss: 0.6309 - val_accuracy: 0.5926\n",
      "Epoch 1625/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6290 - accuracy: 0.6303 - val_loss: 0.6780 - val_accuracy: 0.5150\n",
      "Epoch 1626/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6288 - accuracy: 0.6325 - val_loss: 0.6411 - val_accuracy: 0.5694\n",
      "Epoch 1627/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6278 - accuracy: 0.6337 - val_loss: 0.6593 - val_accuracy: 0.5435\n",
      "Epoch 1628/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6269 - accuracy: 0.6361 - val_loss: 0.6573 - val_accuracy: 0.5468\n",
      "Epoch 1629/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6271 - accuracy: 0.6363 - val_loss: 0.6452 - val_accuracy: 0.5669\n",
      "Epoch 1630/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6269 - accuracy: 0.6351 - val_loss: 0.6702 - val_accuracy: 0.5263\n",
      "Epoch 1631/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6277 - accuracy: 0.6337 - val_loss: 0.6403 - val_accuracy: 0.5740\n",
      "Epoch 1632/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6275 - accuracy: 0.6347 - val_loss: 0.6751 - val_accuracy: 0.5177\n",
      "Epoch 1633/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6281 - accuracy: 0.6349 - val_loss: 0.6364 - val_accuracy: 0.5837\n",
      "Epoch 1634/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6278 - accuracy: 0.6332 - val_loss: 0.6752 - val_accuracy: 0.5201\n",
      "Epoch 1635/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6283 - accuracy: 0.6328 - val_loss: 0.6387 - val_accuracy: 0.5747\n",
      "Epoch 1636/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6277 - accuracy: 0.6341 - val_loss: 0.6677 - val_accuracy: 0.5314\n",
      "Epoch 1637/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6273 - accuracy: 0.6355 - val_loss: 0.6469 - val_accuracy: 0.5676\n",
      "Epoch 1638/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6271 - accuracy: 0.6356 - val_loss: 0.6613 - val_accuracy: 0.5413\n",
      "Epoch 1639/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6267 - accuracy: 0.6363 - val_loss: 0.6506 - val_accuracy: 0.5543\n",
      "Epoch 1640/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6269 - accuracy: 0.6358 - val_loss: 0.6583 - val_accuracy: 0.5451\n",
      "Epoch 1641/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6265 - accuracy: 0.6372 - val_loss: 0.6520 - val_accuracy: 0.5555\n",
      "Epoch 1642/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6268 - accuracy: 0.6365 - val_loss: 0.6609 - val_accuracy: 0.5406\n",
      "Epoch 1643/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6265 - accuracy: 0.6370 - val_loss: 0.6471 - val_accuracy: 0.5601\n",
      "Epoch 1644/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6270 - accuracy: 0.6351 - val_loss: 0.6664 - val_accuracy: 0.5340\n",
      "Epoch 1645/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6269 - accuracy: 0.6359 - val_loss: 0.6399 - val_accuracy: 0.5811\n",
      "Epoch 1646/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6276 - accuracy: 0.6341 - val_loss: 0.6786 - val_accuracy: 0.5183\n",
      "Epoch 1647/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6282 - accuracy: 0.6332 - val_loss: 0.6317 - val_accuracy: 0.5888\n",
      "Epoch 1648/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6294 - accuracy: 0.6309 - val_loss: 0.6932 - val_accuracy: 0.4954\n",
      "Epoch 1649/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6309 - accuracy: 0.6305 - val_loss: 0.6262 - val_accuracy: 0.6018\n",
      "Epoch 1650/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6308 - accuracy: 0.6287 - val_loss: 0.6928 - val_accuracy: 0.4976\n",
      "Epoch 1651/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6311 - accuracy: 0.6288 - val_loss: 0.6374 - val_accuracy: 0.5764\n",
      "Epoch 1652/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6297 - accuracy: 0.6310 - val_loss: 0.6629 - val_accuracy: 0.5378\n",
      "Epoch 1653/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6267 - accuracy: 0.6363 - val_loss: 0.6560 - val_accuracy: 0.5473\n",
      "Epoch 1654/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6281 - accuracy: 0.6351 - val_loss: 0.6499 - val_accuracy: 0.5572\n",
      "Epoch 1655/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6263 - accuracy: 0.6369 - val_loss: 0.6559 - val_accuracy: 0.5482\n",
      "Epoch 1656/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6276 - accuracy: 0.6344 - val_loss: 0.6578 - val_accuracy: 0.5457\n",
      "Epoch 1657/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6266 - accuracy: 0.6360 - val_loss: 0.6502 - val_accuracy: 0.5601\n",
      "Epoch 1658/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6272 - accuracy: 0.6362 - val_loss: 0.6689 - val_accuracy: 0.5283\n",
      "Epoch 1659/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6272 - accuracy: 0.6362 - val_loss: 0.6367 - val_accuracy: 0.5795\n",
      "Epoch 1660/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6276 - accuracy: 0.6338 - val_loss: 0.6771 - val_accuracy: 0.5172\n",
      "Epoch 1661/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6284 - accuracy: 0.6324 - val_loss: 0.6361 - val_accuracy: 0.5818\n",
      "Epoch 1662/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6277 - accuracy: 0.6324 - val_loss: 0.6753 - val_accuracy: 0.5203\n",
      "Epoch 1663/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6277 - accuracy: 0.6358 - val_loss: 0.6427 - val_accuracy: 0.5707\n",
      "Epoch 1664/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6269 - accuracy: 0.6360 - val_loss: 0.6633 - val_accuracy: 0.5364\n",
      "Epoch 1665/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6267 - accuracy: 0.6365 - val_loss: 0.6461 - val_accuracy: 0.5621\n",
      "Epoch 1666/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6264 - accuracy: 0.6359 - val_loss: 0.6582 - val_accuracy: 0.5455\n",
      "Epoch 1667/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6262 - accuracy: 0.6375 - val_loss: 0.6554 - val_accuracy: 0.5491\n",
      "Epoch 1668/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6262 - accuracy: 0.6370 - val_loss: 0.6555 - val_accuracy: 0.5490\n",
      "Epoch 1669/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6261 - accuracy: 0.6368 - val_loss: 0.6540 - val_accuracy: 0.5510\n",
      "Epoch 1670/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6261 - accuracy: 0.6367 - val_loss: 0.6527 - val_accuracy: 0.5543\n",
      "Epoch 1671/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6261 - accuracy: 0.6379 - val_loss: 0.6569 - val_accuracy: 0.5471\n",
      "Epoch 1672/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6260 - accuracy: 0.6372 - val_loss: 0.6552 - val_accuracy: 0.5482\n",
      "Epoch 1673/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6260 - accuracy: 0.6373 - val_loss: 0.6570 - val_accuracy: 0.5480\n",
      "Epoch 1674/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6260 - accuracy: 0.6372 - val_loss: 0.6508 - val_accuracy: 0.5581\n",
      "Epoch 1675/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6260 - accuracy: 0.6369 - val_loss: 0.6595 - val_accuracy: 0.5455\n",
      "Epoch 1676/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6260 - accuracy: 0.6371 - val_loss: 0.6494 - val_accuracy: 0.5590\n",
      "Epoch 1677/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6261 - accuracy: 0.6379 - val_loss: 0.6671 - val_accuracy: 0.5332\n",
      "Epoch 1678/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6264 - accuracy: 0.6362 - val_loss: 0.6405 - val_accuracy: 0.5762\n",
      "Epoch 1679/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6267 - accuracy: 0.6349 - val_loss: 0.6805 - val_accuracy: 0.5141\n",
      "Epoch 1680/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6280 - accuracy: 0.6347 - val_loss: 0.6260 - val_accuracy: 0.6018\n",
      "Epoch 1681/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6295 - accuracy: 0.6309 - val_loss: 0.7071 - val_accuracy: 0.4788\n",
      "Epoch 1682/15000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.6338 - accuracy: 0.6262 - val_loss: 0.6273 - val_accuracy: 0.5966\n",
      "Epoch 1683/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6302 - accuracy: 0.6284 - val_loss: 0.6758 - val_accuracy: 0.5194\n",
      "Epoch 1684/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6276 - accuracy: 0.6358 - val_loss: 0.6522 - val_accuracy: 0.5559\n",
      "Epoch 1685/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6267 - accuracy: 0.6369 - val_loss: 0.6427 - val_accuracy: 0.5661\n",
      "Epoch 1686/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6263 - accuracy: 0.6361 - val_loss: 0.6750 - val_accuracy: 0.5216\n",
      "Epoch 1687/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6280 - accuracy: 0.6327 - val_loss: 0.6350 - val_accuracy: 0.5835\n",
      "Epoch 1688/15000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6279 - accuracy: 0.6327 - val_loss: 0.6860 - val_accuracy: 0.5038\n",
      "Epoch 1689/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6290 - accuracy: 0.6333 - val_loss: 0.6347 - val_accuracy: 0.5881\n",
      "Epoch 1690/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6284 - accuracy: 0.6324 - val_loss: 0.6770 - val_accuracy: 0.5166\n",
      "Epoch 1691/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6282 - accuracy: 0.6323 - val_loss: 0.6401 - val_accuracy: 0.5705\n",
      "Epoch 1692/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6279 - accuracy: 0.6333 - val_loss: 0.6594 - val_accuracy: 0.5431\n",
      "Epoch 1693/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6262 - accuracy: 0.6369 - val_loss: 0.6544 - val_accuracy: 0.5528\n",
      "Epoch 1694/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6273 - accuracy: 0.6360 - val_loss: 0.6570 - val_accuracy: 0.5464\n",
      "Epoch 1695/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6259 - accuracy: 0.6371 - val_loss: 0.6492 - val_accuracy: 0.5559\n",
      "Epoch 1696/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6269 - accuracy: 0.6343 - val_loss: 0.6626 - val_accuracy: 0.5373\n",
      "Epoch 1697/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6263 - accuracy: 0.6366 - val_loss: 0.6430 - val_accuracy: 0.5740\n",
      "Epoch 1698/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6271 - accuracy: 0.6356 - val_loss: 0.6781 - val_accuracy: 0.5148\n",
      "Epoch 1699/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6274 - accuracy: 0.6344 - val_loss: 0.6322 - val_accuracy: 0.5871\n",
      "Epoch 1700/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6285 - accuracy: 0.6318 - val_loss: 0.6845 - val_accuracy: 0.5104\n",
      "Epoch 1701/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6291 - accuracy: 0.6329 - val_loss: 0.6309 - val_accuracy: 0.5952\n",
      "Epoch 1702/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6282 - accuracy: 0.6313 - val_loss: 0.6727 - val_accuracy: 0.5228\n",
      "Epoch 1703/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6267 - accuracy: 0.6360 - val_loss: 0.6490 - val_accuracy: 0.5559\n",
      "Epoch 1704/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6265 - accuracy: 0.6362 - val_loss: 0.6552 - val_accuracy: 0.5493\n",
      "Epoch 1705/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6255 - accuracy: 0.6382 - val_loss: 0.6569 - val_accuracy: 0.5464\n",
      "Epoch 1706/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6261 - accuracy: 0.6370 - val_loss: 0.6453 - val_accuracy: 0.5680\n",
      "Epoch 1707/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6259 - accuracy: 0.6379 - val_loss: 0.6711 - val_accuracy: 0.5245\n",
      "Epoch 1708/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6265 - accuracy: 0.6356 - val_loss: 0.6408 - val_accuracy: 0.5744\n",
      "Epoch 1709/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6268 - accuracy: 0.6360 - val_loss: 0.6775 - val_accuracy: 0.5185\n",
      "Epoch 1710/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6275 - accuracy: 0.6354 - val_loss: 0.6315 - val_accuracy: 0.5937\n",
      "Epoch 1711/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6279 - accuracy: 0.6321 - val_loss: 0.6811 - val_accuracy: 0.5117\n",
      "Epoch 1712/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6278 - accuracy: 0.6348 - val_loss: 0.6376 - val_accuracy: 0.5800\n",
      "Epoch 1713/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6277 - accuracy: 0.6342 - val_loss: 0.6759 - val_accuracy: 0.5205\n",
      "Epoch 1714/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6270 - accuracy: 0.6360 - val_loss: 0.6362 - val_accuracy: 0.5828\n",
      "Epoch 1715/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6271 - accuracy: 0.6344 - val_loss: 0.6739 - val_accuracy: 0.5214\n",
      "Epoch 1716/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6267 - accuracy: 0.6344 - val_loss: 0.6414 - val_accuracy: 0.5723\n",
      "Epoch 1717/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6268 - accuracy: 0.6358 - val_loss: 0.6727 - val_accuracy: 0.5234\n",
      "Epoch 1718/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6263 - accuracy: 0.6362 - val_loss: 0.6392 - val_accuracy: 0.5800\n",
      "Epoch 1719/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6266 - accuracy: 0.6360 - val_loss: 0.6712 - val_accuracy: 0.5237\n",
      "Epoch 1720/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6265 - accuracy: 0.6351 - val_loss: 0.6401 - val_accuracy: 0.5744\n",
      "Epoch 1721/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6265 - accuracy: 0.6357 - val_loss: 0.6700 - val_accuracy: 0.5298\n",
      "Epoch 1722/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6261 - accuracy: 0.6364 - val_loss: 0.6440 - val_accuracy: 0.5716\n",
      "Epoch 1723/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6261 - accuracy: 0.6372 - val_loss: 0.6654 - val_accuracy: 0.5351\n",
      "Epoch 1724/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6257 - accuracy: 0.6371 - val_loss: 0.6457 - val_accuracy: 0.5627\n",
      "Epoch 1725/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6258 - accuracy: 0.6366 - val_loss: 0.6642 - val_accuracy: 0.5385\n",
      "Epoch 1726/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6255 - accuracy: 0.6372 - val_loss: 0.6466 - val_accuracy: 0.5656\n",
      "Epoch 1727/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6259 - accuracy: 0.6386 - val_loss: 0.6681 - val_accuracy: 0.5305\n",
      "Epoch 1728/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6258 - accuracy: 0.6366 - val_loss: 0.6399 - val_accuracy: 0.5734\n",
      "Epoch 1729/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6264 - accuracy: 0.6353 - val_loss: 0.6765 - val_accuracy: 0.5199\n",
      "Epoch 1730/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6267 - accuracy: 0.6360 - val_loss: 0.6331 - val_accuracy: 0.5923\n",
      "Epoch 1731/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6276 - accuracy: 0.6329 - val_loss: 0.6889 - val_accuracy: 0.5040\n",
      "Epoch 1732/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6290 - accuracy: 0.6327 - val_loss: 0.6285 - val_accuracy: 0.5930\n",
      "Epoch 1733/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6288 - accuracy: 0.6306 - val_loss: 0.6850 - val_accuracy: 0.5060\n",
      "Epoch 1734/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6281 - accuracy: 0.6345 - val_loss: 0.6381 - val_accuracy: 0.5824\n",
      "Epoch 1735/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6271 - accuracy: 0.6349 - val_loss: 0.6685 - val_accuracy: 0.5276\n",
      "Epoch 1736/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6259 - accuracy: 0.6363 - val_loss: 0.6462 - val_accuracy: 0.5643\n",
      "Epoch 1737/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6260 - accuracy: 0.6355 - val_loss: 0.6580 - val_accuracy: 0.5466\n",
      "Epoch 1738/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6252 - accuracy: 0.6381 - val_loss: 0.6559 - val_accuracy: 0.5513\n",
      "Epoch 1739/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6257 - accuracy: 0.6381 - val_loss: 0.6550 - val_accuracy: 0.5495\n",
      "Epoch 1740/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6251 - accuracy: 0.6382 - val_loss: 0.6555 - val_accuracy: 0.5493\n",
      "Epoch 1741/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6255 - accuracy: 0.6374 - val_loss: 0.6526 - val_accuracy: 0.5533\n",
      "Epoch 1742/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6252 - accuracy: 0.6373 - val_loss: 0.6564 - val_accuracy: 0.5471\n",
      "Epoch 1743/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6253 - accuracy: 0.6373 - val_loss: 0.6556 - val_accuracy: 0.5464\n",
      "Epoch 1744/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6251 - accuracy: 0.6378 - val_loss: 0.6553 - val_accuracy: 0.5499\n",
      "Epoch 1745/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6252 - accuracy: 0.6381 - val_loss: 0.6537 - val_accuracy: 0.5521\n",
      "Epoch 1746/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6251 - accuracy: 0.6377 - val_loss: 0.6557 - val_accuracy: 0.5506\n",
      "Epoch 1747/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6252 - accuracy: 0.6383 - val_loss: 0.6553 - val_accuracy: 0.5479\n",
      "Epoch 1748/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6250 - accuracy: 0.6381 - val_loss: 0.6577 - val_accuracy: 0.5459\n",
      "Epoch 1749/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6251 - accuracy: 0.6378 - val_loss: 0.6515 - val_accuracy: 0.5566\n",
      "Epoch 1750/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6250 - accuracy: 0.6379 - val_loss: 0.6602 - val_accuracy: 0.5435\n",
      "Epoch 1751/15000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.6252 - accuracy: 0.6378 - val_loss: 0.6477 - val_accuracy: 0.5634\n",
      "Epoch 1752/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6251 - accuracy: 0.6384 - val_loss: 0.6695 - val_accuracy: 0.5312\n",
      "Epoch 1753/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6256 - accuracy: 0.6371 - val_loss: 0.6377 - val_accuracy: 0.5804\n",
      "Epoch 1754/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6262 - accuracy: 0.6352 - val_loss: 0.6851 - val_accuracy: 0.5088\n",
      "Epoch 1755/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6279 - accuracy: 0.6344 - val_loss: 0.6256 - val_accuracy: 0.6036\n",
      "Epoch 1756/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6289 - accuracy: 0.6303 - val_loss: 0.7033 - val_accuracy: 0.4868\n",
      "Epoch 1757/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6317 - accuracy: 0.6288 - val_loss: 0.6299 - val_accuracy: 0.5935\n",
      "Epoch 1758/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6283 - accuracy: 0.6317 - val_loss: 0.6722 - val_accuracy: 0.5267\n",
      "Epoch 1759/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6261 - accuracy: 0.6365 - val_loss: 0.6505 - val_accuracy: 0.5554\n",
      "Epoch 1760/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6252 - accuracy: 0.6384 - val_loss: 0.6434 - val_accuracy: 0.5663\n",
      "Epoch 1761/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6253 - accuracy: 0.6379 - val_loss: 0.6790 - val_accuracy: 0.5161\n",
      "Epoch 1762/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6270 - accuracy: 0.6338 - val_loss: 0.6291 - val_accuracy: 0.5930\n",
      "Epoch 1763/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6281 - accuracy: 0.6324 - val_loss: 0.7002 - val_accuracy: 0.4892\n",
      "Epoch 1764/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6311 - accuracy: 0.6298 - val_loss: 0.6298 - val_accuracy: 0.5948\n",
      "Epoch 1765/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6279 - accuracy: 0.6313 - val_loss: 0.6701 - val_accuracy: 0.5254\n",
      "Epoch 1766/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6259 - accuracy: 0.6367 - val_loss: 0.6528 - val_accuracy: 0.5490\n",
      "Epoch 1767/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6250 - accuracy: 0.6382 - val_loss: 0.6387 - val_accuracy: 0.5802\n",
      "Epoch 1768/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6257 - accuracy: 0.6365 - val_loss: 0.6816 - val_accuracy: 0.5119\n",
      "Epoch 1769/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6276 - accuracy: 0.6348 - val_loss: 0.6284 - val_accuracy: 0.5935\n",
      "Epoch 1770/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6281 - accuracy: 0.6314 - val_loss: 0.6904 - val_accuracy: 0.4987\n",
      "Epoch 1771/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6287 - accuracy: 0.6326 - val_loss: 0.6384 - val_accuracy: 0.5765\n",
      "Epoch 1772/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6261 - accuracy: 0.6361 - val_loss: 0.6564 - val_accuracy: 0.5442\n",
      "Epoch 1773/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6249 - accuracy: 0.6383 - val_loss: 0.6612 - val_accuracy: 0.5400\n",
      "Epoch 1774/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6251 - accuracy: 0.6384 - val_loss: 0.6346 - val_accuracy: 0.5826\n",
      "Epoch 1775/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6263 - accuracy: 0.6364 - val_loss: 0.6864 - val_accuracy: 0.5031\n",
      "Epoch 1776/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6280 - accuracy: 0.6332 - val_loss: 0.6322 - val_accuracy: 0.5873\n",
      "Epoch 1777/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6272 - accuracy: 0.6341 - val_loss: 0.6764 - val_accuracy: 0.5172\n",
      "Epoch 1778/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6265 - accuracy: 0.6353 - val_loss: 0.6440 - val_accuracy: 0.5652\n",
      "Epoch 1779/15000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6251 - accuracy: 0.6371 - val_loss: 0.6511 - val_accuracy: 0.5535\n",
      "Epoch 1780/15000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6246 - accuracy: 0.6388 - val_loss: 0.6666 - val_accuracy: 0.5342\n",
      "Epoch 1781/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6252 - accuracy: 0.6383 - val_loss: 0.6364 - val_accuracy: 0.5835\n",
      "Epoch 1782/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6261 - accuracy: 0.6360 - val_loss: 0.6840 - val_accuracy: 0.5106\n",
      "Epoch 1783/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6276 - accuracy: 0.6340 - val_loss: 0.6318 - val_accuracy: 0.5884\n",
      "Epoch 1784/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6272 - accuracy: 0.6326 - val_loss: 0.6796 - val_accuracy: 0.5126\n",
      "Epoch 1785/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6266 - accuracy: 0.6355 - val_loss: 0.6419 - val_accuracy: 0.5703\n",
      "Epoch 1786/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6256 - accuracy: 0.6372 - val_loss: 0.6593 - val_accuracy: 0.5455\n",
      "Epoch 1787/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6247 - accuracy: 0.6382 - val_loss: 0.6538 - val_accuracy: 0.5543\n",
      "Epoch 1788/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6248 - accuracy: 0.6381 - val_loss: 0.6482 - val_accuracy: 0.5614\n",
      "Epoch 1789/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6247 - accuracy: 0.6389 - val_loss: 0.6681 - val_accuracy: 0.5311\n",
      "Epoch 1790/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6251 - accuracy: 0.6372 - val_loss: 0.6415 - val_accuracy: 0.5729\n",
      "Epoch 1791/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6254 - accuracy: 0.6373 - val_loss: 0.6753 - val_accuracy: 0.5210\n",
      "Epoch 1792/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6261 - accuracy: 0.6345 - val_loss: 0.6362 - val_accuracy: 0.5815\n",
      "Epoch 1793/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6261 - accuracy: 0.6346 - val_loss: 0.6780 - val_accuracy: 0.5190\n",
      "Epoch 1794/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6261 - accuracy: 0.6367 - val_loss: 0.6390 - val_accuracy: 0.5796\n",
      "Epoch 1795/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6261 - accuracy: 0.6368 - val_loss: 0.6754 - val_accuracy: 0.5208\n",
      "Epoch 1796/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6260 - accuracy: 0.6355 - val_loss: 0.6364 - val_accuracy: 0.5818\n",
      "Epoch 1797/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6262 - accuracy: 0.6347 - val_loss: 0.6739 - val_accuracy: 0.5245\n",
      "Epoch 1798/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6256 - accuracy: 0.6374 - val_loss: 0.6432 - val_accuracy: 0.5714\n",
      "Epoch 1799/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6258 - accuracy: 0.6373 - val_loss: 0.6729 - val_accuracy: 0.5252\n",
      "Epoch 1800/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6255 - accuracy: 0.6362 - val_loss: 0.6375 - val_accuracy: 0.5782\n",
      "Epoch 1801/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6259 - accuracy: 0.6355 - val_loss: 0.6748 - val_accuracy: 0.5216\n",
      "Epoch 1802/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6257 - accuracy: 0.6367 - val_loss: 0.6381 - val_accuracy: 0.5826\n",
      "Epoch 1803/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6262 - accuracy: 0.6359 - val_loss: 0.6810 - val_accuracy: 0.5132\n",
      "Epoch 1804/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6265 - accuracy: 0.6349 - val_loss: 0.6347 - val_accuracy: 0.5822\n",
      "Epoch 1805/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6265 - accuracy: 0.6341 - val_loss: 0.6731 - val_accuracy: 0.5243\n",
      "Epoch 1806/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6256 - accuracy: 0.6373 - val_loss: 0.6431 - val_accuracy: 0.5705\n",
      "Epoch 1807/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6254 - accuracy: 0.6377 - val_loss: 0.6645 - val_accuracy: 0.5380\n",
      "Epoch 1808/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6247 - accuracy: 0.6380 - val_loss: 0.6495 - val_accuracy: 0.5588\n",
      "Epoch 1809/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6248 - accuracy: 0.6378 - val_loss: 0.6584 - val_accuracy: 0.5479\n",
      "Epoch 1810/15000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6244 - accuracy: 0.6387 - val_loss: 0.6531 - val_accuracy: 0.5535\n",
      "Epoch 1811/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6246 - accuracy: 0.6390 - val_loss: 0.6568 - val_accuracy: 0.5455\n",
      "Epoch 1812/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6243 - accuracy: 0.6386 - val_loss: 0.6540 - val_accuracy: 0.5530\n",
      "Epoch 1813/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6245 - accuracy: 0.6383 - val_loss: 0.6558 - val_accuracy: 0.5512\n",
      "Epoch 1814/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6242 - accuracy: 0.6386 - val_loss: 0.6528 - val_accuracy: 0.5563\n",
      "Epoch 1815/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6244 - accuracy: 0.6382 - val_loss: 0.6586 - val_accuracy: 0.5448\n",
      "Epoch 1816/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6242 - accuracy: 0.6390 - val_loss: 0.6515 - val_accuracy: 0.5555\n",
      "Epoch 1817/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6244 - accuracy: 0.6387 - val_loss: 0.6608 - val_accuracy: 0.5438\n",
      "Epoch 1818/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6242 - accuracy: 0.6390 - val_loss: 0.6473 - val_accuracy: 0.5658\n",
      "Epoch 1819/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6245 - accuracy: 0.6393 - val_loss: 0.6683 - val_accuracy: 0.5343\n",
      "Epoch 1820/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6246 - accuracy: 0.6390 - val_loss: 0.6409 - val_accuracy: 0.5758\n",
      "Epoch 1821/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6252 - accuracy: 0.6370 - val_loss: 0.6803 - val_accuracy: 0.5159\n",
      "Epoch 1822/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6262 - accuracy: 0.6355 - val_loss: 0.6286 - val_accuracy: 0.6001\n",
      "Epoch 1823/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6272 - accuracy: 0.6323 - val_loss: 0.6975 - val_accuracy: 0.4962\n",
      "Epoch 1824/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6294 - accuracy: 0.6306 - val_loss: 0.6310 - val_accuracy: 0.5930\n",
      "Epoch 1825/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6273 - accuracy: 0.6336 - val_loss: 0.6745 - val_accuracy: 0.5239\n",
      "Epoch 1826/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6255 - accuracy: 0.6373 - val_loss: 0.6469 - val_accuracy: 0.5641\n",
      "Epoch 1827/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6245 - accuracy: 0.6384 - val_loss: 0.6507 - val_accuracy: 0.5563\n",
      "Epoch 1828/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6241 - accuracy: 0.6389 - val_loss: 0.6683 - val_accuracy: 0.5312\n",
      "Epoch 1829/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6248 - accuracy: 0.6369 - val_loss: 0.6393 - val_accuracy: 0.5771\n",
      "Epoch 1830/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6253 - accuracy: 0.6359 - val_loss: 0.6833 - val_accuracy: 0.5115\n",
      "Epoch 1831/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6266 - accuracy: 0.6350 - val_loss: 0.6304 - val_accuracy: 0.5919\n",
      "Epoch 1832/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6265 - accuracy: 0.6339 - val_loss: 0.6863 - val_accuracy: 0.5077\n",
      "Epoch 1833/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6274 - accuracy: 0.6333 - val_loss: 0.6363 - val_accuracy: 0.5796\n",
      "Epoch 1834/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6256 - accuracy: 0.6356 - val_loss: 0.6641 - val_accuracy: 0.5380\n",
      "Epoch 1835/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6244 - accuracy: 0.6391 - val_loss: 0.6549 - val_accuracy: 0.5508\n",
      "Epoch 1836/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6241 - accuracy: 0.6386 - val_loss: 0.6443 - val_accuracy: 0.5667\n",
      "Epoch 1837/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6244 - accuracy: 0.6383 - val_loss: 0.6740 - val_accuracy: 0.5243\n",
      "Epoch 1838/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6253 - accuracy: 0.6363 - val_loss: 0.6344 - val_accuracy: 0.5846\n",
      "Epoch 1839/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6258 - accuracy: 0.6353 - val_loss: 0.6854 - val_accuracy: 0.5055\n",
      "Epoch 1840/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6269 - accuracy: 0.6350 - val_loss: 0.6334 - val_accuracy: 0.5842\n",
      "Epoch 1841/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6260 - accuracy: 0.6353 - val_loss: 0.6760 - val_accuracy: 0.5210\n",
      "Epoch 1842/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6255 - accuracy: 0.6358 - val_loss: 0.6419 - val_accuracy: 0.5705\n",
      "Epoch 1843/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6244 - accuracy: 0.6382 - val_loss: 0.6564 - val_accuracy: 0.5460\n",
      "Epoch 1844/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6239 - accuracy: 0.6387 - val_loss: 0.6603 - val_accuracy: 0.5429\n",
      "Epoch 1845/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6239 - accuracy: 0.6393 - val_loss: 0.6436 - val_accuracy: 0.5691\n",
      "Epoch 1846/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6244 - accuracy: 0.6375 - val_loss: 0.6744 - val_accuracy: 0.5225\n",
      "Epoch 1847/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6251 - accuracy: 0.6362 - val_loss: 0.6340 - val_accuracy: 0.5840\n",
      "Epoch 1848/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6256 - accuracy: 0.6357 - val_loss: 0.6856 - val_accuracy: 0.5079\n",
      "Epoch 1849/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6267 - accuracy: 0.6349 - val_loss: 0.6326 - val_accuracy: 0.5859\n",
      "Epoch 1850/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6261 - accuracy: 0.6349 - val_loss: 0.6794 - val_accuracy: 0.5170\n",
      "Epoch 1851/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6259 - accuracy: 0.6356 - val_loss: 0.6394 - val_accuracy: 0.5762\n",
      "Epoch 1852/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6246 - accuracy: 0.6371 - val_loss: 0.6603 - val_accuracy: 0.5449\n",
      "Epoch 1853/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6238 - accuracy: 0.6395 - val_loss: 0.6574 - val_accuracy: 0.5468\n",
      "Epoch 1854/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6237 - accuracy: 0.6390 - val_loss: 0.6465 - val_accuracy: 0.5634\n",
      "Epoch 1855/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6239 - accuracy: 0.6390 - val_loss: 0.6705 - val_accuracy: 0.5283\n",
      "Epoch 1856/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6246 - accuracy: 0.6376 - val_loss: 0.6365 - val_accuracy: 0.5798\n",
      "Epoch 1857/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6252 - accuracy: 0.6365 - val_loss: 0.6844 - val_accuracy: 0.5091\n",
      "Epoch 1858/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6263 - accuracy: 0.6351 - val_loss: 0.6322 - val_accuracy: 0.5870\n",
      "Epoch 1859/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6262 - accuracy: 0.6354 - val_loss: 0.6840 - val_accuracy: 0.5117\n",
      "Epoch 1860/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6266 - accuracy: 0.6353 - val_loss: 0.6349 - val_accuracy: 0.5868\n",
      "Epoch 1861/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6252 - accuracy: 0.6354 - val_loss: 0.6672 - val_accuracy: 0.5349\n",
      "Epoch 1862/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6241 - accuracy: 0.6388 - val_loss: 0.6521 - val_accuracy: 0.5526\n",
      "Epoch 1863/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6237 - accuracy: 0.6394 - val_loss: 0.6513 - val_accuracy: 0.5552\n",
      "Epoch 1864/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6236 - accuracy: 0.6394 - val_loss: 0.6640 - val_accuracy: 0.5398\n",
      "Epoch 1865/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6240 - accuracy: 0.6388 - val_loss: 0.6412 - val_accuracy: 0.5734\n",
      "Epoch 1866/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6243 - accuracy: 0.6373 - val_loss: 0.6784 - val_accuracy: 0.5164\n",
      "Epoch 1867/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6252 - accuracy: 0.6361 - val_loss: 0.6346 - val_accuracy: 0.5846\n",
      "Epoch 1868/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6255 - accuracy: 0.6365 - val_loss: 0.6834 - val_accuracy: 0.5130\n",
      "Epoch 1869/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6265 - accuracy: 0.6351 - val_loss: 0.6330 - val_accuracy: 0.5884\n",
      "Epoch 1870/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6255 - accuracy: 0.6344 - val_loss: 0.6740 - val_accuracy: 0.5250\n",
      "Epoch 1871/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6247 - accuracy: 0.6381 - val_loss: 0.6459 - val_accuracy: 0.5619\n",
      "Epoch 1872/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6242 - accuracy: 0.6393 - val_loss: 0.6587 - val_accuracy: 0.5473\n",
      "Epoch 1873/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6235 - accuracy: 0.6392 - val_loss: 0.6531 - val_accuracy: 0.5554\n",
      "Epoch 1874/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6237 - accuracy: 0.6383 - val_loss: 0.6529 - val_accuracy: 0.5554\n",
      "Epoch 1875/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6234 - accuracy: 0.6394 - val_loss: 0.6626 - val_accuracy: 0.5424\n",
      "Epoch 1876/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6237 - accuracy: 0.6389 - val_loss: 0.6487 - val_accuracy: 0.5605\n",
      "Epoch 1877/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6236 - accuracy: 0.6396 - val_loss: 0.6629 - val_accuracy: 0.5402\n",
      "Epoch 1878/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6239 - accuracy: 0.6392 - val_loss: 0.6437 - val_accuracy: 0.5685\n",
      "Epoch 1879/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6239 - accuracy: 0.6381 - val_loss: 0.6713 - val_accuracy: 0.5285\n",
      "Epoch 1880/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6242 - accuracy: 0.6387 - val_loss: 0.6406 - val_accuracy: 0.5742\n",
      "Epoch 1881/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6246 - accuracy: 0.6388 - val_loss: 0.6785 - val_accuracy: 0.5199\n",
      "Epoch 1882/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6254 - accuracy: 0.6360 - val_loss: 0.6313 - val_accuracy: 0.5928\n",
      "Epoch 1883/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6261 - accuracy: 0.6346 - val_loss: 0.6891 - val_accuracy: 0.5042\n",
      "Epoch 1884/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6269 - accuracy: 0.6354 - val_loss: 0.6318 - val_accuracy: 0.5908\n",
      "Epoch 1885/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6270 - accuracy: 0.6336 - val_loss: 0.6874 - val_accuracy: 0.5090\n",
      "Epoch 1886/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6271 - accuracy: 0.6341 - val_loss: 0.6339 - val_accuracy: 0.5853\n",
      "Epoch 1887/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6265 - accuracy: 0.6338 - val_loss: 0.6678 - val_accuracy: 0.5353\n",
      "Epoch 1888/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6240 - accuracy: 0.6392 - val_loss: 0.6518 - val_accuracy: 0.5563\n",
      "Epoch 1889/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6249 - accuracy: 0.6381 - val_loss: 0.6597 - val_accuracy: 0.5438\n",
      "Epoch 1890/15000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.6235 - accuracy: 0.6396 - val_loss: 0.6479 - val_accuracy: 0.5610\n",
      "Epoch 1891/15000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6243 - accuracy: 0.6365 - val_loss: 0.6620 - val_accuracy: 0.5415\n",
      "Epoch 1892/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6239 - accuracy: 0.6383 - val_loss: 0.6465 - val_accuracy: 0.5656\n",
      "Epoch 1893/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6242 - accuracy: 0.6393 - val_loss: 0.6739 - val_accuracy: 0.5228\n",
      "Epoch 1894/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6246 - accuracy: 0.6376 - val_loss: 0.6386 - val_accuracy: 0.5744\n",
      "Epoch 1895/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6245 - accuracy: 0.6369 - val_loss: 0.6730 - val_accuracy: 0.5269\n",
      "Epoch 1896/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6250 - accuracy: 0.6370 - val_loss: 0.6367 - val_accuracy: 0.5840\n",
      "Epoch 1897/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6248 - accuracy: 0.6371 - val_loss: 0.6751 - val_accuracy: 0.5223\n",
      "Epoch 1898/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6246 - accuracy: 0.6372 - val_loss: 0.6439 - val_accuracy: 0.5670\n",
      "Epoch 1899/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6244 - accuracy: 0.6380 - val_loss: 0.6671 - val_accuracy: 0.5349\n",
      "Epoch 1900/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6239 - accuracy: 0.6392 - val_loss: 0.6426 - val_accuracy: 0.5734\n",
      "Epoch 1901/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6242 - accuracy: 0.6382 - val_loss: 0.6662 - val_accuracy: 0.5358\n",
      "Epoch 1902/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6236 - accuracy: 0.6398 - val_loss: 0.6458 - val_accuracy: 0.5661\n",
      "Epoch 1903/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6242 - accuracy: 0.6386 - val_loss: 0.6707 - val_accuracy: 0.5298\n",
      "Epoch 1904/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6239 - accuracy: 0.6393 - val_loss: 0.6378 - val_accuracy: 0.5831\n",
      "Epoch 1905/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6247 - accuracy: 0.6372 - val_loss: 0.6773 - val_accuracy: 0.5205\n",
      "Epoch 1906/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6248 - accuracy: 0.6366 - val_loss: 0.6362 - val_accuracy: 0.5807\n",
      "Epoch 1907/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6253 - accuracy: 0.6367 - val_loss: 0.6805 - val_accuracy: 0.5157\n",
      "Epoch 1908/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6251 - accuracy: 0.6368 - val_loss: 0.6358 - val_accuracy: 0.5835\n",
      "Epoch 1909/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6249 - accuracy: 0.6365 - val_loss: 0.6747 - val_accuracy: 0.5234\n",
      "Epoch 1910/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6245 - accuracy: 0.6372 - val_loss: 0.6420 - val_accuracy: 0.5694\n",
      "Epoch 1911/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6242 - accuracy: 0.6372 - val_loss: 0.6676 - val_accuracy: 0.5369\n",
      "Epoch 1912/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6236 - accuracy: 0.6392 - val_loss: 0.6469 - val_accuracy: 0.5654\n",
      "Epoch 1913/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6236 - accuracy: 0.6396 - val_loss: 0.6613 - val_accuracy: 0.5429\n",
      "Epoch 1914/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6232 - accuracy: 0.6399 - val_loss: 0.6501 - val_accuracy: 0.5574\n",
      "Epoch 1915/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6235 - accuracy: 0.6385 - val_loss: 0.6607 - val_accuracy: 0.5457\n",
      "Epoch 1916/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6231 - accuracy: 0.6393 - val_loss: 0.6509 - val_accuracy: 0.5603\n",
      "Epoch 1917/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6234 - accuracy: 0.6395 - val_loss: 0.6618 - val_accuracy: 0.5435\n",
      "Epoch 1918/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6231 - accuracy: 0.6402 - val_loss: 0.6476 - val_accuracy: 0.5619\n",
      "Epoch 1919/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6234 - accuracy: 0.6382 - val_loss: 0.6660 - val_accuracy: 0.5385\n",
      "Epoch 1920/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6233 - accuracy: 0.6401 - val_loss: 0.6432 - val_accuracy: 0.5723\n",
      "Epoch 1921/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6238 - accuracy: 0.6390 - val_loss: 0.6752 - val_accuracy: 0.5237\n",
      "Epoch 1922/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6243 - accuracy: 0.6370 - val_loss: 0.6351 - val_accuracy: 0.5844\n",
      "Epoch 1923/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6252 - accuracy: 0.6352 - val_loss: 0.6859 - val_accuracy: 0.5082\n",
      "Epoch 1924/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6260 - accuracy: 0.6360 - val_loss: 0.6305 - val_accuracy: 0.5932\n",
      "Epoch 1925/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6265 - accuracy: 0.6335 - val_loss: 0.6911 - val_accuracy: 0.5040\n",
      "Epoch 1926/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6274 - accuracy: 0.6329 - val_loss: 0.6348 - val_accuracy: 0.5855\n",
      "Epoch 1927/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6270 - accuracy: 0.6330 - val_loss: 0.6733 - val_accuracy: 0.5263\n",
      "Epoch 1928/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6244 - accuracy: 0.6387 - val_loss: 0.6447 - val_accuracy: 0.5733\n",
      "Epoch 1929/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6260 - accuracy: 0.6374 - val_loss: 0.6691 - val_accuracy: 0.5309\n",
      "Epoch 1930/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6238 - accuracy: 0.6388 - val_loss: 0.6378 - val_accuracy: 0.5791\n",
      "Epoch 1931/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6266 - accuracy: 0.6343 - val_loss: 0.6826 - val_accuracy: 0.5133\n",
      "Epoch 1932/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6255 - accuracy: 0.6356 - val_loss: 0.6336 - val_accuracy: 0.5893\n",
      "Epoch 1933/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6276 - accuracy: 0.6327 - val_loss: 0.6911 - val_accuracy: 0.5024\n",
      "Epoch 1934/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6270 - accuracy: 0.6333 - val_loss: 0.6323 - val_accuracy: 0.5864\n",
      "Epoch 1935/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6278 - accuracy: 0.6332 - val_loss: 0.6724 - val_accuracy: 0.5276\n",
      "Epoch 1936/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6242 - accuracy: 0.6387 - val_loss: 0.6457 - val_accuracy: 0.5698\n",
      "Epoch 1937/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6253 - accuracy: 0.6379 - val_loss: 0.6590 - val_accuracy: 0.5435\n",
      "Epoch 1938/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6229 - accuracy: 0.6397 - val_loss: 0.6513 - val_accuracy: 0.5535\n",
      "Epoch 1939/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6246 - accuracy: 0.6367 - val_loss: 0.6612 - val_accuracy: 0.5398\n",
      "Epoch 1940/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6231 - accuracy: 0.6398 - val_loss: 0.6471 - val_accuracy: 0.5654\n",
      "Epoch 1941/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6242 - accuracy: 0.6392 - val_loss: 0.6699 - val_accuracy: 0.5283\n",
      "Epoch 1942/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6238 - accuracy: 0.6392 - val_loss: 0.6386 - val_accuracy: 0.5745\n",
      "Epoch 1943/15000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6242 - accuracy: 0.6376 - val_loss: 0.6724 - val_accuracy: 0.5252\n",
      "Epoch 1944/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6242 - accuracy: 0.6373 - val_loss: 0.6405 - val_accuracy: 0.5744\n",
      "Epoch 1945/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6236 - accuracy: 0.6386 - val_loss: 0.6654 - val_accuracy: 0.5380\n",
      "Epoch 1946/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6232 - accuracy: 0.6405 - val_loss: 0.6508 - val_accuracy: 0.5572\n",
      "Epoch 1947/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6228 - accuracy: 0.6399 - val_loss: 0.6549 - val_accuracy: 0.5510\n",
      "Epoch 1948/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6227 - accuracy: 0.6396 - val_loss: 0.6577 - val_accuracy: 0.5484\n",
      "Epoch 1949/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6227 - accuracy: 0.6402 - val_loss: 0.6485 - val_accuracy: 0.5636\n",
      "Epoch 1950/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6229 - accuracy: 0.6400 - val_loss: 0.6679 - val_accuracy: 0.5343\n",
      "Epoch 1951/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6230 - accuracy: 0.6400 - val_loss: 0.6424 - val_accuracy: 0.5701\n",
      "Epoch 1952/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6235 - accuracy: 0.6385 - val_loss: 0.6755 - val_accuracy: 0.5223\n",
      "Epoch 1953/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6239 - accuracy: 0.6389 - val_loss: 0.6336 - val_accuracy: 0.5904\n",
      "Epoch 1954/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6245 - accuracy: 0.6369 - val_loss: 0.6855 - val_accuracy: 0.5100\n",
      "Epoch 1955/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6255 - accuracy: 0.6355 - val_loss: 0.6333 - val_accuracy: 0.5891\n",
      "Epoch 1956/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6251 - accuracy: 0.6357 - val_loss: 0.6806 - val_accuracy: 0.5153\n",
      "Epoch 1957/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6246 - accuracy: 0.6367 - val_loss: 0.6387 - val_accuracy: 0.5804\n",
      "Epoch 1958/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6239 - accuracy: 0.6384 - val_loss: 0.6683 - val_accuracy: 0.5331\n",
      "Epoch 1959/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6231 - accuracy: 0.6395 - val_loss: 0.6483 - val_accuracy: 0.5608\n",
      "Epoch 1960/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6230 - accuracy: 0.6394 - val_loss: 0.6593 - val_accuracy: 0.5486\n",
      "Epoch 1961/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6225 - accuracy: 0.6399 - val_loss: 0.6556 - val_accuracy: 0.5543\n",
      "Epoch 1962/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6227 - accuracy: 0.6404 - val_loss: 0.6519 - val_accuracy: 0.5559\n",
      "Epoch 1963/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6224 - accuracy: 0.6400 - val_loss: 0.6605 - val_accuracy: 0.5460\n",
      "Epoch 1964/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6227 - accuracy: 0.6402 - val_loss: 0.6494 - val_accuracy: 0.5610\n",
      "Epoch 1965/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6225 - accuracy: 0.6397 - val_loss: 0.6631 - val_accuracy: 0.5442\n",
      "Epoch 1966/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6227 - accuracy: 0.6399 - val_loss: 0.6468 - val_accuracy: 0.5649\n",
      "Epoch 1967/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6225 - accuracy: 0.6402 - val_loss: 0.6657 - val_accuracy: 0.5367\n",
      "Epoch 1968/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6229 - accuracy: 0.6401 - val_loss: 0.6453 - val_accuracy: 0.5674\n",
      "Epoch 1969/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6227 - accuracy: 0.6394 - val_loss: 0.6709 - val_accuracy: 0.5296\n",
      "Epoch 1970/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6232 - accuracy: 0.6403 - val_loss: 0.6392 - val_accuracy: 0.5798\n",
      "Epoch 1971/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6233 - accuracy: 0.6392 - val_loss: 0.6775 - val_accuracy: 0.5221\n",
      "Epoch 1972/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6242 - accuracy: 0.6370 - val_loss: 0.6335 - val_accuracy: 0.5870\n",
      "Epoch 1973/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6243 - accuracy: 0.6369 - val_loss: 0.6836 - val_accuracy: 0.5124\n",
      "Epoch 1974/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6250 - accuracy: 0.6367 - val_loss: 0.6343 - val_accuracy: 0.5873\n",
      "Epoch 1975/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6246 - accuracy: 0.6368 - val_loss: 0.6814 - val_accuracy: 0.5181\n",
      "Epoch 1976/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6248 - accuracy: 0.6358 - val_loss: 0.6374 - val_accuracy: 0.5795\n",
      "Epoch 1977/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6242 - accuracy: 0.6359 - val_loss: 0.6717 - val_accuracy: 0.5296\n",
      "Epoch 1978/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6234 - accuracy: 0.6397 - val_loss: 0.6442 - val_accuracy: 0.5705\n",
      "Epoch 1979/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6235 - accuracy: 0.6392 - val_loss: 0.6660 - val_accuracy: 0.5356\n",
      "Epoch 1980/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6228 - accuracy: 0.6396 - val_loss: 0.6451 - val_accuracy: 0.5647\n",
      "Epoch 1981/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6234 - accuracy: 0.6381 - val_loss: 0.6662 - val_accuracy: 0.5378\n",
      "Epoch 1982/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6227 - accuracy: 0.6406 - val_loss: 0.6437 - val_accuracy: 0.5722\n",
      "Epoch 1983/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6236 - accuracy: 0.6387 - val_loss: 0.6732 - val_accuracy: 0.5265\n",
      "Epoch 1984/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6234 - accuracy: 0.6381 - val_loss: 0.6353 - val_accuracy: 0.5817\n",
      "Epoch 1985/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6248 - accuracy: 0.6352 - val_loss: 0.6835 - val_accuracy: 0.5115\n",
      "Epoch 1986/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6250 - accuracy: 0.6367 - val_loss: 0.6317 - val_accuracy: 0.5924\n",
      "Epoch 1987/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6259 - accuracy: 0.6342 - val_loss: 0.6883 - val_accuracy: 0.5068\n",
      "Epoch 1988/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6260 - accuracy: 0.6339 - val_loss: 0.6358 - val_accuracy: 0.5833\n",
      "Epoch 1989/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6258 - accuracy: 0.6347 - val_loss: 0.6692 - val_accuracy: 0.5334\n",
      "Epoch 1990/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6231 - accuracy: 0.6403 - val_loss: 0.6481 - val_accuracy: 0.5652\n",
      "Epoch 1991/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6242 - accuracy: 0.6389 - val_loss: 0.6598 - val_accuracy: 0.5433\n",
      "Epoch 1992/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6222 - accuracy: 0.6409 - val_loss: 0.6487 - val_accuracy: 0.5574\n",
      "Epoch 1993/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6239 - accuracy: 0.6367 - val_loss: 0.6651 - val_accuracy: 0.5374\n",
      "Epoch 1994/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6225 - accuracy: 0.6397 - val_loss: 0.6436 - val_accuracy: 0.5734\n",
      "Epoch 1995/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6240 - accuracy: 0.6385 - val_loss: 0.6762 - val_accuracy: 0.5206\n",
      "Epoch 1996/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6237 - accuracy: 0.6380 - val_loss: 0.6315 - val_accuracy: 0.5893\n",
      "Epoch 1997/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6252 - accuracy: 0.6364 - val_loss: 0.6854 - val_accuracy: 0.5102\n",
      "Epoch 1998/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6254 - accuracy: 0.6353 - val_loss: 0.6347 - val_accuracy: 0.5853\n",
      "Epoch 1999/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6243 - accuracy: 0.6368 - val_loss: 0.6721 - val_accuracy: 0.5296\n",
      "Epoch 2000/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6230 - accuracy: 0.6400 - val_loss: 0.6483 - val_accuracy: 0.5597\n",
      "Epoch 2001/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6225 - accuracy: 0.6397 - val_loss: 0.6534 - val_accuracy: 0.5535\n",
      "Epoch 2002/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6219 - accuracy: 0.6407 - val_loss: 0.6608 - val_accuracy: 0.5438\n",
      "Epoch 2003/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6223 - accuracy: 0.6403 - val_loss: 0.6442 - val_accuracy: 0.5700\n",
      "Epoch 2004/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6225 - accuracy: 0.6399 - val_loss: 0.6729 - val_accuracy: 0.5263\n",
      "Epoch 2005/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6231 - accuracy: 0.6385 - val_loss: 0.6373 - val_accuracy: 0.5800\n",
      "Epoch 2006/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6234 - accuracy: 0.6377 - val_loss: 0.6785 - val_accuracy: 0.5179\n",
      "Epoch 2007/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6240 - accuracy: 0.6379 - val_loss: 0.6342 - val_accuracy: 0.5877\n",
      "Epoch 2008/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6239 - accuracy: 0.6373 - val_loss: 0.6805 - val_accuracy: 0.5166\n",
      "Epoch 2009/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6242 - accuracy: 0.6367 - val_loss: 0.6390 - val_accuracy: 0.5765\n",
      "Epoch 2010/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6235 - accuracy: 0.6378 - val_loss: 0.6676 - val_accuracy: 0.5364\n",
      "Epoch 2011/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6225 - accuracy: 0.6403 - val_loss: 0.6476 - val_accuracy: 0.5658\n",
      "Epoch 2012/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6224 - accuracy: 0.6409 - val_loss: 0.6584 - val_accuracy: 0.5473\n",
      "Epoch 2013/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6219 - accuracy: 0.6405 - val_loss: 0.6548 - val_accuracy: 0.5517\n",
      "Epoch 2014/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6222 - accuracy: 0.6399 - val_loss: 0.6549 - val_accuracy: 0.5544\n",
      "Epoch 2015/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6218 - accuracy: 0.6412 - val_loss: 0.6565 - val_accuracy: 0.5532\n",
      "Epoch 2016/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6221 - accuracy: 0.6414 - val_loss: 0.6529 - val_accuracy: 0.5564\n",
      "Epoch 2017/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6217 - accuracy: 0.6409 - val_loss: 0.6568 - val_accuracy: 0.5482\n",
      "Epoch 2018/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6220 - accuracy: 0.6404 - val_loss: 0.6557 - val_accuracy: 0.5532\n",
      "Epoch 2019/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6217 - accuracy: 0.6405 - val_loss: 0.6553 - val_accuracy: 0.5555\n",
      "Epoch 2020/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6219 - accuracy: 0.6406 - val_loss: 0.6574 - val_accuracy: 0.5495\n",
      "Epoch 2021/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6217 - accuracy: 0.6407 - val_loss: 0.6498 - val_accuracy: 0.5585\n",
      "Epoch 2022/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6219 - accuracy: 0.6402 - val_loss: 0.6641 - val_accuracy: 0.5413\n",
      "Epoch 2023/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6219 - accuracy: 0.6409 - val_loss: 0.6444 - val_accuracy: 0.5705\n",
      "Epoch 2024/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6224 - accuracy: 0.6397 - val_loss: 0.6752 - val_accuracy: 0.5254\n",
      "Epoch 2025/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6229 - accuracy: 0.6391 - val_loss: 0.6333 - val_accuracy: 0.5881\n",
      "Epoch 2026/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6240 - accuracy: 0.6374 - val_loss: 0.6925 - val_accuracy: 0.5051\n",
      "Epoch 2027/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6260 - accuracy: 0.6345 - val_loss: 0.6260 - val_accuracy: 0.6028\n",
      "Epoch 2028/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6259 - accuracy: 0.6338 - val_loss: 0.6966 - val_accuracy: 0.5009\n",
      "Epoch 2029/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6271 - accuracy: 0.6333 - val_loss: 0.6357 - val_accuracy: 0.5829\n",
      "Epoch 2030/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6241 - accuracy: 0.6361 - val_loss: 0.6610 - val_accuracy: 0.5446\n",
      "Epoch 2031/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6219 - accuracy: 0.6408 - val_loss: 0.6619 - val_accuracy: 0.5442\n",
      "Epoch 2032/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6225 - accuracy: 0.6404 - val_loss: 0.6365 - val_accuracy: 0.5844\n",
      "Epoch 2033/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6228 - accuracy: 0.6392 - val_loss: 0.6834 - val_accuracy: 0.5155\n",
      "Epoch 2034/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6249 - accuracy: 0.6358 - val_loss: 0.6352 - val_accuracy: 0.5829\n",
      "Epoch 2035/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6242 - accuracy: 0.6349 - val_loss: 0.6770 - val_accuracy: 0.5195\n",
      "Epoch 2036/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6236 - accuracy: 0.6390 - val_loss: 0.6421 - val_accuracy: 0.5729\n",
      "Epoch 2037/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6231 - accuracy: 0.6400 - val_loss: 0.6605 - val_accuracy: 0.5402\n",
      "Epoch 2038/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6223 - accuracy: 0.6400 - val_loss: 0.6497 - val_accuracy: 0.5586\n",
      "Epoch 2039/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6227 - accuracy: 0.6386 - val_loss: 0.6599 - val_accuracy: 0.5469\n",
      "Epoch 2040/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6218 - accuracy: 0.6407 - val_loss: 0.6521 - val_accuracy: 0.5594\n",
      "Epoch 2041/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6226 - accuracy: 0.6407 - val_loss: 0.6620 - val_accuracy: 0.5424\n",
      "Epoch 2042/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6220 - accuracy: 0.6406 - val_loss: 0.6413 - val_accuracy: 0.5723\n",
      "Epoch 2043/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6228 - accuracy: 0.6384 - val_loss: 0.6721 - val_accuracy: 0.5283\n",
      "Epoch 2044/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6227 - accuracy: 0.6399 - val_loss: 0.6375 - val_accuracy: 0.5817\n",
      "Epoch 2045/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6238 - accuracy: 0.6372 - val_loss: 0.6840 - val_accuracy: 0.5108\n",
      "Epoch 2046/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6244 - accuracy: 0.6361 - val_loss: 0.6324 - val_accuracy: 0.5875\n",
      "Epoch 2047/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6243 - accuracy: 0.6361 - val_loss: 0.6754 - val_accuracy: 0.5241\n",
      "Epoch 2048/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6233 - accuracy: 0.6391 - val_loss: 0.6405 - val_accuracy: 0.5773\n",
      "Epoch 2049/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6232 - accuracy: 0.6393 - val_loss: 0.6685 - val_accuracy: 0.5340\n",
      "Epoch 2050/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6221 - accuracy: 0.6405 - val_loss: 0.6471 - val_accuracy: 0.5616\n",
      "Epoch 2051/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6226 - accuracy: 0.6386 - val_loss: 0.6609 - val_accuracy: 0.5455\n",
      "Epoch 2052/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6216 - accuracy: 0.6408 - val_loss: 0.6491 - val_accuracy: 0.5659\n",
      "Epoch 2053/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6224 - accuracy: 0.6411 - val_loss: 0.6628 - val_accuracy: 0.5407\n",
      "Epoch 2054/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6215 - accuracy: 0.6413 - val_loss: 0.6461 - val_accuracy: 0.5658\n",
      "Epoch 2055/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6225 - accuracy: 0.6394 - val_loss: 0.6685 - val_accuracy: 0.5340\n",
      "Epoch 2056/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6220 - accuracy: 0.6403 - val_loss: 0.6387 - val_accuracy: 0.5811\n",
      "Epoch 2057/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6230 - accuracy: 0.6392 - val_loss: 0.6806 - val_accuracy: 0.5179\n",
      "Epoch 2058/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6235 - accuracy: 0.6379 - val_loss: 0.6314 - val_accuracy: 0.5890\n",
      "Epoch 2059/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6249 - accuracy: 0.6348 - val_loss: 0.6929 - val_accuracy: 0.5037\n",
      "Epoch 2060/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6258 - accuracy: 0.6349 - val_loss: 0.6306 - val_accuracy: 0.5948\n",
      "Epoch 2061/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6245 - accuracy: 0.6358 - val_loss: 0.6784 - val_accuracy: 0.5205\n",
      "Epoch 2062/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6233 - accuracy: 0.6378 - val_loss: 0.6431 - val_accuracy: 0.5678\n",
      "Epoch 2063/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6225 - accuracy: 0.6390 - val_loss: 0.6576 - val_accuracy: 0.5499\n",
      "Epoch 2064/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6213 - accuracy: 0.6409 - val_loss: 0.6593 - val_accuracy: 0.5495\n",
      "Epoch 2065/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6219 - accuracy: 0.6414 - val_loss: 0.6447 - val_accuracy: 0.5689\n",
      "Epoch 2066/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6216 - accuracy: 0.6410 - val_loss: 0.6704 - val_accuracy: 0.5305\n",
      "Epoch 2067/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6226 - accuracy: 0.6388 - val_loss: 0.6419 - val_accuracy: 0.5733\n",
      "Epoch 2068/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6220 - accuracy: 0.6392 - val_loss: 0.6709 - val_accuracy: 0.5298\n",
      "Epoch 2069/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6225 - accuracy: 0.6402 - val_loss: 0.6419 - val_accuracy: 0.5736\n",
      "Epoch 2070/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6220 - accuracy: 0.6398 - val_loss: 0.6675 - val_accuracy: 0.5347\n",
      "Epoch 2071/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6222 - accuracy: 0.6396 - val_loss: 0.6447 - val_accuracy: 0.5669\n",
      "Epoch 2072/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6219 - accuracy: 0.6400 - val_loss: 0.6651 - val_accuracy: 0.5413\n",
      "Epoch 2073/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6218 - accuracy: 0.6406 - val_loss: 0.6484 - val_accuracy: 0.5634\n",
      "Epoch 2074/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6218 - accuracy: 0.6409 - val_loss: 0.6624 - val_accuracy: 0.5409\n",
      "Epoch 2075/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6216 - accuracy: 0.6414 - val_loss: 0.6465 - val_accuracy: 0.5643\n",
      "Epoch 2076/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6217 - accuracy: 0.6397 - val_loss: 0.6644 - val_accuracy: 0.5398\n",
      "Epoch 2077/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6215 - accuracy: 0.6411 - val_loss: 0.6456 - val_accuracy: 0.5707\n",
      "Epoch 2078/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6219 - accuracy: 0.6401 - val_loss: 0.6697 - val_accuracy: 0.5316\n",
      "Epoch 2079/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6219 - accuracy: 0.6403 - val_loss: 0.6383 - val_accuracy: 0.5782\n",
      "Epoch 2080/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6226 - accuracy: 0.6390 - val_loss: 0.6791 - val_accuracy: 0.5195\n",
      "Epoch 2081/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6231 - accuracy: 0.6386 - val_loss: 0.6322 - val_accuracy: 0.5934\n",
      "Epoch 2082/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6241 - accuracy: 0.6362 - val_loss: 0.6929 - val_accuracy: 0.5049\n",
      "Epoch 2083/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6257 - accuracy: 0.6348 - val_loss: 0.6316 - val_accuracy: 0.5908\n",
      "Epoch 2084/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6249 - accuracy: 0.6350 - val_loss: 0.6765 - val_accuracy: 0.5232\n",
      "Epoch 2085/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6229 - accuracy: 0.6391 - val_loss: 0.6423 - val_accuracy: 0.5754\n",
      "Epoch 2086/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6229 - accuracy: 0.6400 - val_loss: 0.6634 - val_accuracy: 0.5406\n",
      "Epoch 2087/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6215 - accuracy: 0.6415 - val_loss: 0.6489 - val_accuracy: 0.5581\n",
      "Epoch 2088/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6223 - accuracy: 0.6390 - val_loss: 0.6617 - val_accuracy: 0.5449\n",
      "Epoch 2089/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6212 - accuracy: 0.6416 - val_loss: 0.6483 - val_accuracy: 0.5663\n",
      "Epoch 2090/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6222 - accuracy: 0.6412 - val_loss: 0.6669 - val_accuracy: 0.5358\n",
      "Epoch 2091/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6215 - accuracy: 0.6408 - val_loss: 0.6388 - val_accuracy: 0.5767\n",
      "Epoch 2092/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6230 - accuracy: 0.6382 - val_loss: 0.6807 - val_accuracy: 0.5170\n",
      "Epoch 2093/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6232 - accuracy: 0.6381 - val_loss: 0.6321 - val_accuracy: 0.5939\n",
      "Epoch 2094/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6242 - accuracy: 0.6365 - val_loss: 0.6883 - val_accuracy: 0.5088\n",
      "Epoch 2095/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6248 - accuracy: 0.6360 - val_loss: 0.6331 - val_accuracy: 0.5864\n",
      "Epoch 2096/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6238 - accuracy: 0.6363 - val_loss: 0.6706 - val_accuracy: 0.5316\n",
      "Epoch 2097/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6219 - accuracy: 0.6406 - val_loss: 0.6473 - val_accuracy: 0.5656\n",
      "Epoch 2098/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6220 - accuracy: 0.6406 - val_loss: 0.6563 - val_accuracy: 0.5491\n",
      "Epoch 2099/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6209 - accuracy: 0.6419 - val_loss: 0.6569 - val_accuracy: 0.5482\n",
      "Epoch 2100/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6216 - accuracy: 0.6402 - val_loss: 0.6517 - val_accuracy: 0.5590\n",
      "Epoch 2101/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6209 - accuracy: 0.6416 - val_loss: 0.6595 - val_accuracy: 0.5486\n",
      "Epoch 2102/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6215 - accuracy: 0.6420 - val_loss: 0.6503 - val_accuracy: 0.5612\n",
      "Epoch 2103/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6209 - accuracy: 0.6420 - val_loss: 0.6585 - val_accuracy: 0.5486\n",
      "Epoch 2104/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6213 - accuracy: 0.6415 - val_loss: 0.6507 - val_accuracy: 0.5563\n",
      "Epoch 2105/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6210 - accuracy: 0.6409 - val_loss: 0.6603 - val_accuracy: 0.5490\n",
      "Epoch 2106/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6211 - accuracy: 0.6418 - val_loss: 0.6511 - val_accuracy: 0.5621\n",
      "Epoch 2107/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6210 - accuracy: 0.6418 - val_loss: 0.6610 - val_accuracy: 0.5475\n",
      "Epoch 2108/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6211 - accuracy: 0.6412 - val_loss: 0.6474 - val_accuracy: 0.5638\n",
      "Epoch 2109/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6211 - accuracy: 0.6408 - val_loss: 0.6659 - val_accuracy: 0.5393\n",
      "Epoch 2110/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6213 - accuracy: 0.6409 - val_loss: 0.6428 - val_accuracy: 0.5744\n",
      "Epoch 2111/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6216 - accuracy: 0.6399 - val_loss: 0.6754 - val_accuracy: 0.5248\n",
      "Epoch 2112/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6223 - accuracy: 0.6385 - val_loss: 0.6340 - val_accuracy: 0.5868\n",
      "Epoch 2113/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6232 - accuracy: 0.6374 - val_loss: 0.6883 - val_accuracy: 0.5075\n",
      "Epoch 2114/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6243 - accuracy: 0.6367 - val_loss: 0.6285 - val_accuracy: 0.5986\n",
      "Epoch 2115/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6248 - accuracy: 0.6350 - val_loss: 0.6953 - val_accuracy: 0.5049\n",
      "Epoch 2116/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6262 - accuracy: 0.6343 - val_loss: 0.6326 - val_accuracy: 0.5893\n",
      "Epoch 2117/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6249 - accuracy: 0.6348 - val_loss: 0.6716 - val_accuracy: 0.5311\n",
      "Epoch 2118/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6219 - accuracy: 0.6399 - val_loss: 0.6488 - val_accuracy: 0.5659\n",
      "Epoch 2119/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6228 - accuracy: 0.6412 - val_loss: 0.6568 - val_accuracy: 0.5499\n",
      "Epoch 2120/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6208 - accuracy: 0.6419 - val_loss: 0.6520 - val_accuracy: 0.5539\n",
      "Epoch 2121/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6222 - accuracy: 0.6386 - val_loss: 0.6604 - val_accuracy: 0.5437\n",
      "Epoch 2122/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6209 - accuracy: 0.6414 - val_loss: 0.6479 - val_accuracy: 0.5667\n",
      "Epoch 2123/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6221 - accuracy: 0.6406 - val_loss: 0.6733 - val_accuracy: 0.5265\n",
      "Epoch 2124/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6220 - accuracy: 0.6402 - val_loss: 0.6310 - val_accuracy: 0.5930\n",
      "Epoch 2125/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6237 - accuracy: 0.6370 - val_loss: 0.6907 - val_accuracy: 0.5077\n",
      "Epoch 2126/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6251 - accuracy: 0.6350 - val_loss: 0.6311 - val_accuracy: 0.5939\n",
      "Epoch 2127/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6238 - accuracy: 0.6361 - val_loss: 0.6777 - val_accuracy: 0.5208\n",
      "Epoch 2128/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6224 - accuracy: 0.6389 - val_loss: 0.6449 - val_accuracy: 0.5658\n",
      "Epoch 2129/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6212 - accuracy: 0.6412 - val_loss: 0.6502 - val_accuracy: 0.5575\n",
      "Epoch 2130/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6207 - accuracy: 0.6416 - val_loss: 0.6665 - val_accuracy: 0.5362\n",
      "Epoch 2131/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6213 - accuracy: 0.6412 - val_loss: 0.6360 - val_accuracy: 0.5873\n",
      "Epoch 2132/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6223 - accuracy: 0.6389 - val_loss: 0.6878 - val_accuracy: 0.5080\n",
      "Epoch 2133/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6242 - accuracy: 0.6361 - val_loss: 0.6303 - val_accuracy: 0.5930\n",
      "Epoch 2134/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6235 - accuracy: 0.6363 - val_loss: 0.6804 - val_accuracy: 0.5174\n",
      "Epoch 2135/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6231 - accuracy: 0.6381 - val_loss: 0.6390 - val_accuracy: 0.5802\n",
      "Epoch 2136/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6218 - accuracy: 0.6395 - val_loss: 0.6611 - val_accuracy: 0.5448\n",
      "Epoch 2137/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6208 - accuracy: 0.6420 - val_loss: 0.6560 - val_accuracy: 0.5517\n",
      "Epoch 2138/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6207 - accuracy: 0.6419 - val_loss: 0.6461 - val_accuracy: 0.5681\n",
      "Epoch 2139/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6208 - accuracy: 0.6417 - val_loss: 0.6704 - val_accuracy: 0.5298\n",
      "Epoch 2140/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6216 - accuracy: 0.6401 - val_loss: 0.6360 - val_accuracy: 0.5833\n",
      "Epoch 2141/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6220 - accuracy: 0.6395 - val_loss: 0.6840 - val_accuracy: 0.5128\n",
      "Epoch 2142/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6234 - accuracy: 0.6366 - val_loss: 0.6345 - val_accuracy: 0.5846\n",
      "Epoch 2143/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6223 - accuracy: 0.6384 - val_loss: 0.6706 - val_accuracy: 0.5303\n",
      "Epoch 2144/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6216 - accuracy: 0.6405 - val_loss: 0.6457 - val_accuracy: 0.5705\n",
      "Epoch 2145/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6207 - accuracy: 0.6417 - val_loss: 0.6555 - val_accuracy: 0.5532\n",
      "Epoch 2146/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6204 - accuracy: 0.6423 - val_loss: 0.6610 - val_accuracy: 0.5448\n",
      "Epoch 2147/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6205 - accuracy: 0.6418 - val_loss: 0.6436 - val_accuracy: 0.5720\n",
      "Epoch 2148/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6210 - accuracy: 0.6407 - val_loss: 0.6758 - val_accuracy: 0.5241\n",
      "Epoch 2149/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6219 - accuracy: 0.6397 - val_loss: 0.6317 - val_accuracy: 0.5913\n",
      "Epoch 2150/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6227 - accuracy: 0.6383 - val_loss: 0.6908 - val_accuracy: 0.5075\n",
      "Epoch 2151/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6246 - accuracy: 0.6358 - val_loss: 0.6327 - val_accuracy: 0.5912\n",
      "Epoch 2152/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6227 - accuracy: 0.6372 - val_loss: 0.6716 - val_accuracy: 0.5311\n",
      "Epoch 2153/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6214 - accuracy: 0.6411 - val_loss: 0.6485 - val_accuracy: 0.5650\n",
      "Epoch 2154/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6204 - accuracy: 0.6421 - val_loss: 0.6485 - val_accuracy: 0.5630\n",
      "Epoch 2155/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6204 - accuracy: 0.6424 - val_loss: 0.6704 - val_accuracy: 0.5292\n",
      "Epoch 2156/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6211 - accuracy: 0.6408 - val_loss: 0.6351 - val_accuracy: 0.5886\n",
      "Epoch 2157/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6223 - accuracy: 0.6382 - val_loss: 0.6914 - val_accuracy: 0.5053\n",
      "Epoch 2158/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6244 - accuracy: 0.6361 - val_loss: 0.6292 - val_accuracy: 0.5948\n",
      "Epoch 2159/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6234 - accuracy: 0.6363 - val_loss: 0.6827 - val_accuracy: 0.5144\n",
      "Epoch 2160/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6231 - accuracy: 0.6371 - val_loss: 0.6394 - val_accuracy: 0.5795\n",
      "Epoch 2161/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6211 - accuracy: 0.6397 - val_loss: 0.6559 - val_accuracy: 0.5517\n",
      "Epoch 2162/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6202 - accuracy: 0.6424 - val_loss: 0.6648 - val_accuracy: 0.5389\n",
      "Epoch 2163/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6205 - accuracy: 0.6410 - val_loss: 0.6371 - val_accuracy: 0.5842\n",
      "Epoch 2164/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6216 - accuracy: 0.6399 - val_loss: 0.6850 - val_accuracy: 0.5130\n",
      "Epoch 2165/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6235 - accuracy: 0.6370 - val_loss: 0.6287 - val_accuracy: 0.5963\n",
      "Epoch 2166/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6234 - accuracy: 0.6363 - val_loss: 0.6879 - val_accuracy: 0.5077\n",
      "Epoch 2167/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6237 - accuracy: 0.6370 - val_loss: 0.6386 - val_accuracy: 0.5780\n",
      "Epoch 2168/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6214 - accuracy: 0.6405 - val_loss: 0.6570 - val_accuracy: 0.5486\n",
      "Epoch 2169/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6203 - accuracy: 0.6419 - val_loss: 0.6615 - val_accuracy: 0.5437\n",
      "Epoch 2170/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6205 - accuracy: 0.6420 - val_loss: 0.6360 - val_accuracy: 0.5846\n",
      "Epoch 2171/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6215 - accuracy: 0.6397 - val_loss: 0.6866 - val_accuracy: 0.5106\n",
      "Epoch 2172/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6234 - accuracy: 0.6369 - val_loss: 0.6314 - val_accuracy: 0.5926\n",
      "Epoch 2173/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6231 - accuracy: 0.6368 - val_loss: 0.6835 - val_accuracy: 0.5132\n",
      "Epoch 2174/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6229 - accuracy: 0.6381 - val_loss: 0.6384 - val_accuracy: 0.5802\n",
      "Epoch 2175/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6210 - accuracy: 0.6407 - val_loss: 0.6587 - val_accuracy: 0.5457\n",
      "Epoch 2176/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6202 - accuracy: 0.6429 - val_loss: 0.6596 - val_accuracy: 0.5460\n",
      "Epoch 2177/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6202 - accuracy: 0.6417 - val_loss: 0.6397 - val_accuracy: 0.5798\n",
      "Epoch 2178/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6209 - accuracy: 0.6410 - val_loss: 0.6788 - val_accuracy: 0.5199\n",
      "Epoch 2179/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6221 - accuracy: 0.6394 - val_loss: 0.6323 - val_accuracy: 0.5897\n",
      "Epoch 2180/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6223 - accuracy: 0.6384 - val_loss: 0.6840 - val_accuracy: 0.5133\n",
      "Epoch 2181/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6229 - accuracy: 0.6377 - val_loss: 0.6363 - val_accuracy: 0.5846\n",
      "Epoch 2182/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6215 - accuracy: 0.6402 - val_loss: 0.6678 - val_accuracy: 0.5351\n",
      "Epoch 2183/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6206 - accuracy: 0.6410 - val_loss: 0.6481 - val_accuracy: 0.5636\n",
      "Epoch 2184/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6200 - accuracy: 0.6430 - val_loss: 0.6517 - val_accuracy: 0.5599\n",
      "Epoch 2185/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6199 - accuracy: 0.6427 - val_loss: 0.6649 - val_accuracy: 0.5396\n",
      "Epoch 2186/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6202 - accuracy: 0.6413 - val_loss: 0.6411 - val_accuracy: 0.5769\n",
      "Epoch 2187/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6207 - accuracy: 0.6403 - val_loss: 0.6764 - val_accuracy: 0.5232\n",
      "Epoch 2188/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6215 - accuracy: 0.6392 - val_loss: 0.6346 - val_accuracy: 0.5853\n",
      "Epoch 2189/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6216 - accuracy: 0.6395 - val_loss: 0.6791 - val_accuracy: 0.5185\n",
      "Epoch 2190/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6219 - accuracy: 0.6392 - val_loss: 0.6378 - val_accuracy: 0.5829\n",
      "Epoch 2191/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6212 - accuracy: 0.6400 - val_loss: 0.6720 - val_accuracy: 0.5294\n",
      "Epoch 2192/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6209 - accuracy: 0.6409 - val_loss: 0.6427 - val_accuracy: 0.5754\n",
      "Epoch 2193/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6204 - accuracy: 0.6415 - val_loss: 0.6624 - val_accuracy: 0.5420\n",
      "Epoch 2194/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6200 - accuracy: 0.6417 - val_loss: 0.6518 - val_accuracy: 0.5588\n",
      "Epoch 2195/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6198 - accuracy: 0.6430 - val_loss: 0.6552 - val_accuracy: 0.5521\n",
      "Epoch 2196/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6197 - accuracy: 0.6430 - val_loss: 0.6582 - val_accuracy: 0.5471\n",
      "Epoch 2197/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6198 - accuracy: 0.6426 - val_loss: 0.6499 - val_accuracy: 0.5614\n",
      "Epoch 2198/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6198 - accuracy: 0.6425 - val_loss: 0.6640 - val_accuracy: 0.5409\n",
      "Epoch 2199/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6200 - accuracy: 0.6419 - val_loss: 0.6437 - val_accuracy: 0.5727\n",
      "Epoch 2200/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6203 - accuracy: 0.6412 - val_loss: 0.6730 - val_accuracy: 0.5287\n",
      "Epoch 2201/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6208 - accuracy: 0.6406 - val_loss: 0.6355 - val_accuracy: 0.5860\n",
      "Epoch 2202/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6214 - accuracy: 0.6392 - val_loss: 0.6860 - val_accuracy: 0.5124\n",
      "Epoch 2203/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6228 - accuracy: 0.6382 - val_loss: 0.6311 - val_accuracy: 0.5928\n",
      "Epoch 2204/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6224 - accuracy: 0.6383 - val_loss: 0.6855 - val_accuracy: 0.5141\n",
      "Epoch 2205/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6228 - accuracy: 0.6381 - val_loss: 0.6353 - val_accuracy: 0.5859\n",
      "Epoch 2206/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6213 - accuracy: 0.6398 - val_loss: 0.6694 - val_accuracy: 0.5347\n",
      "Epoch 2207/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6204 - accuracy: 0.6411 - val_loss: 0.6484 - val_accuracy: 0.5654\n",
      "Epoch 2208/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6198 - accuracy: 0.6433 - val_loss: 0.6553 - val_accuracy: 0.5515\n",
      "Epoch 2209/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6196 - accuracy: 0.6425 - val_loss: 0.6602 - val_accuracy: 0.5462\n",
      "Epoch 2210/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6197 - accuracy: 0.6426 - val_loss: 0.6453 - val_accuracy: 0.5711\n",
      "Epoch 2211/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6200 - accuracy: 0.6422 - val_loss: 0.6717 - val_accuracy: 0.5298\n",
      "Epoch 2212/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6205 - accuracy: 0.6408 - val_loss: 0.6363 - val_accuracy: 0.5839\n",
      "Epoch 2213/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6212 - accuracy: 0.6400 - val_loss: 0.6840 - val_accuracy: 0.5153\n",
      "Epoch 2214/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6225 - accuracy: 0.6383 - val_loss: 0.6319 - val_accuracy: 0.5932\n",
      "Epoch 2215/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6220 - accuracy: 0.6377 - val_loss: 0.6807 - val_accuracy: 0.5192\n",
      "Epoch 2216/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6219 - accuracy: 0.6389 - val_loss: 0.6386 - val_accuracy: 0.5806\n",
      "Epoch 2217/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6207 - accuracy: 0.6408 - val_loss: 0.6653 - val_accuracy: 0.5389\n",
      "Epoch 2218/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6199 - accuracy: 0.6417 - val_loss: 0.6505 - val_accuracy: 0.5608\n",
      "Epoch 2219/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6196 - accuracy: 0.6426 - val_loss: 0.6536 - val_accuracy: 0.5544\n",
      "Epoch 2220/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6195 - accuracy: 0.6427 - val_loss: 0.6622 - val_accuracy: 0.5426\n",
      "Epoch 2221/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6196 - accuracy: 0.6419 - val_loss: 0.6433 - val_accuracy: 0.5738\n",
      "Epoch 2222/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6200 - accuracy: 0.6418 - val_loss: 0.6744 - val_accuracy: 0.5267\n",
      "Epoch 2223/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6209 - accuracy: 0.6406 - val_loss: 0.6342 - val_accuracy: 0.5873\n",
      "Epoch 2224/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6213 - accuracy: 0.6395 - val_loss: 0.6838 - val_accuracy: 0.5142\n",
      "Epoch 2225/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6222 - accuracy: 0.6384 - val_loss: 0.6344 - val_accuracy: 0.5873\n",
      "Epoch 2226/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6215 - accuracy: 0.6398 - val_loss: 0.6790 - val_accuracy: 0.5208\n",
      "Epoch 2227/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6215 - accuracy: 0.6399 - val_loss: 0.6374 - val_accuracy: 0.5828\n",
      "Epoch 2228/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6206 - accuracy: 0.6410 - val_loss: 0.6681 - val_accuracy: 0.5356\n",
      "Epoch 2229/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6201 - accuracy: 0.6413 - val_loss: 0.6480 - val_accuracy: 0.5636\n",
      "Epoch 2230/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6197 - accuracy: 0.6424 - val_loss: 0.6584 - val_accuracy: 0.5486\n",
      "Epoch 2231/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6195 - accuracy: 0.6428 - val_loss: 0.6535 - val_accuracy: 0.5526\n",
      "Epoch 2232/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6194 - accuracy: 0.6423 - val_loss: 0.6525 - val_accuracy: 0.5566\n",
      "Epoch 2233/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6194 - accuracy: 0.6431 - val_loss: 0.6622 - val_accuracy: 0.5424\n",
      "Epoch 2234/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6195 - accuracy: 0.6422 - val_loss: 0.6463 - val_accuracy: 0.5681\n",
      "Epoch 2235/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6197 - accuracy: 0.6425 - val_loss: 0.6702 - val_accuracy: 0.5327\n",
      "Epoch 2236/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6202 - accuracy: 0.6413 - val_loss: 0.6370 - val_accuracy: 0.5842\n",
      "Epoch 2237/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6208 - accuracy: 0.6405 - val_loss: 0.6836 - val_accuracy: 0.5155\n",
      "Epoch 2238/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6221 - accuracy: 0.6392 - val_loss: 0.6297 - val_accuracy: 0.5948\n",
      "Epoch 2239/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6224 - accuracy: 0.6376 - val_loss: 0.6909 - val_accuracy: 0.5086\n",
      "Epoch 2240/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6237 - accuracy: 0.6367 - val_loss: 0.6335 - val_accuracy: 0.5886\n",
      "Epoch 2241/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6216 - accuracy: 0.6383 - val_loss: 0.6689 - val_accuracy: 0.5338\n",
      "Epoch 2242/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6201 - accuracy: 0.6419 - val_loss: 0.6514 - val_accuracy: 0.5616\n",
      "Epoch 2243/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6195 - accuracy: 0.6432 - val_loss: 0.6499 - val_accuracy: 0.5605\n",
      "Epoch 2244/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6195 - accuracy: 0.6420 - val_loss: 0.6674 - val_accuracy: 0.5338\n",
      "Epoch 2245/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6200 - accuracy: 0.6406 - val_loss: 0.6390 - val_accuracy: 0.5813\n",
      "Epoch 2246/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6205 - accuracy: 0.6412 - val_loss: 0.6820 - val_accuracy: 0.5164\n",
      "Epoch 2247/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6216 - accuracy: 0.6395 - val_loss: 0.6320 - val_accuracy: 0.5899\n",
      "Epoch 2248/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6219 - accuracy: 0.6386 - val_loss: 0.6856 - val_accuracy: 0.5128\n",
      "Epoch 2249/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6228 - accuracy: 0.6380 - val_loss: 0.6332 - val_accuracy: 0.5899\n",
      "Epoch 2250/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6212 - accuracy: 0.6382 - val_loss: 0.6690 - val_accuracy: 0.5345\n",
      "Epoch 2251/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6199 - accuracy: 0.6419 - val_loss: 0.6534 - val_accuracy: 0.5574\n",
      "Epoch 2252/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6195 - accuracy: 0.6433 - val_loss: 0.6498 - val_accuracy: 0.5634\n",
      "Epoch 2253/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6192 - accuracy: 0.6434 - val_loss: 0.6637 - val_accuracy: 0.5411\n",
      "Epoch 2254/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6198 - accuracy: 0.6421 - val_loss: 0.6402 - val_accuracy: 0.5758\n",
      "Epoch 2255/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6201 - accuracy: 0.6411 - val_loss: 0.6785 - val_accuracy: 0.5199\n",
      "Epoch 2256/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6209 - accuracy: 0.6396 - val_loss: 0.6354 - val_accuracy: 0.5859\n",
      "Epoch 2257/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6212 - accuracy: 0.6400 - val_loss: 0.6819 - val_accuracy: 0.5166\n",
      "Epoch 2258/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6220 - accuracy: 0.6392 - val_loss: 0.6326 - val_accuracy: 0.5908\n",
      "Epoch 2259/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6212 - accuracy: 0.6377 - val_loss: 0.6740 - val_accuracy: 0.5272\n",
      "Epoch 2260/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6203 - accuracy: 0.6407 - val_loss: 0.6476 - val_accuracy: 0.5641\n",
      "Epoch 2261/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6199 - accuracy: 0.6430 - val_loss: 0.6598 - val_accuracy: 0.5431\n",
      "Epoch 2262/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6192 - accuracy: 0.6426 - val_loss: 0.6509 - val_accuracy: 0.5590\n",
      "Epoch 2263/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6194 - accuracy: 0.6424 - val_loss: 0.6538 - val_accuracy: 0.5550\n",
      "Epoch 2264/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6191 - accuracy: 0.6435 - val_loss: 0.6606 - val_accuracy: 0.5459\n",
      "Epoch 2265/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6192 - accuracy: 0.6426 - val_loss: 0.6508 - val_accuracy: 0.5588\n",
      "Epoch 2266/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6192 - accuracy: 0.6427 - val_loss: 0.6607 - val_accuracy: 0.5451\n",
      "Epoch 2267/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6193 - accuracy: 0.6420 - val_loss: 0.6461 - val_accuracy: 0.5678\n",
      "Epoch 2268/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6194 - accuracy: 0.6425 - val_loss: 0.6669 - val_accuracy: 0.5353\n",
      "Epoch 2269/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6194 - accuracy: 0.6420 - val_loss: 0.6447 - val_accuracy: 0.5729\n",
      "Epoch 2270/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6197 - accuracy: 0.6426 - val_loss: 0.6736 - val_accuracy: 0.5300\n",
      "Epoch 2271/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6202 - accuracy: 0.6411 - val_loss: 0.6350 - val_accuracy: 0.5842\n",
      "Epoch 2272/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6208 - accuracy: 0.6396 - val_loss: 0.6838 - val_accuracy: 0.5174\n",
      "Epoch 2273/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6218 - accuracy: 0.6394 - val_loss: 0.6314 - val_accuracy: 0.5913\n",
      "Epoch 2274/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6220 - accuracy: 0.6381 - val_loss: 0.6893 - val_accuracy: 0.5115\n",
      "Epoch 2275/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6229 - accuracy: 0.6372 - val_loss: 0.6345 - val_accuracy: 0.5864\n",
      "Epoch 2276/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6214 - accuracy: 0.6381 - val_loss: 0.6680 - val_accuracy: 0.5369\n",
      "Epoch 2277/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6200 - accuracy: 0.6423 - val_loss: 0.6518 - val_accuracy: 0.5619\n",
      "Epoch 2278/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6196 - accuracy: 0.6434 - val_loss: 0.6516 - val_accuracy: 0.5564\n",
      "Epoch 2279/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6194 - accuracy: 0.6423 - val_loss: 0.6656 - val_accuracy: 0.5389\n",
      "Epoch 2280/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6196 - accuracy: 0.6413 - val_loss: 0.6428 - val_accuracy: 0.5751\n",
      "Epoch 2281/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6199 - accuracy: 0.6419 - val_loss: 0.6750 - val_accuracy: 0.5254\n",
      "Epoch 2282/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6202 - accuracy: 0.6416 - val_loss: 0.6358 - val_accuracy: 0.5828\n",
      "Epoch 2283/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6209 - accuracy: 0.6407 - val_loss: 0.6833 - val_accuracy: 0.5175\n",
      "Epoch 2284/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6221 - accuracy: 0.6390 - val_loss: 0.6299 - val_accuracy: 0.5957\n",
      "Epoch 2285/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6217 - accuracy: 0.6373 - val_loss: 0.6805 - val_accuracy: 0.5199\n",
      "Epoch 2286/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6209 - accuracy: 0.6403 - val_loss: 0.6445 - val_accuracy: 0.5676\n",
      "Epoch 2287/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6200 - accuracy: 0.6428 - val_loss: 0.6607 - val_accuracy: 0.5433\n",
      "Epoch 2288/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6191 - accuracy: 0.6425 - val_loss: 0.6495 - val_accuracy: 0.5607\n",
      "Epoch 2289/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6191 - accuracy: 0.6423 - val_loss: 0.6543 - val_accuracy: 0.5546\n",
      "Epoch 2290/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6188 - accuracy: 0.6436 - val_loss: 0.6619 - val_accuracy: 0.5429\n",
      "Epoch 2291/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6190 - accuracy: 0.6430 - val_loss: 0.6484 - val_accuracy: 0.5645\n",
      "Epoch 2292/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6190 - accuracy: 0.6427 - val_loss: 0.6623 - val_accuracy: 0.5420\n",
      "Epoch 2293/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6192 - accuracy: 0.6419 - val_loss: 0.6435 - val_accuracy: 0.5725\n",
      "Epoch 2294/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6193 - accuracy: 0.6424 - val_loss: 0.6698 - val_accuracy: 0.5323\n",
      "Epoch 2295/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6194 - accuracy: 0.6419 - val_loss: 0.6433 - val_accuracy: 0.5733\n",
      "Epoch 2296/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6196 - accuracy: 0.6418 - val_loss: 0.6732 - val_accuracy: 0.5311\n",
      "Epoch 2297/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6201 - accuracy: 0.6407 - val_loss: 0.6346 - val_accuracy: 0.5873\n",
      "Epoch 2298/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6206 - accuracy: 0.6395 - val_loss: 0.6823 - val_accuracy: 0.5175\n",
      "Epoch 2299/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6211 - accuracy: 0.6401 - val_loss: 0.6355 - val_accuracy: 0.5844\n",
      "Epoch 2300/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6212 - accuracy: 0.6414 - val_loss: 0.6832 - val_accuracy: 0.5174\n",
      "Epoch 2301/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6217 - accuracy: 0.6396 - val_loss: 0.6315 - val_accuracy: 0.5961\n",
      "Epoch 2302/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6212 - accuracy: 0.6385 - val_loss: 0.6763 - val_accuracy: 0.5254\n",
      "Epoch 2303/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6203 - accuracy: 0.6415 - val_loss: 0.6448 - val_accuracy: 0.5678\n",
      "Epoch 2304/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6200 - accuracy: 0.6427 - val_loss: 0.6663 - val_accuracy: 0.5367\n",
      "Epoch 2305/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6193 - accuracy: 0.6416 - val_loss: 0.6440 - val_accuracy: 0.5692\n",
      "Epoch 2306/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6197 - accuracy: 0.6398 - val_loss: 0.6651 - val_accuracy: 0.5402\n",
      "Epoch 2307/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6190 - accuracy: 0.6421 - val_loss: 0.6473 - val_accuracy: 0.5639\n",
      "Epoch 2308/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6198 - accuracy: 0.6429 - val_loss: 0.6708 - val_accuracy: 0.5301\n",
      "Epoch 2309/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6196 - accuracy: 0.6411 - val_loss: 0.6343 - val_accuracy: 0.5875\n",
      "Epoch 2310/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6211 - accuracy: 0.6385 - val_loss: 0.6848 - val_accuracy: 0.5157\n",
      "Epoch 2311/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6216 - accuracy: 0.6398 - val_loss: 0.6320 - val_accuracy: 0.5891\n",
      "Epoch 2312/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6225 - accuracy: 0.6376 - val_loss: 0.6895 - val_accuracy: 0.5119\n",
      "Epoch 2313/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6229 - accuracy: 0.6377 - val_loss: 0.6312 - val_accuracy: 0.5946\n",
      "Epoch 2314/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6228 - accuracy: 0.6358 - val_loss: 0.6758 - val_accuracy: 0.5245\n",
      "Epoch 2315/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6203 - accuracy: 0.6409 - val_loss: 0.6438 - val_accuracy: 0.5696\n",
      "Epoch 2316/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6209 - accuracy: 0.6411 - val_loss: 0.6652 - val_accuracy: 0.5382\n",
      "Epoch 2317/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6192 - accuracy: 0.6417 - val_loss: 0.6462 - val_accuracy: 0.5634\n",
      "Epoch 2318/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6201 - accuracy: 0.6390 - val_loss: 0.6634 - val_accuracy: 0.5402\n",
      "Epoch 2319/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6192 - accuracy: 0.6421 - val_loss: 0.6467 - val_accuracy: 0.5636\n",
      "Epoch 2320/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6198 - accuracy: 0.6422 - val_loss: 0.6698 - val_accuracy: 0.5309\n",
      "Epoch 2321/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6197 - accuracy: 0.6418 - val_loss: 0.6407 - val_accuracy: 0.5740\n",
      "Epoch 2322/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6195 - accuracy: 0.6404 - val_loss: 0.6676 - val_accuracy: 0.5354\n",
      "Epoch 2323/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6198 - accuracy: 0.6421 - val_loss: 0.6445 - val_accuracy: 0.5696\n",
      "Epoch 2324/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6192 - accuracy: 0.6422 - val_loss: 0.6663 - val_accuracy: 0.5376\n",
      "Epoch 2325/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6195 - accuracy: 0.6414 - val_loss: 0.6505 - val_accuracy: 0.5572\n",
      "Epoch 2326/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6185 - accuracy: 0.6428 - val_loss: 0.6535 - val_accuracy: 0.5557\n",
      "Epoch 2327/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6190 - accuracy: 0.6429 - val_loss: 0.6610 - val_accuracy: 0.5462\n",
      "Epoch 2328/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6186 - accuracy: 0.6433 - val_loss: 0.6456 - val_accuracy: 0.5661\n",
      "Epoch 2329/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6195 - accuracy: 0.6427 - val_loss: 0.6749 - val_accuracy: 0.5272\n",
      "Epoch 2330/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6198 - accuracy: 0.6415 - val_loss: 0.6311 - val_accuracy: 0.5952\n",
      "Epoch 2331/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6213 - accuracy: 0.6384 - val_loss: 0.6925 - val_accuracy: 0.5080\n",
      "Epoch 2332/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6229 - accuracy: 0.6378 - val_loss: 0.6303 - val_accuracy: 0.5919\n",
      "Epoch 2333/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6224 - accuracy: 0.6385 - val_loss: 0.6857 - val_accuracy: 0.5146\n",
      "Epoch 2334/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6220 - accuracy: 0.6394 - val_loss: 0.6355 - val_accuracy: 0.5870\n",
      "Epoch 2335/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6205 - accuracy: 0.6401 - val_loss: 0.6639 - val_accuracy: 0.5406\n",
      "Epoch 2336/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6189 - accuracy: 0.6422 - val_loss: 0.6583 - val_accuracy: 0.5468\n",
      "Epoch 2337/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6191 - accuracy: 0.6428 - val_loss: 0.6470 - val_accuracy: 0.5661\n",
      "Epoch 2338/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6190 - accuracy: 0.6430 - val_loss: 0.6704 - val_accuracy: 0.5305\n",
      "Epoch 2339/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6197 - accuracy: 0.6423 - val_loss: 0.6357 - val_accuracy: 0.5839\n",
      "Epoch 2340/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6200 - accuracy: 0.6411 - val_loss: 0.6840 - val_accuracy: 0.5155\n",
      "Epoch 2341/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6212 - accuracy: 0.6393 - val_loss: 0.6357 - val_accuracy: 0.5842\n",
      "Epoch 2342/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6202 - accuracy: 0.6414 - val_loss: 0.6747 - val_accuracy: 0.5285\n",
      "Epoch 2343/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6199 - accuracy: 0.6418 - val_loss: 0.6421 - val_accuracy: 0.5749\n",
      "Epoch 2344/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6188 - accuracy: 0.6427 - val_loss: 0.6588 - val_accuracy: 0.5473\n",
      "Epoch 2345/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6184 - accuracy: 0.6443 - val_loss: 0.6585 - val_accuracy: 0.5499\n",
      "Epoch 2346/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6183 - accuracy: 0.6440 - val_loss: 0.6465 - val_accuracy: 0.5652\n",
      "Epoch 2347/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6185 - accuracy: 0.6433 - val_loss: 0.6698 - val_accuracy: 0.5336\n",
      "Epoch 2348/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6191 - accuracy: 0.6416 - val_loss: 0.6387 - val_accuracy: 0.5793\n",
      "Epoch 2349/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6194 - accuracy: 0.6417 - val_loss: 0.6790 - val_accuracy: 0.5228\n",
      "Epoch 2350/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6203 - accuracy: 0.6415 - val_loss: 0.6337 - val_accuracy: 0.5886\n",
      "Epoch 2351/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6203 - accuracy: 0.6404 - val_loss: 0.6813 - val_accuracy: 0.5192\n",
      "Epoch 2352/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6209 - accuracy: 0.6394 - val_loss: 0.6369 - val_accuracy: 0.5822\n",
      "Epoch 2353/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6202 - accuracy: 0.6402 - val_loss: 0.6707 - val_accuracy: 0.5320\n",
      "Epoch 2354/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6194 - accuracy: 0.6423 - val_loss: 0.6477 - val_accuracy: 0.5639\n",
      "Epoch 2355/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6192 - accuracy: 0.6431 - val_loss: 0.6604 - val_accuracy: 0.5411\n",
      "Epoch 2356/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6188 - accuracy: 0.6413 - val_loss: 0.6536 - val_accuracy: 0.5526\n",
      "Epoch 2357/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6186 - accuracy: 0.6412 - val_loss: 0.6532 - val_accuracy: 0.5574\n",
      "Epoch 2358/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6185 - accuracy: 0.6432 - val_loss: 0.6604 - val_accuracy: 0.5493\n",
      "Epoch 2359/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6186 - accuracy: 0.6434 - val_loss: 0.6511 - val_accuracy: 0.5579\n",
      "Epoch 2360/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6186 - accuracy: 0.6436 - val_loss: 0.6611 - val_accuracy: 0.5429\n",
      "Epoch 2361/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6185 - accuracy: 0.6416 - val_loss: 0.6459 - val_accuracy: 0.5680\n",
      "Epoch 2362/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6187 - accuracy: 0.6425 - val_loss: 0.6692 - val_accuracy: 0.5360\n",
      "Epoch 2363/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6186 - accuracy: 0.6431 - val_loss: 0.6430 - val_accuracy: 0.5698\n",
      "Epoch 2364/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6194 - accuracy: 0.6423 - val_loss: 0.6772 - val_accuracy: 0.5250\n",
      "Epoch 2365/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6201 - accuracy: 0.6414 - val_loss: 0.6296 - val_accuracy: 0.5990\n",
      "Epoch 2366/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6213 - accuracy: 0.6384 - val_loss: 0.6912 - val_accuracy: 0.5064\n",
      "Epoch 2367/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6219 - accuracy: 0.6392 - val_loss: 0.6367 - val_accuracy: 0.5789\n",
      "Epoch 2368/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6216 - accuracy: 0.6395 - val_loss: 0.6771 - val_accuracy: 0.5241\n",
      "Epoch 2369/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6205 - accuracy: 0.6410 - val_loss: 0.6352 - val_accuracy: 0.5882\n",
      "Epoch 2370/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6207 - accuracy: 0.6397 - val_loss: 0.6678 - val_accuracy: 0.5356\n",
      "Epoch 2371/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6186 - accuracy: 0.6424 - val_loss: 0.6525 - val_accuracy: 0.5537\n",
      "Epoch 2372/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6199 - accuracy: 0.6424 - val_loss: 0.6649 - val_accuracy: 0.5409\n",
      "Epoch 2373/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6186 - accuracy: 0.6430 - val_loss: 0.6424 - val_accuracy: 0.5744\n",
      "Epoch 2374/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6198 - accuracy: 0.6404 - val_loss: 0.6678 - val_accuracy: 0.5345\n",
      "Epoch 2375/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6188 - accuracy: 0.6420 - val_loss: 0.6442 - val_accuracy: 0.5680\n",
      "Epoch 2376/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6202 - accuracy: 0.6423 - val_loss: 0.6793 - val_accuracy: 0.5210\n",
      "Epoch 2377/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6203 - accuracy: 0.6414 - val_loss: 0.6324 - val_accuracy: 0.5939\n",
      "Epoch 2378/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6211 - accuracy: 0.6390 - val_loss: 0.6795 - val_accuracy: 0.5217\n",
      "Epoch 2379/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6207 - accuracy: 0.6393 - val_loss: 0.6409 - val_accuracy: 0.5727\n",
      "Epoch 2380/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6210 - accuracy: 0.6407 - val_loss: 0.6703 - val_accuracy: 0.5345\n",
      "Epoch 2381/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6197 - accuracy: 0.6419 - val_loss: 0.6488 - val_accuracy: 0.5665\n",
      "Epoch 2382/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6200 - accuracy: 0.6429 - val_loss: 0.6571 - val_accuracy: 0.5475\n",
      "Epoch 2383/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6185 - accuracy: 0.6417 - val_loss: 0.6560 - val_accuracy: 0.5490\n",
      "Epoch 2384/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6199 - accuracy: 0.6411 - val_loss: 0.6584 - val_accuracy: 0.5513\n",
      "Epoch 2385/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6185 - accuracy: 0.6439 - val_loss: 0.6519 - val_accuracy: 0.5614\n",
      "Epoch 2386/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6198 - accuracy: 0.6425 - val_loss: 0.6653 - val_accuracy: 0.5371\n",
      "Epoch 2387/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6186 - accuracy: 0.6416 - val_loss: 0.6398 - val_accuracy: 0.5751\n",
      "Epoch 2388/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6212 - accuracy: 0.6387 - val_loss: 0.6847 - val_accuracy: 0.5124\n",
      "Epoch 2389/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6212 - accuracy: 0.6405 - val_loss: 0.6299 - val_accuracy: 0.5954\n",
      "Epoch 2390/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6243 - accuracy: 0.6348 - val_loss: 0.6983 - val_accuracy: 0.5020\n",
      "Epoch 2391/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6247 - accuracy: 0.6359 - val_loss: 0.6345 - val_accuracy: 0.5864\n",
      "Epoch 2392/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6271 - accuracy: 0.6329 - val_loss: 0.6805 - val_accuracy: 0.5201\n",
      "Epoch 2393/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6211 - accuracy: 0.6404 - val_loss: 0.6396 - val_accuracy: 0.5826\n",
      "Epoch 2394/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6268 - accuracy: 0.6346 - val_loss: 0.6866 - val_accuracy: 0.5132\n",
      "Epoch 2395/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6226 - accuracy: 0.6378 - val_loss: 0.6258 - val_accuracy: 0.5983\n",
      "Epoch 2396/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6282 - accuracy: 0.6311 - val_loss: 0.6968 - val_accuracy: 0.5000\n",
      "Epoch 2397/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6243 - accuracy: 0.6363 - val_loss: 0.6404 - val_accuracy: 0.5791\n",
      "Epoch 2398/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6220 - accuracy: 0.6398 - val_loss: 0.6563 - val_accuracy: 0.5495\n",
      "Epoch 2399/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6189 - accuracy: 0.6436 - val_loss: 0.6677 - val_accuracy: 0.5329\n",
      "Epoch 2400/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6201 - accuracy: 0.6404 - val_loss: 0.6335 - val_accuracy: 0.5829\n",
      "Epoch 2401/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6210 - accuracy: 0.6384 - val_loss: 0.6803 - val_accuracy: 0.5181\n",
      "Epoch 2402/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6212 - accuracy: 0.6407 - val_loss: 0.6398 - val_accuracy: 0.5773\n",
      "Epoch 2403/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6221 - accuracy: 0.6395 - val_loss: 0.6712 - val_accuracy: 0.5307\n",
      "Epoch 2404/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6194 - accuracy: 0.6416 - val_loss: 0.6457 - val_accuracy: 0.5599\n",
      "Epoch 2405/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6215 - accuracy: 0.6376 - val_loss: 0.6605 - val_accuracy: 0.5440\n",
      "Epoch 2406/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6186 - accuracy: 0.6427 - val_loss: 0.6508 - val_accuracy: 0.5656\n",
      "Epoch 2407/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6206 - accuracy: 0.6413 - val_loss: 0.6646 - val_accuracy: 0.5409\n",
      "Epoch 2408/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6183 - accuracy: 0.6434 - val_loss: 0.6437 - val_accuracy: 0.5636\n",
      "Epoch 2409/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6207 - accuracy: 0.6410 - val_loss: 0.6706 - val_accuracy: 0.5309\n",
      "Epoch 2410/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6191 - accuracy: 0.6418 - val_loss: 0.6394 - val_accuracy: 0.5806\n",
      "Epoch 2411/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6205 - accuracy: 0.6407 - val_loss: 0.6762 - val_accuracy: 0.5245\n",
      "Epoch 2412/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6194 - accuracy: 0.6420 - val_loss: 0.6411 - val_accuracy: 0.5709\n",
      "Epoch 2413/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6201 - accuracy: 0.6422 - val_loss: 0.6665 - val_accuracy: 0.5380\n",
      "Epoch 2414/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6183 - accuracy: 0.6422 - val_loss: 0.6466 - val_accuracy: 0.5683\n",
      "Epoch 2415/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6189 - accuracy: 0.6435 - val_loss: 0.6604 - val_accuracy: 0.5471\n",
      "Epoch 2416/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6178 - accuracy: 0.6438 - val_loss: 0.6555 - val_accuracy: 0.5550\n",
      "Epoch 2417/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6183 - accuracy: 0.6434 - val_loss: 0.6554 - val_accuracy: 0.5499\n",
      "Epoch 2418/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6176 - accuracy: 0.6440 - val_loss: 0.6558 - val_accuracy: 0.5524\n",
      "Epoch 2419/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6180 - accuracy: 0.6440 - val_loss: 0.6547 - val_accuracy: 0.5552\n",
      "Epoch 2420/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6177 - accuracy: 0.6438 - val_loss: 0.6570 - val_accuracy: 0.5522\n",
      "Epoch 2421/15000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.6178 - accuracy: 0.6439 - val_loss: 0.6567 - val_accuracy: 0.5552\n",
      "Epoch 2422/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6176 - accuracy: 0.6438 - val_loss: 0.6554 - val_accuracy: 0.5550\n",
      "Epoch 2423/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6176 - accuracy: 0.6435 - val_loss: 0.6575 - val_accuracy: 0.5508\n",
      "Epoch 2424/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6176 - accuracy: 0.6439 - val_loss: 0.6539 - val_accuracy: 0.5564\n",
      "Epoch 2425/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6176 - accuracy: 0.6439 - val_loss: 0.6585 - val_accuracy: 0.5521\n",
      "Epoch 2426/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6175 - accuracy: 0.6444 - val_loss: 0.6543 - val_accuracy: 0.5566\n",
      "Epoch 2427/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6175 - accuracy: 0.6440 - val_loss: 0.6601 - val_accuracy: 0.5484\n",
      "Epoch 2428/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6176 - accuracy: 0.6437 - val_loss: 0.6525 - val_accuracy: 0.5574\n",
      "Epoch 2429/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6175 - accuracy: 0.6432 - val_loss: 0.6598 - val_accuracy: 0.5501\n",
      "Epoch 2430/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6175 - accuracy: 0.6441 - val_loss: 0.6519 - val_accuracy: 0.5623\n",
      "Epoch 2431/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6174 - accuracy: 0.6451 - val_loss: 0.6623 - val_accuracy: 0.5449\n",
      "Epoch 2432/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6175 - accuracy: 0.6441 - val_loss: 0.6490 - val_accuracy: 0.5634\n",
      "Epoch 2433/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6175 - accuracy: 0.6435 - val_loss: 0.6652 - val_accuracy: 0.5422\n",
      "Epoch 2434/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6176 - accuracy: 0.6436 - val_loss: 0.6457 - val_accuracy: 0.5687\n",
      "Epoch 2435/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6178 - accuracy: 0.6429 - val_loss: 0.6728 - val_accuracy: 0.5318\n",
      "Epoch 2436/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6183 - accuracy: 0.6433 - val_loss: 0.6378 - val_accuracy: 0.5822\n",
      "Epoch 2437/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6188 - accuracy: 0.6416 - val_loss: 0.6816 - val_accuracy: 0.5210\n",
      "Epoch 2438/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6197 - accuracy: 0.6413 - val_loss: 0.6336 - val_accuracy: 0.5866\n",
      "Epoch 2439/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6196 - accuracy: 0.6405 - val_loss: 0.6833 - val_accuracy: 0.5188\n",
      "Epoch 2440/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6199 - accuracy: 0.6410 - val_loss: 0.6364 - val_accuracy: 0.5835\n",
      "Epoch 2441/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6191 - accuracy: 0.6417 - val_loss: 0.6747 - val_accuracy: 0.5272\n",
      "Epoch 2442/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6186 - accuracy: 0.6424 - val_loss: 0.6427 - val_accuracy: 0.5720\n",
      "Epoch 2443/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6180 - accuracy: 0.6435 - val_loss: 0.6624 - val_accuracy: 0.5448\n",
      "Epoch 2444/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6174 - accuracy: 0.6442 - val_loss: 0.6549 - val_accuracy: 0.5539\n",
      "Epoch 2445/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6173 - accuracy: 0.6435 - val_loss: 0.6518 - val_accuracy: 0.5568\n",
      "Epoch 2446/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6172 - accuracy: 0.6442 - val_loss: 0.6633 - val_accuracy: 0.5437\n",
      "Epoch 2447/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6175 - accuracy: 0.6440 - val_loss: 0.6442 - val_accuracy: 0.5720\n",
      "Epoch 2448/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6177 - accuracy: 0.6436 - val_loss: 0.6714 - val_accuracy: 0.5322\n",
      "Epoch 2449/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6181 - accuracy: 0.6426 - val_loss: 0.6397 - val_accuracy: 0.5802\n",
      "Epoch 2450/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6184 - accuracy: 0.6426 - val_loss: 0.6784 - val_accuracy: 0.5237\n",
      "Epoch 2451/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6190 - accuracy: 0.6417 - val_loss: 0.6352 - val_accuracy: 0.5851\n",
      "Epoch 2452/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6189 - accuracy: 0.6415 - val_loss: 0.6776 - val_accuracy: 0.5243\n",
      "Epoch 2453/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6189 - accuracy: 0.6421 - val_loss: 0.6399 - val_accuracy: 0.5782\n",
      "Epoch 2454/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6183 - accuracy: 0.6427 - val_loss: 0.6707 - val_accuracy: 0.5345\n",
      "Epoch 2455/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6179 - accuracy: 0.6435 - val_loss: 0.6449 - val_accuracy: 0.5696\n",
      "Epoch 2456/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6176 - accuracy: 0.6435 - val_loss: 0.6617 - val_accuracy: 0.5451\n",
      "Epoch 2457/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6172 - accuracy: 0.6445 - val_loss: 0.6521 - val_accuracy: 0.5572\n",
      "Epoch 2458/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6172 - accuracy: 0.6436 - val_loss: 0.6570 - val_accuracy: 0.5501\n",
      "Epoch 2459/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6170 - accuracy: 0.6445 - val_loss: 0.6577 - val_accuracy: 0.5510\n",
      "Epoch 2460/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6171 - accuracy: 0.6444 - val_loss: 0.6511 - val_accuracy: 0.5603\n",
      "Epoch 2461/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6171 - accuracy: 0.6442 - val_loss: 0.6626 - val_accuracy: 0.5442\n",
      "Epoch 2462/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6172 - accuracy: 0.6436 - val_loss: 0.6464 - val_accuracy: 0.5692\n",
      "Epoch 2463/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6174 - accuracy: 0.6434 - val_loss: 0.6704 - val_accuracy: 0.5354\n",
      "Epoch 2464/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6178 - accuracy: 0.6433 - val_loss: 0.6393 - val_accuracy: 0.5793\n",
      "Epoch 2465/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6181 - accuracy: 0.6431 - val_loss: 0.6790 - val_accuracy: 0.5230\n",
      "Epoch 2466/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6189 - accuracy: 0.6423 - val_loss: 0.6346 - val_accuracy: 0.5848\n",
      "Epoch 2467/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6191 - accuracy: 0.6407 - val_loss: 0.6851 - val_accuracy: 0.5183\n",
      "Epoch 2468/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6199 - accuracy: 0.6409 - val_loss: 0.6333 - val_accuracy: 0.5882\n",
      "Epoch 2469/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6191 - accuracy: 0.6412 - val_loss: 0.6785 - val_accuracy: 0.5237\n",
      "Epoch 2470/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6189 - accuracy: 0.6421 - val_loss: 0.6406 - val_accuracy: 0.5784\n",
      "Epoch 2471/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6180 - accuracy: 0.6429 - val_loss: 0.6683 - val_accuracy: 0.5382\n",
      "Epoch 2472/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6175 - accuracy: 0.6436 - val_loss: 0.6478 - val_accuracy: 0.5652\n",
      "Epoch 2473/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6172 - accuracy: 0.6440 - val_loss: 0.6595 - val_accuracy: 0.5466\n",
      "Epoch 2474/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6169 - accuracy: 0.6442 - val_loss: 0.6545 - val_accuracy: 0.5532\n",
      "Epoch 2475/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6169 - accuracy: 0.6435 - val_loss: 0.6548 - val_accuracy: 0.5533\n",
      "Epoch 2476/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6168 - accuracy: 0.6447 - val_loss: 0.6590 - val_accuracy: 0.5501\n",
      "Epoch 2477/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6169 - accuracy: 0.6446 - val_loss: 0.6508 - val_accuracy: 0.5605\n",
      "Epoch 2478/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6169 - accuracy: 0.6446 - val_loss: 0.6628 - val_accuracy: 0.5433\n",
      "Epoch 2479/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6170 - accuracy: 0.6442 - val_loss: 0.6462 - val_accuracy: 0.5674\n",
      "Epoch 2480/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6172 - accuracy: 0.6434 - val_loss: 0.6702 - val_accuracy: 0.5367\n",
      "Epoch 2481/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6176 - accuracy: 0.6438 - val_loss: 0.6397 - val_accuracy: 0.5804\n",
      "Epoch 2482/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6179 - accuracy: 0.6426 - val_loss: 0.6807 - val_accuracy: 0.5223\n",
      "Epoch 2483/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6191 - accuracy: 0.6425 - val_loss: 0.6314 - val_accuracy: 0.5891\n",
      "Epoch 2484/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6196 - accuracy: 0.6398 - val_loss: 0.6917 - val_accuracy: 0.5079\n",
      "Epoch 2485/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6211 - accuracy: 0.6392 - val_loss: 0.6311 - val_accuracy: 0.5913\n",
      "Epoch 2486/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6197 - accuracy: 0.6397 - val_loss: 0.6807 - val_accuracy: 0.5228\n",
      "Epoch 2487/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6192 - accuracy: 0.6421 - val_loss: 0.6404 - val_accuracy: 0.5764\n",
      "Epoch 2488/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6178 - accuracy: 0.6433 - val_loss: 0.6624 - val_accuracy: 0.5442\n",
      "Epoch 2489/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6170 - accuracy: 0.6444 - val_loss: 0.6569 - val_accuracy: 0.5528\n",
      "Epoch 2490/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6168 - accuracy: 0.6446 - val_loss: 0.6472 - val_accuracy: 0.5652\n",
      "Epoch 2491/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6170 - accuracy: 0.6442 - val_loss: 0.6710 - val_accuracy: 0.5311\n",
      "Epoch 2492/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6177 - accuracy: 0.6429 - val_loss: 0.6365 - val_accuracy: 0.5813\n",
      "Epoch 2493/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6185 - accuracy: 0.6427 - val_loss: 0.6880 - val_accuracy: 0.5119\n",
      "Epoch 2494/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6203 - accuracy: 0.6400 - val_loss: 0.6285 - val_accuracy: 0.5957\n",
      "Epoch 2495/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6200 - accuracy: 0.6391 - val_loss: 0.6873 - val_accuracy: 0.5141\n",
      "Epoch 2496/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6204 - accuracy: 0.6399 - val_loss: 0.6368 - val_accuracy: 0.5804\n",
      "Epoch 2497/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6183 - accuracy: 0.6422 - val_loss: 0.6645 - val_accuracy: 0.5415\n",
      "Epoch 2498/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6171 - accuracy: 0.6448 - val_loss: 0.6554 - val_accuracy: 0.5526\n",
      "Epoch 2499/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6168 - accuracy: 0.6449 - val_loss: 0.6453 - val_accuracy: 0.5678\n",
      "Epoch 2500/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6171 - accuracy: 0.6437 - val_loss: 0.6751 - val_accuracy: 0.5281\n",
      "Epoch 2501/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6182 - accuracy: 0.6427 - val_loss: 0.6333 - val_accuracy: 0.5875\n",
      "Epoch 2502/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6191 - accuracy: 0.6415 - val_loss: 0.6902 - val_accuracy: 0.5091\n",
      "Epoch 2503/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6208 - accuracy: 0.6397 - val_loss: 0.6301 - val_accuracy: 0.5915\n",
      "Epoch 2504/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6195 - accuracy: 0.6397 - val_loss: 0.6776 - val_accuracy: 0.5259\n",
      "Epoch 2505/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6187 - accuracy: 0.6428 - val_loss: 0.6439 - val_accuracy: 0.5683\n",
      "Epoch 2506/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6172 - accuracy: 0.6436 - val_loss: 0.6563 - val_accuracy: 0.5499\n",
      "Epoch 2507/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6166 - accuracy: 0.6446 - val_loss: 0.6644 - val_accuracy: 0.5402\n",
      "Epoch 2508/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6169 - accuracy: 0.6446 - val_loss: 0.6393 - val_accuracy: 0.5796\n",
      "Epoch 2509/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6177 - accuracy: 0.6434 - val_loss: 0.6833 - val_accuracy: 0.5194\n",
      "Epoch 2510/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6194 - accuracy: 0.6409 - val_loss: 0.6304 - val_accuracy: 0.5912\n",
      "Epoch 2511/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6196 - accuracy: 0.6404 - val_loss: 0.6885 - val_accuracy: 0.5111\n",
      "Epoch 2512/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6204 - accuracy: 0.6399 - val_loss: 0.6346 - val_accuracy: 0.5837\n",
      "Epoch 2513/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6184 - accuracy: 0.6422 - val_loss: 0.6655 - val_accuracy: 0.5389\n",
      "Epoch 2514/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6171 - accuracy: 0.6437 - val_loss: 0.6555 - val_accuracy: 0.5493\n",
      "Epoch 2515/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6166 - accuracy: 0.6445 - val_loss: 0.6452 - val_accuracy: 0.5689\n",
      "Epoch 2516/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6170 - accuracy: 0.6442 - val_loss: 0.6775 - val_accuracy: 0.5252\n",
      "Epoch 2517/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6183 - accuracy: 0.6424 - val_loss: 0.6309 - val_accuracy: 0.5902\n",
      "Epoch 2518/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6195 - accuracy: 0.6404 - val_loss: 0.6949 - val_accuracy: 0.5037\n",
      "Epoch 2519/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6217 - accuracy: 0.6387 - val_loss: 0.6305 - val_accuracy: 0.5923\n",
      "Epoch 2520/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6196 - accuracy: 0.6395 - val_loss: 0.6755 - val_accuracy: 0.5285\n",
      "Epoch 2521/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6182 - accuracy: 0.6436 - val_loss: 0.6479 - val_accuracy: 0.5632\n",
      "Epoch 2522/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6168 - accuracy: 0.6440 - val_loss: 0.6455 - val_accuracy: 0.5672\n",
      "Epoch 2523/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6168 - accuracy: 0.6443 - val_loss: 0.6773 - val_accuracy: 0.5256\n",
      "Epoch 2524/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6182 - accuracy: 0.6426 - val_loss: 0.6332 - val_accuracy: 0.5881\n",
      "Epoch 2525/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6194 - accuracy: 0.6410 - val_loss: 0.6928 - val_accuracy: 0.5040\n",
      "Epoch 2526/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6211 - accuracy: 0.6400 - val_loss: 0.6302 - val_accuracy: 0.5930\n",
      "Epoch 2527/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6192 - accuracy: 0.6400 - val_loss: 0.6755 - val_accuracy: 0.5272\n",
      "Epoch 2528/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6181 - accuracy: 0.6432 - val_loss: 0.6472 - val_accuracy: 0.5623\n",
      "Epoch 2529/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6168 - accuracy: 0.6438 - val_loss: 0.6515 - val_accuracy: 0.5585\n",
      "Epoch 2530/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6166 - accuracy: 0.6452 - val_loss: 0.6700 - val_accuracy: 0.5342\n",
      "Epoch 2531/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6173 - accuracy: 0.6439 - val_loss: 0.6343 - val_accuracy: 0.5860\n",
      "Epoch 2532/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6181 - accuracy: 0.6422 - val_loss: 0.6847 - val_accuracy: 0.5181\n",
      "Epoch 2533/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6195 - accuracy: 0.6410 - val_loss: 0.6347 - val_accuracy: 0.5853\n",
      "Epoch 2534/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6189 - accuracy: 0.6417 - val_loss: 0.6797 - val_accuracy: 0.5206\n",
      "Epoch 2535/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6184 - accuracy: 0.6427 - val_loss: 0.6411 - val_accuracy: 0.5751\n",
      "Epoch 2536/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6171 - accuracy: 0.6436 - val_loss: 0.6585 - val_accuracy: 0.5462\n",
      "Epoch 2537/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6165 - accuracy: 0.6440 - val_loss: 0.6579 - val_accuracy: 0.5473\n",
      "Epoch 2538/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6164 - accuracy: 0.6445 - val_loss: 0.6466 - val_accuracy: 0.5672\n",
      "Epoch 2539/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6167 - accuracy: 0.6446 - val_loss: 0.6739 - val_accuracy: 0.5290\n",
      "Epoch 2540/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6174 - accuracy: 0.6438 - val_loss: 0.6356 - val_accuracy: 0.5842\n",
      "Epoch 2541/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6180 - accuracy: 0.6423 - val_loss: 0.6833 - val_accuracy: 0.5206\n",
      "Epoch 2542/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6191 - accuracy: 0.6416 - val_loss: 0.6340 - val_accuracy: 0.5862\n",
      "Epoch 2543/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6185 - accuracy: 0.6415 - val_loss: 0.6787 - val_accuracy: 0.5237\n",
      "Epoch 2544/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6181 - accuracy: 0.6427 - val_loss: 0.6427 - val_accuracy: 0.5720\n",
      "Epoch 2545/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6169 - accuracy: 0.6446 - val_loss: 0.6593 - val_accuracy: 0.5460\n",
      "Epoch 2546/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6163 - accuracy: 0.6448 - val_loss: 0.6574 - val_accuracy: 0.5484\n",
      "Epoch 2547/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6162 - accuracy: 0.6447 - val_loss: 0.6477 - val_accuracy: 0.5643\n",
      "Epoch 2548/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6165 - accuracy: 0.6449 - val_loss: 0.6731 - val_accuracy: 0.5309\n",
      "Epoch 2549/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6172 - accuracy: 0.6439 - val_loss: 0.6365 - val_accuracy: 0.5837\n",
      "Epoch 2550/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6178 - accuracy: 0.6427 - val_loss: 0.6848 - val_accuracy: 0.5194\n",
      "Epoch 2551/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6192 - accuracy: 0.6412 - val_loss: 0.6315 - val_accuracy: 0.5912\n",
      "Epoch 2552/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6188 - accuracy: 0.6399 - val_loss: 0.6834 - val_accuracy: 0.5194\n",
      "Epoch 2553/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6188 - accuracy: 0.6417 - val_loss: 0.6405 - val_accuracy: 0.5760\n",
      "Epoch 2554/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6172 - accuracy: 0.6436 - val_loss: 0.6617 - val_accuracy: 0.5433\n",
      "Epoch 2555/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6163 - accuracy: 0.6448 - val_loss: 0.6561 - val_accuracy: 0.5493\n",
      "Epoch 2556/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6161 - accuracy: 0.6453 - val_loss: 0.6482 - val_accuracy: 0.5654\n",
      "Epoch 2557/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6164 - accuracy: 0.6450 - val_loss: 0.6743 - val_accuracy: 0.5280\n",
      "Epoch 2558/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6172 - accuracy: 0.6442 - val_loss: 0.6348 - val_accuracy: 0.5862\n",
      "Epoch 2559/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6180 - accuracy: 0.6421 - val_loss: 0.6874 - val_accuracy: 0.5161\n",
      "Epoch 2560/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6197 - accuracy: 0.6406 - val_loss: 0.6307 - val_accuracy: 0.5915\n",
      "Epoch 2561/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6189 - accuracy: 0.6401 - val_loss: 0.6815 - val_accuracy: 0.5216\n",
      "Epoch 2562/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6184 - accuracy: 0.6427 - val_loss: 0.6434 - val_accuracy: 0.5725\n",
      "Epoch 2563/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6167 - accuracy: 0.6441 - val_loss: 0.6565 - val_accuracy: 0.5499\n",
      "Epoch 2564/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6161 - accuracy: 0.6452 - val_loss: 0.6615 - val_accuracy: 0.5429\n",
      "Epoch 2565/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6162 - accuracy: 0.6445 - val_loss: 0.6426 - val_accuracy: 0.5727\n",
      "Epoch 2566/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6169 - accuracy: 0.6436 - val_loss: 0.6820 - val_accuracy: 0.5197\n",
      "Epoch 2567/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6183 - accuracy: 0.6420 - val_loss: 0.6317 - val_accuracy: 0.5906\n",
      "Epoch 2568/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6188 - accuracy: 0.6408 - val_loss: 0.6876 - val_accuracy: 0.5159\n",
      "Epoch 2569/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6199 - accuracy: 0.6404 - val_loss: 0.6331 - val_accuracy: 0.5893\n",
      "Epoch 2570/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6181 - accuracy: 0.6413 - val_loss: 0.6692 - val_accuracy: 0.5353\n",
      "Epoch 2571/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6167 - accuracy: 0.6445 - val_loss: 0.6563 - val_accuracy: 0.5506\n",
      "Epoch 2572/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6160 - accuracy: 0.6455 - val_loss: 0.6436 - val_accuracy: 0.5720\n",
      "Epoch 2573/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6165 - accuracy: 0.6443 - val_loss: 0.6772 - val_accuracy: 0.5256\n",
      "Epoch 2574/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6179 - accuracy: 0.6428 - val_loss: 0.6323 - val_accuracy: 0.5888\n",
      "Epoch 2575/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6188 - accuracy: 0.6412 - val_loss: 0.6919 - val_accuracy: 0.5066\n",
      "Epoch 2576/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6203 - accuracy: 0.6402 - val_loss: 0.6321 - val_accuracy: 0.5897\n",
      "Epoch 2577/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6186 - accuracy: 0.6407 - val_loss: 0.6743 - val_accuracy: 0.5298\n",
      "Epoch 2578/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6175 - accuracy: 0.6432 - val_loss: 0.6485 - val_accuracy: 0.5594\n",
      "Epoch 2579/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6162 - accuracy: 0.6447 - val_loss: 0.6465 - val_accuracy: 0.5667\n",
      "Epoch 2580/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6163 - accuracy: 0.6449 - val_loss: 0.6773 - val_accuracy: 0.5216\n",
      "Epoch 2581/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6176 - accuracy: 0.6433 - val_loss: 0.6319 - val_accuracy: 0.5895\n",
      "Epoch 2582/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6189 - accuracy: 0.6411 - val_loss: 0.6930 - val_accuracy: 0.5058\n",
      "Epoch 2583/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6209 - accuracy: 0.6393 - val_loss: 0.6302 - val_accuracy: 0.5930\n",
      "Epoch 2584/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6188 - accuracy: 0.6400 - val_loss: 0.6747 - val_accuracy: 0.5259\n",
      "Epoch 2585/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6172 - accuracy: 0.6438 - val_loss: 0.6515 - val_accuracy: 0.5550\n",
      "Epoch 2586/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6161 - accuracy: 0.6446 - val_loss: 0.6469 - val_accuracy: 0.5661\n",
      "Epoch 2587/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6161 - accuracy: 0.6454 - val_loss: 0.6715 - val_accuracy: 0.5331\n",
      "Epoch 2588/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6171 - accuracy: 0.6435 - val_loss: 0.6362 - val_accuracy: 0.5822\n",
      "Epoch 2589/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6175 - accuracy: 0.6429 - val_loss: 0.6825 - val_accuracy: 0.5195\n",
      "Epoch 2590/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6182 - accuracy: 0.6419 - val_loss: 0.6378 - val_accuracy: 0.5802\n",
      "Epoch 2591/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6176 - accuracy: 0.6430 - val_loss: 0.6728 - val_accuracy: 0.5322\n",
      "Epoch 2592/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6171 - accuracy: 0.6435 - val_loss: 0.6441 - val_accuracy: 0.5709\n",
      "Epoch 2593/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6163 - accuracy: 0.6445 - val_loss: 0.6563 - val_accuracy: 0.5491\n",
      "Epoch 2594/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6158 - accuracy: 0.6456 - val_loss: 0.6627 - val_accuracy: 0.5426\n",
      "Epoch 2595/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6160 - accuracy: 0.6457 - val_loss: 0.6459 - val_accuracy: 0.5680\n",
      "Epoch 2596/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6161 - accuracy: 0.6447 - val_loss: 0.6695 - val_accuracy: 0.5356\n",
      "Epoch 2597/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6166 - accuracy: 0.6441 - val_loss: 0.6405 - val_accuracy: 0.5767\n",
      "Epoch 2598/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6166 - accuracy: 0.6436 - val_loss: 0.6738 - val_accuracy: 0.5280\n",
      "Epoch 2599/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6168 - accuracy: 0.6441 - val_loss: 0.6426 - val_accuracy: 0.5740\n",
      "Epoch 2600/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6168 - accuracy: 0.6442 - val_loss: 0.6729 - val_accuracy: 0.5318\n",
      "Epoch 2601/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6169 - accuracy: 0.6436 - val_loss: 0.6402 - val_accuracy: 0.5775\n",
      "Epoch 2602/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6166 - accuracy: 0.6439 - val_loss: 0.6678 - val_accuracy: 0.5360\n",
      "Epoch 2603/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6162 - accuracy: 0.6455 - val_loss: 0.6497 - val_accuracy: 0.5623\n",
      "Epoch 2604/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6161 - accuracy: 0.6450 - val_loss: 0.6635 - val_accuracy: 0.5453\n",
      "Epoch 2605/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6158 - accuracy: 0.6453 - val_loss: 0.6507 - val_accuracy: 0.5617\n",
      "Epoch 2606/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6158 - accuracy: 0.6450 - val_loss: 0.6578 - val_accuracy: 0.5493\n",
      "Epoch 2607/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6156 - accuracy: 0.6457 - val_loss: 0.6561 - val_accuracy: 0.5524\n",
      "Epoch 2608/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6157 - accuracy: 0.6450 - val_loss: 0.6582 - val_accuracy: 0.5502\n",
      "Epoch 2609/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6156 - accuracy: 0.6454 - val_loss: 0.6546 - val_accuracy: 0.5546\n",
      "Epoch 2610/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6156 - accuracy: 0.6453 - val_loss: 0.6561 - val_accuracy: 0.5532\n",
      "Epoch 2611/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6155 - accuracy: 0.6455 - val_loss: 0.6547 - val_accuracy: 0.5550\n",
      "Epoch 2612/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6156 - accuracy: 0.6454 - val_loss: 0.6604 - val_accuracy: 0.5479\n",
      "Epoch 2613/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6155 - accuracy: 0.6456 - val_loss: 0.6525 - val_accuracy: 0.5577\n",
      "Epoch 2614/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6156 - accuracy: 0.6453 - val_loss: 0.6616 - val_accuracy: 0.5448\n",
      "Epoch 2615/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6156 - accuracy: 0.6459 - val_loss: 0.6486 - val_accuracy: 0.5672\n",
      "Epoch 2616/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6158 - accuracy: 0.6449 - val_loss: 0.6687 - val_accuracy: 0.5369\n",
      "Epoch 2617/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6159 - accuracy: 0.6451 - val_loss: 0.6421 - val_accuracy: 0.5760\n",
      "Epoch 2618/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6164 - accuracy: 0.6440 - val_loss: 0.6784 - val_accuracy: 0.5256\n",
      "Epoch 2619/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6172 - accuracy: 0.6439 - val_loss: 0.6339 - val_accuracy: 0.5873\n",
      "Epoch 2620/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6176 - accuracy: 0.6418 - val_loss: 0.6876 - val_accuracy: 0.5172\n",
      "Epoch 2621/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6189 - accuracy: 0.6417 - val_loss: 0.6313 - val_accuracy: 0.5941\n",
      "Epoch 2622/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6185 - accuracy: 0.6411 - val_loss: 0.6863 - val_accuracy: 0.5172\n",
      "Epoch 2623/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6185 - accuracy: 0.6420 - val_loss: 0.6376 - val_accuracy: 0.5807\n",
      "Epoch 2624/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6169 - accuracy: 0.6434 - val_loss: 0.6682 - val_accuracy: 0.5371\n",
      "Epoch 2625/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6161 - accuracy: 0.6449 - val_loss: 0.6498 - val_accuracy: 0.5607\n",
      "Epoch 2626/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6155 - accuracy: 0.6454 - val_loss: 0.6550 - val_accuracy: 0.5541\n",
      "Epoch 2627/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6154 - accuracy: 0.6458 - val_loss: 0.6649 - val_accuracy: 0.5407\n",
      "Epoch 2628/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6156 - accuracy: 0.6454 - val_loss: 0.6429 - val_accuracy: 0.5745\n",
      "Epoch 2629/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6160 - accuracy: 0.6443 - val_loss: 0.6766 - val_accuracy: 0.5265\n",
      "Epoch 2630/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6171 - accuracy: 0.6435 - val_loss: 0.6335 - val_accuracy: 0.5884\n",
      "Epoch 2631/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6177 - accuracy: 0.6421 - val_loss: 0.6882 - val_accuracy: 0.5135\n",
      "Epoch 2632/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6190 - accuracy: 0.6413 - val_loss: 0.6323 - val_accuracy: 0.5893\n",
      "Epoch 2633/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6180 - accuracy: 0.6415 - val_loss: 0.6789 - val_accuracy: 0.5263\n",
      "Epoch 2634/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6175 - accuracy: 0.6432 - val_loss: 0.6422 - val_accuracy: 0.5740\n",
      "Epoch 2635/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6160 - accuracy: 0.6447 - val_loss: 0.6579 - val_accuracy: 0.5506\n",
      "Epoch 2636/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6154 - accuracy: 0.6462 - val_loss: 0.6634 - val_accuracy: 0.5417\n",
      "Epoch 2637/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6155 - accuracy: 0.6462 - val_loss: 0.6421 - val_accuracy: 0.5753\n",
      "Epoch 2638/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6162 - accuracy: 0.6442 - val_loss: 0.6793 - val_accuracy: 0.5234\n",
      "Epoch 2639/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6175 - accuracy: 0.6431 - val_loss: 0.6318 - val_accuracy: 0.5915\n",
      "Epoch 2640/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6179 - accuracy: 0.6419 - val_loss: 0.6880 - val_accuracy: 0.5122\n",
      "Epoch 2641/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6188 - accuracy: 0.6413 - val_loss: 0.6360 - val_accuracy: 0.5815\n",
      "Epoch 2642/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6173 - accuracy: 0.6426 - val_loss: 0.6706 - val_accuracy: 0.5365\n",
      "Epoch 2643/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6166 - accuracy: 0.6445 - val_loss: 0.6471 - val_accuracy: 0.5665\n",
      "Epoch 2644/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6156 - accuracy: 0.6458 - val_loss: 0.6537 - val_accuracy: 0.5541\n",
      "Epoch 2645/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6156 - accuracy: 0.6460 - val_loss: 0.6704 - val_accuracy: 0.5309\n",
      "Epoch 2646/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6159 - accuracy: 0.6445 - val_loss: 0.6359 - val_accuracy: 0.5868\n",
      "Epoch 2647/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6173 - accuracy: 0.6431 - val_loss: 0.6879 - val_accuracy: 0.5164\n",
      "Epoch 2648/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6190 - accuracy: 0.6411 - val_loss: 0.6300 - val_accuracy: 0.5932\n",
      "Epoch 2649/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6188 - accuracy: 0.6403 - val_loss: 0.6843 - val_accuracy: 0.5150\n",
      "Epoch 2650/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6187 - accuracy: 0.6421 - val_loss: 0.6399 - val_accuracy: 0.5822\n",
      "Epoch 2651/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6170 - accuracy: 0.6438 - val_loss: 0.6609 - val_accuracy: 0.5437\n",
      "Epoch 2652/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6160 - accuracy: 0.6446 - val_loss: 0.6621 - val_accuracy: 0.5415\n",
      "Epoch 2653/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6158 - accuracy: 0.6442 - val_loss: 0.6429 - val_accuracy: 0.5764\n",
      "Epoch 2654/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6166 - accuracy: 0.6450 - val_loss: 0.6803 - val_accuracy: 0.5195\n",
      "Epoch 2655/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6174 - accuracy: 0.6439 - val_loss: 0.6317 - val_accuracy: 0.5899\n",
      "Epoch 2656/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6187 - accuracy: 0.6416 - val_loss: 0.6907 - val_accuracy: 0.5104\n",
      "Epoch 2657/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6199 - accuracy: 0.6403 - val_loss: 0.6314 - val_accuracy: 0.5943\n",
      "Epoch 2658/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6181 - accuracy: 0.6408 - val_loss: 0.6717 - val_accuracy: 0.5336\n",
      "Epoch 2659/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6162 - accuracy: 0.6452 - val_loss: 0.6565 - val_accuracy: 0.5502\n",
      "Epoch 2660/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6159 - accuracy: 0.6459 - val_loss: 0.6453 - val_accuracy: 0.5701\n",
      "Epoch 2661/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6159 - accuracy: 0.6448 - val_loss: 0.6708 - val_accuracy: 0.5338\n",
      "Epoch 2662/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6167 - accuracy: 0.6439 - val_loss: 0.6391 - val_accuracy: 0.5793\n",
      "Epoch 2663/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6170 - accuracy: 0.6434 - val_loss: 0.6838 - val_accuracy: 0.5152\n",
      "Epoch 2664/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6177 - accuracy: 0.6423 - val_loss: 0.6353 - val_accuracy: 0.5862\n",
      "Epoch 2665/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6171 - accuracy: 0.6437 - val_loss: 0.6735 - val_accuracy: 0.5309\n",
      "Epoch 2666/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6168 - accuracy: 0.6440 - val_loss: 0.6445 - val_accuracy: 0.5681\n",
      "Epoch 2667/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6158 - accuracy: 0.6451 - val_loss: 0.6581 - val_accuracy: 0.5490\n",
      "Epoch 2668/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6152 - accuracy: 0.6475 - val_loss: 0.6630 - val_accuracy: 0.5437\n",
      "Epoch 2669/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6154 - accuracy: 0.6463 - val_loss: 0.6432 - val_accuracy: 0.5729\n",
      "Epoch 2670/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6157 - accuracy: 0.6445 - val_loss: 0.6735 - val_accuracy: 0.5309\n",
      "Epoch 2671/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6164 - accuracy: 0.6437 - val_loss: 0.6397 - val_accuracy: 0.5798\n",
      "Epoch 2672/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6165 - accuracy: 0.6433 - val_loss: 0.6775 - val_accuracy: 0.5243\n",
      "Epoch 2673/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6166 - accuracy: 0.6448 - val_loss: 0.6389 - val_accuracy: 0.5791\n",
      "Epoch 2674/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6163 - accuracy: 0.6449 - val_loss: 0.6723 - val_accuracy: 0.5314\n",
      "Epoch 2675/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6163 - accuracy: 0.6445 - val_loss: 0.6430 - val_accuracy: 0.5740\n",
      "Epoch 2676/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6157 - accuracy: 0.6448 - val_loss: 0.6637 - val_accuracy: 0.5442\n",
      "Epoch 2677/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6152 - accuracy: 0.6471 - val_loss: 0.6563 - val_accuracy: 0.5552\n",
      "Epoch 2678/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6151 - accuracy: 0.6459 - val_loss: 0.6523 - val_accuracy: 0.5579\n",
      "Epoch 2679/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6150 - accuracy: 0.6459 - val_loss: 0.6611 - val_accuracy: 0.5490\n",
      "Epoch 2680/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6152 - accuracy: 0.6458 - val_loss: 0.6492 - val_accuracy: 0.5649\n",
      "Epoch 2681/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6151 - accuracy: 0.6460 - val_loss: 0.6682 - val_accuracy: 0.5353\n",
      "Epoch 2682/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6154 - accuracy: 0.6460 - val_loss: 0.6439 - val_accuracy: 0.5745\n",
      "Epoch 2683/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6155 - accuracy: 0.6454 - val_loss: 0.6721 - val_accuracy: 0.5331\n",
      "Epoch 2684/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6160 - accuracy: 0.6445 - val_loss: 0.6393 - val_accuracy: 0.5807\n",
      "Epoch 2685/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6160 - accuracy: 0.6444 - val_loss: 0.6787 - val_accuracy: 0.5261\n",
      "Epoch 2686/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6166 - accuracy: 0.6441 - val_loss: 0.6378 - val_accuracy: 0.5817\n",
      "Epoch 2687/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6165 - accuracy: 0.6435 - val_loss: 0.6793 - val_accuracy: 0.5256\n",
      "Epoch 2688/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6169 - accuracy: 0.6437 - val_loss: 0.6373 - val_accuracy: 0.5833\n",
      "Epoch 2689/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6164 - accuracy: 0.6441 - val_loss: 0.6738 - val_accuracy: 0.5283\n",
      "Epoch 2690/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6160 - accuracy: 0.6447 - val_loss: 0.6447 - val_accuracy: 0.5716\n",
      "Epoch 2691/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6156 - accuracy: 0.6447 - val_loss: 0.6686 - val_accuracy: 0.5384\n",
      "Epoch 2692/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6154 - accuracy: 0.6459 - val_loss: 0.6453 - val_accuracy: 0.5701\n",
      "Epoch 2693/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6153 - accuracy: 0.6453 - val_loss: 0.6640 - val_accuracy: 0.5426\n",
      "Epoch 2694/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6150 - accuracy: 0.6461 - val_loss: 0.6518 - val_accuracy: 0.5603\n",
      "Epoch 2695/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6150 - accuracy: 0.6458 - val_loss: 0.6615 - val_accuracy: 0.5466\n",
      "Epoch 2696/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6149 - accuracy: 0.6467 - val_loss: 0.6500 - val_accuracy: 0.5636\n",
      "Epoch 2697/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6149 - accuracy: 0.6459 - val_loss: 0.6611 - val_accuracy: 0.5440\n",
      "Epoch 2698/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6148 - accuracy: 0.6459 - val_loss: 0.6513 - val_accuracy: 0.5634\n",
      "Epoch 2699/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6149 - accuracy: 0.6459 - val_loss: 0.6653 - val_accuracy: 0.5437\n",
      "Epoch 2700/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6150 - accuracy: 0.6469 - val_loss: 0.6454 - val_accuracy: 0.5705\n",
      "Epoch 2701/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6152 - accuracy: 0.6451 - val_loss: 0.6690 - val_accuracy: 0.5336\n",
      "Epoch 2702/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6154 - accuracy: 0.6458 - val_loss: 0.6417 - val_accuracy: 0.5769\n",
      "Epoch 2703/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6158 - accuracy: 0.6442 - val_loss: 0.6807 - val_accuracy: 0.5247\n",
      "Epoch 2704/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6168 - accuracy: 0.6437 - val_loss: 0.6328 - val_accuracy: 0.5893\n",
      "Epoch 2705/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6173 - accuracy: 0.6422 - val_loss: 0.6883 - val_accuracy: 0.5126\n",
      "Epoch 2706/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6184 - accuracy: 0.6423 - val_loss: 0.6307 - val_accuracy: 0.5932\n",
      "Epoch 2707/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6178 - accuracy: 0.6427 - val_loss: 0.6844 - val_accuracy: 0.5210\n",
      "Epoch 2708/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6178 - accuracy: 0.6420 - val_loss: 0.6398 - val_accuracy: 0.5775\n",
      "Epoch 2709/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6162 - accuracy: 0.6439 - val_loss: 0.6640 - val_accuracy: 0.5435\n",
      "Epoch 2710/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6155 - accuracy: 0.6464 - val_loss: 0.6571 - val_accuracy: 0.5548\n",
      "Epoch 2711/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6150 - accuracy: 0.6460 - val_loss: 0.6473 - val_accuracy: 0.5661\n",
      "Epoch 2712/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6158 - accuracy: 0.6449 - val_loss: 0.6750 - val_accuracy: 0.5281\n",
      "Epoch 2713/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6164 - accuracy: 0.6443 - val_loss: 0.6329 - val_accuracy: 0.5913\n",
      "Epoch 2714/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6178 - accuracy: 0.6432 - val_loss: 0.6922 - val_accuracy: 0.5073\n",
      "Epoch 2715/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6189 - accuracy: 0.6404 - val_loss: 0.6343 - val_accuracy: 0.5846\n",
      "Epoch 2716/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6186 - accuracy: 0.6416 - val_loss: 0.6781 - val_accuracy: 0.5278\n",
      "Epoch 2717/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6183 - accuracy: 0.6441 - val_loss: 0.6400 - val_accuracy: 0.5793\n",
      "Epoch 2718/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6176 - accuracy: 0.6437 - val_loss: 0.6603 - val_accuracy: 0.5457\n",
      "Epoch 2719/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6153 - accuracy: 0.6452 - val_loss: 0.6639 - val_accuracy: 0.5382\n",
      "Epoch 2720/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6169 - accuracy: 0.6441 - val_loss: 0.6530 - val_accuracy: 0.5610\n",
      "Epoch 2721/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6161 - accuracy: 0.6448 - val_loss: 0.6585 - val_accuracy: 0.5532\n",
      "Epoch 2722/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6166 - accuracy: 0.6449 - val_loss: 0.6501 - val_accuracy: 0.5616\n",
      "Epoch 2723/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6153 - accuracy: 0.6452 - val_loss: 0.6612 - val_accuracy: 0.5427\n",
      "Epoch 2724/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6160 - accuracy: 0.6449 - val_loss: 0.6603 - val_accuracy: 0.5495\n",
      "Epoch 2725/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6158 - accuracy: 0.6457 - val_loss: 0.6508 - val_accuracy: 0.5639\n",
      "Epoch 2726/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6156 - accuracy: 0.6449 - val_loss: 0.6601 - val_accuracy: 0.5460\n",
      "Epoch 2727/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6155 - accuracy: 0.6452 - val_loss: 0.6501 - val_accuracy: 0.5610\n",
      "Epoch 2728/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6156 - accuracy: 0.6456 - val_loss: 0.6679 - val_accuracy: 0.5413\n",
      "Epoch 2729/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6161 - accuracy: 0.6457 - val_loss: 0.6479 - val_accuracy: 0.5691\n",
      "Epoch 2730/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6156 - accuracy: 0.6449 - val_loss: 0.6657 - val_accuracy: 0.5380\n",
      "Epoch 2731/15000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6162 - accuracy: 0.6441 - val_loss: 0.6500 - val_accuracy: 0.5592\n",
      "Epoch 2732/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6152 - accuracy: 0.6455 - val_loss: 0.6590 - val_accuracy: 0.5522\n",
      "Epoch 2733/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6159 - accuracy: 0.6451 - val_loss: 0.6625 - val_accuracy: 0.5459\n",
      "Epoch 2734/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6149 - accuracy: 0.6466 - val_loss: 0.6450 - val_accuracy: 0.5685\n",
      "Epoch 2735/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6163 - accuracy: 0.6439 - val_loss: 0.6761 - val_accuracy: 0.5281\n",
      "Epoch 2736/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6164 - accuracy: 0.6440 - val_loss: 0.6321 - val_accuracy: 0.5932\n",
      "Epoch 2737/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6181 - accuracy: 0.6427 - val_loss: 0.6981 - val_accuracy: 0.5015\n",
      "Epoch 2738/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6197 - accuracy: 0.6399 - val_loss: 0.6298 - val_accuracy: 0.5946\n",
      "Epoch 2739/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6204 - accuracy: 0.6401 - val_loss: 0.6918 - val_accuracy: 0.5068\n",
      "Epoch 2740/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6203 - accuracy: 0.6412 - val_loss: 0.6326 - val_accuracy: 0.5934\n",
      "Epoch 2741/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6190 - accuracy: 0.6407 - val_loss: 0.6669 - val_accuracy: 0.5374\n",
      "Epoch 2742/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6156 - accuracy: 0.6454 - val_loss: 0.6600 - val_accuracy: 0.5471\n",
      "Epoch 2743/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6179 - accuracy: 0.6427 - val_loss: 0.6605 - val_accuracy: 0.5495\n",
      "Epoch 2744/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6159 - accuracy: 0.6458 - val_loss: 0.6492 - val_accuracy: 0.5694\n",
      "Epoch 2745/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6175 - accuracy: 0.6444 - val_loss: 0.6648 - val_accuracy: 0.5407\n",
      "Epoch 2746/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6155 - accuracy: 0.6454 - val_loss: 0.6411 - val_accuracy: 0.5754\n",
      "Epoch 2747/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6198 - accuracy: 0.6420 - val_loss: 0.6957 - val_accuracy: 0.4995\n",
      "Epoch 2748/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6204 - accuracy: 0.6399 - val_loss: 0.6262 - val_accuracy: 0.6074\n",
      "Epoch 2749/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6238 - accuracy: 0.6337 - val_loss: 0.6982 - val_accuracy: 0.5053\n",
      "Epoch 2750/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6225 - accuracy: 0.6370 - val_loss: 0.6422 - val_accuracy: 0.5765\n",
      "Epoch 2751/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6237 - accuracy: 0.6361 - val_loss: 0.6678 - val_accuracy: 0.5345\n",
      "Epoch 2752/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6162 - accuracy: 0.6447 - val_loss: 0.6512 - val_accuracy: 0.5658\n",
      "Epoch 2753/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6210 - accuracy: 0.6420 - val_loss: 0.6757 - val_accuracy: 0.5250\n",
      "Epoch 2754/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6173 - accuracy: 0.6456 - val_loss: 0.6284 - val_accuracy: 0.5977\n",
      "Epoch 2755/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6230 - accuracy: 0.6372 - val_loss: 0.6983 - val_accuracy: 0.4989\n",
      "Epoch 2756/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6221 - accuracy: 0.6376 - val_loss: 0.6380 - val_accuracy: 0.5849\n",
      "Epoch 2757/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6203 - accuracy: 0.6393 - val_loss: 0.6668 - val_accuracy: 0.5393\n",
      "Epoch 2758/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6158 - accuracy: 0.6461 - val_loss: 0.6624 - val_accuracy: 0.5398\n",
      "Epoch 2759/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6170 - accuracy: 0.6438 - val_loss: 0.6394 - val_accuracy: 0.5793\n",
      "Epoch 2760/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6161 - accuracy: 0.6444 - val_loss: 0.6752 - val_accuracy: 0.5287\n",
      "Epoch 2761/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6176 - accuracy: 0.6429 - val_loss: 0.6417 - val_accuracy: 0.5771\n",
      "Epoch 2762/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6167 - accuracy: 0.6439 - val_loss: 0.6665 - val_accuracy: 0.5382\n",
      "Epoch 2763/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6161 - accuracy: 0.6442 - val_loss: 0.6529 - val_accuracy: 0.5543\n",
      "Epoch 2764/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6154 - accuracy: 0.6457 - val_loss: 0.6490 - val_accuracy: 0.5650\n",
      "Epoch 2765/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6153 - accuracy: 0.6460 - val_loss: 0.6696 - val_accuracy: 0.5369\n",
      "Epoch 2766/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6157 - accuracy: 0.6461 - val_loss: 0.6427 - val_accuracy: 0.5745\n",
      "Epoch 2767/15000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6163 - accuracy: 0.6448 - val_loss: 0.6772 - val_accuracy: 0.5281\n",
      "Epoch 2768/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6165 - accuracy: 0.6442 - val_loss: 0.6380 - val_accuracy: 0.5807\n",
      "Epoch 2769/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6162 - accuracy: 0.6440 - val_loss: 0.6755 - val_accuracy: 0.5278\n",
      "Epoch 2770/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6159 - accuracy: 0.6454 - val_loss: 0.6488 - val_accuracy: 0.5639\n",
      "Epoch 2771/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6152 - accuracy: 0.6455 - val_loss: 0.6588 - val_accuracy: 0.5501\n",
      "Epoch 2772/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6146 - accuracy: 0.6460 - val_loss: 0.6573 - val_accuracy: 0.5541\n",
      "Epoch 2773/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6147 - accuracy: 0.6458 - val_loss: 0.6478 - val_accuracy: 0.5674\n",
      "Epoch 2774/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6148 - accuracy: 0.6465 - val_loss: 0.6713 - val_accuracy: 0.5329\n",
      "Epoch 2775/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6149 - accuracy: 0.6457 - val_loss: 0.6441 - val_accuracy: 0.5740\n",
      "Epoch 2776/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6153 - accuracy: 0.6453 - val_loss: 0.6747 - val_accuracy: 0.5322\n",
      "Epoch 2777/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6157 - accuracy: 0.6456 - val_loss: 0.6380 - val_accuracy: 0.5811\n",
      "Epoch 2778/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6154 - accuracy: 0.6450 - val_loss: 0.6711 - val_accuracy: 0.5349\n",
      "Epoch 2779/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6151 - accuracy: 0.6458 - val_loss: 0.6479 - val_accuracy: 0.5676\n",
      "Epoch 2780/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6148 - accuracy: 0.6460 - val_loss: 0.6649 - val_accuracy: 0.5446\n",
      "Epoch 2781/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6145 - accuracy: 0.6475 - val_loss: 0.6504 - val_accuracy: 0.5645\n",
      "Epoch 2782/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6143 - accuracy: 0.6464 - val_loss: 0.6593 - val_accuracy: 0.5490\n",
      "Epoch 2783/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6143 - accuracy: 0.6466 - val_loss: 0.6567 - val_accuracy: 0.5535\n",
      "Epoch 2784/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6141 - accuracy: 0.6471 - val_loss: 0.6553 - val_accuracy: 0.5577\n",
      "Epoch 2785/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6142 - accuracy: 0.6463 - val_loss: 0.6608 - val_accuracy: 0.5468\n",
      "Epoch 2786/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6142 - accuracy: 0.6466 - val_loss: 0.6484 - val_accuracy: 0.5683\n",
      "Epoch 2787/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6143 - accuracy: 0.6469 - val_loss: 0.6656 - val_accuracy: 0.5395\n",
      "Epoch 2788/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6144 - accuracy: 0.6468 - val_loss: 0.6463 - val_accuracy: 0.5705\n",
      "Epoch 2789/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6146 - accuracy: 0.6457 - val_loss: 0.6712 - val_accuracy: 0.5345\n",
      "Epoch 2790/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6148 - accuracy: 0.6461 - val_loss: 0.6421 - val_accuracy: 0.5771\n",
      "Epoch 2791/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6149 - accuracy: 0.6446 - val_loss: 0.6747 - val_accuracy: 0.5323\n",
      "Epoch 2792/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6152 - accuracy: 0.6468 - val_loss: 0.6399 - val_accuracy: 0.5817\n",
      "Epoch 2793/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6153 - accuracy: 0.6460 - val_loss: 0.6792 - val_accuracy: 0.5256\n",
      "Epoch 2794/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6159 - accuracy: 0.6446 - val_loss: 0.6383 - val_accuracy: 0.5804\n",
      "Epoch 2795/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6157 - accuracy: 0.6441 - val_loss: 0.6761 - val_accuracy: 0.5290\n",
      "Epoch 2796/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6156 - accuracy: 0.6463 - val_loss: 0.6410 - val_accuracy: 0.5809\n",
      "Epoch 2797/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6154 - accuracy: 0.6455 - val_loss: 0.6713 - val_accuracy: 0.5322\n",
      "Epoch 2798/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6152 - accuracy: 0.6457 - val_loss: 0.6459 - val_accuracy: 0.5685\n",
      "Epoch 2799/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6149 - accuracy: 0.6446 - val_loss: 0.6637 - val_accuracy: 0.5444\n",
      "Epoch 2800/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6145 - accuracy: 0.6477 - val_loss: 0.6527 - val_accuracy: 0.5596\n",
      "Epoch 2801/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6145 - accuracy: 0.6469 - val_loss: 0.6584 - val_accuracy: 0.5479\n",
      "Epoch 2802/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6143 - accuracy: 0.6465 - val_loss: 0.6539 - val_accuracy: 0.5574\n",
      "Epoch 2803/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6141 - accuracy: 0.6468 - val_loss: 0.6576 - val_accuracy: 0.5532\n",
      "Epoch 2804/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6142 - accuracy: 0.6467 - val_loss: 0.6563 - val_accuracy: 0.5548\n",
      "Epoch 2805/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6140 - accuracy: 0.6479 - val_loss: 0.6556 - val_accuracy: 0.5512\n",
      "Epoch 2806/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6143 - accuracy: 0.6467 - val_loss: 0.6564 - val_accuracy: 0.5528\n",
      "Epoch 2807/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6139 - accuracy: 0.6477 - val_loss: 0.6537 - val_accuracy: 0.5594\n",
      "Epoch 2808/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6140 - accuracy: 0.6466 - val_loss: 0.6631 - val_accuracy: 0.5457\n",
      "Epoch 2809/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6139 - accuracy: 0.6479 - val_loss: 0.6498 - val_accuracy: 0.5643\n",
      "Epoch 2810/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6141 - accuracy: 0.6465 - val_loss: 0.6638 - val_accuracy: 0.5440\n",
      "Epoch 2811/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6143 - accuracy: 0.6474 - val_loss: 0.6436 - val_accuracy: 0.5751\n",
      "Epoch 2812/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6146 - accuracy: 0.6459 - val_loss: 0.6768 - val_accuracy: 0.5280\n",
      "Epoch 2813/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6151 - accuracy: 0.6466 - val_loss: 0.6397 - val_accuracy: 0.5773\n",
      "Epoch 2814/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6155 - accuracy: 0.6443 - val_loss: 0.6797 - val_accuracy: 0.5248\n",
      "Epoch 2815/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6165 - accuracy: 0.6449 - val_loss: 0.6301 - val_accuracy: 0.5979\n",
      "Epoch 2816/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6168 - accuracy: 0.6438 - val_loss: 0.6897 - val_accuracy: 0.5108\n",
      "Epoch 2817/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6175 - accuracy: 0.6420 - val_loss: 0.6409 - val_accuracy: 0.5764\n",
      "Epoch 2818/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6167 - accuracy: 0.6439 - val_loss: 0.6718 - val_accuracy: 0.5345\n",
      "Epoch 2819/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6160 - accuracy: 0.6467 - val_loss: 0.6426 - val_accuracy: 0.5771\n",
      "Epoch 2820/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6160 - accuracy: 0.6451 - val_loss: 0.6617 - val_accuracy: 0.5438\n",
      "Epoch 2821/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6146 - accuracy: 0.6456 - val_loss: 0.6577 - val_accuracy: 0.5486\n",
      "Epoch 2822/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6153 - accuracy: 0.6439 - val_loss: 0.6644 - val_accuracy: 0.5431\n",
      "Epoch 2823/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6149 - accuracy: 0.6465 - val_loss: 0.6446 - val_accuracy: 0.5738\n",
      "Epoch 2824/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6156 - accuracy: 0.6450 - val_loss: 0.6681 - val_accuracy: 0.5338\n",
      "Epoch 2825/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6153 - accuracy: 0.6458 - val_loss: 0.6412 - val_accuracy: 0.5742\n",
      "Epoch 2826/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6166 - accuracy: 0.6428 - val_loss: 0.6868 - val_accuracy: 0.5121\n",
      "Epoch 2827/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6177 - accuracy: 0.6437 - val_loss: 0.6333 - val_accuracy: 0.5926\n",
      "Epoch 2828/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6188 - accuracy: 0.6411 - val_loss: 0.6859 - val_accuracy: 0.5183\n",
      "Epoch 2829/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6181 - accuracy: 0.6416 - val_loss: 0.6384 - val_accuracy: 0.5800\n",
      "Epoch 2830/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6205 - accuracy: 0.6392 - val_loss: 0.6781 - val_accuracy: 0.5256\n",
      "Epoch 2831/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6172 - accuracy: 0.6447 - val_loss: 0.6427 - val_accuracy: 0.5822\n",
      "Epoch 2832/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6218 - accuracy: 0.6395 - val_loss: 0.6852 - val_accuracy: 0.5185\n",
      "Epoch 2833/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6185 - accuracy: 0.6420 - val_loss: 0.6269 - val_accuracy: 0.6021\n",
      "Epoch 2834/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6258 - accuracy: 0.6342 - val_loss: 0.7128 - val_accuracy: 0.4826\n",
      "Epoch 2835/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6238 - accuracy: 0.6354 - val_loss: 0.6314 - val_accuracy: 0.5974\n",
      "Epoch 2836/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6237 - accuracy: 0.6360 - val_loss: 0.6822 - val_accuracy: 0.5197\n",
      "Epoch 2837/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6173 - accuracy: 0.6437 - val_loss: 0.6431 - val_accuracy: 0.5727\n",
      "Epoch 2838/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6197 - accuracy: 0.6384 - val_loss: 0.6578 - val_accuracy: 0.5479\n",
      "Epoch 2839/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6149 - accuracy: 0.6443 - val_loss: 0.6562 - val_accuracy: 0.5552\n",
      "Epoch 2840/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6165 - accuracy: 0.6452 - val_loss: 0.6595 - val_accuracy: 0.5502\n",
      "Epoch 2841/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6155 - accuracy: 0.6462 - val_loss: 0.6552 - val_accuracy: 0.5510\n",
      "Epoch 2842/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6150 - accuracy: 0.6449 - val_loss: 0.6517 - val_accuracy: 0.5564\n",
      "Epoch 2843/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6156 - accuracy: 0.6427 - val_loss: 0.6629 - val_accuracy: 0.5462\n",
      "Epoch 2844/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6147 - accuracy: 0.6466 - val_loss: 0.6454 - val_accuracy: 0.5722\n",
      "Epoch 2845/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6163 - accuracy: 0.6452 - val_loss: 0.6777 - val_accuracy: 0.5228\n",
      "Epoch 2846/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6161 - accuracy: 0.6448 - val_loss: 0.6327 - val_accuracy: 0.5904\n",
      "Epoch 2847/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6172 - accuracy: 0.6422 - val_loss: 0.6771 - val_accuracy: 0.5248\n",
      "Epoch 2848/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6164 - accuracy: 0.6448 - val_loss: 0.6442 - val_accuracy: 0.5751\n",
      "Epoch 2849/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6161 - accuracy: 0.6442 - val_loss: 0.6651 - val_accuracy: 0.5409\n",
      "Epoch 2850/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6142 - accuracy: 0.6471 - val_loss: 0.6537 - val_accuracy: 0.5564\n",
      "Epoch 2851/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6153 - accuracy: 0.6455 - val_loss: 0.6528 - val_accuracy: 0.5605\n",
      "Epoch 2852/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6142 - accuracy: 0.6466 - val_loss: 0.6611 - val_accuracy: 0.5493\n",
      "Epoch 2853/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6151 - accuracy: 0.6460 - val_loss: 0.6549 - val_accuracy: 0.5566\n",
      "Epoch 2854/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6138 - accuracy: 0.6475 - val_loss: 0.6597 - val_accuracy: 0.5466\n",
      "Epoch 2855/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6151 - accuracy: 0.6455 - val_loss: 0.6561 - val_accuracy: 0.5533\n",
      "Epoch 2856/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6138 - accuracy: 0.6478 - val_loss: 0.6475 - val_accuracy: 0.5701\n",
      "Epoch 2857/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6148 - accuracy: 0.6458 - val_loss: 0.6729 - val_accuracy: 0.5314\n",
      "Epoch 2858/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6144 - accuracy: 0.6469 - val_loss: 0.6425 - val_accuracy: 0.5749\n",
      "Epoch 2859/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6158 - accuracy: 0.6449 - val_loss: 0.6782 - val_accuracy: 0.5248\n",
      "Epoch 2860/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6156 - accuracy: 0.6455 - val_loss: 0.6327 - val_accuracy: 0.5948\n",
      "Epoch 2861/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6166 - accuracy: 0.6440 - val_loss: 0.6857 - val_accuracy: 0.5201\n",
      "Epoch 2862/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6163 - accuracy: 0.6437 - val_loss: 0.6400 - val_accuracy: 0.5780\n",
      "Epoch 2863/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6172 - accuracy: 0.6436 - val_loss: 0.6791 - val_accuracy: 0.5248\n",
      "Epoch 2864/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6158 - accuracy: 0.6463 - val_loss: 0.6376 - val_accuracy: 0.5868\n",
      "Epoch 2865/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6163 - accuracy: 0.6450 - val_loss: 0.6700 - val_accuracy: 0.5353\n",
      "Epoch 2866/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6145 - accuracy: 0.6468 - val_loss: 0.6496 - val_accuracy: 0.5641\n",
      "Epoch 2867/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6161 - accuracy: 0.6436 - val_loss: 0.6686 - val_accuracy: 0.5398\n",
      "Epoch 2868/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6143 - accuracy: 0.6467 - val_loss: 0.6447 - val_accuracy: 0.5778\n",
      "Epoch 2869/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6158 - accuracy: 0.6455 - val_loss: 0.6694 - val_accuracy: 0.5358\n",
      "Epoch 2870/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6143 - accuracy: 0.6477 - val_loss: 0.6423 - val_accuracy: 0.5751\n",
      "Epoch 2871/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6170 - accuracy: 0.6438 - val_loss: 0.6843 - val_accuracy: 0.5183\n",
      "Epoch 2872/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6163 - accuracy: 0.6453 - val_loss: 0.6323 - val_accuracy: 0.5948\n",
      "Epoch 2873/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6181 - accuracy: 0.6418 - val_loss: 0.6842 - val_accuracy: 0.5194\n",
      "Epoch 2874/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6168 - accuracy: 0.6430 - val_loss: 0.6391 - val_accuracy: 0.5782\n",
      "Epoch 2875/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6180 - accuracy: 0.6426 - val_loss: 0.6739 - val_accuracy: 0.5301\n",
      "Epoch 2876/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6148 - accuracy: 0.6471 - val_loss: 0.6474 - val_accuracy: 0.5718\n",
      "Epoch 2877/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6165 - accuracy: 0.6451 - val_loss: 0.6656 - val_accuracy: 0.5406\n",
      "Epoch 2878/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6139 - accuracy: 0.6480 - val_loss: 0.6459 - val_accuracy: 0.5689\n",
      "Epoch 2879/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6168 - accuracy: 0.6439 - val_loss: 0.6739 - val_accuracy: 0.5276\n",
      "Epoch 2880/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6146 - accuracy: 0.6478 - val_loss: 0.6406 - val_accuracy: 0.5826\n",
      "Epoch 2881/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6169 - accuracy: 0.6445 - val_loss: 0.6824 - val_accuracy: 0.5197\n",
      "Epoch 2882/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6160 - accuracy: 0.6444 - val_loss: 0.6334 - val_accuracy: 0.5893\n",
      "Epoch 2883/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6180 - accuracy: 0.6418 - val_loss: 0.6831 - val_accuracy: 0.5183\n",
      "Epoch 2884/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6160 - accuracy: 0.6452 - val_loss: 0.6398 - val_accuracy: 0.5824\n",
      "Epoch 2885/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6167 - accuracy: 0.6447 - val_loss: 0.6719 - val_accuracy: 0.5334\n",
      "Epoch 2886/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6143 - accuracy: 0.6473 - val_loss: 0.6469 - val_accuracy: 0.5667\n",
      "Epoch 2887/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6157 - accuracy: 0.6437 - val_loss: 0.6610 - val_accuracy: 0.5469\n",
      "Epoch 2888/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6134 - accuracy: 0.6480 - val_loss: 0.6536 - val_accuracy: 0.5627\n",
      "Epoch 2889/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6148 - accuracy: 0.6463 - val_loss: 0.6625 - val_accuracy: 0.5471\n",
      "Epoch 2890/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6134 - accuracy: 0.6486 - val_loss: 0.6484 - val_accuracy: 0.5669\n",
      "Epoch 2891/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6148 - accuracy: 0.6456 - val_loss: 0.6678 - val_accuracy: 0.5376\n",
      "Epoch 2892/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6139 - accuracy: 0.6474 - val_loss: 0.6417 - val_accuracy: 0.5807\n",
      "Epoch 2893/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6150 - accuracy: 0.6460 - val_loss: 0.6772 - val_accuracy: 0.5254\n",
      "Epoch 2894/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6147 - accuracy: 0.6473 - val_loss: 0.6396 - val_accuracy: 0.5778\n",
      "Epoch 2895/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6155 - accuracy: 0.6445 - val_loss: 0.6740 - val_accuracy: 0.5290\n",
      "Epoch 2896/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6145 - accuracy: 0.6470 - val_loss: 0.6427 - val_accuracy: 0.5795\n",
      "Epoch 2897/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6146 - accuracy: 0.6463 - val_loss: 0.6683 - val_accuracy: 0.5398\n",
      "Epoch 2898/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6136 - accuracy: 0.6479 - val_loss: 0.6502 - val_accuracy: 0.5652\n",
      "Epoch 2899/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6141 - accuracy: 0.6464 - val_loss: 0.6606 - val_accuracy: 0.5493\n",
      "Epoch 2900/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6132 - accuracy: 0.6475 - val_loss: 0.6530 - val_accuracy: 0.5625\n",
      "Epoch 2901/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6137 - accuracy: 0.6471 - val_loss: 0.6579 - val_accuracy: 0.5544\n",
      "Epoch 2902/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6131 - accuracy: 0.6481 - val_loss: 0.6562 - val_accuracy: 0.5532\n",
      "Epoch 2903/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6136 - accuracy: 0.6472 - val_loss: 0.6579 - val_accuracy: 0.5535\n",
      "Epoch 2904/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6131 - accuracy: 0.6482 - val_loss: 0.6540 - val_accuracy: 0.5617\n",
      "Epoch 2905/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6135 - accuracy: 0.6477 - val_loss: 0.6600 - val_accuracy: 0.5512\n",
      "Epoch 2906/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6130 - accuracy: 0.6481 - val_loss: 0.6517 - val_accuracy: 0.5623\n",
      "Epoch 2907/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6136 - accuracy: 0.6472 - val_loss: 0.6653 - val_accuracy: 0.5431\n",
      "Epoch 2908/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6133 - accuracy: 0.6479 - val_loss: 0.6444 - val_accuracy: 0.5747\n",
      "Epoch 2909/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6139 - accuracy: 0.6474 - val_loss: 0.6736 - val_accuracy: 0.5322\n",
      "Epoch 2910/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6141 - accuracy: 0.6480 - val_loss: 0.6396 - val_accuracy: 0.5802\n",
      "Epoch 2911/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6149 - accuracy: 0.6447 - val_loss: 0.6825 - val_accuracy: 0.5199\n",
      "Epoch 2912/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6154 - accuracy: 0.6463 - val_loss: 0.6347 - val_accuracy: 0.5912\n",
      "Epoch 2913/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6157 - accuracy: 0.6449 - val_loss: 0.6832 - val_accuracy: 0.5210\n",
      "Epoch 2914/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6157 - accuracy: 0.6445 - val_loss: 0.6384 - val_accuracy: 0.5806\n",
      "Epoch 2915/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6154 - accuracy: 0.6449 - val_loss: 0.6740 - val_accuracy: 0.5298\n",
      "Epoch 2916/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6144 - accuracy: 0.6480 - val_loss: 0.6463 - val_accuracy: 0.5736\n",
      "Epoch 2917/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6144 - accuracy: 0.6469 - val_loss: 0.6608 - val_accuracy: 0.5482\n",
      "Epoch 2918/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6133 - accuracy: 0.6474 - val_loss: 0.6546 - val_accuracy: 0.5563\n",
      "Epoch 2919/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6139 - accuracy: 0.6461 - val_loss: 0.6582 - val_accuracy: 0.5557\n",
      "Epoch 2920/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6132 - accuracy: 0.6484 - val_loss: 0.6575 - val_accuracy: 0.5575\n",
      "Epoch 2921/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6137 - accuracy: 0.6468 - val_loss: 0.6565 - val_accuracy: 0.5544\n",
      "Epoch 2922/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6130 - accuracy: 0.6482 - val_loss: 0.6537 - val_accuracy: 0.5581\n",
      "Epoch 2923/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6136 - accuracy: 0.6473 - val_loss: 0.6620 - val_accuracy: 0.5495\n",
      "Epoch 2924/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6131 - accuracy: 0.6486 - val_loss: 0.6494 - val_accuracy: 0.5689\n",
      "Epoch 2925/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6138 - accuracy: 0.6470 - val_loss: 0.6679 - val_accuracy: 0.5382\n",
      "Epoch 2926/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6135 - accuracy: 0.6480 - val_loss: 0.6420 - val_accuracy: 0.5760\n",
      "Epoch 2927/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6144 - accuracy: 0.6455 - val_loss: 0.6777 - val_accuracy: 0.5261\n",
      "Epoch 2928/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6147 - accuracy: 0.6475 - val_loss: 0.6364 - val_accuracy: 0.5881\n",
      "Epoch 2929/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6156 - accuracy: 0.6449 - val_loss: 0.6856 - val_accuracy: 0.5186\n",
      "Epoch 2930/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6160 - accuracy: 0.6445 - val_loss: 0.6357 - val_accuracy: 0.5851\n",
      "Epoch 2931/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6162 - accuracy: 0.6440 - val_loss: 0.6794 - val_accuracy: 0.5227\n",
      "Epoch 2932/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6153 - accuracy: 0.6469 - val_loss: 0.6408 - val_accuracy: 0.5824\n",
      "Epoch 2933/15000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.6156 - accuracy: 0.6463 - val_loss: 0.6699 - val_accuracy: 0.5365\n",
      "Epoch 2934/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6139 - accuracy: 0.6474 - val_loss: 0.6474 - val_accuracy: 0.5672\n",
      "Epoch 2935/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6153 - accuracy: 0.6440 - val_loss: 0.6671 - val_accuracy: 0.5415\n",
      "Epoch 2936/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6137 - accuracy: 0.6477 - val_loss: 0.6477 - val_accuracy: 0.5742\n",
      "Epoch 2937/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6153 - accuracy: 0.6465 - val_loss: 0.6718 - val_accuracy: 0.5327\n",
      "Epoch 2938/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6139 - accuracy: 0.6480 - val_loss: 0.6382 - val_accuracy: 0.5800\n",
      "Epoch 2939/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6169 - accuracy: 0.6441 - val_loss: 0.6874 - val_accuracy: 0.5150\n",
      "Epoch 2940/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6166 - accuracy: 0.6446 - val_loss: 0.6297 - val_accuracy: 0.6021\n",
      "Epoch 2941/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6192 - accuracy: 0.6394 - val_loss: 0.6953 - val_accuracy: 0.5073\n",
      "Epoch 2942/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6182 - accuracy: 0.6419 - val_loss: 0.6363 - val_accuracy: 0.5857\n",
      "Epoch 2943/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6195 - accuracy: 0.6412 - val_loss: 0.6719 - val_accuracy: 0.5298\n",
      "Epoch 2944/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6147 - accuracy: 0.6469 - val_loss: 0.6495 - val_accuracy: 0.5701\n",
      "Epoch 2945/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6175 - accuracy: 0.6453 - val_loss: 0.6654 - val_accuracy: 0.5431\n",
      "Epoch 2946/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6136 - accuracy: 0.6487 - val_loss: 0.6435 - val_accuracy: 0.5731\n",
      "Epoch 2947/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6176 - accuracy: 0.6436 - val_loss: 0.6829 - val_accuracy: 0.5183\n",
      "Epoch 2948/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6154 - accuracy: 0.6451 - val_loss: 0.6333 - val_accuracy: 0.5944\n",
      "Epoch 2949/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6182 - accuracy: 0.6412 - val_loss: 0.6922 - val_accuracy: 0.5062\n",
      "Epoch 2950/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6175 - accuracy: 0.6426 - val_loss: 0.6324 - val_accuracy: 0.5937\n",
      "Epoch 2951/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6170 - accuracy: 0.6429 - val_loss: 0.6714 - val_accuracy: 0.5327\n",
      "Epoch 2952/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6140 - accuracy: 0.6477 - val_loss: 0.6516 - val_accuracy: 0.5643\n",
      "Epoch 2953/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6142 - accuracy: 0.6463 - val_loss: 0.6525 - val_accuracy: 0.5607\n",
      "Epoch 2954/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6129 - accuracy: 0.6477 - val_loss: 0.6672 - val_accuracy: 0.5385\n",
      "Epoch 2955/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6141 - accuracy: 0.6462 - val_loss: 0.6437 - val_accuracy: 0.5742\n",
      "Epoch 2956/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6134 - accuracy: 0.6470 - val_loss: 0.6686 - val_accuracy: 0.5362\n",
      "Epoch 2957/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6140 - accuracy: 0.6474 - val_loss: 0.6490 - val_accuracy: 0.5685\n",
      "Epoch 2958/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6134 - accuracy: 0.6472 - val_loss: 0.6614 - val_accuracy: 0.5479\n",
      "Epoch 2959/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6133 - accuracy: 0.6479 - val_loss: 0.6535 - val_accuracy: 0.5592\n",
      "Epoch 2960/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6132 - accuracy: 0.6479 - val_loss: 0.6546 - val_accuracy: 0.5594\n",
      "Epoch 2961/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6130 - accuracy: 0.6484 - val_loss: 0.6616 - val_accuracy: 0.5506\n",
      "Epoch 2962/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6132 - accuracy: 0.6482 - val_loss: 0.6528 - val_accuracy: 0.5625\n",
      "Epoch 2963/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6128 - accuracy: 0.6482 - val_loss: 0.6597 - val_accuracy: 0.5491\n",
      "Epoch 2964/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6131 - accuracy: 0.6479 - val_loss: 0.6529 - val_accuracy: 0.5617\n",
      "Epoch 2965/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6127 - accuracy: 0.6486 - val_loss: 0.6592 - val_accuracy: 0.5554\n",
      "Epoch 2966/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6129 - accuracy: 0.6479 - val_loss: 0.6595 - val_accuracy: 0.5513\n",
      "Epoch 2967/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6126 - accuracy: 0.6487 - val_loss: 0.6521 - val_accuracy: 0.5627\n",
      "Epoch 2968/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6128 - accuracy: 0.6482 - val_loss: 0.6612 - val_accuracy: 0.5486\n",
      "Epoch 2969/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6128 - accuracy: 0.6481 - val_loss: 0.6489 - val_accuracy: 0.5683\n",
      "Epoch 2970/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6130 - accuracy: 0.6472 - val_loss: 0.6697 - val_accuracy: 0.5365\n",
      "Epoch 2971/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6131 - accuracy: 0.6485 - val_loss: 0.6443 - val_accuracy: 0.5734\n",
      "Epoch 2972/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6134 - accuracy: 0.6470 - val_loss: 0.6739 - val_accuracy: 0.5322\n",
      "Epoch 2973/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6139 - accuracy: 0.6471 - val_loss: 0.6374 - val_accuracy: 0.5886\n",
      "Epoch 2974/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6144 - accuracy: 0.6458 - val_loss: 0.6850 - val_accuracy: 0.5205\n",
      "Epoch 2975/15000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6151 - accuracy: 0.6464 - val_loss: 0.6360 - val_accuracy: 0.5862\n",
      "Epoch 2976/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6151 - accuracy: 0.6446 - val_loss: 0.6817 - val_accuracy: 0.5237\n",
      "Epoch 2977/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6153 - accuracy: 0.6461 - val_loss: 0.6353 - val_accuracy: 0.5915\n",
      "Epoch 2978/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6147 - accuracy: 0.6452 - val_loss: 0.6753 - val_accuracy: 0.5285\n",
      "Epoch 2979/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6136 - accuracy: 0.6477 - val_loss: 0.6512 - val_accuracy: 0.5658\n",
      "Epoch 2980/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6135 - accuracy: 0.6468 - val_loss: 0.6593 - val_accuracy: 0.5522\n",
      "Epoch 2981/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6127 - accuracy: 0.6491 - val_loss: 0.6532 - val_accuracy: 0.5623\n",
      "Epoch 2982/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6131 - accuracy: 0.6487 - val_loss: 0.6553 - val_accuracy: 0.5583\n",
      "Epoch 2983/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6125 - accuracy: 0.6485 - val_loss: 0.6646 - val_accuracy: 0.5417\n",
      "Epoch 2984/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6131 - accuracy: 0.6481 - val_loss: 0.6525 - val_accuracy: 0.5641\n",
      "Epoch 2985/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6125 - accuracy: 0.6484 - val_loss: 0.6577 - val_accuracy: 0.5566\n",
      "Epoch 2986/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6129 - accuracy: 0.6486 - val_loss: 0.6519 - val_accuracy: 0.5638\n",
      "Epoch 2987/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6124 - accuracy: 0.6484 - val_loss: 0.6619 - val_accuracy: 0.5484\n",
      "Epoch 2988/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6128 - accuracy: 0.6484 - val_loss: 0.6570 - val_accuracy: 0.5566\n",
      "Epoch 2989/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6124 - accuracy: 0.6489 - val_loss: 0.6535 - val_accuracy: 0.5619\n",
      "Epoch 2990/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6126 - accuracy: 0.6483 - val_loss: 0.6588 - val_accuracy: 0.5532\n",
      "Epoch 2991/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6124 - accuracy: 0.6492 - val_loss: 0.6528 - val_accuracy: 0.5621\n",
      "Epoch 2992/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6126 - accuracy: 0.6479 - val_loss: 0.6675 - val_accuracy: 0.5387\n",
      "Epoch 2993/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6127 - accuracy: 0.6486 - val_loss: 0.6428 - val_accuracy: 0.5784\n",
      "Epoch 2994/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6131 - accuracy: 0.6473 - val_loss: 0.6745 - val_accuracy: 0.5292\n",
      "Epoch 2995/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6137 - accuracy: 0.6480 - val_loss: 0.6379 - val_accuracy: 0.5828\n",
      "Epoch 2996/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6142 - accuracy: 0.6455 - val_loss: 0.6874 - val_accuracy: 0.5142\n",
      "Epoch 2997/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6155 - accuracy: 0.6459 - val_loss: 0.6300 - val_accuracy: 0.6012\n",
      "Epoch 2998/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6158 - accuracy: 0.6443 - val_loss: 0.6916 - val_accuracy: 0.5119\n",
      "Epoch 2999/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6168 - accuracy: 0.6443 - val_loss: 0.6356 - val_accuracy: 0.5857\n",
      "Epoch 3000/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6151 - accuracy: 0.6447 - val_loss: 0.6723 - val_accuracy: 0.5322\n",
      "Epoch 3001/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6136 - accuracy: 0.6490 - val_loss: 0.6518 - val_accuracy: 0.5674\n",
      "Epoch 3002/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6133 - accuracy: 0.6470 - val_loss: 0.6536 - val_accuracy: 0.5585\n",
      "Epoch 3003/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6125 - accuracy: 0.6494 - val_loss: 0.6624 - val_accuracy: 0.5460\n",
      "Epoch 3004/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6131 - accuracy: 0.6470 - val_loss: 0.6501 - val_accuracy: 0.5661\n",
      "Epoch 3005/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6127 - accuracy: 0.6481 - val_loss: 0.6678 - val_accuracy: 0.5418\n",
      "Epoch 3006/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6132 - accuracy: 0.6491 - val_loss: 0.6459 - val_accuracy: 0.5705\n",
      "Epoch 3007/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6127 - accuracy: 0.6483 - val_loss: 0.6666 - val_accuracy: 0.5395\n",
      "Epoch 3008/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6132 - accuracy: 0.6468 - val_loss: 0.6468 - val_accuracy: 0.5698\n",
      "Epoch 3009/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6128 - accuracy: 0.6484 - val_loss: 0.6678 - val_accuracy: 0.5427\n",
      "Epoch 3010/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6129 - accuracy: 0.6490 - val_loss: 0.6483 - val_accuracy: 0.5691\n",
      "Epoch 3011/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6126 - accuracy: 0.6482 - val_loss: 0.6637 - val_accuracy: 0.5435\n",
      "Epoch 3012/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6128 - accuracy: 0.6476 - val_loss: 0.6471 - val_accuracy: 0.5700\n",
      "Epoch 3013/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6127 - accuracy: 0.6481 - val_loss: 0.6698 - val_accuracy: 0.5396\n",
      "Epoch 3014/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6129 - accuracy: 0.6492 - val_loss: 0.6464 - val_accuracy: 0.5733\n",
      "Epoch 3015/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6128 - accuracy: 0.6473 - val_loss: 0.6693 - val_accuracy: 0.5376\n",
      "Epoch 3016/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6133 - accuracy: 0.6472 - val_loss: 0.6399 - val_accuracy: 0.5813\n",
      "Epoch 3017/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6133 - accuracy: 0.6467 - val_loss: 0.6794 - val_accuracy: 0.5248\n",
      "Epoch 3018/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6140 - accuracy: 0.6478 - val_loss: 0.6389 - val_accuracy: 0.5842\n",
      "Epoch 3019/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6143 - accuracy: 0.6462 - val_loss: 0.6839 - val_accuracy: 0.5194\n",
      "Epoch 3020/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6154 - accuracy: 0.6449 - val_loss: 0.6318 - val_accuracy: 0.5963\n",
      "Epoch 3021/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6152 - accuracy: 0.6428 - val_loss: 0.6852 - val_accuracy: 0.5152\n",
      "Epoch 3022/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6152 - accuracy: 0.6464 - val_loss: 0.6400 - val_accuracy: 0.5842\n",
      "Epoch 3023/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6152 - accuracy: 0.6457 - val_loss: 0.6773 - val_accuracy: 0.5274\n",
      "Epoch 3024/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6146 - accuracy: 0.6456 - val_loss: 0.6393 - val_accuracy: 0.5811\n",
      "Epoch 3025/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6154 - accuracy: 0.6426 - val_loss: 0.6746 - val_accuracy: 0.5316\n",
      "Epoch 3026/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6138 - accuracy: 0.6478 - val_loss: 0.6437 - val_accuracy: 0.5776\n",
      "Epoch 3027/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6162 - accuracy: 0.6452 - val_loss: 0.6828 - val_accuracy: 0.5208\n",
      "Epoch 3028/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6152 - accuracy: 0.6447 - val_loss: 0.6296 - val_accuracy: 0.5976\n",
      "Epoch 3029/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6195 - accuracy: 0.6388 - val_loss: 0.7009 - val_accuracy: 0.4962\n",
      "Epoch 3030/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6192 - accuracy: 0.6405 - val_loss: 0.6272 - val_accuracy: 0.6140\n",
      "Epoch 3031/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6231 - accuracy: 0.6365 - val_loss: 0.7028 - val_accuracy: 0.4987\n",
      "Epoch 3032/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6199 - accuracy: 0.6401 - val_loss: 0.6364 - val_accuracy: 0.5842\n",
      "Epoch 3033/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6245 - accuracy: 0.6341 - val_loss: 0.6824 - val_accuracy: 0.5201\n",
      "Epoch 3034/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6162 - accuracy: 0.6447 - val_loss: 0.6381 - val_accuracy: 0.5912\n",
      "Epoch 3035/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6207 - accuracy: 0.6408 - val_loss: 0.6803 - val_accuracy: 0.5185\n",
      "Epoch 3036/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6159 - accuracy: 0.6461 - val_loss: 0.6379 - val_accuracy: 0.5765\n",
      "Epoch 3037/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6163 - accuracy: 0.6422 - val_loss: 0.6704 - val_accuracy: 0.5325\n",
      "Epoch 3038/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6146 - accuracy: 0.6452 - val_loss: 0.6527 - val_accuracy: 0.5608\n",
      "Epoch 3039/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6131 - accuracy: 0.6478 - val_loss: 0.6473 - val_accuracy: 0.5707\n",
      "Epoch 3040/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6143 - accuracy: 0.6470 - val_loss: 0.6820 - val_accuracy: 0.5164\n",
      "Epoch 3041/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6150 - accuracy: 0.6465 - val_loss: 0.6290 - val_accuracy: 0.5990\n",
      "Epoch 3042/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6175 - accuracy: 0.6414 - val_loss: 0.6898 - val_accuracy: 0.5115\n",
      "Epoch 3043/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6173 - accuracy: 0.6429 - val_loss: 0.6367 - val_accuracy: 0.5873\n",
      "Epoch 3044/15000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6165 - accuracy: 0.6436 - val_loss: 0.6611 - val_accuracy: 0.5460\n",
      "Epoch 3045/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6126 - accuracy: 0.6484 - val_loss: 0.6656 - val_accuracy: 0.5365\n",
      "Epoch 3046/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6149 - accuracy: 0.6444 - val_loss: 0.6441 - val_accuracy: 0.5736\n",
      "Epoch 3047/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6129 - accuracy: 0.6484 - val_loss: 0.6678 - val_accuracy: 0.5393\n",
      "Epoch 3048/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6143 - accuracy: 0.6470 - val_loss: 0.6480 - val_accuracy: 0.5705\n",
      "Epoch 3049/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6138 - accuracy: 0.6478 - val_loss: 0.6590 - val_accuracy: 0.5475\n",
      "Epoch 3050/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6128 - accuracy: 0.6473 - val_loss: 0.6585 - val_accuracy: 0.5469\n",
      "Epoch 3051/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6138 - accuracy: 0.6453 - val_loss: 0.6575 - val_accuracy: 0.5561\n",
      "Epoch 3052/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6123 - accuracy: 0.6488 - val_loss: 0.6561 - val_accuracy: 0.5590\n",
      "Epoch 3053/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6132 - accuracy: 0.6478 - val_loss: 0.6568 - val_accuracy: 0.5583\n",
      "Epoch 3054/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6123 - accuracy: 0.6488 - val_loss: 0.6512 - val_accuracy: 0.5625\n",
      "Epoch 3055/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6132 - accuracy: 0.6475 - val_loss: 0.6668 - val_accuracy: 0.5404\n",
      "Epoch 3056/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6125 - accuracy: 0.6486 - val_loss: 0.6453 - val_accuracy: 0.5764\n",
      "Epoch 3057/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6133 - accuracy: 0.6477 - val_loss: 0.6724 - val_accuracy: 0.5316\n",
      "Epoch 3058/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6132 - accuracy: 0.6479 - val_loss: 0.6422 - val_accuracy: 0.5773\n",
      "Epoch 3059/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6135 - accuracy: 0.6455 - val_loss: 0.6728 - val_accuracy: 0.5298\n",
      "Epoch 3060/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6129 - accuracy: 0.6488 - val_loss: 0.6454 - val_accuracy: 0.5765\n",
      "Epoch 3061/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6130 - accuracy: 0.6466 - val_loss: 0.6702 - val_accuracy: 0.5376\n",
      "Epoch 3062/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6128 - accuracy: 0.6482 - val_loss: 0.6434 - val_accuracy: 0.5740\n",
      "Epoch 3063/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6131 - accuracy: 0.6468 - val_loss: 0.6709 - val_accuracy: 0.5347\n",
      "Epoch 3064/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6125 - accuracy: 0.6489 - val_loss: 0.6486 - val_accuracy: 0.5725\n",
      "Epoch 3065/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6128 - accuracy: 0.6474 - val_loss: 0.6683 - val_accuracy: 0.5389\n",
      "Epoch 3066/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6124 - accuracy: 0.6493 - val_loss: 0.6437 - val_accuracy: 0.5756\n",
      "Epoch 3067/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6128 - accuracy: 0.6468 - val_loss: 0.6683 - val_accuracy: 0.5385\n",
      "Epoch 3068/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6123 - accuracy: 0.6487 - val_loss: 0.6481 - val_accuracy: 0.5738\n",
      "Epoch 3069/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6127 - accuracy: 0.6473 - val_loss: 0.6715 - val_accuracy: 0.5358\n",
      "Epoch 3070/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6126 - accuracy: 0.6490 - val_loss: 0.6406 - val_accuracy: 0.5778\n",
      "Epoch 3071/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6129 - accuracy: 0.6463 - val_loss: 0.6736 - val_accuracy: 0.5305\n",
      "Epoch 3072/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6129 - accuracy: 0.6486 - val_loss: 0.6422 - val_accuracy: 0.5791\n",
      "Epoch 3073/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6132 - accuracy: 0.6470 - val_loss: 0.6776 - val_accuracy: 0.5269\n",
      "Epoch 3074/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6133 - accuracy: 0.6482 - val_loss: 0.6384 - val_accuracy: 0.5822\n",
      "Epoch 3075/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6133 - accuracy: 0.6459 - val_loss: 0.6765 - val_accuracy: 0.5259\n",
      "Epoch 3076/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6133 - accuracy: 0.6486 - val_loss: 0.6425 - val_accuracy: 0.5782\n",
      "Epoch 3077/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6131 - accuracy: 0.6474 - val_loss: 0.6738 - val_accuracy: 0.5312\n",
      "Epoch 3078/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6129 - accuracy: 0.6488 - val_loss: 0.6424 - val_accuracy: 0.5758\n",
      "Epoch 3079/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6128 - accuracy: 0.6466 - val_loss: 0.6694 - val_accuracy: 0.5376\n",
      "Epoch 3080/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6126 - accuracy: 0.6495 - val_loss: 0.6465 - val_accuracy: 0.5742\n",
      "Epoch 3081/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6126 - accuracy: 0.6480 - val_loss: 0.6690 - val_accuracy: 0.5395\n",
      "Epoch 3082/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6123 - accuracy: 0.6491 - val_loss: 0.6478 - val_accuracy: 0.5678\n",
      "Epoch 3083/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6123 - accuracy: 0.6481 - val_loss: 0.6636 - val_accuracy: 0.5471\n",
      "Epoch 3084/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6122 - accuracy: 0.6490 - val_loss: 0.6493 - val_accuracy: 0.5689\n",
      "Epoch 3085/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6123 - accuracy: 0.6480 - val_loss: 0.6660 - val_accuracy: 0.5442\n",
      "Epoch 3086/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6120 - accuracy: 0.6496 - val_loss: 0.6503 - val_accuracy: 0.5654\n",
      "Epoch 3087/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6122 - accuracy: 0.6485 - val_loss: 0.6649 - val_accuracy: 0.5451\n",
      "Epoch 3088/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6122 - accuracy: 0.6493 - val_loss: 0.6468 - val_accuracy: 0.5727\n",
      "Epoch 3089/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6124 - accuracy: 0.6479 - val_loss: 0.6700 - val_accuracy: 0.5385\n",
      "Epoch 3090/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6123 - accuracy: 0.6491 - val_loss: 0.6455 - val_accuracy: 0.5731\n",
      "Epoch 3091/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6127 - accuracy: 0.6472 - val_loss: 0.6723 - val_accuracy: 0.5327\n",
      "Epoch 3092/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6129 - accuracy: 0.6490 - val_loss: 0.6388 - val_accuracy: 0.5888\n",
      "Epoch 3093/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6135 - accuracy: 0.6483 - val_loss: 0.6830 - val_accuracy: 0.5216\n",
      "Epoch 3094/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6141 - accuracy: 0.6466 - val_loss: 0.6369 - val_accuracy: 0.5853\n",
      "Epoch 3095/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6148 - accuracy: 0.6449 - val_loss: 0.6856 - val_accuracy: 0.5185\n",
      "Epoch 3096/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6154 - accuracy: 0.6459 - val_loss: 0.6307 - val_accuracy: 0.6012\n",
      "Epoch 3097/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6159 - accuracy: 0.6440 - val_loss: 0.6854 - val_accuracy: 0.5159\n",
      "Epoch 3098/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6146 - accuracy: 0.6458 - val_loss: 0.6435 - val_accuracy: 0.5734\n",
      "Epoch 3099/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6157 - accuracy: 0.6443 - val_loss: 0.6729 - val_accuracy: 0.5334\n",
      "Epoch 3100/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6135 - accuracy: 0.6492 - val_loss: 0.6419 - val_accuracy: 0.5820\n",
      "Epoch 3101/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6154 - accuracy: 0.6469 - val_loss: 0.6722 - val_accuracy: 0.5343\n",
      "Epoch 3102/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6127 - accuracy: 0.6488 - val_loss: 0.6423 - val_accuracy: 0.5753\n",
      "Epoch 3103/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6167 - accuracy: 0.6438 - val_loss: 0.6902 - val_accuracy: 0.5121\n",
      "Epoch 3104/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6157 - accuracy: 0.6447 - val_loss: 0.6256 - val_accuracy: 0.6105\n",
      "Epoch 3105/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6190 - accuracy: 0.6403 - val_loss: 0.6985 - val_accuracy: 0.5031\n",
      "Epoch 3106/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6179 - accuracy: 0.6421 - val_loss: 0.6374 - val_accuracy: 0.5831\n",
      "Epoch 3107/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6183 - accuracy: 0.6419 - val_loss: 0.6707 - val_accuracy: 0.5323\n",
      "Epoch 3108/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6128 - accuracy: 0.6492 - val_loss: 0.6511 - val_accuracy: 0.5670\n",
      "Epoch 3109/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6151 - accuracy: 0.6474 - val_loss: 0.6572 - val_accuracy: 0.5570\n",
      "Epoch 3110/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6120 - accuracy: 0.6494 - val_loss: 0.6544 - val_accuracy: 0.5588\n",
      "Epoch 3111/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6141 - accuracy: 0.6462 - val_loss: 0.6687 - val_accuracy: 0.5373\n",
      "Epoch 3112/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6124 - accuracy: 0.6481 - val_loss: 0.6442 - val_accuracy: 0.5764\n",
      "Epoch 3113/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6134 - accuracy: 0.6477 - val_loss: 0.6738 - val_accuracy: 0.5300\n",
      "Epoch 3114/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6134 - accuracy: 0.6487 - val_loss: 0.6383 - val_accuracy: 0.5826\n",
      "Epoch 3115/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6132 - accuracy: 0.6464 - val_loss: 0.6735 - val_accuracy: 0.5296\n",
      "Epoch 3116/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6129 - accuracy: 0.6479 - val_loss: 0.6474 - val_accuracy: 0.5683\n",
      "Epoch 3117/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6123 - accuracy: 0.6480 - val_loss: 0.6603 - val_accuracy: 0.5533\n",
      "Epoch 3118/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6118 - accuracy: 0.6497 - val_loss: 0.6579 - val_accuracy: 0.5552\n",
      "Epoch 3119/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6117 - accuracy: 0.6495 - val_loss: 0.6469 - val_accuracy: 0.5714\n",
      "Epoch 3120/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6121 - accuracy: 0.6490 - val_loss: 0.6740 - val_accuracy: 0.5289\n",
      "Epoch 3121/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6125 - accuracy: 0.6487 - val_loss: 0.6404 - val_accuracy: 0.5822\n",
      "Epoch 3122/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6131 - accuracy: 0.6477 - val_loss: 0.6787 - val_accuracy: 0.5254\n",
      "Epoch 3123/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6133 - accuracy: 0.6482 - val_loss: 0.6379 - val_accuracy: 0.5855\n",
      "Epoch 3124/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6131 - accuracy: 0.6461 - val_loss: 0.6742 - val_accuracy: 0.5285\n",
      "Epoch 3125/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6127 - accuracy: 0.6490 - val_loss: 0.6458 - val_accuracy: 0.5725\n",
      "Epoch 3126/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6122 - accuracy: 0.6483 - val_loss: 0.6646 - val_accuracy: 0.5480\n",
      "Epoch 3127/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6117 - accuracy: 0.6507 - val_loss: 0.6546 - val_accuracy: 0.5601\n",
      "Epoch 3128/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6115 - accuracy: 0.6503 - val_loss: 0.6522 - val_accuracy: 0.5652\n",
      "Epoch 3129/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6115 - accuracy: 0.6493 - val_loss: 0.6662 - val_accuracy: 0.5435\n",
      "Epoch 3130/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6117 - accuracy: 0.6501 - val_loss: 0.6469 - val_accuracy: 0.5696\n",
      "Epoch 3131/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6120 - accuracy: 0.6486 - val_loss: 0.6726 - val_accuracy: 0.5320\n",
      "Epoch 3132/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6123 - accuracy: 0.6491 - val_loss: 0.6398 - val_accuracy: 0.5846\n",
      "Epoch 3133/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6125 - accuracy: 0.6471 - val_loss: 0.6776 - val_accuracy: 0.5263\n",
      "Epoch 3134/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6129 - accuracy: 0.6486 - val_loss: 0.6389 - val_accuracy: 0.5839\n",
      "Epoch 3135/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6130 - accuracy: 0.6470 - val_loss: 0.6792 - val_accuracy: 0.5261\n",
      "Epoch 3136/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6131 - accuracy: 0.6480 - val_loss: 0.6393 - val_accuracy: 0.5811\n",
      "Epoch 3137/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6126 - accuracy: 0.6476 - val_loss: 0.6730 - val_accuracy: 0.5322\n",
      "Epoch 3138/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6123 - accuracy: 0.6500 - val_loss: 0.6443 - val_accuracy: 0.5749\n",
      "Epoch 3139/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6120 - accuracy: 0.6479 - val_loss: 0.6683 - val_accuracy: 0.5395\n",
      "Epoch 3140/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6117 - accuracy: 0.6492 - val_loss: 0.6506 - val_accuracy: 0.5667\n",
      "Epoch 3141/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6115 - accuracy: 0.6494 - val_loss: 0.6597 - val_accuracy: 0.5561\n",
      "Epoch 3142/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6113 - accuracy: 0.6503 - val_loss: 0.6550 - val_accuracy: 0.5621\n",
      "Epoch 3143/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6113 - accuracy: 0.6497 - val_loss: 0.6556 - val_accuracy: 0.5590\n",
      "Epoch 3144/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6113 - accuracy: 0.6496 - val_loss: 0.6617 - val_accuracy: 0.5482\n",
      "Epoch 3145/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6113 - accuracy: 0.6501 - val_loss: 0.6508 - val_accuracy: 0.5698\n",
      "Epoch 3146/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6114 - accuracy: 0.6494 - val_loss: 0.6660 - val_accuracy: 0.5438\n",
      "Epoch 3147/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6115 - accuracy: 0.6505 - val_loss: 0.6448 - val_accuracy: 0.5740\n",
      "Epoch 3148/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6118 - accuracy: 0.6486 - val_loss: 0.6739 - val_accuracy: 0.5320\n",
      "Epoch 3149/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6122 - accuracy: 0.6498 - val_loss: 0.6384 - val_accuracy: 0.5853\n",
      "Epoch 3150/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6127 - accuracy: 0.6473 - val_loss: 0.6850 - val_accuracy: 0.5199\n",
      "Epoch 3151/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6139 - accuracy: 0.6469 - val_loss: 0.6322 - val_accuracy: 0.5965\n",
      "Epoch 3152/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6141 - accuracy: 0.6447 - val_loss: 0.6894 - val_accuracy: 0.5135\n",
      "Epoch 3153/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6149 - accuracy: 0.6454 - val_loss: 0.6330 - val_accuracy: 0.5944\n",
      "Epoch 3154/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6137 - accuracy: 0.6466 - val_loss: 0.6806 - val_accuracy: 0.5248\n",
      "Epoch 3155/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6131 - accuracy: 0.6484 - val_loss: 0.6428 - val_accuracy: 0.5760\n",
      "Epoch 3156/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6121 - accuracy: 0.6486 - val_loss: 0.6674 - val_accuracy: 0.5420\n",
      "Epoch 3157/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6115 - accuracy: 0.6507 - val_loss: 0.6506 - val_accuracy: 0.5685\n",
      "Epoch 3158/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6112 - accuracy: 0.6497 - val_loss: 0.6578 - val_accuracy: 0.5557\n",
      "Epoch 3159/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6111 - accuracy: 0.6500 - val_loss: 0.6598 - val_accuracy: 0.5537\n",
      "Epoch 3160/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6111 - accuracy: 0.6504 - val_loss: 0.6512 - val_accuracy: 0.5683\n",
      "Epoch 3161/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6112 - accuracy: 0.6496 - val_loss: 0.6664 - val_accuracy: 0.5429\n",
      "Epoch 3162/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6114 - accuracy: 0.6505 - val_loss: 0.6436 - val_accuracy: 0.5764\n",
      "Epoch 3163/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6118 - accuracy: 0.6489 - val_loss: 0.6757 - val_accuracy: 0.5283\n",
      "Epoch 3164/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6124 - accuracy: 0.6491 - val_loss: 0.6368 - val_accuracy: 0.5877\n",
      "Epoch 3165/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6129 - accuracy: 0.6473 - val_loss: 0.6854 - val_accuracy: 0.5181\n",
      "Epoch 3166/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6139 - accuracy: 0.6470 - val_loss: 0.6320 - val_accuracy: 0.5972\n",
      "Epoch 3167/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6140 - accuracy: 0.6451 - val_loss: 0.6881 - val_accuracy: 0.5157\n",
      "Epoch 3168/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6145 - accuracy: 0.6458 - val_loss: 0.6343 - val_accuracy: 0.5937\n",
      "Epoch 3169/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6133 - accuracy: 0.6466 - val_loss: 0.6769 - val_accuracy: 0.5263\n",
      "Epoch 3170/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6125 - accuracy: 0.6492 - val_loss: 0.6461 - val_accuracy: 0.5707\n",
      "Epoch 3171/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6115 - accuracy: 0.6490 - val_loss: 0.6612 - val_accuracy: 0.5522\n",
      "Epoch 3172/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6111 - accuracy: 0.6505 - val_loss: 0.6560 - val_accuracy: 0.5596\n",
      "Epoch 3173/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6109 - accuracy: 0.6502 - val_loss: 0.6523 - val_accuracy: 0.5665\n",
      "Epoch 3174/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6110 - accuracy: 0.6501 - val_loss: 0.6676 - val_accuracy: 0.5398\n",
      "Epoch 3175/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6113 - accuracy: 0.6507 - val_loss: 0.6429 - val_accuracy: 0.5760\n",
      "Epoch 3176/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6118 - accuracy: 0.6486 - val_loss: 0.6765 - val_accuracy: 0.5289\n",
      "Epoch 3177/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6125 - accuracy: 0.6495 - val_loss: 0.6355 - val_accuracy: 0.5888\n",
      "Epoch 3178/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6129 - accuracy: 0.6460 - val_loss: 0.6855 - val_accuracy: 0.5185\n",
      "Epoch 3179/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6138 - accuracy: 0.6469 - val_loss: 0.6337 - val_accuracy: 0.5935\n",
      "Epoch 3180/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6136 - accuracy: 0.6462 - val_loss: 0.6844 - val_accuracy: 0.5203\n",
      "Epoch 3181/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6137 - accuracy: 0.6476 - val_loss: 0.6366 - val_accuracy: 0.5870\n",
      "Epoch 3182/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6127 - accuracy: 0.6470 - val_loss: 0.6747 - val_accuracy: 0.5285\n",
      "Epoch 3183/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6121 - accuracy: 0.6498 - val_loss: 0.6459 - val_accuracy: 0.5718\n",
      "Epoch 3184/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6114 - accuracy: 0.6492 - val_loss: 0.6631 - val_accuracy: 0.5488\n",
      "Epoch 3185/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6110 - accuracy: 0.6505 - val_loss: 0.6547 - val_accuracy: 0.5638\n",
      "Epoch 3186/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6108 - accuracy: 0.6505 - val_loss: 0.6542 - val_accuracy: 0.5623\n",
      "Epoch 3187/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6108 - accuracy: 0.6502 - val_loss: 0.6648 - val_accuracy: 0.5459\n",
      "Epoch 3188/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6110 - accuracy: 0.6507 - val_loss: 0.6457 - val_accuracy: 0.5734\n",
      "Epoch 3189/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6113 - accuracy: 0.6496 - val_loss: 0.6737 - val_accuracy: 0.5316\n",
      "Epoch 3190/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6119 - accuracy: 0.6499 - val_loss: 0.6377 - val_accuracy: 0.5870\n",
      "Epoch 3191/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6124 - accuracy: 0.6475 - val_loss: 0.6846 - val_accuracy: 0.5206\n",
      "Epoch 3192/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6136 - accuracy: 0.6477 - val_loss: 0.6324 - val_accuracy: 0.5972\n",
      "Epoch 3193/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6138 - accuracy: 0.6457 - val_loss: 0.6895 - val_accuracy: 0.5135\n",
      "Epoch 3194/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6147 - accuracy: 0.6456 - val_loss: 0.6320 - val_accuracy: 0.5957\n",
      "Epoch 3195/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6135 - accuracy: 0.6465 - val_loss: 0.6803 - val_accuracy: 0.5245\n",
      "Epoch 3196/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6129 - accuracy: 0.6482 - val_loss: 0.6430 - val_accuracy: 0.5753\n",
      "Epoch 3197/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6118 - accuracy: 0.6487 - val_loss: 0.6666 - val_accuracy: 0.5429\n",
      "Epoch 3198/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6111 - accuracy: 0.6505 - val_loss: 0.6518 - val_accuracy: 0.5674\n",
      "Epoch 3199/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6108 - accuracy: 0.6501 - val_loss: 0.6554 - val_accuracy: 0.5627\n",
      "Epoch 3200/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6107 - accuracy: 0.6504 - val_loss: 0.6630 - val_accuracy: 0.5475\n",
      "Epoch 3201/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6108 - accuracy: 0.6507 - val_loss: 0.6484 - val_accuracy: 0.5711\n",
      "Epoch 3202/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6111 - accuracy: 0.6492 - val_loss: 0.6707 - val_accuracy: 0.5345\n",
      "Epoch 3203/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6115 - accuracy: 0.6497 - val_loss: 0.6390 - val_accuracy: 0.5839\n",
      "Epoch 3204/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6121 - accuracy: 0.6476 - val_loss: 0.6826 - val_accuracy: 0.5221\n",
      "Epoch 3205/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6131 - accuracy: 0.6483 - val_loss: 0.6338 - val_accuracy: 0.5939\n",
      "Epoch 3206/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6133 - accuracy: 0.6461 - val_loss: 0.6872 - val_accuracy: 0.5161\n",
      "Epoch 3207/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6142 - accuracy: 0.6464 - val_loss: 0.6324 - val_accuracy: 0.5954\n",
      "Epoch 3208/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6134 - accuracy: 0.6458 - val_loss: 0.6825 - val_accuracy: 0.5217\n",
      "Epoch 3209/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6130 - accuracy: 0.6484 - val_loss: 0.6415 - val_accuracy: 0.5778\n",
      "Epoch 3210/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6118 - accuracy: 0.6486 - val_loss: 0.6671 - val_accuracy: 0.5400\n",
      "Epoch 3211/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6113 - accuracy: 0.6494 - val_loss: 0.6498 - val_accuracy: 0.5696\n",
      "Epoch 3212/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6108 - accuracy: 0.6502 - val_loss: 0.6596 - val_accuracy: 0.5533\n",
      "Epoch 3213/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6107 - accuracy: 0.6505 - val_loss: 0.6608 - val_accuracy: 0.5530\n",
      "Epoch 3214/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6106 - accuracy: 0.6507 - val_loss: 0.6475 - val_accuracy: 0.5725\n",
      "Epoch 3215/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6109 - accuracy: 0.6501 - val_loss: 0.6702 - val_accuracy: 0.5365\n",
      "Epoch 3216/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6114 - accuracy: 0.6498 - val_loss: 0.6401 - val_accuracy: 0.5800\n",
      "Epoch 3217/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6121 - accuracy: 0.6479 - val_loss: 0.6842 - val_accuracy: 0.5214\n",
      "Epoch 3218/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6135 - accuracy: 0.6478 - val_loss: 0.6300 - val_accuracy: 0.6012\n",
      "Epoch 3219/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6140 - accuracy: 0.6447 - val_loss: 0.6927 - val_accuracy: 0.5117\n",
      "Epoch 3220/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6150 - accuracy: 0.6458 - val_loss: 0.6341 - val_accuracy: 0.5926\n",
      "Epoch 3221/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6133 - accuracy: 0.6461 - val_loss: 0.6763 - val_accuracy: 0.5281\n",
      "Epoch 3222/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6125 - accuracy: 0.6495 - val_loss: 0.6447 - val_accuracy: 0.5747\n",
      "Epoch 3223/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6112 - accuracy: 0.6491 - val_loss: 0.6605 - val_accuracy: 0.5532\n",
      "Epoch 3224/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6109 - accuracy: 0.6506 - val_loss: 0.6628 - val_accuracy: 0.5480\n",
      "Epoch 3225/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6107 - accuracy: 0.6509 - val_loss: 0.6434 - val_accuracy: 0.5776\n",
      "Epoch 3226/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6115 - accuracy: 0.6491 - val_loss: 0.6793 - val_accuracy: 0.5237\n",
      "Epoch 3227/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6125 - accuracy: 0.6486 - val_loss: 0.6335 - val_accuracy: 0.5930\n",
      "Epoch 3228/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6140 - accuracy: 0.6457 - val_loss: 0.6956 - val_accuracy: 0.5077\n",
      "Epoch 3229/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6160 - accuracy: 0.6440 - val_loss: 0.6263 - val_accuracy: 0.6083\n",
      "Epoch 3230/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6148 - accuracy: 0.6445 - val_loss: 0.6845 - val_accuracy: 0.5183\n",
      "Epoch 3231/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6134 - accuracy: 0.6466 - val_loss: 0.6474 - val_accuracy: 0.5680\n",
      "Epoch 3232/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6114 - accuracy: 0.6489 - val_loss: 0.6529 - val_accuracy: 0.5652\n",
      "Epoch 3233/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6109 - accuracy: 0.6498 - val_loss: 0.6692 - val_accuracy: 0.5360\n",
      "Epoch 3234/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6116 - accuracy: 0.6500 - val_loss: 0.6357 - val_accuracy: 0.5891\n",
      "Epoch 3235/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6132 - accuracy: 0.6458 - val_loss: 0.6961 - val_accuracy: 0.5038\n",
      "Epoch 3236/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6157 - accuracy: 0.6440 - val_loss: 0.6269 - val_accuracy: 0.6067\n",
      "Epoch 3237/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6152 - accuracy: 0.6433 - val_loss: 0.6904 - val_accuracy: 0.5124\n",
      "Epoch 3238/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6147 - accuracy: 0.6459 - val_loss: 0.6384 - val_accuracy: 0.5813\n",
      "Epoch 3239/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6121 - accuracy: 0.6477 - val_loss: 0.6584 - val_accuracy: 0.5561\n",
      "Epoch 3240/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6107 - accuracy: 0.6503 - val_loss: 0.6658 - val_accuracy: 0.5427\n",
      "Epoch 3241/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6109 - accuracy: 0.6510 - val_loss: 0.6383 - val_accuracy: 0.5828\n",
      "Epoch 3242/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6124 - accuracy: 0.6477 - val_loss: 0.6900 - val_accuracy: 0.5122\n",
      "Epoch 3243/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6146 - accuracy: 0.6451 - val_loss: 0.6287 - val_accuracy: 0.6018\n",
      "Epoch 3244/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6142 - accuracy: 0.6451 - val_loss: 0.6871 - val_accuracy: 0.5137\n",
      "Epoch 3245/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6139 - accuracy: 0.6464 - val_loss: 0.6396 - val_accuracy: 0.5804\n",
      "Epoch 3246/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6119 - accuracy: 0.6483 - val_loss: 0.6619 - val_accuracy: 0.5502\n",
      "Epoch 3247/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6108 - accuracy: 0.6502 - val_loss: 0.6603 - val_accuracy: 0.5543\n",
      "Epoch 3248/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6106 - accuracy: 0.6508 - val_loss: 0.6420 - val_accuracy: 0.5771\n",
      "Epoch 3249/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6115 - accuracy: 0.6494 - val_loss: 0.6840 - val_accuracy: 0.5186\n",
      "Epoch 3250/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6131 - accuracy: 0.6477 - val_loss: 0.6310 - val_accuracy: 0.5974\n",
      "Epoch 3251/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6138 - accuracy: 0.6449 - val_loss: 0.6893 - val_accuracy: 0.5111\n",
      "Epoch 3252/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6144 - accuracy: 0.6455 - val_loss: 0.6351 - val_accuracy: 0.5901\n",
      "Epoch 3253/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6126 - accuracy: 0.6471 - val_loss: 0.6699 - val_accuracy: 0.5349\n",
      "Epoch 3254/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6113 - accuracy: 0.6503 - val_loss: 0.6548 - val_accuracy: 0.5623\n",
      "Epoch 3255/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6105 - accuracy: 0.6502 - val_loss: 0.6458 - val_accuracy: 0.5727\n",
      "Epoch 3256/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6109 - accuracy: 0.6501 - val_loss: 0.6773 - val_accuracy: 0.5267\n",
      "Epoch 3257/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6121 - accuracy: 0.6490 - val_loss: 0.6329 - val_accuracy: 0.5955\n",
      "Epoch 3258/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6133 - accuracy: 0.6454 - val_loss: 0.6930 - val_accuracy: 0.5088\n",
      "Epoch 3259/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6150 - accuracy: 0.6450 - val_loss: 0.6320 - val_accuracy: 0.5948\n",
      "Epoch 3260/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6134 - accuracy: 0.6455 - val_loss: 0.6770 - val_accuracy: 0.5283\n",
      "Epoch 3261/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6120 - accuracy: 0.6493 - val_loss: 0.6486 - val_accuracy: 0.5707\n",
      "Epoch 3262/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6106 - accuracy: 0.6496 - val_loss: 0.6498 - val_accuracy: 0.5674\n",
      "Epoch 3263/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6105 - accuracy: 0.6501 - val_loss: 0.6734 - val_accuracy: 0.5320\n",
      "Epoch 3264/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6114 - accuracy: 0.6505 - val_loss: 0.6360 - val_accuracy: 0.5895\n",
      "Epoch 3265/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6126 - accuracy: 0.6475 - val_loss: 0.6891 - val_accuracy: 0.5119\n",
      "Epoch 3266/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6142 - accuracy: 0.6462 - val_loss: 0.6314 - val_accuracy: 0.5963\n",
      "Epoch 3267/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6134 - accuracy: 0.6449 - val_loss: 0.6812 - val_accuracy: 0.5221\n",
      "Epoch 3268/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6125 - accuracy: 0.6482 - val_loss: 0.6457 - val_accuracy: 0.5723\n",
      "Epoch 3269/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6109 - accuracy: 0.6490 - val_loss: 0.6557 - val_accuracy: 0.5601\n",
      "Epoch 3270/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6103 - accuracy: 0.6506 - val_loss: 0.6654 - val_accuracy: 0.5433\n",
      "Epoch 3271/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6107 - accuracy: 0.6508 - val_loss: 0.6401 - val_accuracy: 0.5809\n",
      "Epoch 3272/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6117 - accuracy: 0.6487 - val_loss: 0.6852 - val_accuracy: 0.5172\n",
      "Epoch 3273/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6131 - accuracy: 0.6474 - val_loss: 0.6332 - val_accuracy: 0.5928\n",
      "Epoch 3274/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6131 - accuracy: 0.6455 - val_loss: 0.6831 - val_accuracy: 0.5195\n",
      "Epoch 3275/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6129 - accuracy: 0.6481 - val_loss: 0.6404 - val_accuracy: 0.5789\n",
      "Epoch 3276/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6114 - accuracy: 0.6486 - val_loss: 0.6623 - val_accuracy: 0.5502\n",
      "Epoch 3277/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6104 - accuracy: 0.6509 - val_loss: 0.6594 - val_accuracy: 0.5559\n",
      "Epoch 3278/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6102 - accuracy: 0.6507 - val_loss: 0.6464 - val_accuracy: 0.5723\n",
      "Epoch 3279/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6108 - accuracy: 0.6501 - val_loss: 0.6766 - val_accuracy: 0.5283\n",
      "Epoch 3280/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6118 - accuracy: 0.6497 - val_loss: 0.6337 - val_accuracy: 0.5934\n",
      "Epoch 3281/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6126 - accuracy: 0.6463 - val_loss: 0.6880 - val_accuracy: 0.5141\n",
      "Epoch 3282/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6136 - accuracy: 0.6464 - val_loss: 0.6366 - val_accuracy: 0.5866\n",
      "Epoch 3283/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6124 - accuracy: 0.6470 - val_loss: 0.6714 - val_accuracy: 0.5331\n",
      "Epoch 3284/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6111 - accuracy: 0.6510 - val_loss: 0.6495 - val_accuracy: 0.5692\n",
      "Epoch 3285/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6103 - accuracy: 0.6502 - val_loss: 0.6520 - val_accuracy: 0.5661\n",
      "Epoch 3286/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6102 - accuracy: 0.6504 - val_loss: 0.6710 - val_accuracy: 0.5376\n",
      "Epoch 3287/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6109 - accuracy: 0.6507 - val_loss: 0.6395 - val_accuracy: 0.5824\n",
      "Epoch 3288/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6116 - accuracy: 0.6483 - val_loss: 0.6819 - val_accuracy: 0.5232\n",
      "Epoch 3289/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6126 - accuracy: 0.6485 - val_loss: 0.6346 - val_accuracy: 0.5924\n",
      "Epoch 3290/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6124 - accuracy: 0.6460 - val_loss: 0.6806 - val_accuracy: 0.5236\n",
      "Epoch 3291/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6122 - accuracy: 0.6488 - val_loss: 0.6433 - val_accuracy: 0.5769\n",
      "Epoch 3292/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6110 - accuracy: 0.6494 - val_loss: 0.6628 - val_accuracy: 0.5497\n",
      "Epoch 3293/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6103 - accuracy: 0.6507 - val_loss: 0.6570 - val_accuracy: 0.5577\n",
      "Epoch 3294/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6101 - accuracy: 0.6509 - val_loss: 0.6485 - val_accuracy: 0.5703\n",
      "Epoch 3295/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6104 - accuracy: 0.6503 - val_loss: 0.6739 - val_accuracy: 0.5322\n",
      "Epoch 3296/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6111 - accuracy: 0.6506 - val_loss: 0.6389 - val_accuracy: 0.5839\n",
      "Epoch 3297/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6116 - accuracy: 0.6482 - val_loss: 0.6804 - val_accuracy: 0.5243\n",
      "Epoch 3298/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6122 - accuracy: 0.6492 - val_loss: 0.6358 - val_accuracy: 0.5890\n",
      "Epoch 3299/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6121 - accuracy: 0.6470 - val_loss: 0.6799 - val_accuracy: 0.5248\n",
      "Epoch 3300/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6120 - accuracy: 0.6501 - val_loss: 0.6423 - val_accuracy: 0.5778\n",
      "Epoch 3301/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6110 - accuracy: 0.6489 - val_loss: 0.6652 - val_accuracy: 0.5442\n",
      "Epoch 3302/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6103 - accuracy: 0.6515 - val_loss: 0.6546 - val_accuracy: 0.5627\n",
      "Epoch 3303/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6100 - accuracy: 0.6517 - val_loss: 0.6530 - val_accuracy: 0.5638\n",
      "Epoch 3304/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6100 - accuracy: 0.6511 - val_loss: 0.6678 - val_accuracy: 0.5426\n",
      "Epoch 3305/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6104 - accuracy: 0.6516 - val_loss: 0.6433 - val_accuracy: 0.5769\n",
      "Epoch 3306/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6108 - accuracy: 0.6496 - val_loss: 0.6758 - val_accuracy: 0.5290\n",
      "Epoch 3307/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6115 - accuracy: 0.6504 - val_loss: 0.6366 - val_accuracy: 0.5882\n",
      "Epoch 3308/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6118 - accuracy: 0.6477 - val_loss: 0.6825 - val_accuracy: 0.5208\n",
      "Epoch 3309/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6123 - accuracy: 0.6485 - val_loss: 0.6392 - val_accuracy: 0.5813\n",
      "Epoch 3310/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6115 - accuracy: 0.6482 - val_loss: 0.6724 - val_accuracy: 0.5338\n",
      "Epoch 3311/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6109 - accuracy: 0.6509 - val_loss: 0.6460 - val_accuracy: 0.5736\n",
      "Epoch 3312/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6104 - accuracy: 0.6501 - val_loss: 0.6630 - val_accuracy: 0.5499\n",
      "Epoch 3313/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6100 - accuracy: 0.6521 - val_loss: 0.6566 - val_accuracy: 0.5614\n",
      "Epoch 3314/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6099 - accuracy: 0.6508 - val_loss: 0.6537 - val_accuracy: 0.5627\n",
      "Epoch 3315/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6099 - accuracy: 0.6512 - val_loss: 0.6626 - val_accuracy: 0.5522\n",
      "Epoch 3316/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6100 - accuracy: 0.6510 - val_loss: 0.6480 - val_accuracy: 0.5711\n",
      "Epoch 3317/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6102 - accuracy: 0.6507 - val_loss: 0.6704 - val_accuracy: 0.5378\n",
      "Epoch 3318/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6105 - accuracy: 0.6510 - val_loss: 0.6432 - val_accuracy: 0.5778\n",
      "Epoch 3319/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6107 - accuracy: 0.6500 - val_loss: 0.6766 - val_accuracy: 0.5289\n",
      "Epoch 3320/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6113 - accuracy: 0.6508 - val_loss: 0.6367 - val_accuracy: 0.5879\n",
      "Epoch 3321/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6117 - accuracy: 0.6474 - val_loss: 0.6844 - val_accuracy: 0.5206\n",
      "Epoch 3322/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6126 - accuracy: 0.6483 - val_loss: 0.6353 - val_accuracy: 0.5890\n",
      "Epoch 3323/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6122 - accuracy: 0.6477 - val_loss: 0.6804 - val_accuracy: 0.5254\n",
      "Epoch 3324/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6119 - accuracy: 0.6493 - val_loss: 0.6404 - val_accuracy: 0.5807\n",
      "Epoch 3325/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6110 - accuracy: 0.6490 - val_loss: 0.6697 - val_accuracy: 0.5402\n",
      "Epoch 3326/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6105 - accuracy: 0.6511 - val_loss: 0.6501 - val_accuracy: 0.5691\n",
      "Epoch 3327/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6100 - accuracy: 0.6507 - val_loss: 0.6591 - val_accuracy: 0.5566\n",
      "Epoch 3328/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6098 - accuracy: 0.6515 - val_loss: 0.6592 - val_accuracy: 0.5568\n",
      "Epoch 3329/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6098 - accuracy: 0.6515 - val_loss: 0.6513 - val_accuracy: 0.5674\n",
      "Epoch 3330/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6099 - accuracy: 0.6511 - val_loss: 0.6669 - val_accuracy: 0.5435\n",
      "Epoch 3331/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6102 - accuracy: 0.6517 - val_loss: 0.6441 - val_accuracy: 0.5764\n",
      "Epoch 3332/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6105 - accuracy: 0.6499 - val_loss: 0.6745 - val_accuracy: 0.5323\n",
      "Epoch 3333/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6110 - accuracy: 0.6515 - val_loss: 0.6385 - val_accuracy: 0.5835\n",
      "Epoch 3334/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6113 - accuracy: 0.6482 - val_loss: 0.6825 - val_accuracy: 0.5223\n",
      "Epoch 3335/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6121 - accuracy: 0.6491 - val_loss: 0.6356 - val_accuracy: 0.5895\n",
      "Epoch 3336/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6120 - accuracy: 0.6474 - val_loss: 0.6831 - val_accuracy: 0.5221\n",
      "Epoch 3337/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6124 - accuracy: 0.6489 - val_loss: 0.6357 - val_accuracy: 0.5899\n",
      "Epoch 3338/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6117 - accuracy: 0.6478 - val_loss: 0.6794 - val_accuracy: 0.5265\n",
      "Epoch 3339/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6116 - accuracy: 0.6499 - val_loss: 0.6421 - val_accuracy: 0.5782\n",
      "Epoch 3340/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6108 - accuracy: 0.6490 - val_loss: 0.6683 - val_accuracy: 0.5409\n",
      "Epoch 3341/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6103 - accuracy: 0.6518 - val_loss: 0.6494 - val_accuracy: 0.5694\n",
      "Epoch 3342/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6099 - accuracy: 0.6509 - val_loss: 0.6591 - val_accuracy: 0.5570\n",
      "Epoch 3343/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6097 - accuracy: 0.6513 - val_loss: 0.6600 - val_accuracy: 0.5544\n",
      "Epoch 3344/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6097 - accuracy: 0.6519 - val_loss: 0.6510 - val_accuracy: 0.5663\n",
      "Epoch 3345/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6098 - accuracy: 0.6513 - val_loss: 0.6651 - val_accuracy: 0.5457\n",
      "Epoch 3346/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6100 - accuracy: 0.6517 - val_loss: 0.6455 - val_accuracy: 0.5740\n",
      "Epoch 3347/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6102 - accuracy: 0.6503 - val_loss: 0.6736 - val_accuracy: 0.5347\n",
      "Epoch 3348/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6107 - accuracy: 0.6514 - val_loss: 0.6393 - val_accuracy: 0.5828\n",
      "Epoch 3349/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6110 - accuracy: 0.6482 - val_loss: 0.6804 - val_accuracy: 0.5258\n",
      "Epoch 3350/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6117 - accuracy: 0.6493 - val_loss: 0.6356 - val_accuracy: 0.5902\n",
      "Epoch 3351/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6120 - accuracy: 0.6473 - val_loss: 0.6871 - val_accuracy: 0.5170\n",
      "Epoch 3352/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6130 - accuracy: 0.6474 - val_loss: 0.6326 - val_accuracy: 0.5963\n",
      "Epoch 3353/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6124 - accuracy: 0.6463 - val_loss: 0.6836 - val_accuracy: 0.5199\n",
      "Epoch 3354/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6122 - accuracy: 0.6487 - val_loss: 0.6396 - val_accuracy: 0.5815\n",
      "Epoch 3355/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6112 - accuracy: 0.6486 - val_loss: 0.6709 - val_accuracy: 0.5360\n",
      "Epoch 3356/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6106 - accuracy: 0.6506 - val_loss: 0.6479 - val_accuracy: 0.5705\n",
      "Epoch 3357/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6100 - accuracy: 0.6503 - val_loss: 0.6614 - val_accuracy: 0.5543\n",
      "Epoch 3358/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6097 - accuracy: 0.6518 - val_loss: 0.6596 - val_accuracy: 0.5543\n",
      "Epoch 3359/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6097 - accuracy: 0.6518 - val_loss: 0.6486 - val_accuracy: 0.5700\n",
      "Epoch 3360/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6098 - accuracy: 0.6508 - val_loss: 0.6687 - val_accuracy: 0.5413\n",
      "Epoch 3361/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6102 - accuracy: 0.6517 - val_loss: 0.6436 - val_accuracy: 0.5754\n",
      "Epoch 3362/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6106 - accuracy: 0.6502 - val_loss: 0.6773 - val_accuracy: 0.5285\n",
      "Epoch 3363/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6112 - accuracy: 0.6507 - val_loss: 0.6351 - val_accuracy: 0.5915\n",
      "Epoch 3364/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6116 - accuracy: 0.6481 - val_loss: 0.6858 - val_accuracy: 0.5175\n",
      "Epoch 3365/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6126 - accuracy: 0.6483 - val_loss: 0.6352 - val_accuracy: 0.5899\n",
      "Epoch 3366/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6121 - accuracy: 0.6475 - val_loss: 0.6815 - val_accuracy: 0.5234\n",
      "Epoch 3367/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6120 - accuracy: 0.6497 - val_loss: 0.6379 - val_accuracy: 0.5871\n",
      "Epoch 3368/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6110 - accuracy: 0.6483 - val_loss: 0.6729 - val_accuracy: 0.5349\n",
      "Epoch 3369/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6104 - accuracy: 0.6519 - val_loss: 0.6487 - val_accuracy: 0.5711\n",
      "Epoch 3370/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6099 - accuracy: 0.6504 - val_loss: 0.6599 - val_accuracy: 0.5555\n",
      "Epoch 3371/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6096 - accuracy: 0.6519 - val_loss: 0.6562 - val_accuracy: 0.5596\n",
      "Epoch 3372/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6095 - accuracy: 0.6519 - val_loss: 0.6532 - val_accuracy: 0.5649\n",
      "Epoch 3373/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6096 - accuracy: 0.6510 - val_loss: 0.6672 - val_accuracy: 0.5433\n",
      "Epoch 3374/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6098 - accuracy: 0.6519 - val_loss: 0.6433 - val_accuracy: 0.5778\n",
      "Epoch 3375/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6102 - accuracy: 0.6501 - val_loss: 0.6764 - val_accuracy: 0.5312\n",
      "Epoch 3376/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6110 - accuracy: 0.6510 - val_loss: 0.6359 - val_accuracy: 0.5897\n",
      "Epoch 3377/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6116 - accuracy: 0.6481 - val_loss: 0.6886 - val_accuracy: 0.5155\n",
      "Epoch 3378/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6131 - accuracy: 0.6472 - val_loss: 0.6325 - val_accuracy: 0.5970\n",
      "Epoch 3379/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6124 - accuracy: 0.6466 - val_loss: 0.6835 - val_accuracy: 0.5208\n",
      "Epoch 3380/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6121 - accuracy: 0.6493 - val_loss: 0.6398 - val_accuracy: 0.5840\n",
      "Epoch 3381/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6108 - accuracy: 0.6491 - val_loss: 0.6672 - val_accuracy: 0.5426\n",
      "Epoch 3382/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6101 - accuracy: 0.6502 - val_loss: 0.6539 - val_accuracy: 0.5628\n",
      "Epoch 3383/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6096 - accuracy: 0.6506 - val_loss: 0.6547 - val_accuracy: 0.5619\n",
      "Epoch 3384/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6097 - accuracy: 0.6515 - val_loss: 0.6673 - val_accuracy: 0.5413\n",
      "Epoch 3385/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6099 - accuracy: 0.6514 - val_loss: 0.6396 - val_accuracy: 0.5837\n",
      "Epoch 3386/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6108 - accuracy: 0.6486 - val_loss: 0.6828 - val_accuracy: 0.5225\n",
      "Epoch 3387/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6119 - accuracy: 0.6491 - val_loss: 0.6338 - val_accuracy: 0.5968\n",
      "Epoch 3388/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6124 - accuracy: 0.6466 - val_loss: 0.6894 - val_accuracy: 0.5157\n",
      "Epoch 3389/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6135 - accuracy: 0.6467 - val_loss: 0.6332 - val_accuracy: 0.5939\n",
      "Epoch 3390/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6123 - accuracy: 0.6465 - val_loss: 0.6776 - val_accuracy: 0.5305\n",
      "Epoch 3391/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6116 - accuracy: 0.6506 - val_loss: 0.6473 - val_accuracy: 0.5733\n",
      "Epoch 3392/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6102 - accuracy: 0.6503 - val_loss: 0.6559 - val_accuracy: 0.5541\n",
      "Epoch 3393/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6103 - accuracy: 0.6489 - val_loss: 0.6681 - val_accuracy: 0.5415\n",
      "Epoch 3394/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6101 - accuracy: 0.6508 - val_loss: 0.6400 - val_accuracy: 0.5881\n",
      "Epoch 3395/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6118 - accuracy: 0.6490 - val_loss: 0.6899 - val_accuracy: 0.5095\n",
      "Epoch 3396/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6133 - accuracy: 0.6470 - val_loss: 0.6264 - val_accuracy: 0.6028\n",
      "Epoch 3397/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6147 - accuracy: 0.6435 - val_loss: 0.6973 - val_accuracy: 0.5066\n",
      "Epoch 3398/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6157 - accuracy: 0.6445 - val_loss: 0.6320 - val_accuracy: 0.5968\n",
      "Epoch 3399/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6134 - accuracy: 0.6472 - val_loss: 0.6718 - val_accuracy: 0.5342\n",
      "Epoch 3400/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6111 - accuracy: 0.6491 - val_loss: 0.6613 - val_accuracy: 0.5464\n",
      "Epoch 3401/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6109 - accuracy: 0.6489 - val_loss: 0.6430 - val_accuracy: 0.5815\n",
      "Epoch 3402/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6109 - accuracy: 0.6498 - val_loss: 0.6790 - val_accuracy: 0.5280\n",
      "Epoch 3403/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6122 - accuracy: 0.6489 - val_loss: 0.6331 - val_accuracy: 0.5930\n",
      "Epoch 3404/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6122 - accuracy: 0.6463 - val_loss: 0.6863 - val_accuracy: 0.5157\n",
      "Epoch 3405/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6127 - accuracy: 0.6472 - val_loss: 0.6388 - val_accuracy: 0.5831\n",
      "Epoch 3406/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6112 - accuracy: 0.6486 - val_loss: 0.6696 - val_accuracy: 0.5391\n",
      "Epoch 3407/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6101 - accuracy: 0.6521 - val_loss: 0.6525 - val_accuracy: 0.5639\n",
      "Epoch 3408/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6095 - accuracy: 0.6520 - val_loss: 0.6486 - val_accuracy: 0.5703\n",
      "Epoch 3409/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6096 - accuracy: 0.6509 - val_loss: 0.6706 - val_accuracy: 0.5371\n",
      "Epoch 3410/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6102 - accuracy: 0.6524 - val_loss: 0.6410 - val_accuracy: 0.5806\n",
      "Epoch 3411/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6108 - accuracy: 0.6488 - val_loss: 0.6814 - val_accuracy: 0.5227\n",
      "Epoch 3412/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6117 - accuracy: 0.6499 - val_loss: 0.6344 - val_accuracy: 0.5932\n",
      "Epoch 3413/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6116 - accuracy: 0.6466 - val_loss: 0.6808 - val_accuracy: 0.5241\n",
      "Epoch 3414/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6115 - accuracy: 0.6492 - val_loss: 0.6413 - val_accuracy: 0.5776\n",
      "Epoch 3415/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6104 - accuracy: 0.6493 - val_loss: 0.6652 - val_accuracy: 0.5453\n",
      "Epoch 3416/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6098 - accuracy: 0.6510 - val_loss: 0.6561 - val_accuracy: 0.5588\n",
      "Epoch 3417/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6093 - accuracy: 0.6523 - val_loss: 0.6502 - val_accuracy: 0.5674\n",
      "Epoch 3418/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6097 - accuracy: 0.6511 - val_loss: 0.6732 - val_accuracy: 0.5338\n",
      "Epoch 3419/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6102 - accuracy: 0.6513 - val_loss: 0.6367 - val_accuracy: 0.5901\n",
      "Epoch 3420/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6114 - accuracy: 0.6474 - val_loss: 0.6876 - val_accuracy: 0.5144\n",
      "Epoch 3421/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6126 - accuracy: 0.6479 - val_loss: 0.6311 - val_accuracy: 0.6016\n",
      "Epoch 3422/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6127 - accuracy: 0.6466 - val_loss: 0.6874 - val_accuracy: 0.5185\n",
      "Epoch 3423/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6131 - accuracy: 0.6472 - val_loss: 0.6393 - val_accuracy: 0.5851\n",
      "Epoch 3424/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6114 - accuracy: 0.6466 - val_loss: 0.6662 - val_accuracy: 0.5460\n",
      "Epoch 3425/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6100 - accuracy: 0.6525 - val_loss: 0.6600 - val_accuracy: 0.5544\n",
      "Epoch 3426/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6097 - accuracy: 0.6526 - val_loss: 0.6429 - val_accuracy: 0.5804\n",
      "Epoch 3427/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6105 - accuracy: 0.6497 - val_loss: 0.6783 - val_accuracy: 0.5274\n",
      "Epoch 3428/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6111 - accuracy: 0.6505 - val_loss: 0.6386 - val_accuracy: 0.5851\n",
      "Epoch 3429/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6119 - accuracy: 0.6471 - val_loss: 0.6864 - val_accuracy: 0.5133\n",
      "Epoch 3430/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6123 - accuracy: 0.6482 - val_loss: 0.6317 - val_accuracy: 0.5999\n",
      "Epoch 3431/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6119 - accuracy: 0.6464 - val_loss: 0.6769 - val_accuracy: 0.5294\n",
      "Epoch 3432/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6109 - accuracy: 0.6510 - val_loss: 0.6465 - val_accuracy: 0.5734\n",
      "Epoch 3433/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6100 - accuracy: 0.6504 - val_loss: 0.6593 - val_accuracy: 0.5566\n",
      "Epoch 3434/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6092 - accuracy: 0.6521 - val_loss: 0.6627 - val_accuracy: 0.5497\n",
      "Epoch 3435/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6095 - accuracy: 0.6521 - val_loss: 0.6443 - val_accuracy: 0.5762\n",
      "Epoch 3436/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6100 - accuracy: 0.6504 - val_loss: 0.6802 - val_accuracy: 0.5270\n",
      "Epoch 3437/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6111 - accuracy: 0.6500 - val_loss: 0.6349 - val_accuracy: 0.5923\n",
      "Epoch 3438/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6116 - accuracy: 0.6469 - val_loss: 0.6857 - val_accuracy: 0.5174\n",
      "Epoch 3439/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6124 - accuracy: 0.6486 - val_loss: 0.6336 - val_accuracy: 0.5961\n",
      "Epoch 3440/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6115 - accuracy: 0.6475 - val_loss: 0.6777 - val_accuracy: 0.5278\n",
      "Epoch 3441/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6108 - accuracy: 0.6510 - val_loss: 0.6471 - val_accuracy: 0.5705\n",
      "Epoch 3442/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6098 - accuracy: 0.6497 - val_loss: 0.6589 - val_accuracy: 0.5583\n",
      "Epoch 3443/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6091 - accuracy: 0.6524 - val_loss: 0.6625 - val_accuracy: 0.5504\n",
      "Epoch 3444/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6094 - accuracy: 0.6528 - val_loss: 0.6429 - val_accuracy: 0.5786\n",
      "Epoch 3445/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6099 - accuracy: 0.6501 - val_loss: 0.6791 - val_accuracy: 0.5263\n",
      "Epoch 3446/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6108 - accuracy: 0.6501 - val_loss: 0.6373 - val_accuracy: 0.5890\n",
      "Epoch 3447/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6112 - accuracy: 0.6477 - val_loss: 0.6828 - val_accuracy: 0.5212\n",
      "Epoch 3448/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6117 - accuracy: 0.6492 - val_loss: 0.6350 - val_accuracy: 0.5913\n",
      "Epoch 3449/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6109 - accuracy: 0.6480 - val_loss: 0.6742 - val_accuracy: 0.5343\n",
      "Epoch 3450/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6102 - accuracy: 0.6525 - val_loss: 0.6490 - val_accuracy: 0.5711\n",
      "Epoch 3451/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6094 - accuracy: 0.6510 - val_loss: 0.6577 - val_accuracy: 0.5577\n",
      "Epoch 3452/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6090 - accuracy: 0.6524 - val_loss: 0.6623 - val_accuracy: 0.5515\n",
      "Epoch 3453/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6092 - accuracy: 0.6525 - val_loss: 0.6456 - val_accuracy: 0.5740\n",
      "Epoch 3454/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6096 - accuracy: 0.6509 - val_loss: 0.6778 - val_accuracy: 0.5287\n",
      "Epoch 3455/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6106 - accuracy: 0.6511 - val_loss: 0.6345 - val_accuracy: 0.5913\n",
      "Epoch 3456/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6112 - accuracy: 0.6466 - val_loss: 0.6854 - val_accuracy: 0.5190\n",
      "Epoch 3457/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6120 - accuracy: 0.6491 - val_loss: 0.6349 - val_accuracy: 0.5934\n",
      "Epoch 3458/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6113 - accuracy: 0.6482 - val_loss: 0.6786 - val_accuracy: 0.5263\n",
      "Epoch 3459/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6107 - accuracy: 0.6511 - val_loss: 0.6451 - val_accuracy: 0.5758\n",
      "Epoch 3460/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6097 - accuracy: 0.6499 - val_loss: 0.6618 - val_accuracy: 0.5533\n",
      "Epoch 3461/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6091 - accuracy: 0.6532 - val_loss: 0.6573 - val_accuracy: 0.5594\n",
      "Epoch 3462/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6090 - accuracy: 0.6528 - val_loss: 0.6489 - val_accuracy: 0.5698\n",
      "Epoch 3463/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6092 - accuracy: 0.6506 - val_loss: 0.6726 - val_accuracy: 0.5371\n",
      "Epoch 3464/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6098 - accuracy: 0.6523 - val_loss: 0.6409 - val_accuracy: 0.5813\n",
      "Epoch 3465/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6102 - accuracy: 0.6495 - val_loss: 0.6796 - val_accuracy: 0.5267\n",
      "Epoch 3466/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6110 - accuracy: 0.6507 - val_loss: 0.6337 - val_accuracy: 0.5941\n",
      "Epoch 3467/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6112 - accuracy: 0.6478 - val_loss: 0.6853 - val_accuracy: 0.5190\n",
      "Epoch 3468/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6118 - accuracy: 0.6489 - val_loss: 0.6384 - val_accuracy: 0.5875\n",
      "Epoch 3469/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6107 - accuracy: 0.6483 - val_loss: 0.6729 - val_accuracy: 0.5354\n",
      "Epoch 3470/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6098 - accuracy: 0.6518 - val_loss: 0.6480 - val_accuracy: 0.5709\n",
      "Epoch 3471/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6092 - accuracy: 0.6506 - val_loss: 0.6578 - val_accuracy: 0.5583\n",
      "Epoch 3472/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6089 - accuracy: 0.6523 - val_loss: 0.6621 - val_accuracy: 0.5522\n",
      "Epoch 3473/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6089 - accuracy: 0.6526 - val_loss: 0.6487 - val_accuracy: 0.5709\n",
      "Epoch 3474/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6092 - accuracy: 0.6513 - val_loss: 0.6715 - val_accuracy: 0.5374\n",
      "Epoch 3475/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6098 - accuracy: 0.6514 - val_loss: 0.6386 - val_accuracy: 0.5864\n",
      "Epoch 3476/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6102 - accuracy: 0.6490 - val_loss: 0.6832 - val_accuracy: 0.5227\n",
      "Epoch 3477/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6112 - accuracy: 0.6495 - val_loss: 0.6362 - val_accuracy: 0.5906\n",
      "Epoch 3478/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6113 - accuracy: 0.6473 - val_loss: 0.6824 - val_accuracy: 0.5217\n",
      "Epoch 3479/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6115 - accuracy: 0.6500 - val_loss: 0.6361 - val_accuracy: 0.5926\n",
      "Epoch 3480/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6106 - accuracy: 0.6487 - val_loss: 0.6740 - val_accuracy: 0.5347\n",
      "Epoch 3481/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6101 - accuracy: 0.6509 - val_loss: 0.6510 - val_accuracy: 0.5650\n",
      "Epoch 3482/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6093 - accuracy: 0.6509 - val_loss: 0.6568 - val_accuracy: 0.5616\n",
      "Epoch 3483/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6091 - accuracy: 0.6515 - val_loss: 0.6635 - val_accuracy: 0.5497\n",
      "Epoch 3484/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6091 - accuracy: 0.6526 - val_loss: 0.6427 - val_accuracy: 0.5793\n",
      "Epoch 3485/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6101 - accuracy: 0.6491 - val_loss: 0.6825 - val_accuracy: 0.5232\n",
      "Epoch 3486/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6113 - accuracy: 0.6498 - val_loss: 0.6331 - val_accuracy: 0.5992\n",
      "Epoch 3487/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6120 - accuracy: 0.6471 - val_loss: 0.6910 - val_accuracy: 0.5128\n",
      "Epoch 3488/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6132 - accuracy: 0.6468 - val_loss: 0.6331 - val_accuracy: 0.5959\n",
      "Epoch 3489/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6116 - accuracy: 0.6470 - val_loss: 0.6743 - val_accuracy: 0.5358\n",
      "Epoch 3490/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6109 - accuracy: 0.6519 - val_loss: 0.6513 - val_accuracy: 0.5676\n",
      "Epoch 3491/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6096 - accuracy: 0.6507 - val_loss: 0.6535 - val_accuracy: 0.5625\n",
      "Epoch 3492/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6099 - accuracy: 0.6491 - val_loss: 0.6740 - val_accuracy: 0.5331\n",
      "Epoch 3493/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6102 - accuracy: 0.6506 - val_loss: 0.6316 - val_accuracy: 0.6030\n",
      "Epoch 3494/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6125 - accuracy: 0.6469 - val_loss: 0.7009 - val_accuracy: 0.4998\n",
      "Epoch 3495/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6149 - accuracy: 0.6452 - val_loss: 0.6300 - val_accuracy: 0.6014\n",
      "Epoch 3496/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6140 - accuracy: 0.6444 - val_loss: 0.6814 - val_accuracy: 0.5239\n",
      "Epoch 3497/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6124 - accuracy: 0.6500 - val_loss: 0.6426 - val_accuracy: 0.5813\n",
      "Epoch 3498/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6110 - accuracy: 0.6493 - val_loss: 0.6592 - val_accuracy: 0.5566\n",
      "Epoch 3499/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6098 - accuracy: 0.6508 - val_loss: 0.6701 - val_accuracy: 0.5411\n",
      "Epoch 3500/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6100 - accuracy: 0.6505 - val_loss: 0.6405 - val_accuracy: 0.5842\n",
      "Epoch 3501/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6104 - accuracy: 0.6491 - val_loss: 0.6757 - val_accuracy: 0.5316\n",
      "Epoch 3502/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6107 - accuracy: 0.6515 - val_loss: 0.6406 - val_accuracy: 0.5824\n",
      "Epoch 3503/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6107 - accuracy: 0.6485 - val_loss: 0.6737 - val_accuracy: 0.5338\n",
      "Epoch 3504/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6104 - accuracy: 0.6500 - val_loss: 0.6452 - val_accuracy: 0.5765\n",
      "Epoch 3505/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6098 - accuracy: 0.6493 - val_loss: 0.6647 - val_accuracy: 0.5482\n",
      "Epoch 3506/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6093 - accuracy: 0.6525 - val_loss: 0.6580 - val_accuracy: 0.5552\n",
      "Epoch 3507/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6091 - accuracy: 0.6527 - val_loss: 0.6456 - val_accuracy: 0.5769\n",
      "Epoch 3508/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6094 - accuracy: 0.6509 - val_loss: 0.6711 - val_accuracy: 0.5382\n",
      "Epoch 3509/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6096 - accuracy: 0.6528 - val_loss: 0.6463 - val_accuracy: 0.5742\n",
      "Epoch 3510/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6102 - accuracy: 0.6502 - val_loss: 0.6756 - val_accuracy: 0.5283\n",
      "Epoch 3511/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6103 - accuracy: 0.6514 - val_loss: 0.6363 - val_accuracy: 0.5928\n",
      "Epoch 3512/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6104 - accuracy: 0.6482 - val_loss: 0.6768 - val_accuracy: 0.5334\n",
      "Epoch 3513/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6103 - accuracy: 0.6506 - val_loss: 0.6468 - val_accuracy: 0.5734\n",
      "Epoch 3514/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6097 - accuracy: 0.6504 - val_loss: 0.6661 - val_accuracy: 0.5444\n",
      "Epoch 3515/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6096 - accuracy: 0.6521 - val_loss: 0.6499 - val_accuracy: 0.5691\n",
      "Epoch 3516/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6089 - accuracy: 0.6510 - val_loss: 0.6586 - val_accuracy: 0.5579\n",
      "Epoch 3517/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6093 - accuracy: 0.6517 - val_loss: 0.6656 - val_accuracy: 0.5493\n",
      "Epoch 3518/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6088 - accuracy: 0.6527 - val_loss: 0.6436 - val_accuracy: 0.5813\n",
      "Epoch 3519/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6098 - accuracy: 0.6495 - val_loss: 0.6755 - val_accuracy: 0.5338\n",
      "Epoch 3520/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6101 - accuracy: 0.6510 - val_loss: 0.6374 - val_accuracy: 0.5902\n",
      "Epoch 3521/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6112 - accuracy: 0.6478 - val_loss: 0.6886 - val_accuracy: 0.5168\n",
      "Epoch 3522/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6128 - accuracy: 0.6480 - val_loss: 0.6323 - val_accuracy: 0.5972\n",
      "Epoch 3523/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6123 - accuracy: 0.6460 - val_loss: 0.6837 - val_accuracy: 0.5227\n",
      "Epoch 3524/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6117 - accuracy: 0.6489 - val_loss: 0.6461 - val_accuracy: 0.5749\n",
      "Epoch 3525/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6098 - accuracy: 0.6509 - val_loss: 0.6547 - val_accuracy: 0.5597\n",
      "Epoch 3526/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6101 - accuracy: 0.6488 - val_loss: 0.6679 - val_accuracy: 0.5444\n",
      "Epoch 3527/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6095 - accuracy: 0.6510 - val_loss: 0.6467 - val_accuracy: 0.5740\n",
      "Epoch 3528/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6111 - accuracy: 0.6491 - val_loss: 0.6832 - val_accuracy: 0.5206\n",
      "Epoch 3529/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6117 - accuracy: 0.6499 - val_loss: 0.6249 - val_accuracy: 0.6074\n",
      "Epoch 3530/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6132 - accuracy: 0.6463 - val_loss: 0.6954 - val_accuracy: 0.5097\n",
      "Epoch 3531/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6135 - accuracy: 0.6463 - val_loss: 0.6423 - val_accuracy: 0.5822\n",
      "Epoch 3532/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6117 - accuracy: 0.6480 - val_loss: 0.6662 - val_accuracy: 0.5475\n",
      "Epoch 3533/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6106 - accuracy: 0.6510 - val_loss: 0.6542 - val_accuracy: 0.5617\n",
      "Epoch 3534/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6102 - accuracy: 0.6500 - val_loss: 0.6460 - val_accuracy: 0.5745\n",
      "Epoch 3535/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6104 - accuracy: 0.6505 - val_loss: 0.6827 - val_accuracy: 0.5241\n",
      "Epoch 3536/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6108 - accuracy: 0.6496 - val_loss: 0.6361 - val_accuracy: 0.5915\n",
      "Epoch 3537/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6113 - accuracy: 0.6483 - val_loss: 0.6817 - val_accuracy: 0.5236\n",
      "Epoch 3538/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6112 - accuracy: 0.6513 - val_loss: 0.6372 - val_accuracy: 0.5881\n",
      "Epoch 3539/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6110 - accuracy: 0.6477 - val_loss: 0.6759 - val_accuracy: 0.5320\n",
      "Epoch 3540/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6102 - accuracy: 0.6522 - val_loss: 0.6464 - val_accuracy: 0.5745\n",
      "Epoch 3541/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6096 - accuracy: 0.6496 - val_loss: 0.6610 - val_accuracy: 0.5526\n",
      "Epoch 3542/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6087 - accuracy: 0.6526 - val_loss: 0.6608 - val_accuracy: 0.5512\n",
      "Epoch 3543/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6088 - accuracy: 0.6533 - val_loss: 0.6452 - val_accuracy: 0.5780\n",
      "Epoch 3544/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6092 - accuracy: 0.6511 - val_loss: 0.6746 - val_accuracy: 0.5345\n",
      "Epoch 3545/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6098 - accuracy: 0.6514 - val_loss: 0.6418 - val_accuracy: 0.5798\n",
      "Epoch 3546/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6102 - accuracy: 0.6476 - val_loss: 0.6768 - val_accuracy: 0.5323\n",
      "Epoch 3547/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6101 - accuracy: 0.6522 - val_loss: 0.6382 - val_accuracy: 0.5906\n",
      "Epoch 3548/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6102 - accuracy: 0.6493 - val_loss: 0.6735 - val_accuracy: 0.5358\n",
      "Epoch 3549/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6097 - accuracy: 0.6512 - val_loss: 0.6501 - val_accuracy: 0.5687\n",
      "Epoch 3550/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6093 - accuracy: 0.6501 - val_loss: 0.6608 - val_accuracy: 0.5541\n",
      "Epoch 3551/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6088 - accuracy: 0.6529 - val_loss: 0.6567 - val_accuracy: 0.5592\n",
      "Epoch 3552/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6088 - accuracy: 0.6531 - val_loss: 0.6503 - val_accuracy: 0.5670\n",
      "Epoch 3553/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6090 - accuracy: 0.6504 - val_loss: 0.6695 - val_accuracy: 0.5433\n",
      "Epoch 3554/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6090 - accuracy: 0.6531 - val_loss: 0.6464 - val_accuracy: 0.5751\n",
      "Epoch 3555/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6095 - accuracy: 0.6502 - val_loss: 0.6747 - val_accuracy: 0.5338\n",
      "Epoch 3556/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6097 - accuracy: 0.6517 - val_loss: 0.6370 - val_accuracy: 0.5901\n",
      "Epoch 3557/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6102 - accuracy: 0.6491 - val_loss: 0.6802 - val_accuracy: 0.5274\n",
      "Epoch 3558/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6106 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.5842\n",
      "Epoch 3559/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6103 - accuracy: 0.6492 - val_loss: 0.6757 - val_accuracy: 0.5342\n",
      "Epoch 3560/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6097 - accuracy: 0.6518 - val_loss: 0.6460 - val_accuracy: 0.5751\n",
      "Epoch 3561/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6090 - accuracy: 0.6501 - val_loss: 0.6586 - val_accuracy: 0.5581\n",
      "Epoch 3562/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6087 - accuracy: 0.6528 - val_loss: 0.6608 - val_accuracy: 0.5548\n",
      "Epoch 3563/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6084 - accuracy: 0.6524 - val_loss: 0.6515 - val_accuracy: 0.5674\n",
      "Epoch 3564/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6091 - accuracy: 0.6510 - val_loss: 0.6727 - val_accuracy: 0.5374\n",
      "Epoch 3565/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6095 - accuracy: 0.6518 - val_loss: 0.6347 - val_accuracy: 0.5977\n",
      "Epoch 3566/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6106 - accuracy: 0.6485 - val_loss: 0.6902 - val_accuracy: 0.5153\n",
      "Epoch 3567/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6120 - accuracy: 0.6483 - val_loss: 0.6356 - val_accuracy: 0.5928\n",
      "Epoch 3568/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6119 - accuracy: 0.6467 - val_loss: 0.6813 - val_accuracy: 0.5269\n",
      "Epoch 3569/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6115 - accuracy: 0.6509 - val_loss: 0.6379 - val_accuracy: 0.5935\n",
      "Epoch 3570/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6106 - accuracy: 0.6504 - val_loss: 0.6673 - val_accuracy: 0.5455\n",
      "Epoch 3571/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6102 - accuracy: 0.6505 - val_loss: 0.6621 - val_accuracy: 0.5519\n",
      "Epoch 3572/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6091 - accuracy: 0.6505 - val_loss: 0.6487 - val_accuracy: 0.5705\n",
      "Epoch 3573/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6098 - accuracy: 0.6506 - val_loss: 0.6733 - val_accuracy: 0.5354\n",
      "Epoch 3574/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6099 - accuracy: 0.6521 - val_loss: 0.6355 - val_accuracy: 0.5899\n",
      "Epoch 3575/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6115 - accuracy: 0.6484 - val_loss: 0.6899 - val_accuracy: 0.5150\n",
      "Epoch 3576/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6123 - accuracy: 0.6482 - val_loss: 0.6329 - val_accuracy: 0.5999\n",
      "Epoch 3577/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6128 - accuracy: 0.6452 - val_loss: 0.6864 - val_accuracy: 0.5194\n",
      "Epoch 3578/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6115 - accuracy: 0.6484 - val_loss: 0.6419 - val_accuracy: 0.5798\n",
      "Epoch 3579/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6105 - accuracy: 0.6488 - val_loss: 0.6582 - val_accuracy: 0.5583\n",
      "Epoch 3580/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6095 - accuracy: 0.6523 - val_loss: 0.6637 - val_accuracy: 0.5515\n",
      "Epoch 3581/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6095 - accuracy: 0.6518 - val_loss: 0.6446 - val_accuracy: 0.5778\n",
      "Epoch 3582/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6102 - accuracy: 0.6490 - val_loss: 0.6813 - val_accuracy: 0.5248\n",
      "Epoch 3583/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6109 - accuracy: 0.6505 - val_loss: 0.6299 - val_accuracy: 0.6034\n",
      "Epoch 3584/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6116 - accuracy: 0.6486 - val_loss: 0.6911 - val_accuracy: 0.5133\n",
      "Epoch 3585/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6121 - accuracy: 0.6483 - val_loss: 0.6399 - val_accuracy: 0.5833\n",
      "Epoch 3586/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6108 - accuracy: 0.6474 - val_loss: 0.6690 - val_accuracy: 0.5415\n",
      "Epoch 3587/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6091 - accuracy: 0.6522 - val_loss: 0.6500 - val_accuracy: 0.5692\n",
      "Epoch 3588/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6087 - accuracy: 0.6523 - val_loss: 0.6503 - val_accuracy: 0.5681\n",
      "Epoch 3589/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6086 - accuracy: 0.6527 - val_loss: 0.6734 - val_accuracy: 0.5376\n",
      "Epoch 3590/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6091 - accuracy: 0.6523 - val_loss: 0.6412 - val_accuracy: 0.5820\n",
      "Epoch 3591/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6097 - accuracy: 0.6486 - val_loss: 0.6782 - val_accuracy: 0.5292\n",
      "Epoch 3592/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6101 - accuracy: 0.6517 - val_loss: 0.6371 - val_accuracy: 0.5917\n",
      "Epoch 3593/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6100 - accuracy: 0.6486 - val_loss: 0.6767 - val_accuracy: 0.5329\n",
      "Epoch 3594/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6100 - accuracy: 0.6513 - val_loss: 0.6439 - val_accuracy: 0.5782\n",
      "Epoch 3595/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6095 - accuracy: 0.6483 - val_loss: 0.6692 - val_accuracy: 0.5426\n",
      "Epoch 3596/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6089 - accuracy: 0.6532 - val_loss: 0.6515 - val_accuracy: 0.5650\n",
      "Epoch 3597/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6085 - accuracy: 0.6531 - val_loss: 0.6530 - val_accuracy: 0.5625\n",
      "Epoch 3598/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6085 - accuracy: 0.6513 - val_loss: 0.6635 - val_accuracy: 0.5517\n",
      "Epoch 3599/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6084 - accuracy: 0.6530 - val_loss: 0.6511 - val_accuracy: 0.5678\n",
      "Epoch 3600/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6089 - accuracy: 0.6513 - val_loss: 0.6710 - val_accuracy: 0.5400\n",
      "Epoch 3601/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6089 - accuracy: 0.6522 - val_loss: 0.6380 - val_accuracy: 0.5873\n",
      "Epoch 3602/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6096 - accuracy: 0.6501 - val_loss: 0.6791 - val_accuracy: 0.5307\n",
      "Epoch 3603/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6098 - accuracy: 0.6519 - val_loss: 0.6415 - val_accuracy: 0.5820\n",
      "Epoch 3604/15000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6099 - accuracy: 0.6498 - val_loss: 0.6755 - val_accuracy: 0.5327\n",
      "Epoch 3605/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6096 - accuracy: 0.6524 - val_loss: 0.6412 - val_accuracy: 0.5829\n",
      "Epoch 3606/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6091 - accuracy: 0.6493 - val_loss: 0.6676 - val_accuracy: 0.5469\n",
      "Epoch 3607/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6086 - accuracy: 0.6537 - val_loss: 0.6547 - val_accuracy: 0.5639\n",
      "Epoch 3608/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6082 - accuracy: 0.6530 - val_loss: 0.6575 - val_accuracy: 0.5581\n",
      "Epoch 3609/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6082 - accuracy: 0.6523 - val_loss: 0.6615 - val_accuracy: 0.5532\n",
      "Epoch 3610/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6081 - accuracy: 0.6531 - val_loss: 0.6461 - val_accuracy: 0.5754\n",
      "Epoch 3611/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6087 - accuracy: 0.6510 - val_loss: 0.6763 - val_accuracy: 0.5325\n",
      "Epoch 3612/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6094 - accuracy: 0.6525 - val_loss: 0.6360 - val_accuracy: 0.5932\n",
      "Epoch 3613/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6104 - accuracy: 0.6483 - val_loss: 0.6885 - val_accuracy: 0.5172\n",
      "Epoch 3614/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6115 - accuracy: 0.6491 - val_loss: 0.6315 - val_accuracy: 0.6030\n",
      "Epoch 3615/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6113 - accuracy: 0.6484 - val_loss: 0.6859 - val_accuracy: 0.5206\n",
      "Epoch 3616/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6116 - accuracy: 0.6494 - val_loss: 0.6394 - val_accuracy: 0.5868\n",
      "Epoch 3617/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6100 - accuracy: 0.6486 - val_loss: 0.6692 - val_accuracy: 0.5438\n",
      "Epoch 3618/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6091 - accuracy: 0.6522 - val_loss: 0.6574 - val_accuracy: 0.5594\n",
      "Epoch 3619/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6082 - accuracy: 0.6539 - val_loss: 0.6428 - val_accuracy: 0.5826\n",
      "Epoch 3620/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6092 - accuracy: 0.6499 - val_loss: 0.6790 - val_accuracy: 0.5287\n",
      "Epoch 3621/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6096 - accuracy: 0.6517 - val_loss: 0.6389 - val_accuracy: 0.5884\n",
      "Epoch 3622/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6112 - accuracy: 0.6490 - val_loss: 0.6900 - val_accuracy: 0.5153\n",
      "Epoch 3623/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6124 - accuracy: 0.6483 - val_loss: 0.6248 - val_accuracy: 0.6067\n",
      "Epoch 3624/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6123 - accuracy: 0.6467 - val_loss: 0.6885 - val_accuracy: 0.5174\n",
      "Epoch 3625/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6114 - accuracy: 0.6488 - val_loss: 0.6456 - val_accuracy: 0.5767\n",
      "Epoch 3626/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6097 - accuracy: 0.6505 - val_loss: 0.6585 - val_accuracy: 0.5544\n",
      "Epoch 3627/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6089 - accuracy: 0.6517 - val_loss: 0.6611 - val_accuracy: 0.5522\n",
      "Epoch 3628/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6087 - accuracy: 0.6519 - val_loss: 0.6425 - val_accuracy: 0.5806\n",
      "Epoch 3629/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6102 - accuracy: 0.6498 - val_loss: 0.6902 - val_accuracy: 0.5139\n",
      "Epoch 3630/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6119 - accuracy: 0.6489 - val_loss: 0.6284 - val_accuracy: 0.6039\n",
      "Epoch 3631/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6124 - accuracy: 0.6467 - val_loss: 0.6884 - val_accuracy: 0.5170\n",
      "Epoch 3632/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6117 - accuracy: 0.6487 - val_loss: 0.6406 - val_accuracy: 0.5829\n",
      "Epoch 3633/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6102 - accuracy: 0.6495 - val_loss: 0.6641 - val_accuracy: 0.5499\n",
      "Epoch 3634/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6093 - accuracy: 0.6519 - val_loss: 0.6575 - val_accuracy: 0.5568\n",
      "Epoch 3635/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6089 - accuracy: 0.6509 - val_loss: 0.6475 - val_accuracy: 0.5733\n",
      "Epoch 3636/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6091 - accuracy: 0.6514 - val_loss: 0.6771 - val_accuracy: 0.5305\n",
      "Epoch 3637/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6097 - accuracy: 0.6520 - val_loss: 0.6324 - val_accuracy: 0.5996\n",
      "Epoch 3638/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6108 - accuracy: 0.6490 - val_loss: 0.6887 - val_accuracy: 0.5166\n",
      "Epoch 3639/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6115 - accuracy: 0.6486 - val_loss: 0.6390 - val_accuracy: 0.5851\n",
      "Epoch 3640/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6108 - accuracy: 0.6475 - val_loss: 0.6727 - val_accuracy: 0.5367\n",
      "Epoch 3641/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6093 - accuracy: 0.6527 - val_loss: 0.6467 - val_accuracy: 0.5742\n",
      "Epoch 3642/15000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6089 - accuracy: 0.6521 - val_loss: 0.6536 - val_accuracy: 0.5628\n",
      "Epoch 3643/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6085 - accuracy: 0.6510 - val_loss: 0.6681 - val_accuracy: 0.5451\n",
      "Epoch 3644/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6085 - accuracy: 0.6531 - val_loss: 0.6484 - val_accuracy: 0.5720\n",
      "Epoch 3645/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6089 - accuracy: 0.6508 - val_loss: 0.6716 - val_accuracy: 0.5371\n",
      "Epoch 3646/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6089 - accuracy: 0.6530 - val_loss: 0.6382 - val_accuracy: 0.5899\n",
      "Epoch 3647/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6095 - accuracy: 0.6498 - val_loss: 0.6772 - val_accuracy: 0.5311\n",
      "Epoch 3648/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6095 - accuracy: 0.6531 - val_loss: 0.6427 - val_accuracy: 0.5807\n",
      "Epoch 3649/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6096 - accuracy: 0.6495 - val_loss: 0.6737 - val_accuracy: 0.5384\n",
      "Epoch 3650/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6088 - accuracy: 0.6532 - val_loss: 0.6461 - val_accuracy: 0.5749\n",
      "Epoch 3651/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6085 - accuracy: 0.6512 - val_loss: 0.6593 - val_accuracy: 0.5564\n",
      "Epoch 3652/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6080 - accuracy: 0.6537 - val_loss: 0.6600 - val_accuracy: 0.5575\n",
      "Epoch 3653/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6080 - accuracy: 0.6524 - val_loss: 0.6529 - val_accuracy: 0.5656\n",
      "Epoch 3654/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6082 - accuracy: 0.6520 - val_loss: 0.6672 - val_accuracy: 0.5453\n",
      "Epoch 3655/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6084 - accuracy: 0.6528 - val_loss: 0.6385 - val_accuracy: 0.5901\n",
      "Epoch 3656/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6093 - accuracy: 0.6492 - val_loss: 0.6832 - val_accuracy: 0.5252\n",
      "Epoch 3657/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6099 - accuracy: 0.6511 - val_loss: 0.6389 - val_accuracy: 0.5855\n",
      "Epoch 3658/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6105 - accuracy: 0.6474 - val_loss: 0.6820 - val_accuracy: 0.5254\n",
      "Epoch 3659/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6107 - accuracy: 0.6517 - val_loss: 0.6341 - val_accuracy: 0.5977\n",
      "Epoch 3660/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6101 - accuracy: 0.6495 - val_loss: 0.6755 - val_accuracy: 0.5329\n",
      "Epoch 3661/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6098 - accuracy: 0.6518 - val_loss: 0.6538 - val_accuracy: 0.5649\n",
      "Epoch 3662/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6085 - accuracy: 0.6518 - val_loss: 0.6554 - val_accuracy: 0.5647\n",
      "Epoch 3663/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6087 - accuracy: 0.6520 - val_loss: 0.6644 - val_accuracy: 0.5499\n",
      "Epoch 3664/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6084 - accuracy: 0.6536 - val_loss: 0.6414 - val_accuracy: 0.5813\n",
      "Epoch 3665/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6100 - accuracy: 0.6487 - val_loss: 0.6846 - val_accuracy: 0.5212\n",
      "Epoch 3666/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6105 - accuracy: 0.6507 - val_loss: 0.6338 - val_accuracy: 0.5968\n",
      "Epoch 3667/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6115 - accuracy: 0.6468 - val_loss: 0.6884 - val_accuracy: 0.5188\n",
      "Epoch 3668/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6112 - accuracy: 0.6491 - val_loss: 0.6375 - val_accuracy: 0.5908\n",
      "Epoch 3669/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6107 - accuracy: 0.6485 - val_loss: 0.6704 - val_accuracy: 0.5424\n",
      "Epoch 3670/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6098 - accuracy: 0.6525 - val_loss: 0.6513 - val_accuracy: 0.5665\n",
      "Epoch 3671/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6093 - accuracy: 0.6511 - val_loss: 0.6543 - val_accuracy: 0.5616\n",
      "Epoch 3672/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6086 - accuracy: 0.6525 - val_loss: 0.6720 - val_accuracy: 0.5387\n",
      "Epoch 3673/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6092 - accuracy: 0.6523 - val_loss: 0.6367 - val_accuracy: 0.5934\n",
      "Epoch 3674/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6099 - accuracy: 0.6496 - val_loss: 0.6834 - val_accuracy: 0.5225\n",
      "Epoch 3675/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6104 - accuracy: 0.6508 - val_loss: 0.6385 - val_accuracy: 0.5868\n",
      "Epoch 3676/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6107 - accuracy: 0.6470 - val_loss: 0.6817 - val_accuracy: 0.5261\n",
      "Epoch 3677/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6102 - accuracy: 0.6519 - val_loss: 0.6347 - val_accuracy: 0.5966\n",
      "Epoch 3678/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6098 - accuracy: 0.6499 - val_loss: 0.6755 - val_accuracy: 0.5334\n",
      "Epoch 3679/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6092 - accuracy: 0.6519 - val_loss: 0.6505 - val_accuracy: 0.5670\n",
      "Epoch 3680/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6087 - accuracy: 0.6505 - val_loss: 0.6608 - val_accuracy: 0.5575\n",
      "Epoch 3681/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6083 - accuracy: 0.6526 - val_loss: 0.6573 - val_accuracy: 0.5585\n",
      "Epoch 3682/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6081 - accuracy: 0.6542 - val_loss: 0.6473 - val_accuracy: 0.5733\n",
      "Epoch 3683/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6089 - accuracy: 0.6498 - val_loss: 0.6746 - val_accuracy: 0.5380\n",
      "Epoch 3684/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6088 - accuracy: 0.6531 - val_loss: 0.6404 - val_accuracy: 0.5875\n",
      "Epoch 3685/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6098 - accuracy: 0.6487 - val_loss: 0.6825 - val_accuracy: 0.5263\n",
      "Epoch 3686/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6098 - accuracy: 0.6514 - val_loss: 0.6363 - val_accuracy: 0.5901\n",
      "Epoch 3687/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6102 - accuracy: 0.6489 - val_loss: 0.6777 - val_accuracy: 0.5314\n",
      "Epoch 3688/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6103 - accuracy: 0.6523 - val_loss: 0.6411 - val_accuracy: 0.5849\n",
      "Epoch 3689/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6097 - accuracy: 0.6485 - val_loss: 0.6701 - val_accuracy: 0.5422\n",
      "Epoch 3690/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6086 - accuracy: 0.6522 - val_loss: 0.6568 - val_accuracy: 0.5586\n",
      "Epoch 3691/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6083 - accuracy: 0.6517 - val_loss: 0.6493 - val_accuracy: 0.5722\n",
      "Epoch 3692/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6088 - accuracy: 0.6512 - val_loss: 0.6676 - val_accuracy: 0.5480\n",
      "Epoch 3693/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6086 - accuracy: 0.6533 - val_loss: 0.6455 - val_accuracy: 0.5787\n",
      "Epoch 3694/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6093 - accuracy: 0.6497 - val_loss: 0.6786 - val_accuracy: 0.5296\n",
      "Epoch 3695/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6094 - accuracy: 0.6524 - val_loss: 0.6327 - val_accuracy: 0.6014\n",
      "Epoch 3696/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6102 - accuracy: 0.6495 - val_loss: 0.6864 - val_accuracy: 0.5208\n",
      "Epoch 3697/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6104 - accuracy: 0.6505 - val_loss: 0.6389 - val_accuracy: 0.5851\n",
      "Epoch 3698/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6101 - accuracy: 0.6481 - val_loss: 0.6770 - val_accuracy: 0.5311\n",
      "Epoch 3699/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6096 - accuracy: 0.6530 - val_loss: 0.6405 - val_accuracy: 0.5859\n",
      "Epoch 3700/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6088 - accuracy: 0.6500 - val_loss: 0.6657 - val_accuracy: 0.5490\n",
      "Epoch 3701/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6082 - accuracy: 0.6528 - val_loss: 0.6601 - val_accuracy: 0.5561\n",
      "Epoch 3702/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6076 - accuracy: 0.6536 - val_loss: 0.6485 - val_accuracy: 0.5736\n",
      "Epoch 3703/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6083 - accuracy: 0.6517 - val_loss: 0.6712 - val_accuracy: 0.5429\n",
      "Epoch 3704/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6083 - accuracy: 0.6537 - val_loss: 0.6398 - val_accuracy: 0.5855\n",
      "Epoch 3705/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6095 - accuracy: 0.6493 - val_loss: 0.6834 - val_accuracy: 0.5241\n",
      "Epoch 3706/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6102 - accuracy: 0.6514 - val_loss: 0.6331 - val_accuracy: 0.6007\n",
      "Epoch 3707/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6104 - accuracy: 0.6486 - val_loss: 0.6859 - val_accuracy: 0.5214\n",
      "Epoch 3708/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6103 - accuracy: 0.6500 - val_loss: 0.6411 - val_accuracy: 0.5828\n",
      "Epoch 3709/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6091 - accuracy: 0.6493 - val_loss: 0.6659 - val_accuracy: 0.5484\n",
      "Epoch 3710/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6087 - accuracy: 0.6533 - val_loss: 0.6539 - val_accuracy: 0.5636\n",
      "Epoch 3711/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6079 - accuracy: 0.6529 - val_loss: 0.6528 - val_accuracy: 0.5650\n",
      "Epoch 3712/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6086 - accuracy: 0.6521 - val_loss: 0.6758 - val_accuracy: 0.5353\n",
      "Epoch 3713/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6086 - accuracy: 0.6536 - val_loss: 0.6326 - val_accuracy: 0.5992\n",
      "Epoch 3714/15000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6105 - accuracy: 0.6488 - val_loss: 0.6926 - val_accuracy: 0.5124\n",
      "Epoch 3715/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6116 - accuracy: 0.6483 - val_loss: 0.6329 - val_accuracy: 0.5981\n",
      "Epoch 3716/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6115 - accuracy: 0.6485 - val_loss: 0.6841 - val_accuracy: 0.5230\n",
      "Epoch 3717/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6112 - accuracy: 0.6508 - val_loss: 0.6381 - val_accuracy: 0.5923\n",
      "Epoch 3718/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6097 - accuracy: 0.6494 - val_loss: 0.6658 - val_accuracy: 0.5479\n",
      "Epoch 3719/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6085 - accuracy: 0.6528 - val_loss: 0.6655 - val_accuracy: 0.5502\n",
      "Epoch 3720/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6079 - accuracy: 0.6531 - val_loss: 0.6391 - val_accuracy: 0.5890\n",
      "Epoch 3721/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6094 - accuracy: 0.6494 - val_loss: 0.6829 - val_accuracy: 0.5228\n",
      "Epoch 3722/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6102 - accuracy: 0.6509 - val_loss: 0.6341 - val_accuracy: 0.5966\n",
      "Epoch 3723/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6113 - accuracy: 0.6481 - val_loss: 0.6910 - val_accuracy: 0.5128\n",
      "Epoch 3724/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6117 - accuracy: 0.6481 - val_loss: 0.6328 - val_accuracy: 0.5974\n",
      "Epoch 3725/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6104 - accuracy: 0.6478 - val_loss: 0.6742 - val_accuracy: 0.5373\n",
      "Epoch 3726/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6086 - accuracy: 0.6531 - val_loss: 0.6548 - val_accuracy: 0.5639\n",
      "Epoch 3727/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6078 - accuracy: 0.6537 - val_loss: 0.6465 - val_accuracy: 0.5747\n",
      "Epoch 3728/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6082 - accuracy: 0.6510 - val_loss: 0.6719 - val_accuracy: 0.5398\n",
      "Epoch 3729/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6086 - accuracy: 0.6533 - val_loss: 0.6405 - val_accuracy: 0.5837\n",
      "Epoch 3730/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6096 - accuracy: 0.6501 - val_loss: 0.6843 - val_accuracy: 0.5206\n",
      "Epoch 3731/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6101 - accuracy: 0.6512 - val_loss: 0.6324 - val_accuracy: 0.5972\n",
      "Epoch 3732/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6100 - accuracy: 0.6486 - val_loss: 0.6782 - val_accuracy: 0.5336\n",
      "Epoch 3733/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6090 - accuracy: 0.6526 - val_loss: 0.6467 - val_accuracy: 0.5745\n",
      "Epoch 3734/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6084 - accuracy: 0.6521 - val_loss: 0.6623 - val_accuracy: 0.5519\n",
      "Epoch 3735/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6077 - accuracy: 0.6545 - val_loss: 0.6567 - val_accuracy: 0.5607\n",
      "Epoch 3736/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6075 - accuracy: 0.6540 - val_loss: 0.6501 - val_accuracy: 0.5683\n",
      "Epoch 3737/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6077 - accuracy: 0.6530 - val_loss: 0.6718 - val_accuracy: 0.5420\n",
      "Epoch 3738/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6080 - accuracy: 0.6542 - val_loss: 0.6403 - val_accuracy: 0.5853\n",
      "Epoch 3739/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6086 - accuracy: 0.6501 - val_loss: 0.6753 - val_accuracy: 0.5367\n",
      "Epoch 3740/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6086 - accuracy: 0.6533 - val_loss: 0.6412 - val_accuracy: 0.5839\n",
      "Epoch 3741/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6085 - accuracy: 0.6507 - val_loss: 0.6737 - val_accuracy: 0.5376\n",
      "Epoch 3742/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6083 - accuracy: 0.6533 - val_loss: 0.6453 - val_accuracy: 0.5769\n",
      "Epoch 3743/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6080 - accuracy: 0.6502 - val_loss: 0.6660 - val_accuracy: 0.5508\n",
      "Epoch 3744/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6076 - accuracy: 0.6546 - val_loss: 0.6538 - val_accuracy: 0.5652\n",
      "Epoch 3745/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6073 - accuracy: 0.6538 - val_loss: 0.6549 - val_accuracy: 0.5641\n",
      "Epoch 3746/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6074 - accuracy: 0.6527 - val_loss: 0.6630 - val_accuracy: 0.5519\n",
      "Epoch 3747/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6073 - accuracy: 0.6541 - val_loss: 0.6499 - val_accuracy: 0.5718\n",
      "Epoch 3748/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6077 - accuracy: 0.6527 - val_loss: 0.6698 - val_accuracy: 0.5451\n",
      "Epoch 3749/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6078 - accuracy: 0.6534 - val_loss: 0.6405 - val_accuracy: 0.5849\n",
      "Epoch 3750/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6084 - accuracy: 0.6502 - val_loss: 0.6781 - val_accuracy: 0.5347\n",
      "Epoch 3751/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6086 - accuracy: 0.6532 - val_loss: 0.6414 - val_accuracy: 0.5844\n",
      "Epoch 3752/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6086 - accuracy: 0.6508 - val_loss: 0.6755 - val_accuracy: 0.5364\n",
      "Epoch 3753/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6087 - accuracy: 0.6522 - val_loss: 0.6420 - val_accuracy: 0.5833\n",
      "Epoch 3754/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6081 - accuracy: 0.6501 - val_loss: 0.6689 - val_accuracy: 0.5471\n",
      "Epoch 3755/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6080 - accuracy: 0.6539 - val_loss: 0.6525 - val_accuracy: 0.5658\n",
      "Epoch 3756/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6073 - accuracy: 0.6534 - val_loss: 0.6573 - val_accuracy: 0.5605\n",
      "Epoch 3757/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6077 - accuracy: 0.6524 - val_loss: 0.6630 - val_accuracy: 0.5537\n",
      "Epoch 3758/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6072 - accuracy: 0.6542 - val_loss: 0.6464 - val_accuracy: 0.5782\n",
      "Epoch 3759/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6083 - accuracy: 0.6527 - val_loss: 0.6785 - val_accuracy: 0.5311\n",
      "Epoch 3760/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6088 - accuracy: 0.6530 - val_loss: 0.6325 - val_accuracy: 0.5955\n",
      "Epoch 3761/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6104 - accuracy: 0.6476 - val_loss: 0.6920 - val_accuracy: 0.5146\n",
      "Epoch 3762/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6116 - accuracy: 0.6485 - val_loss: 0.6322 - val_accuracy: 0.6034\n",
      "Epoch 3763/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6112 - accuracy: 0.6487 - val_loss: 0.6832 - val_accuracy: 0.5296\n",
      "Epoch 3764/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6111 - accuracy: 0.6499 - val_loss: 0.6485 - val_accuracy: 0.5694\n",
      "Epoch 3765/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6100 - accuracy: 0.6473 - val_loss: 0.6590 - val_accuracy: 0.5561\n",
      "Epoch 3766/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6085 - accuracy: 0.6529 - val_loss: 0.6658 - val_accuracy: 0.5497\n",
      "Epoch 3767/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6089 - accuracy: 0.6526 - val_loss: 0.6425 - val_accuracy: 0.5767\n",
      "Epoch 3768/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6091 - accuracy: 0.6495 - val_loss: 0.6720 - val_accuracy: 0.5382\n",
      "Epoch 3769/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6088 - accuracy: 0.6520 - val_loss: 0.6483 - val_accuracy: 0.5723\n",
      "Epoch 3770/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6087 - accuracy: 0.6516 - val_loss: 0.6705 - val_accuracy: 0.5431\n",
      "Epoch 3771/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6078 - accuracy: 0.6541 - val_loss: 0.6455 - val_accuracy: 0.5734\n",
      "Epoch 3772/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6083 - accuracy: 0.6509 - val_loss: 0.6610 - val_accuracy: 0.5522\n",
      "Epoch 3773/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6074 - accuracy: 0.6531 - val_loss: 0.6536 - val_accuracy: 0.5649\n",
      "Epoch 3774/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6078 - accuracy: 0.6529 - val_loss: 0.6626 - val_accuracy: 0.5533\n",
      "Epoch 3775/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6072 - accuracy: 0.6541 - val_loss: 0.6539 - val_accuracy: 0.5627\n",
      "Epoch 3776/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6074 - accuracy: 0.6526 - val_loss: 0.6555 - val_accuracy: 0.5621\n",
      "Epoch 3777/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6073 - accuracy: 0.6552 - val_loss: 0.6591 - val_accuracy: 0.5594\n",
      "Epoch 3778/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6072 - accuracy: 0.6537 - val_loss: 0.6574 - val_accuracy: 0.5588\n",
      "Epoch 3779/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6072 - accuracy: 0.6529 - val_loss: 0.6600 - val_accuracy: 0.5564\n",
      "Epoch 3780/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6071 - accuracy: 0.6542 - val_loss: 0.6481 - val_accuracy: 0.5753\n",
      "Epoch 3781/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6073 - accuracy: 0.6534 - val_loss: 0.6677 - val_accuracy: 0.5480\n",
      "Epoch 3782/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6073 - accuracy: 0.6545 - val_loss: 0.6473 - val_accuracy: 0.5738\n",
      "Epoch 3783/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6077 - accuracy: 0.6508 - val_loss: 0.6738 - val_accuracy: 0.5406\n",
      "Epoch 3784/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6081 - accuracy: 0.6541 - val_loss: 0.6374 - val_accuracy: 0.5904\n",
      "Epoch 3785/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6084 - accuracy: 0.6509 - val_loss: 0.6809 - val_accuracy: 0.5285\n",
      "Epoch 3786/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6090 - accuracy: 0.6524 - val_loss: 0.6380 - val_accuracy: 0.5886\n",
      "Epoch 3787/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6089 - accuracy: 0.6493 - val_loss: 0.6814 - val_accuracy: 0.5274\n",
      "Epoch 3788/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6095 - accuracy: 0.6521 - val_loss: 0.6360 - val_accuracy: 0.5954\n",
      "Epoch 3789/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6087 - accuracy: 0.6509 - val_loss: 0.6779 - val_accuracy: 0.5336\n",
      "Epoch 3790/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6087 - accuracy: 0.6527 - val_loss: 0.6454 - val_accuracy: 0.5756\n",
      "Epoch 3791/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6076 - accuracy: 0.6509 - val_loss: 0.6645 - val_accuracy: 0.5522\n",
      "Epoch 3792/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6078 - accuracy: 0.6543 - val_loss: 0.6546 - val_accuracy: 0.5639\n",
      "Epoch 3793/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6069 - accuracy: 0.6541 - val_loss: 0.6545 - val_accuracy: 0.5605\n",
      "Epoch 3794/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6077 - accuracy: 0.6530 - val_loss: 0.6703 - val_accuracy: 0.5448\n",
      "Epoch 3795/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6076 - accuracy: 0.6542 - val_loss: 0.6365 - val_accuracy: 0.5950\n",
      "Epoch 3796/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6091 - accuracy: 0.6503 - val_loss: 0.6901 - val_accuracy: 0.5188\n",
      "Epoch 3797/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6108 - accuracy: 0.6493 - val_loss: 0.6310 - val_accuracy: 0.6007\n",
      "Epoch 3798/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6116 - accuracy: 0.6475 - val_loss: 0.6944 - val_accuracy: 0.5135\n",
      "Epoch 3799/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6135 - accuracy: 0.6476 - val_loss: 0.6308 - val_accuracy: 0.6038\n",
      "Epoch 3800/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6122 - accuracy: 0.6479 - val_loss: 0.6774 - val_accuracy: 0.5351\n",
      "Epoch 3801/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6099 - accuracy: 0.6513 - val_loss: 0.6591 - val_accuracy: 0.5535\n",
      "Epoch 3802/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6109 - accuracy: 0.6492 - val_loss: 0.6562 - val_accuracy: 0.5650\n",
      "Epoch 3803/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6094 - accuracy: 0.6516 - val_loss: 0.6594 - val_accuracy: 0.5597\n",
      "Epoch 3804/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6111 - accuracy: 0.6513 - val_loss: 0.6573 - val_accuracy: 0.5575\n",
      "Epoch 3805/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6074 - accuracy: 0.6530 - val_loss: 0.6506 - val_accuracy: 0.5665\n",
      "Epoch 3806/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6122 - accuracy: 0.6475 - val_loss: 0.6877 - val_accuracy: 0.5221\n",
      "Epoch 3807/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6120 - accuracy: 0.6492 - val_loss: 0.6249 - val_accuracy: 0.6145\n",
      "Epoch 3808/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6188 - accuracy: 0.6407 - val_loss: 0.7128 - val_accuracy: 0.4974\n",
      "Epoch 3809/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6181 - accuracy: 0.6423 - val_loss: 0.6411 - val_accuracy: 0.5884\n",
      "Epoch 3810/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6230 - accuracy: 0.6394 - val_loss: 0.6870 - val_accuracy: 0.5205\n",
      "Epoch 3811/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6131 - accuracy: 0.6487 - val_loss: 0.6387 - val_accuracy: 0.6008\n",
      "Epoch 3812/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6237 - accuracy: 0.6375 - val_loss: 0.6980 - val_accuracy: 0.5077\n",
      "Epoch 3813/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6175 - accuracy: 0.6447 - val_loss: 0.6292 - val_accuracy: 0.6007\n",
      "Epoch 3814/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6177 - accuracy: 0.6411 - val_loss: 0.6910 - val_accuracy: 0.5115\n",
      "Epoch 3815/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6152 - accuracy: 0.6455 - val_loss: 0.6627 - val_accuracy: 0.5508\n",
      "Epoch 3816/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6093 - accuracy: 0.6522 - val_loss: 0.6271 - val_accuracy: 0.6080\n",
      "Epoch 3817/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6167 - accuracy: 0.6424 - val_loss: 0.7198 - val_accuracy: 0.4814\n",
      "Epoch 3818/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6215 - accuracy: 0.6380 - val_loss: 0.6383 - val_accuracy: 0.5923\n",
      "Epoch 3819/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6214 - accuracy: 0.6414 - val_loss: 0.6649 - val_accuracy: 0.5440\n",
      "Epoch 3820/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6104 - accuracy: 0.6508 - val_loss: 0.6591 - val_accuracy: 0.5563\n",
      "Epoch 3821/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6165 - accuracy: 0.6470 - val_loss: 0.6558 - val_accuracy: 0.5607\n",
      "Epoch 3822/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6116 - accuracy: 0.6496 - val_loss: 0.6426 - val_accuracy: 0.5727\n",
      "Epoch 3823/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6123 - accuracy: 0.6461 - val_loss: 0.6850 - val_accuracy: 0.5206\n",
      "Epoch 3824/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6138 - accuracy: 0.6460 - val_loss: 0.6620 - val_accuracy: 0.5512\n",
      "Epoch 3825/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6094 - accuracy: 0.6508 - val_loss: 0.6373 - val_accuracy: 0.5890\n",
      "Epoch 3826/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6122 - accuracy: 0.6485 - val_loss: 0.6871 - val_accuracy: 0.5163\n",
      "Epoch 3827/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6142 - accuracy: 0.6480 - val_loss: 0.6285 - val_accuracy: 0.6036\n",
      "Epoch 3828/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6135 - accuracy: 0.6466 - val_loss: 0.6793 - val_accuracy: 0.5259\n",
      "Epoch 3829/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6096 - accuracy: 0.6516 - val_loss: 0.6617 - val_accuracy: 0.5554\n",
      "Epoch 3830/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6092 - accuracy: 0.6523 - val_loss: 0.6384 - val_accuracy: 0.5862\n",
      "Epoch 3831/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6089 - accuracy: 0.6502 - val_loss: 0.6758 - val_accuracy: 0.5334\n",
      "Epoch 3832/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6106 - accuracy: 0.6515 - val_loss: 0.6408 - val_accuracy: 0.5807\n",
      "Epoch 3833/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6096 - accuracy: 0.6504 - val_loss: 0.6653 - val_accuracy: 0.5482\n",
      "Epoch 3834/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6084 - accuracy: 0.6529 - val_loss: 0.6626 - val_accuracy: 0.5524\n",
      "Epoch 3835/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6081 - accuracy: 0.6528 - val_loss: 0.6403 - val_accuracy: 0.5835\n",
      "Epoch 3836/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6090 - accuracy: 0.6501 - val_loss: 0.6775 - val_accuracy: 0.5300\n",
      "Epoch 3837/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6092 - accuracy: 0.6517 - val_loss: 0.6384 - val_accuracy: 0.5897\n",
      "Epoch 3838/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6091 - accuracy: 0.6513 - val_loss: 0.6716 - val_accuracy: 0.5391\n",
      "Epoch 3839/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6082 - accuracy: 0.6525 - val_loss: 0.6503 - val_accuracy: 0.5680\n",
      "Epoch 3840/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6077 - accuracy: 0.6509 - val_loss: 0.6562 - val_accuracy: 0.5608\n",
      "Epoch 3841/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6071 - accuracy: 0.6537 - val_loss: 0.6671 - val_accuracy: 0.5469\n",
      "Epoch 3842/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6077 - accuracy: 0.6544 - val_loss: 0.6440 - val_accuracy: 0.5787\n",
      "Epoch 3843/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6074 - accuracy: 0.6508 - val_loss: 0.6663 - val_accuracy: 0.5451\n",
      "Epoch 3844/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6077 - accuracy: 0.6537 - val_loss: 0.6534 - val_accuracy: 0.5641\n",
      "Epoch 3845/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6072 - accuracy: 0.6521 - val_loss: 0.6571 - val_accuracy: 0.5632\n",
      "Epoch 3846/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6071 - accuracy: 0.6544 - val_loss: 0.6607 - val_accuracy: 0.5586\n",
      "Epoch 3847/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6070 - accuracy: 0.6553 - val_loss: 0.6472 - val_accuracy: 0.5731\n",
      "Epoch 3848/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6074 - accuracy: 0.6517 - val_loss: 0.6715 - val_accuracy: 0.5448\n",
      "Epoch 3849/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6075 - accuracy: 0.6543 - val_loss: 0.6460 - val_accuracy: 0.5753\n",
      "Epoch 3850/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6076 - accuracy: 0.6517 - val_loss: 0.6687 - val_accuracy: 0.5448\n",
      "Epoch 3851/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6074 - accuracy: 0.6540 - val_loss: 0.6474 - val_accuracy: 0.5727\n",
      "Epoch 3852/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6071 - accuracy: 0.6513 - val_loss: 0.6647 - val_accuracy: 0.5528\n",
      "Epoch 3853/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6068 - accuracy: 0.6541 - val_loss: 0.6559 - val_accuracy: 0.5647\n",
      "Epoch 3854/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6068 - accuracy: 0.6535 - val_loss: 0.6545 - val_accuracy: 0.5634\n",
      "Epoch 3855/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6066 - accuracy: 0.6535 - val_loss: 0.6587 - val_accuracy: 0.5561\n",
      "Epoch 3856/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6067 - accuracy: 0.6543 - val_loss: 0.6525 - val_accuracy: 0.5670\n",
      "Epoch 3857/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6067 - accuracy: 0.6539 - val_loss: 0.6658 - val_accuracy: 0.5515\n",
      "Epoch 3858/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6068 - accuracy: 0.6550 - val_loss: 0.6506 - val_accuracy: 0.5722\n",
      "Epoch 3859/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6067 - accuracy: 0.6526 - val_loss: 0.6624 - val_accuracy: 0.5552\n",
      "Epoch 3860/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6067 - accuracy: 0.6547 - val_loss: 0.6511 - val_accuracy: 0.5685\n",
      "Epoch 3861/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6067 - accuracy: 0.6546 - val_loss: 0.6626 - val_accuracy: 0.5548\n",
      "Epoch 3862/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6066 - accuracy: 0.6549 - val_loss: 0.6542 - val_accuracy: 0.5643\n",
      "Epoch 3863/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6066 - accuracy: 0.6537 - val_loss: 0.6601 - val_accuracy: 0.5568\n",
      "Epoch 3864/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6065 - accuracy: 0.6547 - val_loss: 0.6553 - val_accuracy: 0.5638\n",
      "Epoch 3865/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6065 - accuracy: 0.6551 - val_loss: 0.6558 - val_accuracy: 0.5625\n",
      "Epoch 3866/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6064 - accuracy: 0.6549 - val_loss: 0.6592 - val_accuracy: 0.5575\n",
      "Epoch 3867/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6064 - accuracy: 0.6545 - val_loss: 0.6564 - val_accuracy: 0.5612\n",
      "Epoch 3868/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6064 - accuracy: 0.6543 - val_loss: 0.6605 - val_accuracy: 0.5568\n",
      "Epoch 3869/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6065 - accuracy: 0.6553 - val_loss: 0.6511 - val_accuracy: 0.5685\n",
      "Epoch 3870/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6065 - accuracy: 0.6531 - val_loss: 0.6629 - val_accuracy: 0.5548\n",
      "Epoch 3871/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6065 - accuracy: 0.6547 - val_loss: 0.6519 - val_accuracy: 0.5689\n",
      "Epoch 3872/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6065 - accuracy: 0.6535 - val_loss: 0.6638 - val_accuracy: 0.5535\n",
      "Epoch 3873/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6066 - accuracy: 0.6552 - val_loss: 0.6496 - val_accuracy: 0.5711\n",
      "Epoch 3874/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6066 - accuracy: 0.6533 - val_loss: 0.6658 - val_accuracy: 0.5502\n",
      "Epoch 3875/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6067 - accuracy: 0.6549 - val_loss: 0.6472 - val_accuracy: 0.5749\n",
      "Epoch 3876/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6068 - accuracy: 0.6525 - val_loss: 0.6688 - val_accuracy: 0.5480\n",
      "Epoch 3877/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6069 - accuracy: 0.6546 - val_loss: 0.6447 - val_accuracy: 0.5809\n",
      "Epoch 3878/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6070 - accuracy: 0.6520 - val_loss: 0.6725 - val_accuracy: 0.5422\n",
      "Epoch 3879/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6072 - accuracy: 0.6545 - val_loss: 0.6423 - val_accuracy: 0.5820\n",
      "Epoch 3880/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6073 - accuracy: 0.6511 - val_loss: 0.6746 - val_accuracy: 0.5391\n",
      "Epoch 3881/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6076 - accuracy: 0.6542 - val_loss: 0.6402 - val_accuracy: 0.5859\n",
      "Epoch 3882/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6074 - accuracy: 0.6507 - val_loss: 0.6749 - val_accuracy: 0.5389\n",
      "Epoch 3883/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6075 - accuracy: 0.6539 - val_loss: 0.6430 - val_accuracy: 0.5815\n",
      "Epoch 3884/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6073 - accuracy: 0.6511 - val_loss: 0.6734 - val_accuracy: 0.5406\n",
      "Epoch 3885/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6075 - accuracy: 0.6545 - val_loss: 0.6412 - val_accuracy: 0.5837\n",
      "Epoch 3886/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6072 - accuracy: 0.6507 - val_loss: 0.6723 - val_accuracy: 0.5424\n",
      "Epoch 3887/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6072 - accuracy: 0.6541 - val_loss: 0.6463 - val_accuracy: 0.5780\n",
      "Epoch 3888/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6069 - accuracy: 0.6522 - val_loss: 0.6679 - val_accuracy: 0.5473\n",
      "Epoch 3889/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6069 - accuracy: 0.6548 - val_loss: 0.6472 - val_accuracy: 0.5769\n",
      "Epoch 3890/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6066 - accuracy: 0.6528 - val_loss: 0.6645 - val_accuracy: 0.5515\n",
      "Epoch 3891/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6066 - accuracy: 0.6544 - val_loss: 0.6533 - val_accuracy: 0.5663\n",
      "Epoch 3892/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6063 - accuracy: 0.6545 - val_loss: 0.6566 - val_accuracy: 0.5623\n",
      "Epoch 3893/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6063 - accuracy: 0.6548 - val_loss: 0.6606 - val_accuracy: 0.5550\n",
      "Epoch 3894/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6062 - accuracy: 0.6557 - val_loss: 0.6506 - val_accuracy: 0.5698\n",
      "Epoch 3895/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6065 - accuracy: 0.6534 - val_loss: 0.6681 - val_accuracy: 0.5482\n",
      "Epoch 3896/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6068 - accuracy: 0.6549 - val_loss: 0.6422 - val_accuracy: 0.5818\n",
      "Epoch 3897/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6072 - accuracy: 0.6511 - val_loss: 0.6798 - val_accuracy: 0.5332\n",
      "Epoch 3898/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6080 - accuracy: 0.6533 - val_loss: 0.6367 - val_accuracy: 0.5921\n",
      "Epoch 3899/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6084 - accuracy: 0.6496 - val_loss: 0.6864 - val_accuracy: 0.5230\n",
      "Epoch 3900/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6099 - accuracy: 0.6511 - val_loss: 0.6308 - val_accuracy: 0.6023\n",
      "Epoch 3901/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6093 - accuracy: 0.6492 - val_loss: 0.6858 - val_accuracy: 0.5241\n",
      "Epoch 3902/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6094 - accuracy: 0.6508 - val_loss: 0.6441 - val_accuracy: 0.5771\n",
      "Epoch 3903/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6076 - accuracy: 0.6499 - val_loss: 0.6627 - val_accuracy: 0.5552\n",
      "Epoch 3904/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6074 - accuracy: 0.6553 - val_loss: 0.6574 - val_accuracy: 0.5597\n",
      "Epoch 3905/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6067 - accuracy: 0.6548 - val_loss: 0.6460 - val_accuracy: 0.5745\n",
      "Epoch 3906/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6080 - accuracy: 0.6508 - val_loss: 0.6835 - val_accuracy: 0.5250\n",
      "Epoch 3907/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6088 - accuracy: 0.6518 - val_loss: 0.6279 - val_accuracy: 0.6072\n",
      "Epoch 3908/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6111 - accuracy: 0.6486 - val_loss: 0.7022 - val_accuracy: 0.5057\n",
      "Epoch 3909/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6129 - accuracy: 0.6474 - val_loss: 0.6299 - val_accuracy: 0.6008\n",
      "Epoch 3910/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6113 - accuracy: 0.6477 - val_loss: 0.6798 - val_accuracy: 0.5312\n",
      "Epoch 3911/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6097 - accuracy: 0.6523 - val_loss: 0.6454 - val_accuracy: 0.5773\n",
      "Epoch 3912/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6087 - accuracy: 0.6504 - val_loss: 0.6567 - val_accuracy: 0.5588\n",
      "Epoch 3913/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6067 - accuracy: 0.6542 - val_loss: 0.6706 - val_accuracy: 0.5415\n",
      "Epoch 3914/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6085 - accuracy: 0.6521 - val_loss: 0.6424 - val_accuracy: 0.5818\n",
      "Epoch 3915/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6076 - accuracy: 0.6519 - val_loss: 0.6704 - val_accuracy: 0.5451\n",
      "Epoch 3916/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6081 - accuracy: 0.6541 - val_loss: 0.6470 - val_accuracy: 0.5769\n",
      "Epoch 3917/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6069 - accuracy: 0.6522 - val_loss: 0.6669 - val_accuracy: 0.5440\n",
      "Epoch 3918/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6072 - accuracy: 0.6534 - val_loss: 0.6506 - val_accuracy: 0.5698\n",
      "Epoch 3919/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6064 - accuracy: 0.6536 - val_loss: 0.6555 - val_accuracy: 0.5632\n",
      "Epoch 3920/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6066 - accuracy: 0.6541 - val_loss: 0.6635 - val_accuracy: 0.5532\n",
      "Epoch 3921/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6064 - accuracy: 0.6544 - val_loss: 0.6471 - val_accuracy: 0.5734\n",
      "Epoch 3922/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6069 - accuracy: 0.6515 - val_loss: 0.6713 - val_accuracy: 0.5438\n",
      "Epoch 3923/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6076 - accuracy: 0.6548 - val_loss: 0.6384 - val_accuracy: 0.5902\n",
      "Epoch 3924/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6079 - accuracy: 0.6516 - val_loss: 0.6816 - val_accuracy: 0.5320\n",
      "Epoch 3925/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6085 - accuracy: 0.6525 - val_loss: 0.6414 - val_accuracy: 0.5824\n",
      "Epoch 3926/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6081 - accuracy: 0.6501 - val_loss: 0.6748 - val_accuracy: 0.5409\n",
      "Epoch 3927/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6087 - accuracy: 0.6539 - val_loss: 0.6407 - val_accuracy: 0.5868\n",
      "Epoch 3928/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6081 - accuracy: 0.6515 - val_loss: 0.6685 - val_accuracy: 0.5453\n",
      "Epoch 3929/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6077 - accuracy: 0.6525 - val_loss: 0.6567 - val_accuracy: 0.5605\n",
      "Epoch 3930/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6073 - accuracy: 0.6522 - val_loss: 0.6581 - val_accuracy: 0.5612\n",
      "Epoch 3931/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6077 - accuracy: 0.6534 - val_loss: 0.6580 - val_accuracy: 0.5608\n",
      "Epoch 3932/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6075 - accuracy: 0.6541 - val_loss: 0.6501 - val_accuracy: 0.5685\n",
      "Epoch 3933/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6071 - accuracy: 0.6514 - val_loss: 0.6697 - val_accuracy: 0.5455\n",
      "Epoch 3934/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6071 - accuracy: 0.6545 - val_loss: 0.6467 - val_accuracy: 0.5753\n",
      "Epoch 3935/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6074 - accuracy: 0.6526 - val_loss: 0.6694 - val_accuracy: 0.5460\n",
      "Epoch 3936/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6072 - accuracy: 0.6544 - val_loss: 0.6424 - val_accuracy: 0.5800\n",
      "Epoch 3937/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6074 - accuracy: 0.6508 - val_loss: 0.6752 - val_accuracy: 0.5389\n",
      "Epoch 3938/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6073 - accuracy: 0.6542 - val_loss: 0.6400 - val_accuracy: 0.5862\n",
      "Epoch 3939/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6077 - accuracy: 0.6512 - val_loss: 0.6798 - val_accuracy: 0.5338\n",
      "Epoch 3940/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6080 - accuracy: 0.6530 - val_loss: 0.6376 - val_accuracy: 0.5893\n",
      "Epoch 3941/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6082 - accuracy: 0.6500 - val_loss: 0.6818 - val_accuracy: 0.5294\n",
      "Epoch 3942/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6083 - accuracy: 0.6532 - val_loss: 0.6362 - val_accuracy: 0.5941\n",
      "Epoch 3943/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6081 - accuracy: 0.6519 - val_loss: 0.6798 - val_accuracy: 0.5331\n",
      "Epoch 3944/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6083 - accuracy: 0.6524 - val_loss: 0.6432 - val_accuracy: 0.5800\n",
      "Epoch 3945/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6076 - accuracy: 0.6501 - val_loss: 0.6697 - val_accuracy: 0.5477\n",
      "Epoch 3946/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6074 - accuracy: 0.6545 - val_loss: 0.6499 - val_accuracy: 0.5720\n",
      "Epoch 3947/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6066 - accuracy: 0.6539 - val_loss: 0.6558 - val_accuracy: 0.5634\n",
      "Epoch 3948/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6069 - accuracy: 0.6524 - val_loss: 0.6649 - val_accuracy: 0.5521\n",
      "Epoch 3949/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6065 - accuracy: 0.6552 - val_loss: 0.6462 - val_accuracy: 0.5787\n",
      "Epoch 3950/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6074 - accuracy: 0.6538 - val_loss: 0.6762 - val_accuracy: 0.5356\n",
      "Epoch 3951/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6077 - accuracy: 0.6538 - val_loss: 0.6332 - val_accuracy: 0.5943\n",
      "Epoch 3952/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6089 - accuracy: 0.6491 - val_loss: 0.6916 - val_accuracy: 0.5172\n",
      "Epoch 3953/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6100 - accuracy: 0.6510 - val_loss: 0.6312 - val_accuracy: 0.6041\n",
      "Epoch 3954/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6102 - accuracy: 0.6497 - val_loss: 0.6873 - val_accuracy: 0.5216\n",
      "Epoch 3955/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6100 - accuracy: 0.6509 - val_loss: 0.6386 - val_accuracy: 0.5870\n",
      "Epoch 3956/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6087 - accuracy: 0.6490 - val_loss: 0.6700 - val_accuracy: 0.5468\n",
      "Epoch 3957/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6077 - accuracy: 0.6538 - val_loss: 0.6570 - val_accuracy: 0.5596\n",
      "Epoch 3958/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6070 - accuracy: 0.6545 - val_loss: 0.6463 - val_accuracy: 0.5745\n",
      "Epoch 3959/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6076 - accuracy: 0.6498 - val_loss: 0.6755 - val_accuracy: 0.5374\n",
      "Epoch 3960/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6079 - accuracy: 0.6527 - val_loss: 0.6386 - val_accuracy: 0.5915\n",
      "Epoch 3961/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6088 - accuracy: 0.6519 - val_loss: 0.6883 - val_accuracy: 0.5206\n",
      "Epoch 3962/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6097 - accuracy: 0.6506 - val_loss: 0.6281 - val_accuracy: 0.6036\n",
      "Epoch 3963/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6097 - accuracy: 0.6487 - val_loss: 0.6862 - val_accuracy: 0.5230\n",
      "Epoch 3964/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6090 - accuracy: 0.6511 - val_loss: 0.6406 - val_accuracy: 0.5855\n",
      "Epoch 3965/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6078 - accuracy: 0.6537 - val_loss: 0.6662 - val_accuracy: 0.5499\n",
      "Epoch 3966/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6067 - accuracy: 0.6550 - val_loss: 0.6546 - val_accuracy: 0.5634\n",
      "Epoch 3967/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6063 - accuracy: 0.6537 - val_loss: 0.6504 - val_accuracy: 0.5683\n",
      "Epoch 3968/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6065 - accuracy: 0.6542 - val_loss: 0.6726 - val_accuracy: 0.5404\n",
      "Epoch 3969/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6070 - accuracy: 0.6560 - val_loss: 0.6345 - val_accuracy: 0.5944\n",
      "Epoch 3970/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6080 - accuracy: 0.6497 - val_loss: 0.6855 - val_accuracy: 0.5248\n",
      "Epoch 3971/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6087 - accuracy: 0.6516 - val_loss: 0.6352 - val_accuracy: 0.5961\n",
      "Epoch 3972/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6088 - accuracy: 0.6509 - val_loss: 0.6848 - val_accuracy: 0.5252\n",
      "Epoch 3973/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6093 - accuracy: 0.6514 - val_loss: 0.6341 - val_accuracy: 0.5944\n",
      "Epoch 3974/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6081 - accuracy: 0.6498 - val_loss: 0.6739 - val_accuracy: 0.5376\n",
      "Epoch 3975/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6072 - accuracy: 0.6535 - val_loss: 0.6536 - val_accuracy: 0.5654\n",
      "Epoch 3976/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6060 - accuracy: 0.6548 - val_loss: 0.6494 - val_accuracy: 0.5722\n",
      "Epoch 3977/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6065 - accuracy: 0.6527 - val_loss: 0.6697 - val_accuracy: 0.5438\n",
      "Epoch 3978/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6067 - accuracy: 0.6542 - val_loss: 0.6400 - val_accuracy: 0.5875\n",
      "Epoch 3979/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6082 - accuracy: 0.6520 - val_loss: 0.6887 - val_accuracy: 0.5185\n",
      "Epoch 3980/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6096 - accuracy: 0.6506 - val_loss: 0.6256 - val_accuracy: 0.6100\n",
      "Epoch 3981/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6101 - accuracy: 0.6492 - val_loss: 0.6929 - val_accuracy: 0.5164\n",
      "Epoch 3982/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6102 - accuracy: 0.6508 - val_loss: 0.6399 - val_accuracy: 0.5881\n",
      "Epoch 3983/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6082 - accuracy: 0.6522 - val_loss: 0.6666 - val_accuracy: 0.5471\n",
      "Epoch 3984/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6074 - accuracy: 0.6539 - val_loss: 0.6534 - val_accuracy: 0.5647\n",
      "Epoch 3985/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6064 - accuracy: 0.6535 - val_loss: 0.6487 - val_accuracy: 0.5731\n",
      "Epoch 3986/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6074 - accuracy: 0.6536 - val_loss: 0.6822 - val_accuracy: 0.5298\n",
      "Epoch 3987/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6080 - accuracy: 0.6524 - val_loss: 0.6275 - val_accuracy: 0.6049\n",
      "Epoch 3988/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6102 - accuracy: 0.6487 - val_loss: 0.6978 - val_accuracy: 0.5090\n",
      "Epoch 3989/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6114 - accuracy: 0.6494 - val_loss: 0.6325 - val_accuracy: 0.5985\n",
      "Epoch 3990/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6100 - accuracy: 0.6499 - val_loss: 0.6782 - val_accuracy: 0.5354\n",
      "Epoch 3991/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6086 - accuracy: 0.6526 - val_loss: 0.6448 - val_accuracy: 0.5778\n",
      "Epoch 3992/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6073 - accuracy: 0.6506 - val_loss: 0.6565 - val_accuracy: 0.5605\n",
      "Epoch 3993/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6066 - accuracy: 0.6546 - val_loss: 0.6733 - val_accuracy: 0.5400\n",
      "Epoch 3994/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6070 - accuracy: 0.6535 - val_loss: 0.6340 - val_accuracy: 0.5954\n",
      "Epoch 3995/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6085 - accuracy: 0.6498 - val_loss: 0.6876 - val_accuracy: 0.5194\n",
      "Epoch 3996/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6096 - accuracy: 0.6509 - val_loss: 0.6324 - val_accuracy: 0.5988\n",
      "Epoch 3997/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6096 - accuracy: 0.6498 - val_loss: 0.6852 - val_accuracy: 0.5248\n",
      "Epoch 3998/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6090 - accuracy: 0.6517 - val_loss: 0.6372 - val_accuracy: 0.5884\n",
      "Epoch 3999/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6077 - accuracy: 0.6501 - val_loss: 0.6649 - val_accuracy: 0.5512\n",
      "Epoch 4000/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6061 - accuracy: 0.6558 - val_loss: 0.6611 - val_accuracy: 0.5555\n",
      "Epoch 4001/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6063 - accuracy: 0.6554 - val_loss: 0.6444 - val_accuracy: 0.5778\n",
      "Epoch 4002/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6066 - accuracy: 0.6528 - val_loss: 0.6740 - val_accuracy: 0.5378\n",
      "Epoch 4003/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6073 - accuracy: 0.6545 - val_loss: 0.6377 - val_accuracy: 0.5917\n",
      "Epoch 4004/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6078 - accuracy: 0.6515 - val_loss: 0.6843 - val_accuracy: 0.5259\n",
      "Epoch 4005/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6084 - accuracy: 0.6520 - val_loss: 0.6353 - val_accuracy: 0.5913\n",
      "Epoch 4006/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6078 - accuracy: 0.6492 - val_loss: 0.6730 - val_accuracy: 0.5395\n",
      "Epoch 4007/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6068 - accuracy: 0.6548 - val_loss: 0.6476 - val_accuracy: 0.5756\n",
      "Epoch 4008/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6062 - accuracy: 0.6542 - val_loss: 0.6598 - val_accuracy: 0.5581\n",
      "Epoch 4009/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6059 - accuracy: 0.6551 - val_loss: 0.6588 - val_accuracy: 0.5581\n",
      "Epoch 4010/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6058 - accuracy: 0.6555 - val_loss: 0.6491 - val_accuracy: 0.5729\n",
      "Epoch 4011/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6061 - accuracy: 0.6541 - val_loss: 0.6691 - val_accuracy: 0.5444\n",
      "Epoch 4012/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6063 - accuracy: 0.6552 - val_loss: 0.6412 - val_accuracy: 0.5833\n",
      "Epoch 4013/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6067 - accuracy: 0.6511 - val_loss: 0.6758 - val_accuracy: 0.5385\n",
      "Epoch 4014/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6069 - accuracy: 0.6542 - val_loss: 0.6408 - val_accuracy: 0.5855\n",
      "Epoch 4015/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6070 - accuracy: 0.6531 - val_loss: 0.6765 - val_accuracy: 0.5371\n",
      "Epoch 4016/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6072 - accuracy: 0.6539 - val_loss: 0.6393 - val_accuracy: 0.5840\n",
      "Epoch 4017/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6069 - accuracy: 0.6511 - val_loss: 0.6726 - val_accuracy: 0.5449\n",
      "Epoch 4018/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6067 - accuracy: 0.6558 - val_loss: 0.6480 - val_accuracy: 0.5760\n",
      "Epoch 4019/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6061 - accuracy: 0.6543 - val_loss: 0.6618 - val_accuracy: 0.5574\n",
      "Epoch 4020/15000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6060 - accuracy: 0.6545 - val_loss: 0.6567 - val_accuracy: 0.5627\n",
      "Epoch 4021/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6056 - accuracy: 0.6559 - val_loss: 0.6507 - val_accuracy: 0.5698\n",
      "Epoch 4022/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6061 - accuracy: 0.6540 - val_loss: 0.6703 - val_accuracy: 0.5442\n",
      "Epoch 4023/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6062 - accuracy: 0.6554 - val_loss: 0.6388 - val_accuracy: 0.5860\n",
      "Epoch 4024/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6073 - accuracy: 0.6506 - val_loss: 0.6860 - val_accuracy: 0.5263\n",
      "Epoch 4025/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6085 - accuracy: 0.6517 - val_loss: 0.6310 - val_accuracy: 0.6041\n",
      "Epoch 4026/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6090 - accuracy: 0.6505 - val_loss: 0.6903 - val_accuracy: 0.5210\n",
      "Epoch 4027/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6099 - accuracy: 0.6505 - val_loss: 0.6356 - val_accuracy: 0.5937\n",
      "Epoch 4028/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6085 - accuracy: 0.6493 - val_loss: 0.6740 - val_accuracy: 0.5415\n",
      "Epoch 4029/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6076 - accuracy: 0.6543 - val_loss: 0.6513 - val_accuracy: 0.5689\n",
      "Epoch 4030/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6064 - accuracy: 0.6548 - val_loss: 0.6509 - val_accuracy: 0.5680\n",
      "Epoch 4031/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6071 - accuracy: 0.6505 - val_loss: 0.6737 - val_accuracy: 0.5393\n",
      "Epoch 4032/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6069 - accuracy: 0.6539 - val_loss: 0.6371 - val_accuracy: 0.5963\n",
      "Epoch 4033/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6089 - accuracy: 0.6516 - val_loss: 0.6909 - val_accuracy: 0.5168\n",
      "Epoch 4034/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6097 - accuracy: 0.6501 - val_loss: 0.6267 - val_accuracy: 0.6074\n",
      "Epoch 4035/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6106 - accuracy: 0.6478 - val_loss: 0.6918 - val_accuracy: 0.5168\n",
      "Epoch 4036/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6100 - accuracy: 0.6505 - val_loss: 0.6370 - val_accuracy: 0.5939\n",
      "Epoch 4037/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6087 - accuracy: 0.6525 - val_loss: 0.6698 - val_accuracy: 0.5444\n",
      "Epoch 4038/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6071 - accuracy: 0.6535 - val_loss: 0.6556 - val_accuracy: 0.5607\n",
      "Epoch 4039/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6067 - accuracy: 0.6522 - val_loss: 0.6480 - val_accuracy: 0.5733\n",
      "Epoch 4040/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6067 - accuracy: 0.6543 - val_loss: 0.6744 - val_accuracy: 0.5389\n",
      "Epoch 4041/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6071 - accuracy: 0.6548 - val_loss: 0.6362 - val_accuracy: 0.5906\n",
      "Epoch 4042/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6078 - accuracy: 0.6503 - val_loss: 0.6823 - val_accuracy: 0.5269\n",
      "Epoch 4043/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6081 - accuracy: 0.6532 - val_loss: 0.6351 - val_accuracy: 0.5976\n",
      "Epoch 4044/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6082 - accuracy: 0.6519 - val_loss: 0.6819 - val_accuracy: 0.5290\n",
      "Epoch 4045/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6078 - accuracy: 0.6531 - val_loss: 0.6391 - val_accuracy: 0.5857\n",
      "Epoch 4046/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6071 - accuracy: 0.6498 - val_loss: 0.6695 - val_accuracy: 0.5457\n",
      "Epoch 4047/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6062 - accuracy: 0.6562 - val_loss: 0.6489 - val_accuracy: 0.5723\n",
      "Epoch 4048/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6059 - accuracy: 0.6542 - val_loss: 0.6568 - val_accuracy: 0.5625\n",
      "Epoch 4049/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6056 - accuracy: 0.6550 - val_loss: 0.6597 - val_accuracy: 0.5585\n",
      "Epoch 4050/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6056 - accuracy: 0.6551 - val_loss: 0.6508 - val_accuracy: 0.5692\n",
      "Epoch 4051/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6057 - accuracy: 0.6553 - val_loss: 0.6678 - val_accuracy: 0.5482\n",
      "Epoch 4052/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6059 - accuracy: 0.6567 - val_loss: 0.6419 - val_accuracy: 0.5824\n",
      "Epoch 4053/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6062 - accuracy: 0.6512 - val_loss: 0.6743 - val_accuracy: 0.5404\n",
      "Epoch 4054/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6065 - accuracy: 0.6549 - val_loss: 0.6405 - val_accuracy: 0.5877\n",
      "Epoch 4055/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6067 - accuracy: 0.6524 - val_loss: 0.6775 - val_accuracy: 0.5367\n",
      "Epoch 4056/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6071 - accuracy: 0.6544 - val_loss: 0.6377 - val_accuracy: 0.5873\n",
      "Epoch 4057/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6069 - accuracy: 0.6505 - val_loss: 0.6771 - val_accuracy: 0.5364\n",
      "Epoch 4058/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6068 - accuracy: 0.6543 - val_loss: 0.6427 - val_accuracy: 0.5833\n",
      "Epoch 4059/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6063 - accuracy: 0.6529 - val_loss: 0.6689 - val_accuracy: 0.5442\n",
      "Epoch 4060/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6062 - accuracy: 0.6544 - val_loss: 0.6481 - val_accuracy: 0.5769\n",
      "Epoch 4061/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6056 - accuracy: 0.6536 - val_loss: 0.6620 - val_accuracy: 0.5563\n",
      "Epoch 4062/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6056 - accuracy: 0.6557 - val_loss: 0.6571 - val_accuracy: 0.5627\n",
      "Epoch 4063/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6053 - accuracy: 0.6561 - val_loss: 0.6508 - val_accuracy: 0.5714\n",
      "Epoch 4064/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6056 - accuracy: 0.6533 - val_loss: 0.6666 - val_accuracy: 0.5506\n",
      "Epoch 4065/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6056 - accuracy: 0.6555 - val_loss: 0.6451 - val_accuracy: 0.5804\n",
      "Epoch 4066/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6062 - accuracy: 0.6541 - val_loss: 0.6758 - val_accuracy: 0.5376\n",
      "Epoch 4067/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6068 - accuracy: 0.6544 - val_loss: 0.6355 - val_accuracy: 0.5917\n",
      "Epoch 4068/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6072 - accuracy: 0.6506 - val_loss: 0.6836 - val_accuracy: 0.5281\n",
      "Epoch 4069/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6079 - accuracy: 0.6524 - val_loss: 0.6368 - val_accuracy: 0.5944\n",
      "Epoch 4070/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6074 - accuracy: 0.6524 - val_loss: 0.6793 - val_accuracy: 0.5332\n",
      "Epoch 4071/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6078 - accuracy: 0.6531 - val_loss: 0.6407 - val_accuracy: 0.5839\n",
      "Epoch 4072/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6066 - accuracy: 0.6507 - val_loss: 0.6691 - val_accuracy: 0.5479\n",
      "Epoch 4073/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6066 - accuracy: 0.6550 - val_loss: 0.6547 - val_accuracy: 0.5650\n",
      "Epoch 4074/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6055 - accuracy: 0.6555 - val_loss: 0.6488 - val_accuracy: 0.5698\n",
      "Epoch 4075/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6064 - accuracy: 0.6510 - val_loss: 0.6713 - val_accuracy: 0.5440\n",
      "Epoch 4076/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6061 - accuracy: 0.6544 - val_loss: 0.6405 - val_accuracy: 0.5908\n",
      "Epoch 4077/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6079 - accuracy: 0.6529 - val_loss: 0.6900 - val_accuracy: 0.5199\n",
      "Epoch 4078/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6093 - accuracy: 0.6513 - val_loss: 0.6238 - val_accuracy: 0.6160\n",
      "Epoch 4079/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6105 - accuracy: 0.6489 - val_loss: 0.6971 - val_accuracy: 0.5126\n",
      "Epoch 4080/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6109 - accuracy: 0.6488 - val_loss: 0.6364 - val_accuracy: 0.5966\n",
      "Epoch 4081/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6091 - accuracy: 0.6529 - val_loss: 0.6707 - val_accuracy: 0.5427\n",
      "Epoch 4082/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6076 - accuracy: 0.6520 - val_loss: 0.6546 - val_accuracy: 0.5638\n",
      "Epoch 4083/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6070 - accuracy: 0.6505 - val_loss: 0.6496 - val_accuracy: 0.5714\n",
      "Epoch 4084/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6067 - accuracy: 0.6552 - val_loss: 0.6778 - val_accuracy: 0.5338\n",
      "Epoch 4085/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6077 - accuracy: 0.6542 - val_loss: 0.6328 - val_accuracy: 0.5959\n",
      "Epoch 4086/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6077 - accuracy: 0.6507 - val_loss: 0.6819 - val_accuracy: 0.5307\n",
      "Epoch 4087/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6081 - accuracy: 0.6530 - val_loss: 0.6399 - val_accuracy: 0.5890\n",
      "Epoch 4088/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6071 - accuracy: 0.6533 - val_loss: 0.6732 - val_accuracy: 0.5395\n",
      "Epoch 4089/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6064 - accuracy: 0.6557 - val_loss: 0.6438 - val_accuracy: 0.5786\n",
      "Epoch 4090/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6059 - accuracy: 0.6526 - val_loss: 0.6608 - val_accuracy: 0.5555\n",
      "Epoch 4091/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6053 - accuracy: 0.6556 - val_loss: 0.6573 - val_accuracy: 0.5614\n",
      "Epoch 4092/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6053 - accuracy: 0.6561 - val_loss: 0.6518 - val_accuracy: 0.5703\n",
      "Epoch 4093/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6053 - accuracy: 0.6555 - val_loss: 0.6649 - val_accuracy: 0.5490\n",
      "Epoch 4094/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6056 - accuracy: 0.6551 - val_loss: 0.6442 - val_accuracy: 0.5804\n",
      "Epoch 4095/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6059 - accuracy: 0.6536 - val_loss: 0.6737 - val_accuracy: 0.5407\n",
      "Epoch 4096/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6064 - accuracy: 0.6556 - val_loss: 0.6386 - val_accuracy: 0.5882\n",
      "Epoch 4097/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6065 - accuracy: 0.6518 - val_loss: 0.6779 - val_accuracy: 0.5358\n",
      "Epoch 4098/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6069 - accuracy: 0.6538 - val_loss: 0.6402 - val_accuracy: 0.5868\n",
      "Epoch 4099/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6066 - accuracy: 0.6521 - val_loss: 0.6768 - val_accuracy: 0.5367\n",
      "Epoch 4100/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6069 - accuracy: 0.6549 - val_loss: 0.6402 - val_accuracy: 0.5857\n",
      "Epoch 4101/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6063 - accuracy: 0.6521 - val_loss: 0.6719 - val_accuracy: 0.5440\n",
      "Epoch 4102/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6063 - accuracy: 0.6545 - val_loss: 0.6466 - val_accuracy: 0.5771\n",
      "Epoch 4103/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6054 - accuracy: 0.6543 - val_loss: 0.6619 - val_accuracy: 0.5564\n",
      "Epoch 4104/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6056 - accuracy: 0.6558 - val_loss: 0.6563 - val_accuracy: 0.5634\n",
      "Epoch 4105/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6050 - accuracy: 0.6558 - val_loss: 0.6531 - val_accuracy: 0.5670\n",
      "Epoch 4106/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6054 - accuracy: 0.6555 - val_loss: 0.6662 - val_accuracy: 0.5486\n",
      "Epoch 4107/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6055 - accuracy: 0.6556 - val_loss: 0.6407 - val_accuracy: 0.5859\n",
      "Epoch 4108/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6063 - accuracy: 0.6521 - val_loss: 0.6815 - val_accuracy: 0.5311\n",
      "Epoch 4109/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6071 - accuracy: 0.6538 - val_loss: 0.6348 - val_accuracy: 0.5963\n",
      "Epoch 4110/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6079 - accuracy: 0.6506 - val_loss: 0.6903 - val_accuracy: 0.5190\n",
      "Epoch 4111/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6099 - accuracy: 0.6502 - val_loss: 0.6268 - val_accuracy: 0.6096\n",
      "Epoch 4112/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6094 - accuracy: 0.6498 - val_loss: 0.6896 - val_accuracy: 0.5214\n",
      "Epoch 4113/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6093 - accuracy: 0.6514 - val_loss: 0.6445 - val_accuracy: 0.5809\n",
      "Epoch 4114/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6068 - accuracy: 0.6512 - val_loss: 0.6595 - val_accuracy: 0.5599\n",
      "Epoch 4115/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6071 - accuracy: 0.6544 - val_loss: 0.6634 - val_accuracy: 0.5554\n",
      "Epoch 4116/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6065 - accuracy: 0.6562 - val_loss: 0.6399 - val_accuracy: 0.5846\n",
      "Epoch 4117/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6078 - accuracy: 0.6511 - val_loss: 0.6923 - val_accuracy: 0.5185\n",
      "Epoch 4118/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6094 - accuracy: 0.6511 - val_loss: 0.6263 - val_accuracy: 0.6111\n",
      "Epoch 4119/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6103 - accuracy: 0.6489 - val_loss: 0.6981 - val_accuracy: 0.5097\n",
      "Epoch 4120/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6107 - accuracy: 0.6495 - val_loss: 0.6333 - val_accuracy: 0.5972\n",
      "Epoch 4121/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6083 - accuracy: 0.6494 - val_loss: 0.6696 - val_accuracy: 0.5437\n",
      "Epoch 4122/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6067 - accuracy: 0.6550 - val_loss: 0.6502 - val_accuracy: 0.5705\n",
      "Epoch 4123/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6058 - accuracy: 0.6550 - val_loss: 0.6509 - val_accuracy: 0.5700\n",
      "Epoch 4124/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6056 - accuracy: 0.6556 - val_loss: 0.6765 - val_accuracy: 0.5364\n",
      "Epoch 4125/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6066 - accuracy: 0.6545 - val_loss: 0.6330 - val_accuracy: 0.5965\n",
      "Epoch 4126/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6075 - accuracy: 0.6513 - val_loss: 0.6872 - val_accuracy: 0.5241\n",
      "Epoch 4127/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6085 - accuracy: 0.6511 - val_loss: 0.6338 - val_accuracy: 0.5983\n",
      "Epoch 4128/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6079 - accuracy: 0.6506 - val_loss: 0.6794 - val_accuracy: 0.5323\n",
      "Epoch 4129/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6074 - accuracy: 0.6539 - val_loss: 0.6392 - val_accuracy: 0.5864\n",
      "Epoch 4130/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6062 - accuracy: 0.6519 - val_loss: 0.6675 - val_accuracy: 0.5502\n",
      "Epoch 4131/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6055 - accuracy: 0.6562 - val_loss: 0.6558 - val_accuracy: 0.5634\n",
      "Epoch 4132/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6050 - accuracy: 0.6556 - val_loss: 0.6491 - val_accuracy: 0.5734\n",
      "Epoch 4133/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6053 - accuracy: 0.6545 - val_loss: 0.6659 - val_accuracy: 0.5491\n",
      "Epoch 4134/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6054 - accuracy: 0.6564 - val_loss: 0.6436 - val_accuracy: 0.5835\n",
      "Epoch 4135/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6061 - accuracy: 0.6540 - val_loss: 0.6789 - val_accuracy: 0.5345\n",
      "Epoch 4136/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6068 - accuracy: 0.6546 - val_loss: 0.6340 - val_accuracy: 0.5961\n",
      "Epoch 4137/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6071 - accuracy: 0.6507 - val_loss: 0.6823 - val_accuracy: 0.5280\n",
      "Epoch 4138/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6076 - accuracy: 0.6529 - val_loss: 0.6374 - val_accuracy: 0.5915\n",
      "Epoch 4139/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6069 - accuracy: 0.6526 - val_loss: 0.6761 - val_accuracy: 0.5393\n",
      "Epoch 4140/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6070 - accuracy: 0.6538 - val_loss: 0.6451 - val_accuracy: 0.5789\n",
      "Epoch 4141/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6058 - accuracy: 0.6526 - val_loss: 0.6642 - val_accuracy: 0.5546\n",
      "Epoch 4142/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6058 - accuracy: 0.6566 - val_loss: 0.6589 - val_accuracy: 0.5601\n",
      "Epoch 4143/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6050 - accuracy: 0.6569 - val_loss: 0.6426 - val_accuracy: 0.5809\n",
      "Epoch 4144/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6062 - accuracy: 0.6516 - val_loss: 0.6792 - val_accuracy: 0.5340\n",
      "Epoch 4145/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6065 - accuracy: 0.6544 - val_loss: 0.6370 - val_accuracy: 0.5946\n",
      "Epoch 4146/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6082 - accuracy: 0.6528 - val_loss: 0.6904 - val_accuracy: 0.5194\n",
      "Epoch 4147/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6097 - accuracy: 0.6507 - val_loss: 0.6255 - val_accuracy: 0.6118\n",
      "Epoch 4148/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6095 - accuracy: 0.6492 - val_loss: 0.6894 - val_accuracy: 0.5192\n",
      "Epoch 4149/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6089 - accuracy: 0.6517 - val_loss: 0.6454 - val_accuracy: 0.5817\n",
      "Epoch 4150/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6069 - accuracy: 0.6546 - val_loss: 0.6577 - val_accuracy: 0.5592\n",
      "Epoch 4151/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6068 - accuracy: 0.6527 - val_loss: 0.6633 - val_accuracy: 0.5521\n",
      "Epoch 4152/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6062 - accuracy: 0.6543 - val_loss: 0.6423 - val_accuracy: 0.5875\n",
      "Epoch 4153/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6078 - accuracy: 0.6538 - val_loss: 0.6906 - val_accuracy: 0.5172\n",
      "Epoch 4154/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6092 - accuracy: 0.6509 - val_loss: 0.6232 - val_accuracy: 0.6175\n",
      "Epoch 4155/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6100 - accuracy: 0.6509 - val_loss: 0.6938 - val_accuracy: 0.5161\n",
      "Epoch 4156/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6095 - accuracy: 0.6506 - val_loss: 0.6393 - val_accuracy: 0.5917\n",
      "Epoch 4157/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6077 - accuracy: 0.6537 - val_loss: 0.6660 - val_accuracy: 0.5504\n",
      "Epoch 4158/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6066 - accuracy: 0.6536 - val_loss: 0.6522 - val_accuracy: 0.5685\n",
      "Epoch 4159/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6058 - accuracy: 0.6537 - val_loss: 0.6506 - val_accuracy: 0.5725\n",
      "Epoch 4160/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6060 - accuracy: 0.6553 - val_loss: 0.6761 - val_accuracy: 0.5362\n",
      "Epoch 4161/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6064 - accuracy: 0.6541 - val_loss: 0.6319 - val_accuracy: 0.5985\n",
      "Epoch 4162/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6076 - accuracy: 0.6507 - val_loss: 0.6867 - val_accuracy: 0.5234\n",
      "Epoch 4163/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6081 - accuracy: 0.6516 - val_loss: 0.6372 - val_accuracy: 0.5924\n",
      "Epoch 4164/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6076 - accuracy: 0.6516 - val_loss: 0.6756 - val_accuracy: 0.5371\n",
      "Epoch 4165/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6069 - accuracy: 0.6547 - val_loss: 0.6394 - val_accuracy: 0.5839\n",
      "Epoch 4166/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6060 - accuracy: 0.6519 - val_loss: 0.6643 - val_accuracy: 0.5510\n",
      "Epoch 4167/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6053 - accuracy: 0.6553 - val_loss: 0.6631 - val_accuracy: 0.5555\n",
      "Epoch 4168/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6051 - accuracy: 0.6557 - val_loss: 0.6450 - val_accuracy: 0.5798\n",
      "Epoch 4169/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6055 - accuracy: 0.6539 - val_loss: 0.6700 - val_accuracy: 0.5424\n",
      "Epoch 4170/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6059 - accuracy: 0.6551 - val_loss: 0.6387 - val_accuracy: 0.5899\n",
      "Epoch 4171/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6070 - accuracy: 0.6520 - val_loss: 0.6847 - val_accuracy: 0.5269\n",
      "Epoch 4172/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6077 - accuracy: 0.6528 - val_loss: 0.6325 - val_accuracy: 0.6005\n",
      "Epoch 4173/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6075 - accuracy: 0.6512 - val_loss: 0.6811 - val_accuracy: 0.5318\n",
      "Epoch 4174/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6070 - accuracy: 0.6534 - val_loss: 0.6428 - val_accuracy: 0.5840\n",
      "Epoch 4175/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6061 - accuracy: 0.6540 - val_loss: 0.6646 - val_accuracy: 0.5532\n",
      "Epoch 4176/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6057 - accuracy: 0.6559 - val_loss: 0.6526 - val_accuracy: 0.5700\n",
      "Epoch 4177/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6052 - accuracy: 0.6553 - val_loss: 0.6550 - val_accuracy: 0.5649\n",
      "Epoch 4178/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6053 - accuracy: 0.6558 - val_loss: 0.6677 - val_accuracy: 0.5473\n",
      "Epoch 4179/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6052 - accuracy: 0.6559 - val_loss: 0.6395 - val_accuracy: 0.5859\n",
      "Epoch 4180/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6060 - accuracy: 0.6526 - val_loss: 0.6779 - val_accuracy: 0.5351\n",
      "Epoch 4181/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6064 - accuracy: 0.6545 - val_loss: 0.6385 - val_accuracy: 0.5923\n",
      "Epoch 4182/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6070 - accuracy: 0.6523 - val_loss: 0.6823 - val_accuracy: 0.5285\n",
      "Epoch 4183/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6075 - accuracy: 0.6533 - val_loss: 0.6331 - val_accuracy: 0.6003\n",
      "Epoch 4184/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6071 - accuracy: 0.6508 - val_loss: 0.6786 - val_accuracy: 0.5353\n",
      "Epoch 4185/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6066 - accuracy: 0.6538 - val_loss: 0.6484 - val_accuracy: 0.5760\n",
      "Epoch 4186/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6054 - accuracy: 0.6549 - val_loss: 0.6580 - val_accuracy: 0.5627\n",
      "Epoch 4187/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6054 - accuracy: 0.6555 - val_loss: 0.6594 - val_accuracy: 0.5594\n",
      "Epoch 4188/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6050 - accuracy: 0.6563 - val_loss: 0.6464 - val_accuracy: 0.5793\n",
      "Epoch 4189/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6061 - accuracy: 0.6549 - val_loss: 0.6810 - val_accuracy: 0.5301\n",
      "Epoch 4190/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6067 - accuracy: 0.6544 - val_loss: 0.6299 - val_accuracy: 0.6054\n",
      "Epoch 4191/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6082 - accuracy: 0.6506 - val_loss: 0.6926 - val_accuracy: 0.5175\n",
      "Epoch 4192/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6093 - accuracy: 0.6507 - val_loss: 0.6324 - val_accuracy: 0.6008\n",
      "Epoch 4193/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6083 - accuracy: 0.6507 - val_loss: 0.6810 - val_accuracy: 0.5311\n",
      "Epoch 4194/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6081 - accuracy: 0.6530 - val_loss: 0.6432 - val_accuracy: 0.5820\n",
      "Epoch 4195/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6066 - accuracy: 0.6512 - val_loss: 0.6598 - val_accuracy: 0.5590\n",
      "Epoch 4196/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6058 - accuracy: 0.6557 - val_loss: 0.6675 - val_accuracy: 0.5484\n",
      "Epoch 4197/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6055 - accuracy: 0.6551 - val_loss: 0.6362 - val_accuracy: 0.5915\n",
      "Epoch 4198/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6073 - accuracy: 0.6513 - val_loss: 0.6885 - val_accuracy: 0.5241\n",
      "Epoch 4199/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6083 - accuracy: 0.6513 - val_loss: 0.6318 - val_accuracy: 0.6019\n",
      "Epoch 4200/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6092 - accuracy: 0.6505 - val_loss: 0.6887 - val_accuracy: 0.5208\n",
      "Epoch 4201/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6088 - accuracy: 0.6519 - val_loss: 0.6321 - val_accuracy: 0.5994\n",
      "Epoch 4202/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6076 - accuracy: 0.6508 - val_loss: 0.6725 - val_accuracy: 0.5431\n",
      "Epoch 4203/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6058 - accuracy: 0.6549 - val_loss: 0.6563 - val_accuracy: 0.5652\n",
      "Epoch 4204/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6053 - accuracy: 0.6550 - val_loss: 0.6472 - val_accuracy: 0.5749\n",
      "Epoch 4205/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6054 - accuracy: 0.6541 - val_loss: 0.6707 - val_accuracy: 0.5429\n",
      "Epoch 4206/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6060 - accuracy: 0.6555 - val_loss: 0.6379 - val_accuracy: 0.5928\n",
      "Epoch 4207/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6068 - accuracy: 0.6534 - val_loss: 0.6852 - val_accuracy: 0.5272\n",
      "Epoch 4208/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6075 - accuracy: 0.6528 - val_loss: 0.6339 - val_accuracy: 0.5976\n",
      "Epoch 4209/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6070 - accuracy: 0.6511 - val_loss: 0.6760 - val_accuracy: 0.5356\n",
      "Epoch 4210/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6060 - accuracy: 0.6558 - val_loss: 0.6453 - val_accuracy: 0.5833\n",
      "Epoch 4211/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6054 - accuracy: 0.6557 - val_loss: 0.6620 - val_accuracy: 0.5535\n",
      "Epoch 4212/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6048 - accuracy: 0.6557 - val_loss: 0.6552 - val_accuracy: 0.5645\n",
      "Epoch 4213/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6046 - accuracy: 0.6560 - val_loss: 0.6531 - val_accuracy: 0.5689\n",
      "Epoch 4214/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6047 - accuracy: 0.6562 - val_loss: 0.6657 - val_accuracy: 0.5504\n",
      "Epoch 4215/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6049 - accuracy: 0.6561 - val_loss: 0.6425 - val_accuracy: 0.5833\n",
      "Epoch 4216/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6053 - accuracy: 0.6533 - val_loss: 0.6744 - val_accuracy: 0.5407\n",
      "Epoch 4217/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6057 - accuracy: 0.6560 - val_loss: 0.6394 - val_accuracy: 0.5913\n",
      "Epoch 4218/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6060 - accuracy: 0.6539 - val_loss: 0.6785 - val_accuracy: 0.5365\n",
      "Epoch 4219/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6064 - accuracy: 0.6548 - val_loss: 0.6366 - val_accuracy: 0.5906\n",
      "Epoch 4220/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6061 - accuracy: 0.6512 - val_loss: 0.6771 - val_accuracy: 0.5351\n",
      "Epoch 4221/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6059 - accuracy: 0.6552 - val_loss: 0.6441 - val_accuracy: 0.5824\n",
      "Epoch 4222/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6053 - accuracy: 0.6543 - val_loss: 0.6653 - val_accuracy: 0.5521\n",
      "Epoch 4223/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6049 - accuracy: 0.6556 - val_loss: 0.6509 - val_accuracy: 0.5722\n",
      "Epoch 4224/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6045 - accuracy: 0.6560 - val_loss: 0.6565 - val_accuracy: 0.5650\n",
      "Epoch 4225/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6045 - accuracy: 0.6567 - val_loss: 0.6630 - val_accuracy: 0.5548\n",
      "Epoch 4226/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6045 - accuracy: 0.6563 - val_loss: 0.6462 - val_accuracy: 0.5787\n",
      "Epoch 4227/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6049 - accuracy: 0.6542 - val_loss: 0.6700 - val_accuracy: 0.5451\n",
      "Epoch 4228/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6052 - accuracy: 0.6567 - val_loss: 0.6418 - val_accuracy: 0.5868\n",
      "Epoch 4229/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6055 - accuracy: 0.6545 - val_loss: 0.6764 - val_accuracy: 0.5371\n",
      "Epoch 4230/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6058 - accuracy: 0.6557 - val_loss: 0.6393 - val_accuracy: 0.5871\n",
      "Epoch 4231/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6057 - accuracy: 0.6524 - val_loss: 0.6751 - val_accuracy: 0.5373\n",
      "Epoch 4232/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6058 - accuracy: 0.6563 - val_loss: 0.6414 - val_accuracy: 0.5866\n",
      "Epoch 4233/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6053 - accuracy: 0.6541 - val_loss: 0.6703 - val_accuracy: 0.5446\n",
      "Epoch 4234/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6054 - accuracy: 0.6548 - val_loss: 0.6476 - val_accuracy: 0.5784\n",
      "Epoch 4235/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6047 - accuracy: 0.6551 - val_loss: 0.6632 - val_accuracy: 0.5570\n",
      "Epoch 4236/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6048 - accuracy: 0.6571 - val_loss: 0.6545 - val_accuracy: 0.5676\n",
      "Epoch 4237/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6043 - accuracy: 0.6571 - val_loss: 0.6521 - val_accuracy: 0.5692\n",
      "Epoch 4238/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6046 - accuracy: 0.6550 - val_loss: 0.6657 - val_accuracy: 0.5526\n",
      "Epoch 4239/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6045 - accuracy: 0.6568 - val_loss: 0.6467 - val_accuracy: 0.5800\n",
      "Epoch 4240/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6051 - accuracy: 0.6561 - val_loss: 0.6727 - val_accuracy: 0.5406\n",
      "Epoch 4241/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6056 - accuracy: 0.6551 - val_loss: 0.6359 - val_accuracy: 0.5934\n",
      "Epoch 4242/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6060 - accuracy: 0.6520 - val_loss: 0.6829 - val_accuracy: 0.5270\n",
      "Epoch 4243/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6069 - accuracy: 0.6539 - val_loss: 0.6364 - val_accuracy: 0.5959\n",
      "Epoch 4244/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6066 - accuracy: 0.6530 - val_loss: 0.6807 - val_accuracy: 0.5325\n",
      "Epoch 4245/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6070 - accuracy: 0.6539 - val_loss: 0.6386 - val_accuracy: 0.5886\n",
      "Epoch 4246/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6057 - accuracy: 0.6512 - val_loss: 0.6699 - val_accuracy: 0.5466\n",
      "Epoch 4247/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6057 - accuracy: 0.6558 - val_loss: 0.6535 - val_accuracy: 0.5678\n",
      "Epoch 4248/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6044 - accuracy: 0.6566 - val_loss: 0.6511 - val_accuracy: 0.5689\n",
      "Epoch 4249/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6052 - accuracy: 0.6528 - val_loss: 0.6693 - val_accuracy: 0.5451\n",
      "Epoch 4250/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6049 - accuracy: 0.6562 - val_loss: 0.6387 - val_accuracy: 0.5955\n",
      "Epoch 4251/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6069 - accuracy: 0.6548 - val_loss: 0.6902 - val_accuracy: 0.5217\n",
      "Epoch 4252/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6084 - accuracy: 0.6525 - val_loss: 0.6248 - val_accuracy: 0.6162\n",
      "Epoch 4253/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6098 - accuracy: 0.6494 - val_loss: 0.6983 - val_accuracy: 0.5082\n",
      "Epoch 4254/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6105 - accuracy: 0.6490 - val_loss: 0.6349 - val_accuracy: 0.6016\n",
      "Epoch 4255/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6085 - accuracy: 0.6535 - val_loss: 0.6707 - val_accuracy: 0.5457\n",
      "Epoch 4256/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6073 - accuracy: 0.6521 - val_loss: 0.6589 - val_accuracy: 0.5603\n",
      "Epoch 4257/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6069 - accuracy: 0.6508 - val_loss: 0.6498 - val_accuracy: 0.5751\n",
      "Epoch 4258/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6059 - accuracy: 0.6560 - val_loss: 0.6731 - val_accuracy: 0.5376\n",
      "Epoch 4259/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6068 - accuracy: 0.6547 - val_loss: 0.6368 - val_accuracy: 0.5901\n",
      "Epoch 4260/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6061 - accuracy: 0.6526 - val_loss: 0.6725 - val_accuracy: 0.5407\n",
      "Epoch 4261/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6059 - accuracy: 0.6543 - val_loss: 0.6478 - val_accuracy: 0.5765\n",
      "Epoch 4262/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6054 - accuracy: 0.6557 - val_loss: 0.6661 - val_accuracy: 0.5515\n",
      "Epoch 4263/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6048 - accuracy: 0.6566 - val_loss: 0.6486 - val_accuracy: 0.5744\n",
      "Epoch 4264/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6047 - accuracy: 0.6549 - val_loss: 0.6554 - val_accuracy: 0.5656\n",
      "Epoch 4265/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6043 - accuracy: 0.6558 - val_loss: 0.6601 - val_accuracy: 0.5603\n",
      "Epoch 4266/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6046 - accuracy: 0.6562 - val_loss: 0.6529 - val_accuracy: 0.5701\n",
      "Epoch 4267/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6043 - accuracy: 0.6565 - val_loss: 0.6610 - val_accuracy: 0.5563\n",
      "Epoch 4268/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6047 - accuracy: 0.6559 - val_loss: 0.6477 - val_accuracy: 0.5758\n",
      "Epoch 4269/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6044 - accuracy: 0.6557 - val_loss: 0.6679 - val_accuracy: 0.5502\n",
      "Epoch 4270/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6048 - accuracy: 0.6570 - val_loss: 0.6468 - val_accuracy: 0.5778\n",
      "Epoch 4271/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6047 - accuracy: 0.6552 - val_loss: 0.6672 - val_accuracy: 0.5486\n",
      "Epoch 4272/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6049 - accuracy: 0.6555 - val_loss: 0.6437 - val_accuracy: 0.5837\n",
      "Epoch 4273/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6049 - accuracy: 0.6543 - val_loss: 0.6728 - val_accuracy: 0.5409\n",
      "Epoch 4274/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6051 - accuracy: 0.6557 - val_loss: 0.6429 - val_accuracy: 0.5835\n",
      "Epoch 4275/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6052 - accuracy: 0.6538 - val_loss: 0.6735 - val_accuracy: 0.5402\n",
      "Epoch 4276/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6054 - accuracy: 0.6559 - val_loss: 0.6386 - val_accuracy: 0.5888\n",
      "Epoch 4277/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6054 - accuracy: 0.6537 - val_loss: 0.6769 - val_accuracy: 0.5378\n",
      "Epoch 4278/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6056 - accuracy: 0.6554 - val_loss: 0.6402 - val_accuracy: 0.5873\n",
      "Epoch 4279/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6055 - accuracy: 0.6530 - val_loss: 0.6775 - val_accuracy: 0.5376\n",
      "Epoch 4280/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6057 - accuracy: 0.6558 - val_loss: 0.6363 - val_accuracy: 0.5944\n",
      "Epoch 4281/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6057 - accuracy: 0.6534 - val_loss: 0.6792 - val_accuracy: 0.5347\n",
      "Epoch 4282/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6061 - accuracy: 0.6545 - val_loss: 0.6372 - val_accuracy: 0.5926\n",
      "Epoch 4283/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6059 - accuracy: 0.6523 - val_loss: 0.6820 - val_accuracy: 0.5289\n",
      "Epoch 4284/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6062 - accuracy: 0.6550 - val_loss: 0.6349 - val_accuracy: 0.5965\n",
      "Epoch 4285/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6060 - accuracy: 0.6526 - val_loss: 0.6806 - val_accuracy: 0.5329\n",
      "Epoch 4286/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6064 - accuracy: 0.6547 - val_loss: 0.6356 - val_accuracy: 0.5963\n",
      "Epoch 4287/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6059 - accuracy: 0.6524 - val_loss: 0.6809 - val_accuracy: 0.5307\n",
      "Epoch 4288/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6060 - accuracy: 0.6556 - val_loss: 0.6380 - val_accuracy: 0.5915\n",
      "Epoch 4289/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6055 - accuracy: 0.6532 - val_loss: 0.6751 - val_accuracy: 0.5400\n",
      "Epoch 4290/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6055 - accuracy: 0.6550 - val_loss: 0.6406 - val_accuracy: 0.5875\n",
      "Epoch 4291/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6051 - accuracy: 0.6537 - val_loss: 0.6732 - val_accuracy: 0.5400\n",
      "Epoch 4292/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6050 - accuracy: 0.6564 - val_loss: 0.6428 - val_accuracy: 0.5839\n",
      "Epoch 4293/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6047 - accuracy: 0.6547 - val_loss: 0.6680 - val_accuracy: 0.5473\n",
      "Epoch 4294/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6045 - accuracy: 0.6561 - val_loss: 0.6477 - val_accuracy: 0.5776\n",
      "Epoch 4295/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6043 - accuracy: 0.6558 - val_loss: 0.6651 - val_accuracy: 0.5517\n",
      "Epoch 4296/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6042 - accuracy: 0.6571 - val_loss: 0.6499 - val_accuracy: 0.5749\n",
      "Epoch 4297/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6041 - accuracy: 0.6564 - val_loss: 0.6608 - val_accuracy: 0.5594\n",
      "Epoch 4298/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6040 - accuracy: 0.6573 - val_loss: 0.6544 - val_accuracy: 0.5694\n",
      "Epoch 4299/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6039 - accuracy: 0.6568 - val_loss: 0.6589 - val_accuracy: 0.5599\n",
      "Epoch 4300/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6039 - accuracy: 0.6571 - val_loss: 0.6547 - val_accuracy: 0.5687\n",
      "Epoch 4301/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6039 - accuracy: 0.6564 - val_loss: 0.6577 - val_accuracy: 0.5641\n",
      "Epoch 4302/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6039 - accuracy: 0.6577 - val_loss: 0.6566 - val_accuracy: 0.5658\n",
      "Epoch 4303/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6038 - accuracy: 0.6575 - val_loss: 0.6565 - val_accuracy: 0.5639\n",
      "Epoch 4304/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6038 - accuracy: 0.6567 - val_loss: 0.6577 - val_accuracy: 0.5638\n",
      "Epoch 4305/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6038 - accuracy: 0.6575 - val_loss: 0.6547 - val_accuracy: 0.5676\n",
      "Epoch 4306/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6038 - accuracy: 0.6572 - val_loss: 0.6593 - val_accuracy: 0.5610\n",
      "Epoch 4307/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6038 - accuracy: 0.6574 - val_loss: 0.6534 - val_accuracy: 0.5705\n",
      "Epoch 4308/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6039 - accuracy: 0.6565 - val_loss: 0.6621 - val_accuracy: 0.5570\n",
      "Epoch 4309/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6039 - accuracy: 0.6574 - val_loss: 0.6497 - val_accuracy: 0.5753\n",
      "Epoch 4310/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6040 - accuracy: 0.6566 - val_loss: 0.6663 - val_accuracy: 0.5502\n",
      "Epoch 4311/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6042 - accuracy: 0.6565 - val_loss: 0.6445 - val_accuracy: 0.5817\n",
      "Epoch 4312/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6045 - accuracy: 0.6550 - val_loss: 0.6769 - val_accuracy: 0.5382\n",
      "Epoch 4313/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6053 - accuracy: 0.6564 - val_loss: 0.6328 - val_accuracy: 0.6012\n",
      "Epoch 4314/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6063 - accuracy: 0.6522 - val_loss: 0.6934 - val_accuracy: 0.5168\n",
      "Epoch 4315/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6086 - accuracy: 0.6511 - val_loss: 0.6245 - val_accuracy: 0.6182\n",
      "Epoch 4316/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6090 - accuracy: 0.6514 - val_loss: 0.7048 - val_accuracy: 0.5055\n",
      "Epoch 4317/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6112 - accuracy: 0.6482 - val_loss: 0.6271 - val_accuracy: 0.6140\n",
      "Epoch 4318/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6080 - accuracy: 0.6514 - val_loss: 0.6813 - val_accuracy: 0.5307\n",
      "Epoch 4319/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6063 - accuracy: 0.6545 - val_loss: 0.6439 - val_accuracy: 0.5833\n",
      "Epoch 4320/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6044 - accuracy: 0.6560 - val_loss: 0.6572 - val_accuracy: 0.5623\n",
      "Epoch 4321/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6038 - accuracy: 0.6571 - val_loss: 0.6656 - val_accuracy: 0.5513\n",
      "Epoch 4322/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6041 - accuracy: 0.6566 - val_loss: 0.6398 - val_accuracy: 0.5906\n",
      "Epoch 4323/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6052 - accuracy: 0.6542 - val_loss: 0.6859 - val_accuracy: 0.5239\n",
      "Epoch 4324/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6073 - accuracy: 0.6533 - val_loss: 0.6243 - val_accuracy: 0.6178\n",
      "Epoch 4325/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6085 - accuracy: 0.6516 - val_loss: 0.7038 - val_accuracy: 0.5038\n",
      "Epoch 4326/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6111 - accuracy: 0.6483 - val_loss: 0.6287 - val_accuracy: 0.6094\n",
      "Epoch 4327/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6079 - accuracy: 0.6507 - val_loss: 0.6780 - val_accuracy: 0.5347\n",
      "Epoch 4328/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6060 - accuracy: 0.6549 - val_loss: 0.6488 - val_accuracy: 0.5745\n",
      "Epoch 4329/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6042 - accuracy: 0.6554 - val_loss: 0.6493 - val_accuracy: 0.5742\n",
      "Epoch 4330/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6045 - accuracy: 0.6561 - val_loss: 0.6762 - val_accuracy: 0.5376\n",
      "Epoch 4331/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6053 - accuracy: 0.6557 - val_loss: 0.6292 - val_accuracy: 0.6091\n",
      "Epoch 4332/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6079 - accuracy: 0.6508 - val_loss: 0.7035 - val_accuracy: 0.5042\n",
      "Epoch 4333/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6110 - accuracy: 0.6486 - val_loss: 0.6233 - val_accuracy: 0.6206\n",
      "Epoch 4334/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6098 - accuracy: 0.6497 - val_loss: 0.6906 - val_accuracy: 0.5216\n",
      "Epoch 4335/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6091 - accuracy: 0.6513 - val_loss: 0.6405 - val_accuracy: 0.5857\n",
      "Epoch 4336/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6061 - accuracy: 0.6517 - val_loss: 0.6571 - val_accuracy: 0.5649\n",
      "Epoch 4337/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6053 - accuracy: 0.6568 - val_loss: 0.6763 - val_accuracy: 0.5342\n",
      "Epoch 4338/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6059 - accuracy: 0.6557 - val_loss: 0.6241 - val_accuracy: 0.6184\n",
      "Epoch 4339/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6088 - accuracy: 0.6506 - val_loss: 0.7046 - val_accuracy: 0.5013\n",
      "Epoch 4340/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6110 - accuracy: 0.6483 - val_loss: 0.6309 - val_accuracy: 0.6074\n",
      "Epoch 4341/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6090 - accuracy: 0.6512 - val_loss: 0.6776 - val_accuracy: 0.5347\n",
      "Epoch 4342/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6070 - accuracy: 0.6541 - val_loss: 0.6436 - val_accuracy: 0.5800\n",
      "Epoch 4343/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6051 - accuracy: 0.6532 - val_loss: 0.6534 - val_accuracy: 0.5689\n",
      "Epoch 4344/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6050 - accuracy: 0.6560 - val_loss: 0.6823 - val_accuracy: 0.5270\n",
      "Epoch 4345/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6063 - accuracy: 0.6541 - val_loss: 0.6233 - val_accuracy: 0.6204\n",
      "Epoch 4346/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6086 - accuracy: 0.6519 - val_loss: 0.7002 - val_accuracy: 0.5097\n",
      "Epoch 4347/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6101 - accuracy: 0.6496 - val_loss: 0.6350 - val_accuracy: 0.5976\n",
      "Epoch 4348/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6077 - accuracy: 0.6517 - val_loss: 0.6700 - val_accuracy: 0.5429\n",
      "Epoch 4349/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6060 - accuracy: 0.6554 - val_loss: 0.6499 - val_accuracy: 0.5711\n",
      "Epoch 4350/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6047 - accuracy: 0.6550 - val_loss: 0.6460 - val_accuracy: 0.5787\n",
      "Epoch 4351/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6055 - accuracy: 0.6560 - val_loss: 0.6880 - val_accuracy: 0.5214\n",
      "Epoch 4352/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6070 - accuracy: 0.6531 - val_loss: 0.6249 - val_accuracy: 0.6153\n",
      "Epoch 4353/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6088 - accuracy: 0.6506 - val_loss: 0.6971 - val_accuracy: 0.5126\n",
      "Epoch 4354/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6094 - accuracy: 0.6502 - val_loss: 0.6367 - val_accuracy: 0.5943\n",
      "Epoch 4355/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6068 - accuracy: 0.6520 - val_loss: 0.6641 - val_accuracy: 0.5539\n",
      "Epoch 4356/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6052 - accuracy: 0.6568 - val_loss: 0.6569 - val_accuracy: 0.5649\n",
      "Epoch 4357/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6047 - accuracy: 0.6567 - val_loss: 0.6428 - val_accuracy: 0.5844\n",
      "Epoch 4358/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6056 - accuracy: 0.6546 - val_loss: 0.6885 - val_accuracy: 0.5225\n",
      "Epoch 4359/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6071 - accuracy: 0.6526 - val_loss: 0.6278 - val_accuracy: 0.6103\n",
      "Epoch 4360/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6079 - accuracy: 0.6509 - val_loss: 0.6880 - val_accuracy: 0.5214\n",
      "Epoch 4361/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6076 - accuracy: 0.6532 - val_loss: 0.6397 - val_accuracy: 0.5901\n",
      "Epoch 4362/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6056 - accuracy: 0.6529 - val_loss: 0.6634 - val_accuracy: 0.5563\n",
      "Epoch 4363/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6045 - accuracy: 0.6571 - val_loss: 0.6590 - val_accuracy: 0.5623\n",
      "Epoch 4364/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6041 - accuracy: 0.6572 - val_loss: 0.6415 - val_accuracy: 0.5848\n",
      "Epoch 4365/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6052 - accuracy: 0.6547 - val_loss: 0.6819 - val_accuracy: 0.5290\n",
      "Epoch 4366/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6061 - accuracy: 0.6545 - val_loss: 0.6321 - val_accuracy: 0.6023\n",
      "Epoch 4367/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6071 - accuracy: 0.6525 - val_loss: 0.6871 - val_accuracy: 0.5230\n",
      "Epoch 4368/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6070 - accuracy: 0.6533 - val_loss: 0.6393 - val_accuracy: 0.5884\n",
      "Epoch 4369/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6056 - accuracy: 0.6527 - val_loss: 0.6655 - val_accuracy: 0.5543\n",
      "Epoch 4370/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6049 - accuracy: 0.6572 - val_loss: 0.6558 - val_accuracy: 0.5669\n",
      "Epoch 4371/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6041 - accuracy: 0.6571 - val_loss: 0.6458 - val_accuracy: 0.5798\n",
      "Epoch 4372/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6052 - accuracy: 0.6539 - val_loss: 0.6810 - val_accuracy: 0.5311\n",
      "Epoch 4373/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6057 - accuracy: 0.6555 - val_loss: 0.6309 - val_accuracy: 0.6071\n",
      "Epoch 4374/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6075 - accuracy: 0.6517 - val_loss: 0.6895 - val_accuracy: 0.5217\n",
      "Epoch 4375/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6077 - accuracy: 0.6526 - val_loss: 0.6360 - val_accuracy: 0.5930\n",
      "Epoch 4376/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6064 - accuracy: 0.6519 - val_loss: 0.6712 - val_accuracy: 0.5466\n",
      "Epoch 4377/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6055 - accuracy: 0.6558 - val_loss: 0.6525 - val_accuracy: 0.5729\n",
      "Epoch 4378/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6044 - accuracy: 0.6569 - val_loss: 0.6503 - val_accuracy: 0.5734\n",
      "Epoch 4379/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6052 - accuracy: 0.6533 - val_loss: 0.6751 - val_accuracy: 0.5411\n",
      "Epoch 4380/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6050 - accuracy: 0.6556 - val_loss: 0.6327 - val_accuracy: 0.6045\n",
      "Epoch 4381/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6074 - accuracy: 0.6525 - val_loss: 0.6932 - val_accuracy: 0.5181\n",
      "Epoch 4382/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6080 - accuracy: 0.6519 - val_loss: 0.6339 - val_accuracy: 0.5983\n",
      "Epoch 4383/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6074 - accuracy: 0.6524 - val_loss: 0.6755 - val_accuracy: 0.5369\n",
      "Epoch 4384/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6063 - accuracy: 0.6554 - val_loss: 0.6456 - val_accuracy: 0.5817\n",
      "Epoch 4385/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6055 - accuracy: 0.6563 - val_loss: 0.6588 - val_accuracy: 0.5614\n",
      "Epoch 4386/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6050 - accuracy: 0.6543 - val_loss: 0.6669 - val_accuracy: 0.5508\n",
      "Epoch 4387/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6045 - accuracy: 0.6558 - val_loss: 0.6425 - val_accuracy: 0.5875\n",
      "Epoch 4388/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6056 - accuracy: 0.6553 - val_loss: 0.6783 - val_accuracy: 0.5323\n",
      "Epoch 4389/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6055 - accuracy: 0.6562 - val_loss: 0.6349 - val_accuracy: 0.5957\n",
      "Epoch 4390/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6066 - accuracy: 0.6524 - val_loss: 0.6834 - val_accuracy: 0.5283\n",
      "Epoch 4391/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6064 - accuracy: 0.6543 - val_loss: 0.6359 - val_accuracy: 0.6001\n",
      "Epoch 4392/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6064 - accuracy: 0.6538 - val_loss: 0.6755 - val_accuracy: 0.5407\n",
      "Epoch 4393/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6052 - accuracy: 0.6555 - val_loss: 0.6487 - val_accuracy: 0.5749\n",
      "Epoch 4394/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6045 - accuracy: 0.6547 - val_loss: 0.6552 - val_accuracy: 0.5667\n",
      "Epoch 4395/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6046 - accuracy: 0.6569 - val_loss: 0.6645 - val_accuracy: 0.5537\n",
      "Epoch 4396/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6043 - accuracy: 0.6578 - val_loss: 0.6437 - val_accuracy: 0.5840\n",
      "Epoch 4397/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6052 - accuracy: 0.6538 - val_loss: 0.6792 - val_accuracy: 0.5336\n",
      "Epoch 4398/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6054 - accuracy: 0.6557 - val_loss: 0.6335 - val_accuracy: 0.6018\n",
      "Epoch 4399/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6064 - accuracy: 0.6533 - val_loss: 0.6849 - val_accuracy: 0.5285\n",
      "Epoch 4400/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6063 - accuracy: 0.6548 - val_loss: 0.6390 - val_accuracy: 0.5910\n",
      "Epoch 4401/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6058 - accuracy: 0.6527 - val_loss: 0.6704 - val_accuracy: 0.5469\n",
      "Epoch 4402/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6050 - accuracy: 0.6571 - val_loss: 0.6477 - val_accuracy: 0.5804\n",
      "Epoch 4403/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6043 - accuracy: 0.6571 - val_loss: 0.6587 - val_accuracy: 0.5632\n",
      "Epoch 4404/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6044 - accuracy: 0.6556 - val_loss: 0.6655 - val_accuracy: 0.5530\n",
      "Epoch 4405/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6039 - accuracy: 0.6569 - val_loss: 0.6425 - val_accuracy: 0.5877\n",
      "Epoch 4406/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6050 - accuracy: 0.6560 - val_loss: 0.6763 - val_accuracy: 0.5389\n",
      "Epoch 4407/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6051 - accuracy: 0.6565 - val_loss: 0.6355 - val_accuracy: 0.5959\n",
      "Epoch 4408/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6064 - accuracy: 0.6521 - val_loss: 0.6859 - val_accuracy: 0.5252\n",
      "Epoch 4409/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6069 - accuracy: 0.6536 - val_loss: 0.6340 - val_accuracy: 0.6032\n",
      "Epoch 4410/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6066 - accuracy: 0.6537 - val_loss: 0.6784 - val_accuracy: 0.5374\n",
      "Epoch 4411/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6058 - accuracy: 0.6545 - val_loss: 0.6494 - val_accuracy: 0.5740\n",
      "Epoch 4412/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6044 - accuracy: 0.6551 - val_loss: 0.6519 - val_accuracy: 0.5734\n",
      "Epoch 4413/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6049 - accuracy: 0.6573 - val_loss: 0.6710 - val_accuracy: 0.5446\n",
      "Epoch 4414/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6048 - accuracy: 0.6580 - val_loss: 0.6370 - val_accuracy: 0.5932\n",
      "Epoch 4415/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6067 - accuracy: 0.6528 - val_loss: 0.6908 - val_accuracy: 0.5208\n",
      "Epoch 4416/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6076 - accuracy: 0.6524 - val_loss: 0.6268 - val_accuracy: 0.6138\n",
      "Epoch 4417/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6083 - accuracy: 0.6510 - val_loss: 0.6896 - val_accuracy: 0.5254\n",
      "Epoch 4418/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6074 - accuracy: 0.6531 - val_loss: 0.6435 - val_accuracy: 0.5844\n",
      "Epoch 4419/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6058 - accuracy: 0.6523 - val_loss: 0.6602 - val_accuracy: 0.5619\n",
      "Epoch 4420/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6048 - accuracy: 0.6568 - val_loss: 0.6609 - val_accuracy: 0.5605\n",
      "Epoch 4421/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6049 - accuracy: 0.6573 - val_loss: 0.6408 - val_accuracy: 0.5851\n",
      "Epoch 4422/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6053 - accuracy: 0.6530 - val_loss: 0.6846 - val_accuracy: 0.5278\n",
      "Epoch 4423/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6060 - accuracy: 0.6548 - val_loss: 0.6360 - val_accuracy: 0.5988\n",
      "Epoch 4424/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6060 - accuracy: 0.6529 - val_loss: 0.6763 - val_accuracy: 0.5374\n",
      "Epoch 4425/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6051 - accuracy: 0.6570 - val_loss: 0.6428 - val_accuracy: 0.5844\n",
      "Epoch 4426/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6045 - accuracy: 0.6550 - val_loss: 0.6628 - val_accuracy: 0.5555\n",
      "Epoch 4427/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6035 - accuracy: 0.6582 - val_loss: 0.6557 - val_accuracy: 0.5667\n",
      "Epoch 4428/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6036 - accuracy: 0.6577 - val_loss: 0.6519 - val_accuracy: 0.5723\n",
      "Epoch 4429/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6035 - accuracy: 0.6561 - val_loss: 0.6664 - val_accuracy: 0.5491\n",
      "Epoch 4430/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6038 - accuracy: 0.6570 - val_loss: 0.6434 - val_accuracy: 0.5859\n",
      "Epoch 4431/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6040 - accuracy: 0.6559 - val_loss: 0.6724 - val_accuracy: 0.5427\n",
      "Epoch 4432/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6043 - accuracy: 0.6573 - val_loss: 0.6419 - val_accuracy: 0.5884\n",
      "Epoch 4433/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6043 - accuracy: 0.6550 - val_loss: 0.6711 - val_accuracy: 0.5457\n",
      "Epoch 4434/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6041 - accuracy: 0.6577 - val_loss: 0.6445 - val_accuracy: 0.5855\n",
      "Epoch 4435/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6039 - accuracy: 0.6561 - val_loss: 0.6674 - val_accuracy: 0.5501\n",
      "Epoch 4436/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6036 - accuracy: 0.6577 - val_loss: 0.6510 - val_accuracy: 0.5754\n",
      "Epoch 4437/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6034 - accuracy: 0.6560 - val_loss: 0.6587 - val_accuracy: 0.5643\n",
      "Epoch 4438/15000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6032 - accuracy: 0.6581 - val_loss: 0.6557 - val_accuracy: 0.5681\n",
      "Epoch 4439/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6032 - accuracy: 0.6578 - val_loss: 0.6538 - val_accuracy: 0.5701\n",
      "Epoch 4440/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6033 - accuracy: 0.6572 - val_loss: 0.6633 - val_accuracy: 0.5561\n",
      "Epoch 4441/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6033 - accuracy: 0.6581 - val_loss: 0.6477 - val_accuracy: 0.5811\n",
      "Epoch 4442/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6035 - accuracy: 0.6568 - val_loss: 0.6669 - val_accuracy: 0.5510\n",
      "Epoch 4443/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6036 - accuracy: 0.6580 - val_loss: 0.6457 - val_accuracy: 0.5835\n",
      "Epoch 4444/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6037 - accuracy: 0.6565 - val_loss: 0.6705 - val_accuracy: 0.5459\n",
      "Epoch 4445/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6039 - accuracy: 0.6577 - val_loss: 0.6435 - val_accuracy: 0.5870\n",
      "Epoch 4446/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6039 - accuracy: 0.6557 - val_loss: 0.6715 - val_accuracy: 0.5457\n",
      "Epoch 4447/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6040 - accuracy: 0.6576 - val_loss: 0.6428 - val_accuracy: 0.5870\n",
      "Epoch 4448/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6039 - accuracy: 0.6548 - val_loss: 0.6711 - val_accuracy: 0.5457\n",
      "Epoch 4449/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6039 - accuracy: 0.6578 - val_loss: 0.6453 - val_accuracy: 0.5855\n",
      "Epoch 4450/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6037 - accuracy: 0.6560 - val_loss: 0.6689 - val_accuracy: 0.5493\n",
      "Epoch 4451/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6037 - accuracy: 0.6579 - val_loss: 0.6444 - val_accuracy: 0.5855\n",
      "Epoch 4452/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6036 - accuracy: 0.6559 - val_loss: 0.6679 - val_accuracy: 0.5502\n",
      "Epoch 4453/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6035 - accuracy: 0.6580 - val_loss: 0.6479 - val_accuracy: 0.5817\n",
      "Epoch 4454/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6035 - accuracy: 0.6565 - val_loss: 0.6664 - val_accuracy: 0.5508\n",
      "Epoch 4455/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6034 - accuracy: 0.6579 - val_loss: 0.6465 - val_accuracy: 0.5837\n",
      "Epoch 4456/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6034 - accuracy: 0.6568 - val_loss: 0.6662 - val_accuracy: 0.5522\n",
      "Epoch 4457/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6033 - accuracy: 0.6584 - val_loss: 0.6488 - val_accuracy: 0.5804\n",
      "Epoch 4458/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6033 - accuracy: 0.6566 - val_loss: 0.6662 - val_accuracy: 0.5504\n",
      "Epoch 4459/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6034 - accuracy: 0.6578 - val_loss: 0.6461 - val_accuracy: 0.5839\n",
      "Epoch 4460/15000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6034 - accuracy: 0.6568 - val_loss: 0.6687 - val_accuracy: 0.5490\n",
      "Epoch 4461/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6035 - accuracy: 0.6579 - val_loss: 0.6453 - val_accuracy: 0.5846\n",
      "Epoch 4462/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6036 - accuracy: 0.6564 - val_loss: 0.6697 - val_accuracy: 0.5469\n",
      "Epoch 4463/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6037 - accuracy: 0.6583 - val_loss: 0.6430 - val_accuracy: 0.5890\n",
      "Epoch 4464/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6038 - accuracy: 0.6553 - val_loss: 0.6748 - val_accuracy: 0.5400\n",
      "Epoch 4465/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6042 - accuracy: 0.6571 - val_loss: 0.6384 - val_accuracy: 0.5934\n",
      "Epoch 4466/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6045 - accuracy: 0.6544 - val_loss: 0.6813 - val_accuracy: 0.5325\n",
      "Epoch 4467/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6052 - accuracy: 0.6561 - val_loss: 0.6330 - val_accuracy: 0.6021\n",
      "Epoch 4468/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6055 - accuracy: 0.6528 - val_loss: 0.6881 - val_accuracy: 0.5252\n",
      "Epoch 4469/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6064 - accuracy: 0.6541 - val_loss: 0.6316 - val_accuracy: 0.6056\n",
      "Epoch 4470/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6060 - accuracy: 0.6525 - val_loss: 0.6864 - val_accuracy: 0.5274\n",
      "Epoch 4471/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6061 - accuracy: 0.6542 - val_loss: 0.6345 - val_accuracy: 0.6001\n",
      "Epoch 4472/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6051 - accuracy: 0.6537 - val_loss: 0.6767 - val_accuracy: 0.5387\n",
      "Epoch 4473/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6046 - accuracy: 0.6569 - val_loss: 0.6425 - val_accuracy: 0.5881\n",
      "Epoch 4474/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6038 - accuracy: 0.6556 - val_loss: 0.6673 - val_accuracy: 0.5504\n",
      "Epoch 4475/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6033 - accuracy: 0.6587 - val_loss: 0.6502 - val_accuracy: 0.5778\n",
      "Epoch 4476/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6030 - accuracy: 0.6572 - val_loss: 0.6579 - val_accuracy: 0.5647\n",
      "Epoch 4477/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6029 - accuracy: 0.6583 - val_loss: 0.6575 - val_accuracy: 0.5634\n",
      "Epoch 4478/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6029 - accuracy: 0.6576 - val_loss: 0.6538 - val_accuracy: 0.5705\n",
      "Epoch 4479/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6029 - accuracy: 0.6578 - val_loss: 0.6608 - val_accuracy: 0.5579\n",
      "Epoch 4480/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6030 - accuracy: 0.6582 - val_loss: 0.6492 - val_accuracy: 0.5791\n",
      "Epoch 4481/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6031 - accuracy: 0.6573 - val_loss: 0.6685 - val_accuracy: 0.5495\n",
      "Epoch 4482/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6034 - accuracy: 0.6583 - val_loss: 0.6431 - val_accuracy: 0.5879\n",
      "Epoch 4483/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6037 - accuracy: 0.6556 - val_loss: 0.6751 - val_accuracy: 0.5402\n",
      "Epoch 4484/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6043 - accuracy: 0.6580 - val_loss: 0.6367 - val_accuracy: 0.5972\n",
      "Epoch 4485/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6048 - accuracy: 0.6544 - val_loss: 0.6868 - val_accuracy: 0.5280\n",
      "Epoch 4486/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6060 - accuracy: 0.6548 - val_loss: 0.6300 - val_accuracy: 0.6080\n",
      "Epoch 4487/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6063 - accuracy: 0.6524 - val_loss: 0.6919 - val_accuracy: 0.5206\n",
      "Epoch 4488/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6072 - accuracy: 0.6524 - val_loss: 0.6304 - val_accuracy: 0.6069\n",
      "Epoch 4489/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6060 - accuracy: 0.6536 - val_loss: 0.6843 - val_accuracy: 0.5290\n",
      "Epoch 4490/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6058 - accuracy: 0.6554 - val_loss: 0.6381 - val_accuracy: 0.5939\n",
      "Epoch 4491/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6045 - accuracy: 0.6543 - val_loss: 0.6726 - val_accuracy: 0.5446\n",
      "Epoch 4492/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6039 - accuracy: 0.6581 - val_loss: 0.6463 - val_accuracy: 0.5848\n",
      "Epoch 4493/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6032 - accuracy: 0.6569 - val_loss: 0.6615 - val_accuracy: 0.5581\n",
      "Epoch 4494/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6030 - accuracy: 0.6581 - val_loss: 0.6551 - val_accuracy: 0.5680\n",
      "Epoch 4495/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6029 - accuracy: 0.6576 - val_loss: 0.6563 - val_accuracy: 0.5694\n",
      "Epoch 4496/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6028 - accuracy: 0.6577 - val_loss: 0.6575 - val_accuracy: 0.5641\n",
      "Epoch 4497/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6029 - accuracy: 0.6578 - val_loss: 0.6526 - val_accuracy: 0.5733\n",
      "Epoch 4498/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6028 - accuracy: 0.6573 - val_loss: 0.6642 - val_accuracy: 0.5572\n",
      "Epoch 4499/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6030 - accuracy: 0.6587 - val_loss: 0.6481 - val_accuracy: 0.5804\n",
      "Epoch 4500/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6030 - accuracy: 0.6568 - val_loss: 0.6673 - val_accuracy: 0.5504\n",
      "Epoch 4501/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6033 - accuracy: 0.6585 - val_loss: 0.6432 - val_accuracy: 0.5871\n",
      "Epoch 4502/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6036 - accuracy: 0.6557 - val_loss: 0.6771 - val_accuracy: 0.5382\n",
      "Epoch 4503/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6043 - accuracy: 0.6572 - val_loss: 0.6361 - val_accuracy: 0.5983\n",
      "Epoch 4504/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6048 - accuracy: 0.6535 - val_loss: 0.6862 - val_accuracy: 0.5281\n",
      "Epoch 4505/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6059 - accuracy: 0.6544 - val_loss: 0.6299 - val_accuracy: 0.6087\n",
      "Epoch 4506/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6061 - accuracy: 0.6531 - val_loss: 0.6929 - val_accuracy: 0.5181\n",
      "Epoch 4507/15000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6073 - accuracy: 0.6528 - val_loss: 0.6301 - val_accuracy: 0.6085\n",
      "Epoch 4508/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6064 - accuracy: 0.6526 - val_loss: 0.6874 - val_accuracy: 0.5263\n",
      "Epoch 4509/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6061 - accuracy: 0.6543 - val_loss: 0.6363 - val_accuracy: 0.5983\n",
      "Epoch 4510/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6045 - accuracy: 0.6544 - val_loss: 0.6709 - val_accuracy: 0.5457\n",
      "Epoch 4511/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6039 - accuracy: 0.6576 - val_loss: 0.6488 - val_accuracy: 0.5826\n",
      "Epoch 4512/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6031 - accuracy: 0.6570 - val_loss: 0.6605 - val_accuracy: 0.5607\n",
      "Epoch 4513/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6031 - accuracy: 0.6580 - val_loss: 0.6583 - val_accuracy: 0.5630\n",
      "Epoch 4514/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6029 - accuracy: 0.6577 - val_loss: 0.6460 - val_accuracy: 0.5828\n",
      "Epoch 4515/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6033 - accuracy: 0.6559 - val_loss: 0.6755 - val_accuracy: 0.5417\n",
      "Epoch 4516/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6040 - accuracy: 0.6573 - val_loss: 0.6385 - val_accuracy: 0.5928\n",
      "Epoch 4517/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6043 - accuracy: 0.6545 - val_loss: 0.6799 - val_accuracy: 0.5329\n",
      "Epoch 4518/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6056 - accuracy: 0.6563 - val_loss: 0.6330 - val_accuracy: 0.6027\n",
      "Epoch 4519/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6052 - accuracy: 0.6534 - val_loss: 0.6870 - val_accuracy: 0.5281\n",
      "Epoch 4520/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6059 - accuracy: 0.6533 - val_loss: 0.6390 - val_accuracy: 0.5921\n",
      "Epoch 4521/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6043 - accuracy: 0.6548 - val_loss: 0.6685 - val_accuracy: 0.5475\n",
      "Epoch 4522/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6040 - accuracy: 0.6579 - val_loss: 0.6490 - val_accuracy: 0.5807\n",
      "Epoch 4523/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6029 - accuracy: 0.6581 - val_loss: 0.6584 - val_accuracy: 0.5639\n",
      "Epoch 4524/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6033 - accuracy: 0.6578 - val_loss: 0.6644 - val_accuracy: 0.5555\n",
      "Epoch 4525/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6032 - accuracy: 0.6582 - val_loss: 0.6417 - val_accuracy: 0.5904\n",
      "Epoch 4526/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6039 - accuracy: 0.6552 - val_loss: 0.6804 - val_accuracy: 0.5362\n",
      "Epoch 4527/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6051 - accuracy: 0.6549 - val_loss: 0.6337 - val_accuracy: 0.6018\n",
      "Epoch 4528/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6054 - accuracy: 0.6539 - val_loss: 0.6904 - val_accuracy: 0.5203\n",
      "Epoch 4529/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6078 - accuracy: 0.6528 - val_loss: 0.6297 - val_accuracy: 0.6109\n",
      "Epoch 4530/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6065 - accuracy: 0.6524 - val_loss: 0.6850 - val_accuracy: 0.5307\n",
      "Epoch 4531/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6066 - accuracy: 0.6536 - val_loss: 0.6466 - val_accuracy: 0.5837\n",
      "Epoch 4532/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6032 - accuracy: 0.6566 - val_loss: 0.6524 - val_accuracy: 0.5751\n",
      "Epoch 4533/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6041 - accuracy: 0.6558 - val_loss: 0.6750 - val_accuracy: 0.5406\n",
      "Epoch 4534/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6040 - accuracy: 0.6581 - val_loss: 0.6325 - val_accuracy: 0.6030\n",
      "Epoch 4535/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6080 - accuracy: 0.6524 - val_loss: 0.7077 - val_accuracy: 0.5004\n",
      "Epoch 4536/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6128 - accuracy: 0.6483 - val_loss: 0.6156 - val_accuracy: 0.6326\n",
      "Epoch 4537/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6127 - accuracy: 0.6479 - val_loss: 0.7065 - val_accuracy: 0.5066\n",
      "Epoch 4538/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6109 - accuracy: 0.6492 - val_loss: 0.6500 - val_accuracy: 0.5811\n",
      "Epoch 4539/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6074 - accuracy: 0.6545 - val_loss: 0.6473 - val_accuracy: 0.5817\n",
      "Epoch 4540/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6078 - accuracy: 0.6521 - val_loss: 0.6843 - val_accuracy: 0.5292\n",
      "Epoch 4541/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6115 - accuracy: 0.6528 - val_loss: 0.6301 - val_accuracy: 0.6080\n",
      "Epoch 4542/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6071 - accuracy: 0.6527 - val_loss: 0.6876 - val_accuracy: 0.5320\n",
      "Epoch 4543/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6107 - accuracy: 0.6510 - val_loss: 0.6682 - val_accuracy: 0.5491\n",
      "Epoch 4544/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6045 - accuracy: 0.6567 - val_loss: 0.6230 - val_accuracy: 0.6231\n",
      "Epoch 4545/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6117 - accuracy: 0.6498 - val_loss: 0.7243 - val_accuracy: 0.4830\n",
      "Epoch 4546/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6172 - accuracy: 0.6412 - val_loss: 0.6258 - val_accuracy: 0.6176\n",
      "Epoch 4547/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6149 - accuracy: 0.6463 - val_loss: 0.6800 - val_accuracy: 0.5311\n",
      "Epoch 4548/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6097 - accuracy: 0.6531 - val_loss: 0.6552 - val_accuracy: 0.5733\n",
      "Epoch 4549/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6127 - accuracy: 0.6476 - val_loss: 0.6530 - val_accuracy: 0.5749\n",
      "Epoch 4550/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6091 - accuracy: 0.6513 - val_loss: 0.6721 - val_accuracy: 0.5475\n",
      "Epoch 4551/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6074 - accuracy: 0.6548 - val_loss: 0.6494 - val_accuracy: 0.5762\n",
      "Epoch 4552/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6087 - accuracy: 0.6538 - val_loss: 0.6759 - val_accuracy: 0.5345\n",
      "Epoch 4553/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6072 - accuracy: 0.6535 - val_loss: 0.6346 - val_accuracy: 0.6056\n",
      "Epoch 4554/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6112 - accuracy: 0.6499 - val_loss: 0.6875 - val_accuracy: 0.5210\n",
      "Epoch 4555/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6085 - accuracy: 0.6514 - val_loss: 0.6479 - val_accuracy: 0.5789\n",
      "Epoch 4556/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6093 - accuracy: 0.6526 - val_loss: 0.6626 - val_accuracy: 0.5592\n",
      "Epoch 4557/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6078 - accuracy: 0.6547 - val_loss: 0.6624 - val_accuracy: 0.5667\n",
      "Epoch 4558/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6101 - accuracy: 0.6539 - val_loss: 0.6510 - val_accuracy: 0.5813\n",
      "Epoch 4559/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6071 - accuracy: 0.6540 - val_loss: 0.6775 - val_accuracy: 0.5406\n",
      "Epoch 4560/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6079 - accuracy: 0.6530 - val_loss: 0.6582 - val_accuracy: 0.5678\n",
      "Epoch 4561/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6060 - accuracy: 0.6537 - val_loss: 0.6525 - val_accuracy: 0.5771\n",
      "Epoch 4562/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6075 - accuracy: 0.6531 - val_loss: 0.6668 - val_accuracy: 0.5504\n",
      "Epoch 4563/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6060 - accuracy: 0.6548 - val_loss: 0.6429 - val_accuracy: 0.5882\n",
      "Epoch 4564/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6074 - accuracy: 0.6527 - val_loss: 0.6878 - val_accuracy: 0.5243\n",
      "Epoch 4565/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6071 - accuracy: 0.6528 - val_loss: 0.6360 - val_accuracy: 0.5986\n",
      "Epoch 4566/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6061 - accuracy: 0.6530 - val_loss: 0.6721 - val_accuracy: 0.5464\n",
      "Epoch 4567/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6045 - accuracy: 0.6566 - val_loss: 0.6560 - val_accuracy: 0.5700\n",
      "Epoch 4568/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6042 - accuracy: 0.6565 - val_loss: 0.6535 - val_accuracy: 0.5740\n",
      "Epoch 4569/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6038 - accuracy: 0.6578 - val_loss: 0.6645 - val_accuracy: 0.5559\n",
      "Epoch 4570/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6041 - accuracy: 0.6578 - val_loss: 0.6432 - val_accuracy: 0.5866\n",
      "Epoch 4571/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6047 - accuracy: 0.6545 - val_loss: 0.6735 - val_accuracy: 0.5431\n",
      "Epoch 4572/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6039 - accuracy: 0.6569 - val_loss: 0.6473 - val_accuracy: 0.5826\n",
      "Epoch 4573/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6040 - accuracy: 0.6569 - val_loss: 0.6683 - val_accuracy: 0.5506\n",
      "Epoch 4574/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6040 - accuracy: 0.6563 - val_loss: 0.6449 - val_accuracy: 0.5829\n",
      "Epoch 4575/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6036 - accuracy: 0.6563 - val_loss: 0.6668 - val_accuracy: 0.5524\n",
      "Epoch 4576/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6036 - accuracy: 0.6585 - val_loss: 0.6562 - val_accuracy: 0.5701\n",
      "Epoch 4577/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6031 - accuracy: 0.6581 - val_loss: 0.6542 - val_accuracy: 0.5720\n",
      "Epoch 4578/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6032 - accuracy: 0.6566 - val_loss: 0.6637 - val_accuracy: 0.5572\n",
      "Epoch 4579/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6032 - accuracy: 0.6576 - val_loss: 0.6494 - val_accuracy: 0.5804\n",
      "Epoch 4580/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6035 - accuracy: 0.6574 - val_loss: 0.6712 - val_accuracy: 0.5471\n",
      "Epoch 4581/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6036 - accuracy: 0.6576 - val_loss: 0.6426 - val_accuracy: 0.5871\n",
      "Epoch 4582/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6039 - accuracy: 0.6549 - val_loss: 0.6755 - val_accuracy: 0.5395\n",
      "Epoch 4583/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6038 - accuracy: 0.6580 - val_loss: 0.6418 - val_accuracy: 0.5912\n",
      "Epoch 4584/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6039 - accuracy: 0.6556 - val_loss: 0.6733 - val_accuracy: 0.5437\n",
      "Epoch 4585/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6039 - accuracy: 0.6569 - val_loss: 0.6441 - val_accuracy: 0.5862\n",
      "Epoch 4586/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6035 - accuracy: 0.6561 - val_loss: 0.6687 - val_accuracy: 0.5491\n",
      "Epoch 4587/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6032 - accuracy: 0.6589 - val_loss: 0.6521 - val_accuracy: 0.5754\n",
      "Epoch 4588/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6027 - accuracy: 0.6584 - val_loss: 0.6569 - val_accuracy: 0.5669\n",
      "Epoch 4589/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6028 - accuracy: 0.6572 - val_loss: 0.6592 - val_accuracy: 0.5667\n",
      "Epoch 4590/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6026 - accuracy: 0.6579 - val_loss: 0.6518 - val_accuracy: 0.5753\n",
      "Epoch 4591/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6028 - accuracy: 0.6583 - val_loss: 0.6659 - val_accuracy: 0.5513\n",
      "Epoch 4592/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6029 - accuracy: 0.6581 - val_loss: 0.6438 - val_accuracy: 0.5882\n",
      "Epoch 4593/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6032 - accuracy: 0.6563 - val_loss: 0.6731 - val_accuracy: 0.5427\n",
      "Epoch 4594/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6034 - accuracy: 0.6581 - val_loss: 0.6426 - val_accuracy: 0.5901\n",
      "Epoch 4595/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6036 - accuracy: 0.6566 - val_loss: 0.6735 - val_accuracy: 0.5422\n",
      "Epoch 4596/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6037 - accuracy: 0.6573 - val_loss: 0.6399 - val_accuracy: 0.5908\n",
      "Epoch 4597/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6034 - accuracy: 0.6557 - val_loss: 0.6722 - val_accuracy: 0.5460\n",
      "Epoch 4598/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6034 - accuracy: 0.6587 - val_loss: 0.6472 - val_accuracy: 0.5840\n",
      "Epoch 4599/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6028 - accuracy: 0.6574 - val_loss: 0.6631 - val_accuracy: 0.5568\n",
      "Epoch 4600/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6027 - accuracy: 0.6582 - val_loss: 0.6519 - val_accuracy: 0.5751\n",
      "Epoch 4601/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6023 - accuracy: 0.6582 - val_loss: 0.6586 - val_accuracy: 0.5683\n",
      "Epoch 4602/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6024 - accuracy: 0.6580 - val_loss: 0.6587 - val_accuracy: 0.5641\n",
      "Epoch 4603/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6024 - accuracy: 0.6578 - val_loss: 0.6518 - val_accuracy: 0.5765\n",
      "Epoch 4604/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6024 - accuracy: 0.6574 - val_loss: 0.6639 - val_accuracy: 0.5594\n",
      "Epoch 4605/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6025 - accuracy: 0.6584 - val_loss: 0.6482 - val_accuracy: 0.5820\n",
      "Epoch 4606/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6026 - accuracy: 0.6576 - val_loss: 0.6674 - val_accuracy: 0.5497\n",
      "Epoch 4607/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6028 - accuracy: 0.6583 - val_loss: 0.6448 - val_accuracy: 0.5864\n",
      "Epoch 4608/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6029 - accuracy: 0.6569 - val_loss: 0.6724 - val_accuracy: 0.5442\n",
      "Epoch 4609/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6032 - accuracy: 0.6588 - val_loss: 0.6418 - val_accuracy: 0.5904\n",
      "Epoch 4610/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6031 - accuracy: 0.6561 - val_loss: 0.6723 - val_accuracy: 0.5438\n",
      "Epoch 4611/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6033 - accuracy: 0.6582 - val_loss: 0.6425 - val_accuracy: 0.5915\n",
      "Epoch 4612/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6032 - accuracy: 0.6563 - val_loss: 0.6747 - val_accuracy: 0.5407\n",
      "Epoch 4613/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6033 - accuracy: 0.6581 - val_loss: 0.6402 - val_accuracy: 0.5928\n",
      "Epoch 4614/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6033 - accuracy: 0.6557 - val_loss: 0.6753 - val_accuracy: 0.5409\n",
      "Epoch 4615/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6035 - accuracy: 0.6586 - val_loss: 0.6396 - val_accuracy: 0.5935\n",
      "Epoch 4616/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6036 - accuracy: 0.6568 - val_loss: 0.6784 - val_accuracy: 0.5393\n",
      "Epoch 4617/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6038 - accuracy: 0.6577 - val_loss: 0.6379 - val_accuracy: 0.5943\n",
      "Epoch 4618/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6037 - accuracy: 0.6554 - val_loss: 0.6774 - val_accuracy: 0.5378\n",
      "Epoch 4619/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6038 - accuracy: 0.6579 - val_loss: 0.6387 - val_accuracy: 0.5948\n",
      "Epoch 4620/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6036 - accuracy: 0.6555 - val_loss: 0.6767 - val_accuracy: 0.5413\n",
      "Epoch 4621/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6037 - accuracy: 0.6573 - val_loss: 0.6406 - val_accuracy: 0.5930\n",
      "Epoch 4622/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6033 - accuracy: 0.6556 - val_loss: 0.6743 - val_accuracy: 0.5415\n",
      "Epoch 4623/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6033 - accuracy: 0.6589 - val_loss: 0.6414 - val_accuracy: 0.5917\n",
      "Epoch 4624/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6030 - accuracy: 0.6559 - val_loss: 0.6713 - val_accuracy: 0.5448\n",
      "Epoch 4625/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6030 - accuracy: 0.6584 - val_loss: 0.6441 - val_accuracy: 0.5895\n",
      "Epoch 4626/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6028 - accuracy: 0.6565 - val_loss: 0.6710 - val_accuracy: 0.5466\n",
      "Epoch 4627/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6028 - accuracy: 0.6596 - val_loss: 0.6437 - val_accuracy: 0.5890\n",
      "Epoch 4628/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6027 - accuracy: 0.6566 - val_loss: 0.6702 - val_accuracy: 0.5462\n",
      "Epoch 4629/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6028 - accuracy: 0.6590 - val_loss: 0.6438 - val_accuracy: 0.5895\n",
      "Epoch 4630/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6028 - accuracy: 0.6564 - val_loss: 0.6727 - val_accuracy: 0.5435\n",
      "Epoch 4631/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6030 - accuracy: 0.6588 - val_loss: 0.6413 - val_accuracy: 0.5924\n",
      "Epoch 4632/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6031 - accuracy: 0.6560 - val_loss: 0.6768 - val_accuracy: 0.5393\n",
      "Epoch 4633/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6035 - accuracy: 0.6585 - val_loss: 0.6371 - val_accuracy: 0.5961\n",
      "Epoch 4634/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6038 - accuracy: 0.6560 - val_loss: 0.6833 - val_accuracy: 0.5334\n",
      "Epoch 4635/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6046 - accuracy: 0.6569 - val_loss: 0.6329 - val_accuracy: 0.6041\n",
      "Epoch 4636/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6047 - accuracy: 0.6540 - val_loss: 0.6893 - val_accuracy: 0.5243\n",
      "Epoch 4637/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6057 - accuracy: 0.6550 - val_loss: 0.6302 - val_accuracy: 0.6094\n",
      "Epoch 4638/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6052 - accuracy: 0.6541 - val_loss: 0.6884 - val_accuracy: 0.5245\n",
      "Epoch 4639/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6055 - accuracy: 0.6555 - val_loss: 0.6355 - val_accuracy: 0.5992\n",
      "Epoch 4640/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6042 - accuracy: 0.6548 - val_loss: 0.6767 - val_accuracy: 0.5378\n",
      "Epoch 4641/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6036 - accuracy: 0.6586 - val_loss: 0.6423 - val_accuracy: 0.5904\n",
      "Epoch 4642/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6028 - accuracy: 0.6562 - val_loss: 0.6668 - val_accuracy: 0.5537\n",
      "Epoch 4643/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6024 - accuracy: 0.6580 - val_loss: 0.6519 - val_accuracy: 0.5765\n",
      "Epoch 4644/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6021 - accuracy: 0.6585 - val_loss: 0.6582 - val_accuracy: 0.5678\n",
      "Epoch 4645/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6020 - accuracy: 0.6591 - val_loss: 0.6570 - val_accuracy: 0.5672\n",
      "Epoch 4646/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6020 - accuracy: 0.6586 - val_loss: 0.6531 - val_accuracy: 0.5744\n",
      "Epoch 4647/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6021 - accuracy: 0.6587 - val_loss: 0.6640 - val_accuracy: 0.5566\n",
      "Epoch 4648/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6022 - accuracy: 0.6589 - val_loss: 0.6474 - val_accuracy: 0.5844\n",
      "Epoch 4649/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6023 - accuracy: 0.6578 - val_loss: 0.6691 - val_accuracy: 0.5488\n",
      "Epoch 4650/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6026 - accuracy: 0.6586 - val_loss: 0.6431 - val_accuracy: 0.5910\n",
      "Epoch 4651/15000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6028 - accuracy: 0.6563 - val_loss: 0.6760 - val_accuracy: 0.5391\n",
      "Epoch 4652/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6033 - accuracy: 0.6583 - val_loss: 0.6365 - val_accuracy: 0.5976\n",
      "Epoch 4653/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6038 - accuracy: 0.6553 - val_loss: 0.6859 - val_accuracy: 0.5296\n",
      "Epoch 4654/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6049 - accuracy: 0.6561 - val_loss: 0.6305 - val_accuracy: 0.6102\n",
      "Epoch 4655/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6053 - accuracy: 0.6544 - val_loss: 0.6939 - val_accuracy: 0.5157\n",
      "Epoch 4656/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6068 - accuracy: 0.6535 - val_loss: 0.6283 - val_accuracy: 0.6129\n",
      "Epoch 4657/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6058 - accuracy: 0.6537 - val_loss: 0.6904 - val_accuracy: 0.5234\n",
      "Epoch 4658/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6057 - accuracy: 0.6550 - val_loss: 0.6359 - val_accuracy: 0.5976\n",
      "Epoch 4659/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6039 - accuracy: 0.6550 - val_loss: 0.6719 - val_accuracy: 0.5427\n",
      "Epoch 4660/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6031 - accuracy: 0.6583 - val_loss: 0.6475 - val_accuracy: 0.5837\n",
      "Epoch 4661/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6022 - accuracy: 0.6579 - val_loss: 0.6608 - val_accuracy: 0.5617\n",
      "Epoch 4662/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6021 - accuracy: 0.6588 - val_loss: 0.6583 - val_accuracy: 0.5650\n",
      "Epoch 4663/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6019 - accuracy: 0.6587 - val_loss: 0.6481 - val_accuracy: 0.5837\n",
      "Epoch 4664/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6022 - accuracy: 0.6578 - val_loss: 0.6730 - val_accuracy: 0.5451\n",
      "Epoch 4665/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6028 - accuracy: 0.6583 - val_loss: 0.6393 - val_accuracy: 0.5924\n",
      "Epoch 4666/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6033 - accuracy: 0.6558 - val_loss: 0.6801 - val_accuracy: 0.5340\n",
      "Epoch 4667/15000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.6045 - accuracy: 0.6574 - val_loss: 0.6319 - val_accuracy: 0.6076\n",
      "Epoch 4668/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6046 - accuracy: 0.6545 - val_loss: 0.6909 - val_accuracy: 0.5212\n",
      "Epoch 4669/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6056 - accuracy: 0.6549 - val_loss: 0.6346 - val_accuracy: 0.6014\n",
      "Epoch 4670/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6044 - accuracy: 0.6542 - val_loss: 0.6776 - val_accuracy: 0.5378\n",
      "Epoch 4671/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6042 - accuracy: 0.6576 - val_loss: 0.6393 - val_accuracy: 0.5961\n",
      "Epoch 4672/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6031 - accuracy: 0.6560 - val_loss: 0.6716 - val_accuracy: 0.5475\n",
      "Epoch 4673/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6031 - accuracy: 0.6577 - val_loss: 0.6520 - val_accuracy: 0.5769\n",
      "Epoch 4674/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6020 - accuracy: 0.6586 - val_loss: 0.6549 - val_accuracy: 0.5720\n",
      "Epoch 4675/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6023 - accuracy: 0.6584 - val_loss: 0.6627 - val_accuracy: 0.5586\n",
      "Epoch 4676/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6021 - accuracy: 0.6588 - val_loss: 0.6449 - val_accuracy: 0.5886\n",
      "Epoch 4677/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6030 - accuracy: 0.6567 - val_loss: 0.6815 - val_accuracy: 0.5327\n",
      "Epoch 4678/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6046 - accuracy: 0.6562 - val_loss: 0.6288 - val_accuracy: 0.6138\n",
      "Epoch 4679/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6056 - accuracy: 0.6539 - val_loss: 0.6968 - val_accuracy: 0.5185\n",
      "Epoch 4680/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6076 - accuracy: 0.6530 - val_loss: 0.6329 - val_accuracy: 0.6049\n",
      "Epoch 4681/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6057 - accuracy: 0.6529 - val_loss: 0.6794 - val_accuracy: 0.5400\n",
      "Epoch 4682/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6062 - accuracy: 0.6552 - val_loss: 0.6447 - val_accuracy: 0.5840\n",
      "Epoch 4683/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6042 - accuracy: 0.6551 - val_loss: 0.6570 - val_accuracy: 0.5689\n",
      "Epoch 4684/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6034 - accuracy: 0.6558 - val_loss: 0.6742 - val_accuracy: 0.5460\n",
      "Epoch 4685/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6038 - accuracy: 0.6563 - val_loss: 0.6371 - val_accuracy: 0.5999\n",
      "Epoch 4686/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6057 - accuracy: 0.6559 - val_loss: 0.6897 - val_accuracy: 0.5241\n",
      "Epoch 4687/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6068 - accuracy: 0.6541 - val_loss: 0.6270 - val_accuracy: 0.6158\n",
      "Epoch 4688/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6081 - accuracy: 0.6515 - val_loss: 0.7018 - val_accuracy: 0.5093\n",
      "Epoch 4689/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6093 - accuracy: 0.6492 - val_loss: 0.6299 - val_accuracy: 0.6089\n",
      "Epoch 4690/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6068 - accuracy: 0.6529 - val_loss: 0.6728 - val_accuracy: 0.5451\n",
      "Epoch 4691/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6060 - accuracy: 0.6526 - val_loss: 0.6673 - val_accuracy: 0.5517\n",
      "Epoch 4692/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6053 - accuracy: 0.6533 - val_loss: 0.6450 - val_accuracy: 0.5884\n",
      "Epoch 4693/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6051 - accuracy: 0.6565 - val_loss: 0.6800 - val_accuracy: 0.5340\n",
      "Epoch 4694/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6057 - accuracy: 0.6555 - val_loss: 0.6262 - val_accuracy: 0.6167\n",
      "Epoch 4695/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6062 - accuracy: 0.6525 - val_loss: 0.6892 - val_accuracy: 0.5237\n",
      "Epoch 4696/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6051 - accuracy: 0.6555 - val_loss: 0.6467 - val_accuracy: 0.5835\n",
      "Epoch 4697/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6047 - accuracy: 0.6556 - val_loss: 0.6641 - val_accuracy: 0.5546\n",
      "Epoch 4698/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6025 - accuracy: 0.6587 - val_loss: 0.6496 - val_accuracy: 0.5751\n",
      "Epoch 4699/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6029 - accuracy: 0.6567 - val_loss: 0.6511 - val_accuracy: 0.5754\n",
      "Epoch 4700/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6025 - accuracy: 0.6588 - val_loss: 0.6724 - val_accuracy: 0.5469\n",
      "Epoch 4701/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6031 - accuracy: 0.6576 - val_loss: 0.6391 - val_accuracy: 0.5954\n",
      "Epoch 4702/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6035 - accuracy: 0.6540 - val_loss: 0.6774 - val_accuracy: 0.5351\n",
      "Epoch 4703/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6038 - accuracy: 0.6571 - val_loss: 0.6387 - val_accuracy: 0.5955\n",
      "Epoch 4704/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6038 - accuracy: 0.6564 - val_loss: 0.6749 - val_accuracy: 0.5413\n",
      "Epoch 4705/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6038 - accuracy: 0.6567 - val_loss: 0.6431 - val_accuracy: 0.5888\n",
      "Epoch 4706/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6035 - accuracy: 0.6552 - val_loss: 0.6711 - val_accuracy: 0.5473\n",
      "Epoch 4707/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6028 - accuracy: 0.6590 - val_loss: 0.6492 - val_accuracy: 0.5813\n",
      "Epoch 4708/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6025 - accuracy: 0.6583 - val_loss: 0.6543 - val_accuracy: 0.5687\n",
      "Epoch 4709/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6023 - accuracy: 0.6573 - val_loss: 0.6618 - val_accuracy: 0.5616\n",
      "Epoch 4710/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6023 - accuracy: 0.6582 - val_loss: 0.6571 - val_accuracy: 0.5711\n",
      "Epoch 4711/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6023 - accuracy: 0.6590 - val_loss: 0.6613 - val_accuracy: 0.5596\n",
      "Epoch 4712/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6024 - accuracy: 0.6582 - val_loss: 0.6425 - val_accuracy: 0.5890\n",
      "Epoch 4713/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6025 - accuracy: 0.6561 - val_loss: 0.6750 - val_accuracy: 0.5451\n",
      "Epoch 4714/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6028 - accuracy: 0.6585 - val_loss: 0.6470 - val_accuracy: 0.5833\n",
      "Epoch 4715/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6029 - accuracy: 0.6568 - val_loss: 0.6682 - val_accuracy: 0.5512\n",
      "Epoch 4716/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6030 - accuracy: 0.6579 - val_loss: 0.6401 - val_accuracy: 0.5928\n",
      "Epoch 4717/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6029 - accuracy: 0.6554 - val_loss: 0.6766 - val_accuracy: 0.5422\n",
      "Epoch 4718/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6029 - accuracy: 0.6581 - val_loss: 0.6475 - val_accuracy: 0.5849\n",
      "Epoch 4719/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6027 - accuracy: 0.6570 - val_loss: 0.6663 - val_accuracy: 0.5537\n",
      "Epoch 4720/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6026 - accuracy: 0.6583 - val_loss: 0.6423 - val_accuracy: 0.5908\n",
      "Epoch 4721/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6025 - accuracy: 0.6568 - val_loss: 0.6727 - val_accuracy: 0.5482\n",
      "Epoch 4722/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6026 - accuracy: 0.6583 - val_loss: 0.6470 - val_accuracy: 0.5844\n",
      "Epoch 4723/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6025 - accuracy: 0.6566 - val_loss: 0.6691 - val_accuracy: 0.5501\n",
      "Epoch 4724/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6024 - accuracy: 0.6588 - val_loss: 0.6429 - val_accuracy: 0.5897\n",
      "Epoch 4725/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6025 - accuracy: 0.6575 - val_loss: 0.6721 - val_accuracy: 0.5449\n",
      "Epoch 4726/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6026 - accuracy: 0.6586 - val_loss: 0.6423 - val_accuracy: 0.5932\n",
      "Epoch 4727/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6027 - accuracy: 0.6559 - val_loss: 0.6763 - val_accuracy: 0.5398\n",
      "Epoch 4728/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6029 - accuracy: 0.6581 - val_loss: 0.6392 - val_accuracy: 0.5948\n",
      "Epoch 4729/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6030 - accuracy: 0.6564 - val_loss: 0.6786 - val_accuracy: 0.5369\n",
      "Epoch 4730/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6036 - accuracy: 0.6578 - val_loss: 0.6343 - val_accuracy: 0.6008\n",
      "Epoch 4731/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6038 - accuracy: 0.6554 - val_loss: 0.6879 - val_accuracy: 0.5270\n",
      "Epoch 4732/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6045 - accuracy: 0.6569 - val_loss: 0.6339 - val_accuracy: 0.6027\n",
      "Epoch 4733/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6043 - accuracy: 0.6548 - val_loss: 0.6841 - val_accuracy: 0.5294\n",
      "Epoch 4734/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6049 - accuracy: 0.6566 - val_loss: 0.6326 - val_accuracy: 0.6050\n",
      "Epoch 4735/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6039 - accuracy: 0.6549 - val_loss: 0.6807 - val_accuracy: 0.5378\n",
      "Epoch 4736/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6036 - accuracy: 0.6576 - val_loss: 0.6445 - val_accuracy: 0.5882\n",
      "Epoch 4737/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6023 - accuracy: 0.6573 - val_loss: 0.6640 - val_accuracy: 0.5583\n",
      "Epoch 4738/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6021 - accuracy: 0.6588 - val_loss: 0.6522 - val_accuracy: 0.5789\n",
      "Epoch 4739/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6015 - accuracy: 0.6593 - val_loss: 0.6552 - val_accuracy: 0.5723\n",
      "Epoch 4740/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6019 - accuracy: 0.6588 - val_loss: 0.6664 - val_accuracy: 0.5508\n",
      "Epoch 4741/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6020 - accuracy: 0.6592 - val_loss: 0.6403 - val_accuracy: 0.5917\n",
      "Epoch 4742/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6027 - accuracy: 0.6567 - val_loss: 0.6818 - val_accuracy: 0.5343\n",
      "Epoch 4743/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6039 - accuracy: 0.6564 - val_loss: 0.6333 - val_accuracy: 0.6021\n",
      "Epoch 4744/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6044 - accuracy: 0.6549 - val_loss: 0.6906 - val_accuracy: 0.5192\n",
      "Epoch 4745/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6064 - accuracy: 0.6547 - val_loss: 0.6280 - val_accuracy: 0.6155\n",
      "Epoch 4746/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6057 - accuracy: 0.6538 - val_loss: 0.6883 - val_accuracy: 0.5269\n",
      "Epoch 4747/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6054 - accuracy: 0.6553 - val_loss: 0.6439 - val_accuracy: 0.5893\n",
      "Epoch 4748/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6030 - accuracy: 0.6568 - val_loss: 0.6607 - val_accuracy: 0.5638\n",
      "Epoch 4749/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6035 - accuracy: 0.6578 - val_loss: 0.6599 - val_accuracy: 0.5678\n",
      "Epoch 4750/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6026 - accuracy: 0.6583 - val_loss: 0.6441 - val_accuracy: 0.5866\n",
      "Epoch 4751/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6037 - accuracy: 0.6564 - val_loss: 0.6879 - val_accuracy: 0.5259\n",
      "Epoch 4752/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6047 - accuracy: 0.6559 - val_loss: 0.6236 - val_accuracy: 0.6239\n",
      "Epoch 4753/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6073 - accuracy: 0.6523 - val_loss: 0.7070 - val_accuracy: 0.5042\n",
      "Epoch 4754/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6094 - accuracy: 0.6509 - val_loss: 0.6313 - val_accuracy: 0.6074\n",
      "Epoch 4755/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6069 - accuracy: 0.6521 - val_loss: 0.6745 - val_accuracy: 0.5460\n",
      "Epoch 4756/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6046 - accuracy: 0.6574 - val_loss: 0.6490 - val_accuracy: 0.5809\n",
      "Epoch 4757/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6035 - accuracy: 0.6573 - val_loss: 0.6492 - val_accuracy: 0.5789\n",
      "Epoch 4758/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6031 - accuracy: 0.6557 - val_loss: 0.6827 - val_accuracy: 0.5362\n",
      "Epoch 4759/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6040 - accuracy: 0.6562 - val_loss: 0.6358 - val_accuracy: 0.6008\n",
      "Epoch 4760/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6046 - accuracy: 0.6565 - val_loss: 0.6818 - val_accuracy: 0.5294\n",
      "Epoch 4761/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6050 - accuracy: 0.6553 - val_loss: 0.6324 - val_accuracy: 0.6071\n",
      "Epoch 4762/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6045 - accuracy: 0.6539 - val_loss: 0.6816 - val_accuracy: 0.5336\n",
      "Epoch 4763/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6039 - accuracy: 0.6577 - val_loss: 0.6443 - val_accuracy: 0.5855\n",
      "Epoch 4764/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6028 - accuracy: 0.6570 - val_loss: 0.6630 - val_accuracy: 0.5577\n",
      "Epoch 4765/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6025 - accuracy: 0.6568 - val_loss: 0.6569 - val_accuracy: 0.5672\n",
      "Epoch 4766/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6016 - accuracy: 0.6589 - val_loss: 0.6471 - val_accuracy: 0.5831\n",
      "Epoch 4767/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6028 - accuracy: 0.6587 - val_loss: 0.6771 - val_accuracy: 0.5367\n",
      "Epoch 4768/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6034 - accuracy: 0.6571 - val_loss: 0.6324 - val_accuracy: 0.6060\n",
      "Epoch 4769/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6049 - accuracy: 0.6533 - val_loss: 0.6925 - val_accuracy: 0.5144\n",
      "Epoch 4770/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6064 - accuracy: 0.6540 - val_loss: 0.6310 - val_accuracy: 0.6107\n",
      "Epoch 4771/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6056 - accuracy: 0.6555 - val_loss: 0.6830 - val_accuracy: 0.5314\n",
      "Epoch 4772/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6064 - accuracy: 0.6530 - val_loss: 0.6516 - val_accuracy: 0.5780\n",
      "Epoch 4773/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6045 - accuracy: 0.6536 - val_loss: 0.6557 - val_accuracy: 0.5720\n",
      "Epoch 4774/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6042 - accuracy: 0.6580 - val_loss: 0.6737 - val_accuracy: 0.5435\n",
      "Epoch 4775/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6039 - accuracy: 0.6581 - val_loss: 0.6265 - val_accuracy: 0.6153\n",
      "Epoch 4776/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6063 - accuracy: 0.6531 - val_loss: 0.6961 - val_accuracy: 0.5130\n",
      "Epoch 4777/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6062 - accuracy: 0.6542 - val_loss: 0.6377 - val_accuracy: 0.6025\n",
      "Epoch 4778/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6071 - accuracy: 0.6544 - val_loss: 0.6821 - val_accuracy: 0.5320\n",
      "Epoch 4779/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6043 - accuracy: 0.6567 - val_loss: 0.6345 - val_accuracy: 0.5990\n",
      "Epoch 4780/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6045 - accuracy: 0.6532 - val_loss: 0.6654 - val_accuracy: 0.5583\n",
      "Epoch 4781/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6021 - accuracy: 0.6586 - val_loss: 0.6613 - val_accuracy: 0.5645\n",
      "Epoch 4782/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6025 - accuracy: 0.6579 - val_loss: 0.6506 - val_accuracy: 0.5784\n",
      "Epoch 4783/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6023 - accuracy: 0.6561 - val_loss: 0.6667 - val_accuracy: 0.5506\n",
      "Epoch 4784/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6025 - accuracy: 0.6577 - val_loss: 0.6407 - val_accuracy: 0.5946\n",
      "Epoch 4785/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6033 - accuracy: 0.6573 - val_loss: 0.6801 - val_accuracy: 0.5358\n",
      "Epoch 4786/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6035 - accuracy: 0.6570 - val_loss: 0.6348 - val_accuracy: 0.6028\n",
      "Epoch 4787/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6046 - accuracy: 0.6534 - val_loss: 0.6819 - val_accuracy: 0.5314\n",
      "Epoch 4788/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6038 - accuracy: 0.6579 - val_loss: 0.6377 - val_accuracy: 0.6008\n",
      "Epoch 4789/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6040 - accuracy: 0.6569 - val_loss: 0.6735 - val_accuracy: 0.5460\n",
      "Epoch 4790/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6032 - accuracy: 0.6575 - val_loss: 0.6478 - val_accuracy: 0.5813\n",
      "Epoch 4791/15000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6030 - accuracy: 0.6553 - val_loss: 0.6663 - val_accuracy: 0.5590\n",
      "Epoch 4792/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6024 - accuracy: 0.6588 - val_loss: 0.6539 - val_accuracy: 0.5738\n",
      "Epoch 4793/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6019 - accuracy: 0.6591 - val_loss: 0.6464 - val_accuracy: 0.5820\n",
      "Epoch 4794/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6024 - accuracy: 0.6558 - val_loss: 0.6714 - val_accuracy: 0.5490\n",
      "Epoch 4795/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6021 - accuracy: 0.6585 - val_loss: 0.6467 - val_accuracy: 0.5820\n",
      "Epoch 4796/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6032 - accuracy: 0.6568 - val_loss: 0.6758 - val_accuracy: 0.5396\n",
      "Epoch 4797/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6031 - accuracy: 0.6568 - val_loss: 0.6323 - val_accuracy: 0.6063\n",
      "Epoch 4798/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6039 - accuracy: 0.6543 - val_loss: 0.6819 - val_accuracy: 0.5322\n",
      "Epoch 4799/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6036 - accuracy: 0.6580 - val_loss: 0.6438 - val_accuracy: 0.5893\n",
      "Epoch 4800/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6034 - accuracy: 0.6568 - val_loss: 0.6695 - val_accuracy: 0.5499\n",
      "Epoch 4801/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6026 - accuracy: 0.6571 - val_loss: 0.6471 - val_accuracy: 0.5820\n",
      "Epoch 4802/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6019 - accuracy: 0.6564 - val_loss: 0.6575 - val_accuracy: 0.5709\n",
      "Epoch 4803/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6021 - accuracy: 0.6590 - val_loss: 0.6671 - val_accuracy: 0.5537\n",
      "Epoch 4804/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6016 - accuracy: 0.6594 - val_loss: 0.6405 - val_accuracy: 0.5930\n",
      "Epoch 4805/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6031 - accuracy: 0.6551 - val_loss: 0.6815 - val_accuracy: 0.5309\n",
      "Epoch 4806/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6037 - accuracy: 0.6578 - val_loss: 0.6306 - val_accuracy: 0.6081\n",
      "Epoch 4807/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6053 - accuracy: 0.6551 - val_loss: 0.6944 - val_accuracy: 0.5221\n",
      "Epoch 4808/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6066 - accuracy: 0.6534 - val_loss: 0.6376 - val_accuracy: 0.6003\n",
      "Epoch 4809/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6058 - accuracy: 0.6523 - val_loss: 0.6740 - val_accuracy: 0.5471\n",
      "Epoch 4810/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6041 - accuracy: 0.6561 - val_loss: 0.6503 - val_accuracy: 0.5795\n",
      "Epoch 4811/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6033 - accuracy: 0.6584 - val_loss: 0.6487 - val_accuracy: 0.5798\n",
      "Epoch 4812/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6041 - accuracy: 0.6537 - val_loss: 0.6743 - val_accuracy: 0.5422\n",
      "Epoch 4813/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6031 - accuracy: 0.6573 - val_loss: 0.6447 - val_accuracy: 0.5884\n",
      "Epoch 4814/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6050 - accuracy: 0.6561 - val_loss: 0.6819 - val_accuracy: 0.5307\n",
      "Epoch 4815/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6038 - accuracy: 0.6570 - val_loss: 0.6287 - val_accuracy: 0.6134\n",
      "Epoch 4816/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6057 - accuracy: 0.6533 - val_loss: 0.6829 - val_accuracy: 0.5323\n",
      "Epoch 4817/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6040 - accuracy: 0.6580 - val_loss: 0.6421 - val_accuracy: 0.5950\n",
      "Epoch 4818/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6049 - accuracy: 0.6555 - val_loss: 0.6745 - val_accuracy: 0.5459\n",
      "Epoch 4819/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6028 - accuracy: 0.6574 - val_loss: 0.6477 - val_accuracy: 0.5789\n",
      "Epoch 4820/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6027 - accuracy: 0.6549 - val_loss: 0.6516 - val_accuracy: 0.5778\n",
      "Epoch 4821/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6023 - accuracy: 0.6595 - val_loss: 0.6714 - val_accuracy: 0.5519\n",
      "Epoch 4822/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6023 - accuracy: 0.6585 - val_loss: 0.6395 - val_accuracy: 0.5954\n",
      "Epoch 4823/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6041 - accuracy: 0.6542 - val_loss: 0.6854 - val_accuracy: 0.5281\n",
      "Epoch 4824/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6047 - accuracy: 0.6562 - val_loss: 0.6252 - val_accuracy: 0.6173\n",
      "Epoch 4825/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6065 - accuracy: 0.6535 - val_loss: 0.6988 - val_accuracy: 0.5144\n",
      "Epoch 4826/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6070 - accuracy: 0.6542 - val_loss: 0.6382 - val_accuracy: 0.5996\n",
      "Epoch 4827/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6057 - accuracy: 0.6535 - val_loss: 0.6692 - val_accuracy: 0.5539\n",
      "Epoch 4828/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6033 - accuracy: 0.6576 - val_loss: 0.6518 - val_accuracy: 0.5760\n",
      "Epoch 4829/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6036 - accuracy: 0.6579 - val_loss: 0.6481 - val_accuracy: 0.5796\n",
      "Epoch 4830/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6028 - accuracy: 0.6558 - val_loss: 0.6716 - val_accuracy: 0.5469\n",
      "Epoch 4831/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6027 - accuracy: 0.6568 - val_loss: 0.6513 - val_accuracy: 0.5786\n",
      "Epoch 4832/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6028 - accuracy: 0.6574 - val_loss: 0.6631 - val_accuracy: 0.5596\n",
      "Epoch 4833/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6018 - accuracy: 0.6592 - val_loss: 0.6467 - val_accuracy: 0.5795\n",
      "Epoch 4834/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6028 - accuracy: 0.6552 - val_loss: 0.6607 - val_accuracy: 0.5616\n",
      "Epoch 4835/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6011 - accuracy: 0.6593 - val_loss: 0.6552 - val_accuracy: 0.5725\n",
      "Epoch 4836/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6023 - accuracy: 0.6581 - val_loss: 0.6650 - val_accuracy: 0.5554\n",
      "Epoch 4837/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6011 - accuracy: 0.6591 - val_loss: 0.6471 - val_accuracy: 0.5839\n",
      "Epoch 4838/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6021 - accuracy: 0.6560 - val_loss: 0.6623 - val_accuracy: 0.5628\n",
      "Epoch 4839/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6015 - accuracy: 0.6598 - val_loss: 0.6494 - val_accuracy: 0.5820\n",
      "Epoch 4840/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6018 - accuracy: 0.6579 - val_loss: 0.6675 - val_accuracy: 0.5546\n",
      "Epoch 4841/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6017 - accuracy: 0.6583 - val_loss: 0.6500 - val_accuracy: 0.5811\n",
      "Epoch 4842/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6013 - accuracy: 0.6579 - val_loss: 0.6579 - val_accuracy: 0.5674\n",
      "Epoch 4843/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6016 - accuracy: 0.6589 - val_loss: 0.6581 - val_accuracy: 0.5707\n",
      "Epoch 4844/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6009 - accuracy: 0.6597 - val_loss: 0.6525 - val_accuracy: 0.5767\n",
      "Epoch 4845/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6016 - accuracy: 0.6574 - val_loss: 0.6670 - val_accuracy: 0.5522\n",
      "Epoch 4846/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6014 - accuracy: 0.6592 - val_loss: 0.6392 - val_accuracy: 0.5961\n",
      "Epoch 4847/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6026 - accuracy: 0.6570 - val_loss: 0.6833 - val_accuracy: 0.5334\n",
      "Epoch 4848/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6035 - accuracy: 0.6570 - val_loss: 0.6337 - val_accuracy: 0.6067\n",
      "Epoch 4849/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6043 - accuracy: 0.6545 - val_loss: 0.6883 - val_accuracy: 0.5228\n",
      "Epoch 4850/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6055 - accuracy: 0.6558 - val_loss: 0.6307 - val_accuracy: 0.6052\n",
      "Epoch 4851/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6046 - accuracy: 0.6550 - val_loss: 0.6798 - val_accuracy: 0.5382\n",
      "Epoch 4852/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6043 - accuracy: 0.6555 - val_loss: 0.6518 - val_accuracy: 0.5787\n",
      "Epoch 4853/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6023 - accuracy: 0.6566 - val_loss: 0.6563 - val_accuracy: 0.5714\n",
      "Epoch 4854/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6032 - accuracy: 0.6571 - val_loss: 0.6672 - val_accuracy: 0.5554\n",
      "Epoch 4855/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6025 - accuracy: 0.6586 - val_loss: 0.6334 - val_accuracy: 0.6036\n",
      "Epoch 4856/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6044 - accuracy: 0.6544 - val_loss: 0.6928 - val_accuracy: 0.5188\n",
      "Epoch 4857/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6052 - accuracy: 0.6549 - val_loss: 0.6288 - val_accuracy: 0.6140\n",
      "Epoch 4858/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6062 - accuracy: 0.6534 - val_loss: 0.6925 - val_accuracy: 0.5216\n",
      "Epoch 4859/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6053 - accuracy: 0.6551 - val_loss: 0.6364 - val_accuracy: 0.6014\n",
      "Epoch 4860/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6037 - accuracy: 0.6546 - val_loss: 0.6648 - val_accuracy: 0.5586\n",
      "Epoch 4861/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6021 - accuracy: 0.6593 - val_loss: 0.6565 - val_accuracy: 0.5718\n",
      "Epoch 4862/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6017 - accuracy: 0.6595 - val_loss: 0.6447 - val_accuracy: 0.5851\n",
      "Epoch 4863/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6022 - accuracy: 0.6558 - val_loss: 0.6806 - val_accuracy: 0.5367\n",
      "Epoch 4864/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6029 - accuracy: 0.6577 - val_loss: 0.6331 - val_accuracy: 0.6045\n",
      "Epoch 4865/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6042 - accuracy: 0.6565 - val_loss: 0.6892 - val_accuracy: 0.5219\n",
      "Epoch 4866/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6048 - accuracy: 0.6557 - val_loss: 0.6299 - val_accuracy: 0.6118\n",
      "Epoch 4867/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6043 - accuracy: 0.6548 - val_loss: 0.6799 - val_accuracy: 0.5360\n",
      "Epoch 4868/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6031 - accuracy: 0.6583 - val_loss: 0.6434 - val_accuracy: 0.5910\n",
      "Epoch 4869/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6021 - accuracy: 0.6590 - val_loss: 0.6609 - val_accuracy: 0.5597\n",
      "Epoch 4870/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6015 - accuracy: 0.6583 - val_loss: 0.6613 - val_accuracy: 0.5623\n",
      "Epoch 4871/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6011 - accuracy: 0.6590 - val_loss: 0.6448 - val_accuracy: 0.5871\n",
      "Epoch 4872/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6022 - accuracy: 0.6589 - val_loss: 0.6773 - val_accuracy: 0.5367\n",
      "Epoch 4873/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6026 - accuracy: 0.6583 - val_loss: 0.6304 - val_accuracy: 0.6103\n",
      "Epoch 4874/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6041 - accuracy: 0.6545 - val_loss: 0.6923 - val_accuracy: 0.5195\n",
      "Epoch 4875/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6051 - accuracy: 0.6550 - val_loss: 0.6313 - val_accuracy: 0.6081\n",
      "Epoch 4876/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6047 - accuracy: 0.6556 - val_loss: 0.6828 - val_accuracy: 0.5325\n",
      "Epoch 4877/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6039 - accuracy: 0.6561 - val_loss: 0.6424 - val_accuracy: 0.5875\n",
      "Epoch 4878/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6022 - accuracy: 0.6559 - val_loss: 0.6576 - val_accuracy: 0.5689\n",
      "Epoch 4879/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6016 - accuracy: 0.6591 - val_loss: 0.6696 - val_accuracy: 0.5543\n",
      "Epoch 4880/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6015 - accuracy: 0.6597 - val_loss: 0.6338 - val_accuracy: 0.6043\n",
      "Epoch 4881/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6038 - accuracy: 0.6541 - val_loss: 0.6934 - val_accuracy: 0.5170\n",
      "Epoch 4882/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6056 - accuracy: 0.6546 - val_loss: 0.6249 - val_accuracy: 0.6197\n",
      "Epoch 4883/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6063 - accuracy: 0.6538 - val_loss: 0.6965 - val_accuracy: 0.5163\n",
      "Epoch 4884/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6063 - accuracy: 0.6544 - val_loss: 0.6367 - val_accuracy: 0.5996\n",
      "Epoch 4885/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6040 - accuracy: 0.6547 - val_loss: 0.6635 - val_accuracy: 0.5614\n",
      "Epoch 4886/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6019 - accuracy: 0.6594 - val_loss: 0.6623 - val_accuracy: 0.5619\n",
      "Epoch 4887/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6018 - accuracy: 0.6601 - val_loss: 0.6370 - val_accuracy: 0.5999\n",
      "Epoch 4888/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6031 - accuracy: 0.6558 - val_loss: 0.6879 - val_accuracy: 0.5247\n",
      "Epoch 4889/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6043 - accuracy: 0.6559 - val_loss: 0.6331 - val_accuracy: 0.6032\n",
      "Epoch 4890/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6043 - accuracy: 0.6559 - val_loss: 0.6812 - val_accuracy: 0.5316\n",
      "Epoch 4891/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6031 - accuracy: 0.6579 - val_loss: 0.6390 - val_accuracy: 0.5952\n",
      "Epoch 4892/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6021 - accuracy: 0.6554 - val_loss: 0.6605 - val_accuracy: 0.5658\n",
      "Epoch 4893/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6008 - accuracy: 0.6595 - val_loss: 0.6618 - val_accuracy: 0.5650\n",
      "Epoch 4894/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6010 - accuracy: 0.6597 - val_loss: 0.6483 - val_accuracy: 0.5844\n",
      "Epoch 4895/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6012 - accuracy: 0.6587 - val_loss: 0.6719 - val_accuracy: 0.5422\n",
      "Epoch 4896/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6021 - accuracy: 0.6590 - val_loss: 0.6335 - val_accuracy: 0.6016\n",
      "Epoch 4897/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6026 - accuracy: 0.6557 - val_loss: 0.6831 - val_accuracy: 0.5331\n",
      "Epoch 4898/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6031 - accuracy: 0.6575 - val_loss: 0.6393 - val_accuracy: 0.5943\n",
      "Epoch 4899/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6024 - accuracy: 0.6562 - val_loss: 0.6713 - val_accuracy: 0.5482\n",
      "Epoch 4900/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6020 - accuracy: 0.6588 - val_loss: 0.6435 - val_accuracy: 0.5902\n",
      "Epoch 4901/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6013 - accuracy: 0.6586 - val_loss: 0.6632 - val_accuracy: 0.5605\n",
      "Epoch 4902/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6010 - accuracy: 0.6590 - val_loss: 0.6591 - val_accuracy: 0.5661\n",
      "Epoch 4903/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6007 - accuracy: 0.6593 - val_loss: 0.6473 - val_accuracy: 0.5839\n",
      "Epoch 4904/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6010 - accuracy: 0.6583 - val_loss: 0.6692 - val_accuracy: 0.5501\n",
      "Epoch 4905/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6013 - accuracy: 0.6596 - val_loss: 0.6410 - val_accuracy: 0.5930\n",
      "Epoch 4906/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6019 - accuracy: 0.6578 - val_loss: 0.6782 - val_accuracy: 0.5384\n",
      "Epoch 4907/15000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.6029 - accuracy: 0.6573 - val_loss: 0.6342 - val_accuracy: 0.6028\n",
      "Epoch 4908/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6031 - accuracy: 0.6559 - val_loss: 0.6818 - val_accuracy: 0.5343\n",
      "Epoch 4909/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6029 - accuracy: 0.6581 - val_loss: 0.6414 - val_accuracy: 0.5926\n",
      "Epoch 4910/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6018 - accuracy: 0.6568 - val_loss: 0.6631 - val_accuracy: 0.5632\n",
      "Epoch 4911/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6016 - accuracy: 0.6591 - val_loss: 0.6551 - val_accuracy: 0.5756\n",
      "Epoch 4912/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6009 - accuracy: 0.6592 - val_loss: 0.6537 - val_accuracy: 0.5773\n",
      "Epoch 4913/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6015 - accuracy: 0.6586 - val_loss: 0.6690 - val_accuracy: 0.5519\n",
      "Epoch 4914/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6015 - accuracy: 0.6588 - val_loss: 0.6326 - val_accuracy: 0.6067\n",
      "Epoch 4915/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6030 - accuracy: 0.6550 - val_loss: 0.6903 - val_accuracy: 0.5258\n",
      "Epoch 4916/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6040 - accuracy: 0.6562 - val_loss: 0.6345 - val_accuracy: 0.6036\n",
      "Epoch 4917/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6047 - accuracy: 0.6547 - val_loss: 0.6842 - val_accuracy: 0.5285\n",
      "Epoch 4918/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6054 - accuracy: 0.6565 - val_loss: 0.6313 - val_accuracy: 0.6078\n",
      "Epoch 4919/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6042 - accuracy: 0.6540 - val_loss: 0.6739 - val_accuracy: 0.5488\n",
      "Epoch 4920/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6024 - accuracy: 0.6580 - val_loss: 0.6614 - val_accuracy: 0.5665\n",
      "Epoch 4921/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6014 - accuracy: 0.6591 - val_loss: 0.6453 - val_accuracy: 0.5846\n",
      "Epoch 4922/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6022 - accuracy: 0.6564 - val_loss: 0.6690 - val_accuracy: 0.5522\n",
      "Epoch 4923/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6025 - accuracy: 0.6585 - val_loss: 0.6381 - val_accuracy: 0.5954\n",
      "Epoch 4924/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6034 - accuracy: 0.6565 - val_loss: 0.6870 - val_accuracy: 0.5276\n",
      "Epoch 4925/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6038 - accuracy: 0.6572 - val_loss: 0.6315 - val_accuracy: 0.6109\n",
      "Epoch 4926/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6044 - accuracy: 0.6538 - val_loss: 0.6847 - val_accuracy: 0.5292\n",
      "Epoch 4927/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6032 - accuracy: 0.6579 - val_loss: 0.6394 - val_accuracy: 0.5994\n",
      "Epoch 4928/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6029 - accuracy: 0.6573 - val_loss: 0.6655 - val_accuracy: 0.5546\n",
      "Epoch 4929/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6022 - accuracy: 0.6576 - val_loss: 0.6499 - val_accuracy: 0.5795\n",
      "Epoch 4930/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6017 - accuracy: 0.6571 - val_loss: 0.6615 - val_accuracy: 0.5672\n",
      "Epoch 4931/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6012 - accuracy: 0.6595 - val_loss: 0.6632 - val_accuracy: 0.5608\n",
      "Epoch 4932/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6009 - accuracy: 0.6590 - val_loss: 0.6378 - val_accuracy: 0.5972\n",
      "Epoch 4933/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6020 - accuracy: 0.6556 - val_loss: 0.6775 - val_accuracy: 0.5413\n",
      "Epoch 4934/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6020 - accuracy: 0.6584 - val_loss: 0.6397 - val_accuracy: 0.5974\n",
      "Epoch 4935/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6036 - accuracy: 0.6568 - val_loss: 0.6863 - val_accuracy: 0.5278\n",
      "Epoch 4936/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6043 - accuracy: 0.6561 - val_loss: 0.6252 - val_accuracy: 0.6197\n",
      "Epoch 4937/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6045 - accuracy: 0.6547 - val_loss: 0.6867 - val_accuracy: 0.5290\n",
      "Epoch 4938/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6034 - accuracy: 0.6576 - val_loss: 0.6475 - val_accuracy: 0.5849\n",
      "Epoch 4939/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6021 - accuracy: 0.6580 - val_loss: 0.6562 - val_accuracy: 0.5709\n",
      "Epoch 4940/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6015 - accuracy: 0.6579 - val_loss: 0.6573 - val_accuracy: 0.5694\n",
      "Epoch 4941/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6011 - accuracy: 0.6590 - val_loss: 0.6469 - val_accuracy: 0.5881\n",
      "Epoch 4942/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6023 - accuracy: 0.6584 - val_loss: 0.6850 - val_accuracy: 0.5287\n",
      "Epoch 4943/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6032 - accuracy: 0.6579 - val_loss: 0.6228 - val_accuracy: 0.6253\n",
      "Epoch 4944/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6057 - accuracy: 0.6543 - val_loss: 0.7018 - val_accuracy: 0.5102\n",
      "Epoch 4945/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6068 - accuracy: 0.6537 - val_loss: 0.6315 - val_accuracy: 0.6076\n",
      "Epoch 4946/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6053 - accuracy: 0.6546 - val_loss: 0.6772 - val_accuracy: 0.5427\n",
      "Epoch 4947/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6042 - accuracy: 0.6570 - val_loss: 0.6452 - val_accuracy: 0.5897\n",
      "Epoch 4948/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6028 - accuracy: 0.6553 - val_loss: 0.6570 - val_accuracy: 0.5701\n",
      "Epoch 4949/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6014 - accuracy: 0.6601 - val_loss: 0.6760 - val_accuracy: 0.5426\n",
      "Epoch 4950/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6027 - accuracy: 0.6584 - val_loss: 0.6284 - val_accuracy: 0.6138\n",
      "Epoch 4951/15000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6037 - accuracy: 0.6556 - val_loss: 0.6879 - val_accuracy: 0.5263\n",
      "Epoch 4952/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6045 - accuracy: 0.6563 - val_loss: 0.6377 - val_accuracy: 0.5986\n",
      "Epoch 4953/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6041 - accuracy: 0.6559 - val_loss: 0.6798 - val_accuracy: 0.5353\n",
      "Epoch 4954/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6026 - accuracy: 0.6581 - val_loss: 0.6357 - val_accuracy: 0.6014\n",
      "Epoch 4955/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6020 - accuracy: 0.6563 - val_loss: 0.6630 - val_accuracy: 0.5621\n",
      "Epoch 4956/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6003 - accuracy: 0.6603 - val_loss: 0.6647 - val_accuracy: 0.5583\n",
      "Epoch 4957/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6009 - accuracy: 0.6599 - val_loss: 0.6464 - val_accuracy: 0.5857\n",
      "Epoch 4958/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6006 - accuracy: 0.6587 - val_loss: 0.6669 - val_accuracy: 0.5566\n",
      "Epoch 4959/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6014 - accuracy: 0.6588 - val_loss: 0.6393 - val_accuracy: 0.5928\n",
      "Epoch 4960/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6014 - accuracy: 0.6576 - val_loss: 0.6770 - val_accuracy: 0.5438\n",
      "Epoch 4961/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6016 - accuracy: 0.6589 - val_loss: 0.6433 - val_accuracy: 0.5904\n",
      "Epoch 4962/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6014 - accuracy: 0.6574 - val_loss: 0.6695 - val_accuracy: 0.5510\n",
      "Epoch 4963/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6011 - accuracy: 0.6598 - val_loss: 0.6419 - val_accuracy: 0.5910\n",
      "Epoch 4964/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6011 - accuracy: 0.6586 - val_loss: 0.6678 - val_accuracy: 0.5535\n",
      "Epoch 4965/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6006 - accuracy: 0.6594 - val_loss: 0.6491 - val_accuracy: 0.5842\n",
      "Epoch 4966/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6007 - accuracy: 0.6582 - val_loss: 0.6626 - val_accuracy: 0.5643\n",
      "Epoch 4967/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6002 - accuracy: 0.6604 - val_loss: 0.6500 - val_accuracy: 0.5817\n",
      "Epoch 4968/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6003 - accuracy: 0.6594 - val_loss: 0.6575 - val_accuracy: 0.5700\n",
      "Epoch 4969/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6001 - accuracy: 0.6598 - val_loss: 0.6556 - val_accuracy: 0.5751\n",
      "Epoch 4970/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6002 - accuracy: 0.6596 - val_loss: 0.6593 - val_accuracy: 0.5692\n",
      "Epoch 4971/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6000 - accuracy: 0.6597 - val_loss: 0.6545 - val_accuracy: 0.5764\n",
      "Epoch 4972/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6001 - accuracy: 0.6599 - val_loss: 0.6540 - val_accuracy: 0.5760\n",
      "Epoch 4973/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6000 - accuracy: 0.6597 - val_loss: 0.6577 - val_accuracy: 0.5725\n",
      "Epoch 4974/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6000 - accuracy: 0.6597 - val_loss: 0.6546 - val_accuracy: 0.5769\n",
      "Epoch 4975/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6000 - accuracy: 0.6597 - val_loss: 0.6593 - val_accuracy: 0.5685\n",
      "Epoch 4976/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.5999 - accuracy: 0.6595 - val_loss: 0.6506 - val_accuracy: 0.5806\n",
      "Epoch 4977/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6000 - accuracy: 0.6599 - val_loss: 0.6623 - val_accuracy: 0.5628\n",
      "Epoch 4978/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6000 - accuracy: 0.6598 - val_loss: 0.6491 - val_accuracy: 0.5829\n",
      "Epoch 4979/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6002 - accuracy: 0.6589 - val_loss: 0.6670 - val_accuracy: 0.5561\n",
      "Epoch 4980/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6003 - accuracy: 0.6604 - val_loss: 0.6435 - val_accuracy: 0.5895\n",
      "Epoch 4981/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6006 - accuracy: 0.6585 - val_loss: 0.6742 - val_accuracy: 0.5455\n",
      "Epoch 4982/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6011 - accuracy: 0.6595 - val_loss: 0.6357 - val_accuracy: 0.6010\n",
      "Epoch 4983/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6018 - accuracy: 0.6570 - val_loss: 0.6851 - val_accuracy: 0.5305\n",
      "Epoch 4984/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6027 - accuracy: 0.6584 - val_loss: 0.6298 - val_accuracy: 0.6120\n",
      "Epoch 4985/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6030 - accuracy: 0.6558 - val_loss: 0.6907 - val_accuracy: 0.5247\n",
      "Epoch 4986/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6042 - accuracy: 0.6568 - val_loss: 0.6295 - val_accuracy: 0.6127\n",
      "Epoch 4987/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6032 - accuracy: 0.6551 - val_loss: 0.6868 - val_accuracy: 0.5287\n",
      "Epoch 4988/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6029 - accuracy: 0.6583 - val_loss: 0.6367 - val_accuracy: 0.5988\n",
      "Epoch 4989/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6015 - accuracy: 0.6569 - val_loss: 0.6689 - val_accuracy: 0.5530\n",
      "Epoch 4990/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6007 - accuracy: 0.6600 - val_loss: 0.6479 - val_accuracy: 0.5857\n",
      "Epoch 4991/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6000 - accuracy: 0.6594 - val_loss: 0.6602 - val_accuracy: 0.5676\n",
      "Epoch 4992/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5998 - accuracy: 0.6600 - val_loss: 0.6575 - val_accuracy: 0.5723\n",
      "Epoch 4993/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.5998 - accuracy: 0.6600 - val_loss: 0.6477 - val_accuracy: 0.5840\n",
      "Epoch 4994/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5999 - accuracy: 0.6588 - val_loss: 0.6684 - val_accuracy: 0.5528\n",
      "Epoch 4995/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6003 - accuracy: 0.6599 - val_loss: 0.6414 - val_accuracy: 0.5924\n",
      "Epoch 4996/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6008 - accuracy: 0.6575 - val_loss: 0.6783 - val_accuracy: 0.5387\n",
      "Epoch 4997/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6018 - accuracy: 0.6589 - val_loss: 0.6317 - val_accuracy: 0.6061\n",
      "Epoch 4998/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6023 - accuracy: 0.6569 - val_loss: 0.6884 - val_accuracy: 0.5265\n",
      "Epoch 4999/15000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6033 - accuracy: 0.6579 - val_loss: 0.6311 - val_accuracy: 0.6080\n",
      "Epoch 5000/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6027 - accuracy: 0.6563 - val_loss: 0.6831 - val_accuracy: 0.5320\n",
      "Epoch 5001/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6028 - accuracy: 0.6581 - val_loss: 0.6355 - val_accuracy: 0.5992\n",
      "Epoch 5002/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6015 - accuracy: 0.6570 - val_loss: 0.6745 - val_accuracy: 0.5451\n",
      "Epoch 5003/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6010 - accuracy: 0.6599 - val_loss: 0.6441 - val_accuracy: 0.5881\n",
      "Epoch 5004/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6002 - accuracy: 0.6587 - val_loss: 0.6626 - val_accuracy: 0.5632\n",
      "Epoch 5005/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6000 - accuracy: 0.6601 - val_loss: 0.6512 - val_accuracy: 0.5813\n",
      "Epoch 5006/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5998 - accuracy: 0.6600 - val_loss: 0.6601 - val_accuracy: 0.5663\n",
      "Epoch 5007/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5997 - accuracy: 0.6604 - val_loss: 0.6514 - val_accuracy: 0.5802\n",
      "Epoch 5008/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5997 - accuracy: 0.6598 - val_loss: 0.6577 - val_accuracy: 0.5729\n",
      "Epoch 5009/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.5996 - accuracy: 0.6603 - val_loss: 0.6556 - val_accuracy: 0.5740\n",
      "Epoch 5010/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.5996 - accuracy: 0.6599 - val_loss: 0.6575 - val_accuracy: 0.5731\n",
      "Epoch 5011/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5996 - accuracy: 0.6604 - val_loss: 0.6531 - val_accuracy: 0.5787\n",
      "Epoch 5012/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5996 - accuracy: 0.6596 - val_loss: 0.6598 - val_accuracy: 0.5701\n",
      "Epoch 5013/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5996 - accuracy: 0.6602 - val_loss: 0.6521 - val_accuracy: 0.5780\n",
      "Epoch 5014/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5996 - accuracy: 0.6598 - val_loss: 0.6604 - val_accuracy: 0.5689\n",
      "Epoch 5015/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5997 - accuracy: 0.6601 - val_loss: 0.6482 - val_accuracy: 0.5851\n",
      "Epoch 5016/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5998 - accuracy: 0.6594 - val_loss: 0.6695 - val_accuracy: 0.5530\n",
      "Epoch 5017/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6001 - accuracy: 0.6604 - val_loss: 0.6399 - val_accuracy: 0.5946\n",
      "Epoch 5018/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6007 - accuracy: 0.6576 - val_loss: 0.6820 - val_accuracy: 0.5354\n",
      "Epoch 5019/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6020 - accuracy: 0.6581 - val_loss: 0.6282 - val_accuracy: 0.6155\n",
      "Epoch 5020/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6034 - accuracy: 0.6556 - val_loss: 0.7023 - val_accuracy: 0.5132\n",
      "Epoch 5021/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6068 - accuracy: 0.6539 - val_loss: 0.6198 - val_accuracy: 0.6293\n",
      "Epoch 5022/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6060 - accuracy: 0.6535 - val_loss: 0.7023 - val_accuracy: 0.5132\n",
      "Epoch 5023/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6063 - accuracy: 0.6551 - val_loss: 0.6336 - val_accuracy: 0.6038\n",
      "Epoch 5024/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6024 - accuracy: 0.6565 - val_loss: 0.6659 - val_accuracy: 0.5605\n",
      "Epoch 5025/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6007 - accuracy: 0.6603 - val_loss: 0.6556 - val_accuracy: 0.5736\n",
      "Epoch 5026/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5997 - accuracy: 0.6605 - val_loss: 0.6453 - val_accuracy: 0.5866\n",
      "Epoch 5027/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6008 - accuracy: 0.6578 - val_loss: 0.6842 - val_accuracy: 0.5296\n",
      "Epoch 5028/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6028 - accuracy: 0.6577 - val_loss: 0.6206 - val_accuracy: 0.6295\n",
      "Epoch 5029/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6055 - accuracy: 0.6545 - val_loss: 0.7128 - val_accuracy: 0.5009\n",
      "Epoch 5030/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6095 - accuracy: 0.6515 - val_loss: 0.6277 - val_accuracy: 0.6140\n",
      "Epoch 5031/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6058 - accuracy: 0.6526 - val_loss: 0.6733 - val_accuracy: 0.5486\n",
      "Epoch 5032/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6034 - accuracy: 0.6573 - val_loss: 0.6533 - val_accuracy: 0.5769\n",
      "Epoch 5033/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6020 - accuracy: 0.6587 - val_loss: 0.6428 - val_accuracy: 0.5901\n",
      "Epoch 5034/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6025 - accuracy: 0.6567 - val_loss: 0.6902 - val_accuracy: 0.5263\n",
      "Epoch 5035/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6038 - accuracy: 0.6575 - val_loss: 0.6269 - val_accuracy: 0.6189\n",
      "Epoch 5036/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6046 - accuracy: 0.6559 - val_loss: 0.6904 - val_accuracy: 0.5227\n",
      "Epoch 5037/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6044 - accuracy: 0.6563 - val_loss: 0.6333 - val_accuracy: 0.6039\n",
      "Epoch 5038/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6031 - accuracy: 0.6552 - val_loss: 0.6723 - val_accuracy: 0.5471\n",
      "Epoch 5039/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6011 - accuracy: 0.6600 - val_loss: 0.6452 - val_accuracy: 0.5860\n",
      "Epoch 5040/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6007 - accuracy: 0.6586 - val_loss: 0.6607 - val_accuracy: 0.5639\n",
      "Epoch 5041/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6002 - accuracy: 0.6589 - val_loss: 0.6597 - val_accuracy: 0.5659\n",
      "Epoch 5042/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5999 - accuracy: 0.6590 - val_loss: 0.6442 - val_accuracy: 0.5890\n",
      "Epoch 5043/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6007 - accuracy: 0.6590 - val_loss: 0.6712 - val_accuracy: 0.5473\n",
      "Epoch 5044/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6007 - accuracy: 0.6594 - val_loss: 0.6372 - val_accuracy: 0.6001\n",
      "Epoch 5045/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6021 - accuracy: 0.6557 - val_loss: 0.6834 - val_accuracy: 0.5311\n",
      "Epoch 5046/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6028 - accuracy: 0.6578 - val_loss: 0.6284 - val_accuracy: 0.6160\n",
      "Epoch 5047/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6036 - accuracy: 0.6566 - val_loss: 0.6935 - val_accuracy: 0.5265\n",
      "Epoch 5048/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6048 - accuracy: 0.6559 - val_loss: 0.6392 - val_accuracy: 0.6001\n",
      "Epoch 5049/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6027 - accuracy: 0.6558 - val_loss: 0.6651 - val_accuracy: 0.5597\n",
      "Epoch 5050/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6021 - accuracy: 0.6582 - val_loss: 0.6577 - val_accuracy: 0.5696\n",
      "Epoch 5051/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6010 - accuracy: 0.6593 - val_loss: 0.6370 - val_accuracy: 0.6001\n",
      "Epoch 5052/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6030 - accuracy: 0.6559 - val_loss: 0.6961 - val_accuracy: 0.5170\n",
      "Epoch 5053/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6042 - accuracy: 0.6566 - val_loss: 0.6267 - val_accuracy: 0.6187\n",
      "Epoch 5054/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6065 - accuracy: 0.6535 - val_loss: 0.7007 - val_accuracy: 0.5144\n",
      "Epoch 5055/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6069 - accuracy: 0.6547 - val_loss: 0.6284 - val_accuracy: 0.6125\n",
      "Epoch 5056/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6048 - accuracy: 0.6532 - val_loss: 0.6691 - val_accuracy: 0.5541\n",
      "Epoch 5057/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6018 - accuracy: 0.6591 - val_loss: 0.6612 - val_accuracy: 0.5663\n",
      "Epoch 5058/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6011 - accuracy: 0.6595 - val_loss: 0.6411 - val_accuracy: 0.5959\n",
      "Epoch 5059/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6028 - accuracy: 0.6550 - val_loss: 0.6879 - val_accuracy: 0.5272\n",
      "Epoch 5060/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6039 - accuracy: 0.6565 - val_loss: 0.6257 - val_accuracy: 0.6156\n",
      "Epoch 5061/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6053 - accuracy: 0.6547 - val_loss: 0.6967 - val_accuracy: 0.5183\n",
      "Epoch 5062/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6052 - accuracy: 0.6552 - val_loss: 0.6350 - val_accuracy: 0.6050\n",
      "Epoch 5063/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6037 - accuracy: 0.6543 - val_loss: 0.6660 - val_accuracy: 0.5574\n",
      "Epoch 5064/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6009 - accuracy: 0.6594 - val_loss: 0.6553 - val_accuracy: 0.5740\n",
      "Epoch 5065/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6010 - accuracy: 0.6593 - val_loss: 0.6448 - val_accuracy: 0.5881\n",
      "Epoch 5066/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6013 - accuracy: 0.6574 - val_loss: 0.6780 - val_accuracy: 0.5411\n",
      "Epoch 5067/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6018 - accuracy: 0.6583 - val_loss: 0.6376 - val_accuracy: 0.5994\n",
      "Epoch 5068/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6023 - accuracy: 0.6570 - val_loss: 0.6771 - val_accuracy: 0.5415\n",
      "Epoch 5069/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6015 - accuracy: 0.6591 - val_loss: 0.6382 - val_accuracy: 0.5974\n",
      "Epoch 5070/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6010 - accuracy: 0.6568 - val_loss: 0.6630 - val_accuracy: 0.5647\n",
      "Epoch 5071/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6000 - accuracy: 0.6601 - val_loss: 0.6565 - val_accuracy: 0.5723\n",
      "Epoch 5072/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6001 - accuracy: 0.6594 - val_loss: 0.6542 - val_accuracy: 0.5767\n",
      "Epoch 5073/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5997 - accuracy: 0.6600 - val_loss: 0.6611 - val_accuracy: 0.5619\n",
      "Epoch 5074/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6000 - accuracy: 0.6592 - val_loss: 0.6402 - val_accuracy: 0.5944\n",
      "Epoch 5075/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6004 - accuracy: 0.6581 - val_loss: 0.6756 - val_accuracy: 0.5440\n",
      "Epoch 5076/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6007 - accuracy: 0.6592 - val_loss: 0.6433 - val_accuracy: 0.5908\n",
      "Epoch 5077/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.6010 - accuracy: 0.6579 - val_loss: 0.6729 - val_accuracy: 0.5469\n",
      "Epoch 5078/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6012 - accuracy: 0.6589 - val_loss: 0.6349 - val_accuracy: 0.6030\n",
      "Epoch 5079/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6011 - accuracy: 0.6566 - val_loss: 0.6766 - val_accuracy: 0.5455\n",
      "Epoch 5080/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6013 - accuracy: 0.6586 - val_loss: 0.6465 - val_accuracy: 0.5870\n",
      "Epoch 5081/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6004 - accuracy: 0.6585 - val_loss: 0.6605 - val_accuracy: 0.5703\n",
      "Epoch 5082/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6001 - accuracy: 0.6598 - val_loss: 0.6529 - val_accuracy: 0.5780\n",
      "Epoch 5083/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5997 - accuracy: 0.6595 - val_loss: 0.6525 - val_accuracy: 0.5789\n",
      "Epoch 5084/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6003 - accuracy: 0.6591 - val_loss: 0.6698 - val_accuracy: 0.5522\n",
      "Epoch 5085/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6004 - accuracy: 0.6594 - val_loss: 0.6371 - val_accuracy: 0.6018\n",
      "Epoch 5086/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6014 - accuracy: 0.6572 - val_loss: 0.6824 - val_accuracy: 0.5347\n",
      "Epoch 5087/15000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6021 - accuracy: 0.6579 - val_loss: 0.6331 - val_accuracy: 0.6056\n",
      "Epoch 5088/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6021 - accuracy: 0.6559 - val_loss: 0.6799 - val_accuracy: 0.5402\n",
      "Epoch 5089/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6028 - accuracy: 0.6579 - val_loss: 0.6389 - val_accuracy: 0.5986\n",
      "Epoch 5090/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6021 - accuracy: 0.6567 - val_loss: 0.6729 - val_accuracy: 0.5515\n",
      "Epoch 5091/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6009 - accuracy: 0.6600 - val_loss: 0.6494 - val_accuracy: 0.5833\n",
      "Epoch 5092/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6002 - accuracy: 0.6591 - val_loss: 0.6523 - val_accuracy: 0.5769\n",
      "Epoch 5093/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6007 - accuracy: 0.6587 - val_loss: 0.6652 - val_accuracy: 0.5621\n",
      "Epoch 5094/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6003 - accuracy: 0.6600 - val_loss: 0.6438 - val_accuracy: 0.5886\n",
      "Epoch 5095/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6018 - accuracy: 0.6578 - val_loss: 0.6826 - val_accuracy: 0.5340\n",
      "Epoch 5096/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6025 - accuracy: 0.6580 - val_loss: 0.6232 - val_accuracy: 0.6239\n",
      "Epoch 5097/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6046 - accuracy: 0.6547 - val_loss: 0.7038 - val_accuracy: 0.5142\n",
      "Epoch 5098/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6061 - accuracy: 0.6549 - val_loss: 0.6354 - val_accuracy: 0.6056\n",
      "Epoch 5099/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6046 - accuracy: 0.6551 - val_loss: 0.6721 - val_accuracy: 0.5522\n",
      "Epoch 5100/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6030 - accuracy: 0.6583 - val_loss: 0.6459 - val_accuracy: 0.5868\n",
      "Epoch 5101/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6032 - accuracy: 0.6548 - val_loss: 0.6543 - val_accuracy: 0.5749\n",
      "Epoch 5102/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6000 - accuracy: 0.6592 - val_loss: 0.6693 - val_accuracy: 0.5592\n",
      "Epoch 5103/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6026 - accuracy: 0.6574 - val_loss: 0.6594 - val_accuracy: 0.5678\n",
      "Epoch 5104/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6012 - accuracy: 0.6587 - val_loss: 0.6403 - val_accuracy: 0.5924\n",
      "Epoch 5105/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6030 - accuracy: 0.6551 - val_loss: 0.6783 - val_accuracy: 0.5407\n",
      "Epoch 5106/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6022 - accuracy: 0.6578 - val_loss: 0.6359 - val_accuracy: 0.6052\n",
      "Epoch 5107/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6077 - accuracy: 0.6535 - val_loss: 0.7087 - val_accuracy: 0.5031\n",
      "Epoch 5108/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6116 - accuracy: 0.6503 - val_loss: 0.6234 - val_accuracy: 0.6279\n",
      "Epoch 5109/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6169 - accuracy: 0.6430 - val_loss: 0.7001 - val_accuracy: 0.5227\n",
      "Epoch 5110/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6101 - accuracy: 0.6520 - val_loss: 0.6458 - val_accuracy: 0.5890\n",
      "Epoch 5111/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6111 - accuracy: 0.6496 - val_loss: 0.6752 - val_accuracy: 0.5457\n",
      "Epoch 5112/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6018 - accuracy: 0.6596 - val_loss: 0.6428 - val_accuracy: 0.5943\n",
      "Epoch 5113/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6055 - accuracy: 0.6555 - val_loss: 0.6672 - val_accuracy: 0.5594\n",
      "Epoch 5114/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6042 - accuracy: 0.6553 - val_loss: 0.6468 - val_accuracy: 0.5831\n",
      "Epoch 5115/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6046 - accuracy: 0.6530 - val_loss: 0.6666 - val_accuracy: 0.5533\n",
      "Epoch 5116/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6015 - accuracy: 0.6590 - val_loss: 0.6485 - val_accuracy: 0.5835\n",
      "Epoch 5117/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6041 - accuracy: 0.6560 - val_loss: 0.6734 - val_accuracy: 0.5462\n",
      "Epoch 5118/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6025 - accuracy: 0.6575 - val_loss: 0.6406 - val_accuracy: 0.5970\n",
      "Epoch 5119/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6024 - accuracy: 0.6555 - val_loss: 0.6737 - val_accuracy: 0.5501\n",
      "Epoch 5120/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6024 - accuracy: 0.6580 - val_loss: 0.6504 - val_accuracy: 0.5769\n",
      "Epoch 5121/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6022 - accuracy: 0.6586 - val_loss: 0.6461 - val_accuracy: 0.5881\n",
      "Epoch 5122/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6007 - accuracy: 0.6570 - val_loss: 0.6598 - val_accuracy: 0.5652\n",
      "Epoch 5123/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6012 - accuracy: 0.6569 - val_loss: 0.6571 - val_accuracy: 0.5734\n",
      "Epoch 5124/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6008 - accuracy: 0.6589 - val_loss: 0.6625 - val_accuracy: 0.5628\n",
      "Epoch 5125/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6005 - accuracy: 0.6591 - val_loss: 0.6463 - val_accuracy: 0.5853\n",
      "Epoch 5126/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6006 - accuracy: 0.6581 - val_loss: 0.6626 - val_accuracy: 0.5634\n",
      "Epoch 5127/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6003 - accuracy: 0.6586 - val_loss: 0.6512 - val_accuracy: 0.5800\n",
      "Epoch 5128/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6000 - accuracy: 0.6593 - val_loss: 0.6615 - val_accuracy: 0.5656\n",
      "Epoch 5129/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6001 - accuracy: 0.6608 - val_loss: 0.6528 - val_accuracy: 0.5796\n",
      "Epoch 5130/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5998 - accuracy: 0.6583 - val_loss: 0.6566 - val_accuracy: 0.5753\n",
      "Epoch 5131/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5995 - accuracy: 0.6597 - val_loss: 0.6585 - val_accuracy: 0.5712\n",
      "Epoch 5132/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.5998 - accuracy: 0.6600 - val_loss: 0.6490 - val_accuracy: 0.5839\n",
      "Epoch 5133/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5994 - accuracy: 0.6589 - val_loss: 0.6623 - val_accuracy: 0.5639\n",
      "Epoch 5134/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5998 - accuracy: 0.6590 - val_loss: 0.6518 - val_accuracy: 0.5804\n",
      "Epoch 5135/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5994 - accuracy: 0.6596 - val_loss: 0.6624 - val_accuracy: 0.5669\n",
      "Epoch 5136/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5995 - accuracy: 0.6606 - val_loss: 0.6473 - val_accuracy: 0.5860\n",
      "Epoch 5137/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5994 - accuracy: 0.6595 - val_loss: 0.6635 - val_accuracy: 0.5649\n",
      "Epoch 5138/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5994 - accuracy: 0.6592 - val_loss: 0.6505 - val_accuracy: 0.5833\n",
      "Epoch 5139/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5993 - accuracy: 0.6597 - val_loss: 0.6637 - val_accuracy: 0.5627\n",
      "Epoch 5140/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5994 - accuracy: 0.6606 - val_loss: 0.6480 - val_accuracy: 0.5879\n",
      "Epoch 5141/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5993 - accuracy: 0.6588 - val_loss: 0.6654 - val_accuracy: 0.5594\n",
      "Epoch 5142/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5993 - accuracy: 0.6591 - val_loss: 0.6469 - val_accuracy: 0.5871\n",
      "Epoch 5143/15000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.5992 - accuracy: 0.6597 - val_loss: 0.6649 - val_accuracy: 0.5608\n",
      "Epoch 5144/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5994 - accuracy: 0.6602 - val_loss: 0.6441 - val_accuracy: 0.5923\n",
      "Epoch 5145/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5996 - accuracy: 0.6585 - val_loss: 0.6738 - val_accuracy: 0.5477\n",
      "Epoch 5146/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5999 - accuracy: 0.6601 - val_loss: 0.6385 - val_accuracy: 0.5988\n",
      "Epoch 5147/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6002 - accuracy: 0.6584 - val_loss: 0.6782 - val_accuracy: 0.5427\n",
      "Epoch 5148/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6009 - accuracy: 0.6591 - val_loss: 0.6341 - val_accuracy: 0.6071\n",
      "Epoch 5149/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6009 - accuracy: 0.6575 - val_loss: 0.6829 - val_accuracy: 0.5365\n",
      "Epoch 5150/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6012 - accuracy: 0.6599 - val_loss: 0.6348 - val_accuracy: 0.6058\n",
      "Epoch 5151/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6008 - accuracy: 0.6568 - val_loss: 0.6780 - val_accuracy: 0.5427\n",
      "Epoch 5152/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6007 - accuracy: 0.6589 - val_loss: 0.6381 - val_accuracy: 0.5990\n",
      "Epoch 5153/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6000 - accuracy: 0.6582 - val_loss: 0.6713 - val_accuracy: 0.5512\n",
      "Epoch 5154/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.5996 - accuracy: 0.6610 - val_loss: 0.6449 - val_accuracy: 0.5906\n",
      "Epoch 5155/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5992 - accuracy: 0.6593 - val_loss: 0.6654 - val_accuracy: 0.5592\n",
      "Epoch 5156/15000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5991 - accuracy: 0.6601 - val_loss: 0.6482 - val_accuracy: 0.5844\n",
      "Epoch 5157/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.5989 - accuracy: 0.6596 - val_loss: 0.6624 - val_accuracy: 0.5665\n",
      "Epoch 5158/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5989 - accuracy: 0.6610 - val_loss: 0.6475 - val_accuracy: 0.5866\n",
      "Epoch 5159/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5989 - accuracy: 0.6599 - val_loss: 0.6636 - val_accuracy: 0.5625\n",
      "Epoch 5160/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5989 - accuracy: 0.6605 - val_loss: 0.6479 - val_accuracy: 0.5859\n",
      "Epoch 5161/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5990 - accuracy: 0.6600 - val_loss: 0.6669 - val_accuracy: 0.5559\n",
      "Epoch 5162/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5991 - accuracy: 0.6603 - val_loss: 0.6408 - val_accuracy: 0.5961\n",
      "Epoch 5163/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5995 - accuracy: 0.6584 - val_loss: 0.6757 - val_accuracy: 0.5455\n",
      "Epoch 5164/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6000 - accuracy: 0.6595 - val_loss: 0.6362 - val_accuracy: 0.6036\n",
      "Epoch 5165/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6005 - accuracy: 0.6583 - val_loss: 0.6837 - val_accuracy: 0.5347\n",
      "Epoch 5166/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6015 - accuracy: 0.6583 - val_loss: 0.6292 - val_accuracy: 0.6142\n",
      "Epoch 5167/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6019 - accuracy: 0.6570 - val_loss: 0.6913 - val_accuracy: 0.5243\n",
      "Epoch 5168/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6031 - accuracy: 0.6584 - val_loss: 0.6279 - val_accuracy: 0.6162\n",
      "Epoch 5169/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6023 - accuracy: 0.6567 - val_loss: 0.6869 - val_accuracy: 0.5303\n",
      "Epoch 5170/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6022 - accuracy: 0.6587 - val_loss: 0.6345 - val_accuracy: 0.6061\n",
      "Epoch 5171/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6006 - accuracy: 0.6580 - val_loss: 0.6739 - val_accuracy: 0.5462\n",
      "Epoch 5172/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5999 - accuracy: 0.6608 - val_loss: 0.6440 - val_accuracy: 0.5915\n",
      "Epoch 5173/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.5991 - accuracy: 0.6595 - val_loss: 0.6625 - val_accuracy: 0.5652\n",
      "Epoch 5174/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5988 - accuracy: 0.6601 - val_loss: 0.6522 - val_accuracy: 0.5806\n",
      "Epoch 5175/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5985 - accuracy: 0.6604 - val_loss: 0.6563 - val_accuracy: 0.5760\n",
      "Epoch 5176/15000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.5986 - accuracy: 0.6610 - val_loss: 0.6563 - val_accuracy: 0.5736\n",
      "Epoch 5177/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5985 - accuracy: 0.6603 - val_loss: 0.6514 - val_accuracy: 0.5817\n",
      "Epoch 5178/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.5985 - accuracy: 0.6605 - val_loss: 0.6629 - val_accuracy: 0.5656\n",
      "Epoch 5179/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5987 - accuracy: 0.6608 - val_loss: 0.6455 - val_accuracy: 0.5904\n",
      "Epoch 5180/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5989 - accuracy: 0.6592 - val_loss: 0.6712 - val_accuracy: 0.5521\n",
      "Epoch 5181/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5995 - accuracy: 0.6600 - val_loss: 0.6368 - val_accuracy: 0.6028\n",
      "Epoch 5182/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6002 - accuracy: 0.6579 - val_loss: 0.6853 - val_accuracy: 0.5327\n",
      "Epoch 5183/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6016 - accuracy: 0.6585 - val_loss: 0.6263 - val_accuracy: 0.6191\n",
      "Epoch 5184/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6026 - accuracy: 0.6563 - val_loss: 0.7003 - val_accuracy: 0.5166\n",
      "Epoch 5185/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6050 - accuracy: 0.6566 - val_loss: 0.6242 - val_accuracy: 0.6217\n",
      "Epoch 5186/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6035 - accuracy: 0.6553 - val_loss: 0.6908 - val_accuracy: 0.5259\n",
      "Epoch 5187/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6030 - accuracy: 0.6583 - val_loss: 0.6336 - val_accuracy: 0.6067\n",
      "Epoch 5188/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6005 - accuracy: 0.6578 - val_loss: 0.6690 - val_accuracy: 0.5559\n",
      "Epoch 5189/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5991 - accuracy: 0.6604 - val_loss: 0.6534 - val_accuracy: 0.5796\n",
      "Epoch 5190/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.5985 - accuracy: 0.6609 - val_loss: 0.6497 - val_accuracy: 0.5844\n",
      "Epoch 5191/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.5985 - accuracy: 0.6602 - val_loss: 0.6686 - val_accuracy: 0.5554\n",
      "Epoch 5192/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.5992 - accuracy: 0.6606 - val_loss: 0.6354 - val_accuracy: 0.6056\n",
      "Epoch 5193/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6004 - accuracy: 0.6575 - val_loss: 0.6895 - val_accuracy: 0.5245\n",
      "Epoch 5194/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6026 - accuracy: 0.6578 - val_loss: 0.6238 - val_accuracy: 0.6228\n",
      "Epoch 5195/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6035 - accuracy: 0.6559 - val_loss: 0.7020 - val_accuracy: 0.5144\n",
      "Epoch 5196/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6056 - accuracy: 0.6557 - val_loss: 0.6267 - val_accuracy: 0.6167\n",
      "Epoch 5197/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6026 - accuracy: 0.6565 - val_loss: 0.6774 - val_accuracy: 0.5433\n",
      "Epoch 5198/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6006 - accuracy: 0.6602 - val_loss: 0.6485 - val_accuracy: 0.5831\n",
      "Epoch 5199/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5988 - accuracy: 0.6600 - val_loss: 0.6502 - val_accuracy: 0.5807\n",
      "Epoch 5200/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5986 - accuracy: 0.6601 - val_loss: 0.6719 - val_accuracy: 0.5479\n",
      "Epoch 5201/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5996 - accuracy: 0.6602 - val_loss: 0.6298 - val_accuracy: 0.6138\n",
      "Epoch 5202/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6014 - accuracy: 0.6587 - val_loss: 0.6973 - val_accuracy: 0.5181\n",
      "Epoch 5203/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6044 - accuracy: 0.6560 - val_loss: 0.6231 - val_accuracy: 0.6222\n",
      "Epoch 5204/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6043 - accuracy: 0.6543 - val_loss: 0.6948 - val_accuracy: 0.5201\n",
      "Epoch 5205/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6042 - accuracy: 0.6567 - val_loss: 0.6323 - val_accuracy: 0.6122\n",
      "Epoch 5206/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6011 - accuracy: 0.6591 - val_loss: 0.6651 - val_accuracy: 0.5594\n",
      "Epoch 5207/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5994 - accuracy: 0.6591 - val_loss: 0.6604 - val_accuracy: 0.5689\n",
      "Epoch 5208/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5988 - accuracy: 0.6599 - val_loss: 0.6400 - val_accuracy: 0.5965\n",
      "Epoch 5209/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6001 - accuracy: 0.6592 - val_loss: 0.6851 - val_accuracy: 0.5322\n",
      "Epoch 5210/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6021 - accuracy: 0.6580 - val_loss: 0.6231 - val_accuracy: 0.6224\n",
      "Epoch 5211/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6040 - accuracy: 0.6554 - val_loss: 0.7029 - val_accuracy: 0.5086\n",
      "Epoch 5212/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6058 - accuracy: 0.6543 - val_loss: 0.6272 - val_accuracy: 0.6180\n",
      "Epoch 5213/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6035 - accuracy: 0.6561 - val_loss: 0.6798 - val_accuracy: 0.5395\n",
      "Epoch 5214/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6021 - accuracy: 0.6580 - val_loss: 0.6468 - val_accuracy: 0.5864\n",
      "Epoch 5215/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.5998 - accuracy: 0.6578 - val_loss: 0.6495 - val_accuracy: 0.5818\n",
      "Epoch 5216/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6000 - accuracy: 0.6597 - val_loss: 0.6790 - val_accuracy: 0.5389\n",
      "Epoch 5217/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6009 - accuracy: 0.6594 - val_loss: 0.6265 - val_accuracy: 0.6176\n",
      "Epoch 5218/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6034 - accuracy: 0.6550 - val_loss: 0.6965 - val_accuracy: 0.5163\n",
      "Epoch 5219/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6044 - accuracy: 0.6567 - val_loss: 0.6257 - val_accuracy: 0.6198\n",
      "Epoch 5220/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6039 - accuracy: 0.6557 - val_loss: 0.6866 - val_accuracy: 0.5364\n",
      "Epoch 5221/15000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6029 - accuracy: 0.6570 - val_loss: 0.6440 - val_accuracy: 0.5928\n",
      "Epoch 5222/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6010 - accuracy: 0.6575 - val_loss: 0.6567 - val_accuracy: 0.5756\n",
      "Epoch 5223/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5997 - accuracy: 0.6605 - val_loss: 0.6676 - val_accuracy: 0.5559\n",
      "Epoch 5224/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6001 - accuracy: 0.6609 - val_loss: 0.6279 - val_accuracy: 0.6122\n",
      "Epoch 5225/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6021 - accuracy: 0.6565 - val_loss: 0.6952 - val_accuracy: 0.5188\n",
      "Epoch 5226/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6035 - accuracy: 0.6578 - val_loss: 0.6353 - val_accuracy: 0.6045\n",
      "Epoch 5227/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6029 - accuracy: 0.6562 - val_loss: 0.6768 - val_accuracy: 0.5406\n",
      "Epoch 5228/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6008 - accuracy: 0.6600 - val_loss: 0.6388 - val_accuracy: 0.5979\n",
      "Epoch 5229/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5999 - accuracy: 0.6583 - val_loss: 0.6571 - val_accuracy: 0.5734\n",
      "Epoch 5230/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5986 - accuracy: 0.6612 - val_loss: 0.6682 - val_accuracy: 0.5583\n",
      "Epoch 5231/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5992 - accuracy: 0.6619 - val_loss: 0.6416 - val_accuracy: 0.5977\n",
      "Epoch 5232/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5996 - accuracy: 0.6584 - val_loss: 0.6729 - val_accuracy: 0.5455\n",
      "Epoch 5233/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6003 - accuracy: 0.6599 - val_loss: 0.6347 - val_accuracy: 0.6030\n",
      "Epoch 5234/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6008 - accuracy: 0.6567 - val_loss: 0.6810 - val_accuracy: 0.5398\n",
      "Epoch 5235/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6009 - accuracy: 0.6583 - val_loss: 0.6392 - val_accuracy: 0.6012\n",
      "Epoch 5236/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6007 - accuracy: 0.6588 - val_loss: 0.6706 - val_accuracy: 0.5533\n",
      "Epoch 5237/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.5997 - accuracy: 0.6617 - val_loss: 0.6449 - val_accuracy: 0.5915\n",
      "Epoch 5238/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5995 - accuracy: 0.6595 - val_loss: 0.6601 - val_accuracy: 0.5685\n",
      "Epoch 5239/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5990 - accuracy: 0.6591 - val_loss: 0.6562 - val_accuracy: 0.5720\n",
      "Epoch 5240/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.5990 - accuracy: 0.6600 - val_loss: 0.6555 - val_accuracy: 0.5756\n",
      "Epoch 5241/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5989 - accuracy: 0.6606 - val_loss: 0.6599 - val_accuracy: 0.5665\n",
      "Epoch 5242/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.5988 - accuracy: 0.6600 - val_loss: 0.6430 - val_accuracy: 0.5957\n",
      "Epoch 5243/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5991 - accuracy: 0.6587 - val_loss: 0.6704 - val_accuracy: 0.5541\n",
      "Epoch 5244/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5992 - accuracy: 0.6611 - val_loss: 0.6473 - val_accuracy: 0.5864\n",
      "Epoch 5245/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5993 - accuracy: 0.6587 - val_loss: 0.6685 - val_accuracy: 0.5570\n",
      "Epoch 5246/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5994 - accuracy: 0.6599 - val_loss: 0.6379 - val_accuracy: 0.6005\n",
      "Epoch 5247/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5994 - accuracy: 0.6594 - val_loss: 0.6702 - val_accuracy: 0.5559\n",
      "Epoch 5248/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5990 - accuracy: 0.6617 - val_loss: 0.6510 - val_accuracy: 0.5815\n",
      "Epoch 5249/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5989 - accuracy: 0.6601 - val_loss: 0.6617 - val_accuracy: 0.5667\n",
      "Epoch 5250/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5986 - accuracy: 0.6595 - val_loss: 0.6462 - val_accuracy: 0.5884\n",
      "Epoch 5251/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5985 - accuracy: 0.6598 - val_loss: 0.6633 - val_accuracy: 0.5654\n",
      "Epoch 5252/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5984 - accuracy: 0.6617 - val_loss: 0.6521 - val_accuracy: 0.5787\n",
      "Epoch 5253/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5984 - accuracy: 0.6607 - val_loss: 0.6595 - val_accuracy: 0.5711\n",
      "Epoch 5254/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5983 - accuracy: 0.6603 - val_loss: 0.6499 - val_accuracy: 0.5853\n",
      "Epoch 5255/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.5983 - accuracy: 0.6606 - val_loss: 0.6630 - val_accuracy: 0.5658\n",
      "Epoch 5256/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.5983 - accuracy: 0.6620 - val_loss: 0.6483 - val_accuracy: 0.5862\n",
      "Epoch 5257/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5983 - accuracy: 0.6603 - val_loss: 0.6639 - val_accuracy: 0.5649\n",
      "Epoch 5258/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5983 - accuracy: 0.6614 - val_loss: 0.6469 - val_accuracy: 0.5888\n",
      "Epoch 5259/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5985 - accuracy: 0.6597 - val_loss: 0.6687 - val_accuracy: 0.5559\n",
      "Epoch 5260/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5987 - accuracy: 0.6615 - val_loss: 0.6390 - val_accuracy: 0.6012\n",
      "Epoch 5261/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5991 - accuracy: 0.6591 - val_loss: 0.6798 - val_accuracy: 0.5415\n",
      "Epoch 5262/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5998 - accuracy: 0.6602 - val_loss: 0.6347 - val_accuracy: 0.6065\n",
      "Epoch 5263/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6002 - accuracy: 0.6584 - val_loss: 0.6837 - val_accuracy: 0.5345\n",
      "Epoch 5264/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6015 - accuracy: 0.6588 - val_loss: 0.6283 - val_accuracy: 0.6167\n",
      "Epoch 5265/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6011 - accuracy: 0.6575 - val_loss: 0.6895 - val_accuracy: 0.5285\n",
      "Epoch 5266/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6014 - accuracy: 0.6596 - val_loss: 0.6358 - val_accuracy: 0.6056\n",
      "Epoch 5267/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6003 - accuracy: 0.6579 - val_loss: 0.6738 - val_accuracy: 0.5495\n",
      "Epoch 5268/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5999 - accuracy: 0.6597 - val_loss: 0.6401 - val_accuracy: 0.5959\n",
      "Epoch 5269/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5988 - accuracy: 0.6600 - val_loss: 0.6678 - val_accuracy: 0.5581\n",
      "Epoch 5270/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5985 - accuracy: 0.6614 - val_loss: 0.6515 - val_accuracy: 0.5815\n",
      "Epoch 5271/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5981 - accuracy: 0.6608 - val_loss: 0.6529 - val_accuracy: 0.5804\n",
      "Epoch 5272/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5980 - accuracy: 0.6603 - val_loss: 0.6611 - val_accuracy: 0.5685\n",
      "Epoch 5273/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5981 - accuracy: 0.6609 - val_loss: 0.6485 - val_accuracy: 0.5873\n",
      "Epoch 5274/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.5981 - accuracy: 0.6597 - val_loss: 0.6660 - val_accuracy: 0.5597\n",
      "Epoch 5275/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5986 - accuracy: 0.6613 - val_loss: 0.6408 - val_accuracy: 0.5974\n",
      "Epoch 5276/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5988 - accuracy: 0.6595 - val_loss: 0.6772 - val_accuracy: 0.5446\n",
      "Epoch 5277/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5996 - accuracy: 0.6606 - val_loss: 0.6333 - val_accuracy: 0.6078\n",
      "Epoch 5278/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6000 - accuracy: 0.6586 - val_loss: 0.6854 - val_accuracy: 0.5336\n",
      "Epoch 5279/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6011 - accuracy: 0.6588 - val_loss: 0.6327 - val_accuracy: 0.6113\n",
      "Epoch 5280/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6011 - accuracy: 0.6582 - val_loss: 0.6867 - val_accuracy: 0.5312\n",
      "Epoch 5281/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6017 - accuracy: 0.6589 - val_loss: 0.6280 - val_accuracy: 0.6164\n",
      "Epoch 5282/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6010 - accuracy: 0.6578 - val_loss: 0.6851 - val_accuracy: 0.5362\n",
      "Epoch 5283/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6009 - accuracy: 0.6595 - val_loss: 0.6411 - val_accuracy: 0.5988\n",
      "Epoch 5284/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5995 - accuracy: 0.6587 - val_loss: 0.6671 - val_accuracy: 0.5590\n",
      "Epoch 5285/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5990 - accuracy: 0.6619 - val_loss: 0.6457 - val_accuracy: 0.5902\n",
      "Epoch 5286/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5982 - accuracy: 0.6603 - val_loss: 0.6585 - val_accuracy: 0.5698\n",
      "Epoch 5287/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5985 - accuracy: 0.6596 - val_loss: 0.6614 - val_accuracy: 0.5676\n",
      "Epoch 5288/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5983 - accuracy: 0.6619 - val_loss: 0.6439 - val_accuracy: 0.5930\n",
      "Epoch 5289/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5987 - accuracy: 0.6595 - val_loss: 0.6757 - val_accuracy: 0.5464\n",
      "Epoch 5290/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5999 - accuracy: 0.6598 - val_loss: 0.6323 - val_accuracy: 0.6103\n",
      "Epoch 5291/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6003 - accuracy: 0.6585 - val_loss: 0.6883 - val_accuracy: 0.5285\n",
      "Epoch 5292/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6025 - accuracy: 0.6584 - val_loss: 0.6300 - val_accuracy: 0.6156\n",
      "Epoch 5293/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6017 - accuracy: 0.6577 - val_loss: 0.6870 - val_accuracy: 0.5362\n",
      "Epoch 5294/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6020 - accuracy: 0.6584 - val_loss: 0.6410 - val_accuracy: 0.5977\n",
      "Epoch 5295/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5992 - accuracy: 0.6595 - val_loss: 0.6586 - val_accuracy: 0.5733\n",
      "Epoch 5296/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5997 - accuracy: 0.6596 - val_loss: 0.6624 - val_accuracy: 0.5672\n",
      "Epoch 5297/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5985 - accuracy: 0.6617 - val_loss: 0.6387 - val_accuracy: 0.6021\n",
      "Epoch 5298/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6017 - accuracy: 0.6575 - val_loss: 0.6964 - val_accuracy: 0.5208\n",
      "Epoch 5299/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6049 - accuracy: 0.6569 - val_loss: 0.6121 - val_accuracy: 0.6425\n",
      "Epoch 5300/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6090 - accuracy: 0.6501 - val_loss: 0.7262 - val_accuracy: 0.4995\n",
      "Epoch 5301/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6123 - accuracy: 0.6494 - val_loss: 0.6497 - val_accuracy: 0.5901\n",
      "Epoch 5302/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6098 - accuracy: 0.6493 - val_loss: 0.6570 - val_accuracy: 0.5756\n",
      "Epoch 5303/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6037 - accuracy: 0.6560 - val_loss: 0.6628 - val_accuracy: 0.5703\n",
      "Epoch 5304/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6112 - accuracy: 0.6514 - val_loss: 0.6577 - val_accuracy: 0.5744\n",
      "Epoch 5305/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6042 - accuracy: 0.6558 - val_loss: 0.6413 - val_accuracy: 0.5932\n",
      "Epoch 5306/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6063 - accuracy: 0.6519 - val_loss: 0.7092 - val_accuracy: 0.5110\n",
      "Epoch 5307/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6090 - accuracy: 0.6528 - val_loss: 0.6369 - val_accuracy: 0.6050\n",
      "Epoch 5308/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6035 - accuracy: 0.6553 - val_loss: 0.6620 - val_accuracy: 0.5659\n",
      "Epoch 5309/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6027 - accuracy: 0.6557 - val_loss: 0.6569 - val_accuracy: 0.5703\n",
      "Epoch 5310/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6013 - accuracy: 0.6565 - val_loss: 0.6401 - val_accuracy: 0.6014\n",
      "Epoch 5311/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6037 - accuracy: 0.6555 - val_loss: 0.6933 - val_accuracy: 0.5206\n",
      "Epoch 5312/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6043 - accuracy: 0.6562 - val_loss: 0.6255 - val_accuracy: 0.6224\n",
      "Epoch 5313/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6041 - accuracy: 0.6564 - val_loss: 0.6810 - val_accuracy: 0.5373\n",
      "Epoch 5314/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6020 - accuracy: 0.6576 - val_loss: 0.6523 - val_accuracy: 0.5784\n",
      "Epoch 5315/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6002 - accuracy: 0.6591 - val_loss: 0.6407 - val_accuracy: 0.5930\n",
      "Epoch 5316/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6002 - accuracy: 0.6590 - val_loss: 0.6758 - val_accuracy: 0.5479\n",
      "Epoch 5317/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6019 - accuracy: 0.6572 - val_loss: 0.6358 - val_accuracy: 0.6047\n",
      "Epoch 5318/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6014 - accuracy: 0.6570 - val_loss: 0.6807 - val_accuracy: 0.5378\n",
      "Epoch 5319/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6018 - accuracy: 0.6596 - val_loss: 0.6392 - val_accuracy: 0.5992\n",
      "Epoch 5320/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5997 - accuracy: 0.6595 - val_loss: 0.6604 - val_accuracy: 0.5674\n",
      "Epoch 5321/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5991 - accuracy: 0.6602 - val_loss: 0.6567 - val_accuracy: 0.5716\n",
      "Epoch 5322/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5986 - accuracy: 0.6602 - val_loss: 0.6521 - val_accuracy: 0.5791\n",
      "Epoch 5323/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5990 - accuracy: 0.6597 - val_loss: 0.6612 - val_accuracy: 0.5630\n",
      "Epoch 5324/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5990 - accuracy: 0.6611 - val_loss: 0.6403 - val_accuracy: 0.5957\n",
      "Epoch 5325/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5992 - accuracy: 0.6592 - val_loss: 0.6742 - val_accuracy: 0.5497\n",
      "Epoch 5326/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5996 - accuracy: 0.6598 - val_loss: 0.6437 - val_accuracy: 0.5935\n",
      "Epoch 5327/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5988 - accuracy: 0.6589 - val_loss: 0.6634 - val_accuracy: 0.5617\n",
      "Epoch 5328/15000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.5989 - accuracy: 0.6599 - val_loss: 0.6462 - val_accuracy: 0.5877\n",
      "Epoch 5329/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5984 - accuracy: 0.6596 - val_loss: 0.6645 - val_accuracy: 0.5641\n",
      "Epoch 5330/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.5986 - accuracy: 0.6612 - val_loss: 0.6563 - val_accuracy: 0.5754\n",
      "Epoch 5331/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5980 - accuracy: 0.6613 - val_loss: 0.6465 - val_accuracy: 0.5881\n",
      "Epoch 5332/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5982 - accuracy: 0.6599 - val_loss: 0.6666 - val_accuracy: 0.5588\n",
      "Epoch 5333/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5983 - accuracy: 0.6612 - val_loss: 0.6439 - val_accuracy: 0.5954\n",
      "Epoch 5334/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5991 - accuracy: 0.6581 - val_loss: 0.6783 - val_accuracy: 0.5459\n",
      "Epoch 5335/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6001 - accuracy: 0.6602 - val_loss: 0.6310 - val_accuracy: 0.6125\n",
      "Epoch 5336/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6006 - accuracy: 0.6577 - val_loss: 0.6893 - val_accuracy: 0.5305\n",
      "Epoch 5337/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6016 - accuracy: 0.6594 - val_loss: 0.6338 - val_accuracy: 0.6054\n",
      "Epoch 5338/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6001 - accuracy: 0.6596 - val_loss: 0.6755 - val_accuracy: 0.5488\n",
      "Epoch 5339/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6006 - accuracy: 0.6586 - val_loss: 0.6414 - val_accuracy: 0.5955\n",
      "Epoch 5340/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5991 - accuracy: 0.6594 - val_loss: 0.6708 - val_accuracy: 0.5541\n",
      "Epoch 5341/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5992 - accuracy: 0.6614 - val_loss: 0.6541 - val_accuracy: 0.5784\n",
      "Epoch 5342/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5976 - accuracy: 0.6605 - val_loss: 0.6419 - val_accuracy: 0.5939\n",
      "Epoch 5343/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5987 - accuracy: 0.6599 - val_loss: 0.6758 - val_accuracy: 0.5480\n",
      "Epoch 5344/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5988 - accuracy: 0.6611 - val_loss: 0.6373 - val_accuracy: 0.6038\n",
      "Epoch 5345/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6015 - accuracy: 0.6570 - val_loss: 0.6956 - val_accuracy: 0.5225\n",
      "Epoch 5346/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6050 - accuracy: 0.6563 - val_loss: 0.6166 - val_accuracy: 0.6335\n",
      "Epoch 5347/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6052 - accuracy: 0.6547 - val_loss: 0.6995 - val_accuracy: 0.5206\n",
      "Epoch 5348/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6036 - accuracy: 0.6577 - val_loss: 0.6485 - val_accuracy: 0.5888\n",
      "Epoch 5349/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6013 - accuracy: 0.6589 - val_loss: 0.6513 - val_accuracy: 0.5829\n",
      "Epoch 5350/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6016 - accuracy: 0.6572 - val_loss: 0.6665 - val_accuracy: 0.5610\n",
      "Epoch 5351/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6034 - accuracy: 0.6569 - val_loss: 0.6377 - val_accuracy: 0.6021\n",
      "Epoch 5352/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6006 - accuracy: 0.6579 - val_loss: 0.6894 - val_accuracy: 0.5311\n",
      "Epoch 5353/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6040 - accuracy: 0.6580 - val_loss: 0.6460 - val_accuracy: 0.5897\n",
      "Epoch 5354/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5986 - accuracy: 0.6598 - val_loss: 0.6437 - val_accuracy: 0.5910\n",
      "Epoch 5355/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6007 - accuracy: 0.6584 - val_loss: 0.6831 - val_accuracy: 0.5353\n",
      "Epoch 5356/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6009 - accuracy: 0.6603 - val_loss: 0.6260 - val_accuracy: 0.6209\n",
      "Epoch 5357/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6073 - accuracy: 0.6524 - val_loss: 0.7180 - val_accuracy: 0.5004\n",
      "Epoch 5358/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6121 - accuracy: 0.6492 - val_loss: 0.6203 - val_accuracy: 0.6282\n",
      "Epoch 5359/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6076 - accuracy: 0.6499 - val_loss: 0.6681 - val_accuracy: 0.5594\n",
      "Epoch 5360/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5992 - accuracy: 0.6606 - val_loss: 0.6768 - val_accuracy: 0.5504\n",
      "Epoch 5361/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6044 - accuracy: 0.6584 - val_loss: 0.6416 - val_accuracy: 0.5959\n",
      "Epoch 5362/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5996 - accuracy: 0.6603 - val_loss: 0.6599 - val_accuracy: 0.5714\n",
      "Epoch 5363/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6021 - accuracy: 0.6584 - val_loss: 0.6544 - val_accuracy: 0.5776\n",
      "Epoch 5364/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5988 - accuracy: 0.6602 - val_loss: 0.6527 - val_accuracy: 0.5818\n",
      "Epoch 5365/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6023 - accuracy: 0.6581 - val_loss: 0.6795 - val_accuracy: 0.5395\n",
      "Epoch 5366/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6011 - accuracy: 0.6593 - val_loss: 0.6222 - val_accuracy: 0.6211\n",
      "Epoch 5367/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6052 - accuracy: 0.6546 - val_loss: 0.7026 - val_accuracy: 0.5142\n",
      "Epoch 5368/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6045 - accuracy: 0.6568 - val_loss: 0.6401 - val_accuracy: 0.6050\n",
      "Epoch 5369/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6066 - accuracy: 0.6552 - val_loss: 0.6763 - val_accuracy: 0.5512\n",
      "Epoch 5370/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6035 - accuracy: 0.6575 - val_loss: 0.6376 - val_accuracy: 0.6036\n",
      "Epoch 5371/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6070 - accuracy: 0.6518 - val_loss: 0.6716 - val_accuracy: 0.5544\n",
      "Epoch 5372/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6020 - accuracy: 0.6577 - val_loss: 0.6540 - val_accuracy: 0.5817\n",
      "Epoch 5373/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6038 - accuracy: 0.6567 - val_loss: 0.6761 - val_accuracy: 0.5488\n",
      "Epoch 5374/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.6007 - accuracy: 0.6597 - val_loss: 0.6368 - val_accuracy: 0.6016\n",
      "Epoch 5375/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6025 - accuracy: 0.6577 - val_loss: 0.6728 - val_accuracy: 0.5497\n",
      "Epoch 5376/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6027 - accuracy: 0.6560 - val_loss: 0.6379 - val_accuracy: 0.6001\n",
      "Epoch 5377/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6002 - accuracy: 0.6572 - val_loss: 0.6698 - val_accuracy: 0.5557\n",
      "Epoch 5378/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6004 - accuracy: 0.6606 - val_loss: 0.6566 - val_accuracy: 0.5778\n",
      "Epoch 5379/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6000 - accuracy: 0.6591 - val_loss: 0.6459 - val_accuracy: 0.5891\n",
      "Epoch 5380/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5996 - accuracy: 0.6585 - val_loss: 0.6678 - val_accuracy: 0.5601\n",
      "Epoch 5381/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5992 - accuracy: 0.6612 - val_loss: 0.6475 - val_accuracy: 0.5886\n",
      "Epoch 5382/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6009 - accuracy: 0.6588 - val_loss: 0.6725 - val_accuracy: 0.5510\n",
      "Epoch 5383/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5998 - accuracy: 0.6597 - val_loss: 0.6332 - val_accuracy: 0.6098\n",
      "Epoch 5384/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6021 - accuracy: 0.6557 - val_loss: 0.6855 - val_accuracy: 0.5325\n",
      "Epoch 5385/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6020 - accuracy: 0.6581 - val_loss: 0.6346 - val_accuracy: 0.6047\n",
      "Epoch 5386/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6010 - accuracy: 0.6594 - val_loss: 0.6754 - val_accuracy: 0.5501\n",
      "Epoch 5387/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6002 - accuracy: 0.6592 - val_loss: 0.6473 - val_accuracy: 0.5891\n",
      "Epoch 5388/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5990 - accuracy: 0.6593 - val_loss: 0.6517 - val_accuracy: 0.5828\n",
      "Epoch 5389/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5978 - accuracy: 0.6608 - val_loss: 0.6677 - val_accuracy: 0.5590\n",
      "Epoch 5390/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5992 - accuracy: 0.6596 - val_loss: 0.6400 - val_accuracy: 0.6012\n",
      "Epoch 5391/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5992 - accuracy: 0.6586 - val_loss: 0.6758 - val_accuracy: 0.5488\n",
      "Epoch 5392/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5996 - accuracy: 0.6599 - val_loss: 0.6388 - val_accuracy: 0.6021\n",
      "Epoch 5393/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5998 - accuracy: 0.6597 - val_loss: 0.6726 - val_accuracy: 0.5532\n",
      "Epoch 5394/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5989 - accuracy: 0.6607 - val_loss: 0.6412 - val_accuracy: 0.5965\n",
      "Epoch 5395/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5986 - accuracy: 0.6603 - val_loss: 0.6651 - val_accuracy: 0.5639\n",
      "Epoch 5396/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.5982 - accuracy: 0.6612 - val_loss: 0.6542 - val_accuracy: 0.5789\n",
      "Epoch 5397/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5976 - accuracy: 0.6616 - val_loss: 0.6520 - val_accuracy: 0.5826\n",
      "Epoch 5398/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.5977 - accuracy: 0.6605 - val_loss: 0.6623 - val_accuracy: 0.5649\n",
      "Epoch 5399/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5979 - accuracy: 0.6614 - val_loss: 0.6424 - val_accuracy: 0.5939\n",
      "Epoch 5400/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5981 - accuracy: 0.6600 - val_loss: 0.6705 - val_accuracy: 0.5546\n",
      "Epoch 5401/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5982 - accuracy: 0.6616 - val_loss: 0.6452 - val_accuracy: 0.5941\n",
      "Epoch 5402/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5983 - accuracy: 0.6589 - val_loss: 0.6693 - val_accuracy: 0.5574\n",
      "Epoch 5403/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5981 - accuracy: 0.6613 - val_loss: 0.6410 - val_accuracy: 0.5968\n",
      "Epoch 5404/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5981 - accuracy: 0.6608 - val_loss: 0.6662 - val_accuracy: 0.5625\n",
      "Epoch 5405/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5980 - accuracy: 0.6607 - val_loss: 0.6476 - val_accuracy: 0.5866\n",
      "Epoch 5406/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5976 - accuracy: 0.6613 - val_loss: 0.6625 - val_accuracy: 0.5680\n",
      "Epoch 5407/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5976 - accuracy: 0.6622 - val_loss: 0.6528 - val_accuracy: 0.5811\n",
      "Epoch 5408/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5972 - accuracy: 0.6608 - val_loss: 0.6533 - val_accuracy: 0.5820\n",
      "Epoch 5409/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5974 - accuracy: 0.6610 - val_loss: 0.6620 - val_accuracy: 0.5672\n",
      "Epoch 5410/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5974 - accuracy: 0.6620 - val_loss: 0.6446 - val_accuracy: 0.5917\n",
      "Epoch 5411/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5977 - accuracy: 0.6599 - val_loss: 0.6715 - val_accuracy: 0.5552\n",
      "Epoch 5412/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5981 - accuracy: 0.6609 - val_loss: 0.6396 - val_accuracy: 0.5992\n",
      "Epoch 5413/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5984 - accuracy: 0.6592 - val_loss: 0.6769 - val_accuracy: 0.5460\n",
      "Epoch 5414/15000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.5991 - accuracy: 0.6617 - val_loss: 0.6333 - val_accuracy: 0.6083\n",
      "Epoch 5415/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5992 - accuracy: 0.6596 - val_loss: 0.6810 - val_accuracy: 0.5400\n",
      "Epoch 5416/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5996 - accuracy: 0.6603 - val_loss: 0.6370 - val_accuracy: 0.6032\n",
      "Epoch 5417/15000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.5987 - accuracy: 0.6591 - val_loss: 0.6734 - val_accuracy: 0.5521\n",
      "Epoch 5418/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.5987 - accuracy: 0.6610 - val_loss: 0.6413 - val_accuracy: 0.5961\n",
      "Epoch 5419/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5979 - accuracy: 0.6602 - val_loss: 0.6672 - val_accuracy: 0.5610\n",
      "Epoch 5420/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5979 - accuracy: 0.6616 - val_loss: 0.6499 - val_accuracy: 0.5857\n",
      "Epoch 5421/15000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.5971 - accuracy: 0.6602 - val_loss: 0.6558 - val_accuracy: 0.5764\n",
      "Epoch 5422/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5974 - accuracy: 0.6605 - val_loss: 0.6567 - val_accuracy: 0.5749\n",
      "Epoch 5423/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5970 - accuracy: 0.6616 - val_loss: 0.6519 - val_accuracy: 0.5828\n",
      "Epoch 5424/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5975 - accuracy: 0.6609 - val_loss: 0.6647 - val_accuracy: 0.5621\n",
      "Epoch 5425/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5975 - accuracy: 0.6626 - val_loss: 0.6388 - val_accuracy: 0.5992\n",
      "Epoch 5426/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5981 - accuracy: 0.6606 - val_loss: 0.6776 - val_accuracy: 0.5455\n",
      "Epoch 5427/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5988 - accuracy: 0.6608 - val_loss: 0.6363 - val_accuracy: 0.6032\n",
      "Epoch 5428/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5995 - accuracy: 0.6588 - val_loss: 0.6865 - val_accuracy: 0.5334\n",
      "Epoch 5429/15000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6010 - accuracy: 0.6597 - val_loss: 0.6261 - val_accuracy: 0.6209\n",
      "Epoch 5430/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6008 - accuracy: 0.6578 - val_loss: 0.6899 - val_accuracy: 0.5312\n",
      "Epoch 5431/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6013 - accuracy: 0.6600 - val_loss: 0.6366 - val_accuracy: 0.6030\n",
      "Epoch 5432/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5991 - accuracy: 0.6589 - val_loss: 0.6702 - val_accuracy: 0.5572\n",
      "Epoch 5433/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5993 - accuracy: 0.6608 - val_loss: 0.6430 - val_accuracy: 0.5928\n",
      "Epoch 5434/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5981 - accuracy: 0.6595 - val_loss: 0.6618 - val_accuracy: 0.5676\n",
      "Epoch 5435/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5981 - accuracy: 0.6621 - val_loss: 0.6612 - val_accuracy: 0.5685\n",
      "Epoch 5436/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5970 - accuracy: 0.6628 - val_loss: 0.6395 - val_accuracy: 0.5990\n",
      "Epoch 5437/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5985 - accuracy: 0.6592 - val_loss: 0.6799 - val_accuracy: 0.5400\n",
      "Epoch 5438/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5992 - accuracy: 0.6609 - val_loss: 0.6304 - val_accuracy: 0.6147\n",
      "Epoch 5439/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6019 - accuracy: 0.6575 - val_loss: 0.7039 - val_accuracy: 0.5135\n",
      "Epoch 5440/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6057 - accuracy: 0.6564 - val_loss: 0.6163 - val_accuracy: 0.6366\n",
      "Epoch 5441/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6051 - accuracy: 0.6538 - val_loss: 0.6977 - val_accuracy: 0.5232\n",
      "Epoch 5442/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.6029 - accuracy: 0.6582 - val_loss: 0.6476 - val_accuracy: 0.5910\n",
      "Epoch 5443/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6001 - accuracy: 0.6605 - val_loss: 0.6493 - val_accuracy: 0.5835\n",
      "Epoch 5444/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5998 - accuracy: 0.6588 - val_loss: 0.6717 - val_accuracy: 0.5539\n",
      "Epoch 5445/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6018 - accuracy: 0.6594 - val_loss: 0.6301 - val_accuracy: 0.6136\n",
      "Epoch 5446/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6013 - accuracy: 0.6577 - val_loss: 0.7011 - val_accuracy: 0.5223\n",
      "Epoch 5447/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6048 - accuracy: 0.6568 - val_loss: 0.6341 - val_accuracy: 0.6065\n",
      "Epoch 5448/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5998 - accuracy: 0.6589 - val_loss: 0.6648 - val_accuracy: 0.5663\n",
      "Epoch 5449/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5999 - accuracy: 0.6598 - val_loss: 0.6557 - val_accuracy: 0.5745\n",
      "Epoch 5450/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5980 - accuracy: 0.6611 - val_loss: 0.6408 - val_accuracy: 0.6001\n",
      "Epoch 5451/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6006 - accuracy: 0.6577 - val_loss: 0.6945 - val_accuracy: 0.5212\n",
      "Epoch 5452/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6024 - accuracy: 0.6587 - val_loss: 0.6191 - val_accuracy: 0.6354\n",
      "Epoch 5453/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6049 - accuracy: 0.6552 - val_loss: 0.7070 - val_accuracy: 0.5115\n",
      "Epoch 5454/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6052 - accuracy: 0.6558 - val_loss: 0.6367 - val_accuracy: 0.6072\n",
      "Epoch 5455/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6017 - accuracy: 0.6572 - val_loss: 0.6592 - val_accuracy: 0.5725\n",
      "Epoch 5456/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.5995 - accuracy: 0.6598 - val_loss: 0.6636 - val_accuracy: 0.5658\n",
      "Epoch 5457/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6000 - accuracy: 0.6611 - val_loss: 0.6345 - val_accuracy: 0.6065\n",
      "Epoch 5458/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6000 - accuracy: 0.6580 - val_loss: 0.6960 - val_accuracy: 0.5250\n",
      "Epoch 5459/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6035 - accuracy: 0.6579 - val_loss: 0.6367 - val_accuracy: 0.6023\n",
      "Epoch 5460/15000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5988 - accuracy: 0.6597 - val_loss: 0.6569 - val_accuracy: 0.5747\n",
      "Epoch 5461/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5986 - accuracy: 0.6597 - val_loss: 0.6606 - val_accuracy: 0.5658\n",
      "Epoch 5462/15000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5980 - accuracy: 0.6607 - val_loss: 0.6395 - val_accuracy: 0.6019\n",
      "Epoch 5463/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5999 - accuracy: 0.6578 - val_loss: 0.6911 - val_accuracy: 0.5267\n",
      "Epoch 5464/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6016 - accuracy: 0.6588 - val_loss: 0.6221 - val_accuracy: 0.6290\n",
      "Epoch 5465/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.6032 - accuracy: 0.6566 - val_loss: 0.6984 - val_accuracy: 0.5217\n",
      "Epoch 5466/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6032 - accuracy: 0.6578 - val_loss: 0.6349 - val_accuracy: 0.6058\n",
      "Epoch 5467/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6004 - accuracy: 0.6582 - val_loss: 0.6624 - val_accuracy: 0.5669\n",
      "Epoch 5468/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5984 - accuracy: 0.6615 - val_loss: 0.6583 - val_accuracy: 0.5734\n",
      "Epoch 5469/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5982 - accuracy: 0.6604 - val_loss: 0.6414 - val_accuracy: 0.5965\n",
      "Epoch 5470/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5985 - accuracy: 0.6601 - val_loss: 0.6866 - val_accuracy: 0.5312\n",
      "Epoch 5471/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6006 - accuracy: 0.6598 - val_loss: 0.6249 - val_accuracy: 0.6228\n",
      "Epoch 5472/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6010 - accuracy: 0.6581 - val_loss: 0.6897 - val_accuracy: 0.5300\n",
      "Epoch 5473/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6016 - accuracy: 0.6592 - val_loss: 0.6343 - val_accuracy: 0.6072\n",
      "Epoch 5474/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5994 - accuracy: 0.6588 - val_loss: 0.6692 - val_accuracy: 0.5572\n",
      "Epoch 5475/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.5980 - accuracy: 0.6616 - val_loss: 0.6544 - val_accuracy: 0.5789\n",
      "Epoch 5476/15000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.5969 - accuracy: 0.6620 - val_loss: 0.6420 - val_accuracy: 0.5965\n",
      "Epoch 5477/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5980 - accuracy: 0.6603 - val_loss: 0.6799 - val_accuracy: 0.5426\n",
      "Epoch 5478/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5991 - accuracy: 0.6613 - val_loss: 0.6307 - val_accuracy: 0.6131\n",
      "Epoch 5479/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6002 - accuracy: 0.6588 - val_loss: 0.6881 - val_accuracy: 0.5320\n",
      "Epoch 5480/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6011 - accuracy: 0.6598 - val_loss: 0.6306 - val_accuracy: 0.6142\n",
      "Epoch 5481/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6000 - accuracy: 0.6575 - val_loss: 0.6739 - val_accuracy: 0.5510\n",
      "Epoch 5482/15000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5985 - accuracy: 0.6618 - val_loss: 0.6513 - val_accuracy: 0.5857\n",
      "Epoch 5483/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5972 - accuracy: 0.6618 - val_loss: 0.6489 - val_accuracy: 0.5851\n",
      "Epoch 5484/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5977 - accuracy: 0.6599 - val_loss: 0.6682 - val_accuracy: 0.5599\n",
      "Epoch 5485/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5977 - accuracy: 0.6613 - val_loss: 0.6362 - val_accuracy: 0.6023\n",
      "Epoch 5486/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5992 - accuracy: 0.6591 - val_loss: 0.6849 - val_accuracy: 0.5364\n",
      "Epoch 5487/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6004 - accuracy: 0.6593 - val_loss: 0.6290 - val_accuracy: 0.6160\n",
      "Epoch 5488/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6006 - accuracy: 0.6577 - val_loss: 0.6806 - val_accuracy: 0.5426\n",
      "Epoch 5489/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5991 - accuracy: 0.6615 - val_loss: 0.6437 - val_accuracy: 0.5943\n",
      "Epoch 5490/15000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5981 - accuracy: 0.6611 - val_loss: 0.6611 - val_accuracy: 0.5694\n",
      "Epoch 5491/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5980 - accuracy: 0.6601 - val_loss: 0.6543 - val_accuracy: 0.5773\n",
      "Epoch 5492/15000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.5972 - accuracy: 0.6609 - val_loss: 0.6513 - val_accuracy: 0.5807\n",
      "Epoch 5493/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5978 - accuracy: 0.6618 - val_loss: 0.6677 - val_accuracy: 0.5607\n",
      "Epoch 5494/15000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.5975 - accuracy: 0.6620 - val_loss: 0.6350 - val_accuracy: 0.6087\n",
      "Epoch 5495/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5990 - accuracy: 0.6588 - val_loss: 0.6831 - val_accuracy: 0.5367\n",
      "Epoch 5496/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5992 - accuracy: 0.6616 - val_loss: 0.6356 - val_accuracy: 0.6072\n",
      "Epoch 5497/15000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5999 - accuracy: 0.6585 - val_loss: 0.6832 - val_accuracy: 0.5409\n",
      "Epoch 5498/15000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.6005 - accuracy: 0.6595 - val_loss: 0.6311 - val_accuracy: 0.6116\n",
      "Epoch 5499/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5995 - accuracy: 0.6584 - val_loss: 0.6742 - val_accuracy: 0.5502\n",
      "Epoch 5500/15000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5987 - accuracy: 0.6617 - val_loss: 0.6528 - val_accuracy: 0.5826\n",
      "Epoch 5501/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5972 - accuracy: 0.6616 - val_loss: 0.6478 - val_accuracy: 0.5886\n",
      "Epoch 5502/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.5981 - accuracy: 0.6595 - val_loss: 0.6676 - val_accuracy: 0.5619\n",
      "Epoch 5503/15000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5975 - accuracy: 0.6617 - val_loss: 0.6386 - val_accuracy: 0.6028\n",
      "Epoch 5504/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.5998 - accuracy: 0.6596 - val_loss: 0.6903 - val_accuracy: 0.5298\n",
      "Epoch 5505/15000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6013 - accuracy: 0.6587 - val_loss: 0.6229 - val_accuracy: 0.6248\n",
      "Epoch 5506/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6028 - accuracy: 0.6560 - val_loss: 0.6934 - val_accuracy: 0.5245\n",
      "Epoch 5507/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6019 - accuracy: 0.6592 - val_loss: 0.6383 - val_accuracy: 0.6018\n",
      "Epoch 5508/15000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6004 - accuracy: 0.6581 - val_loss: 0.6670 - val_accuracy: 0.5656\n",
      "Epoch 5509/15000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.6001 - accuracy: 0.6584 - val_loss: 0.6536 - val_accuracy: 0.5824\n",
      "Epoch 5510/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5985 - accuracy: 0.6594 - val_loss: 0.6492 - val_accuracy: 0.5839\n",
      "Epoch 5511/15000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.5997 - accuracy: 0.6604 - val_loss: 0.6795 - val_accuracy: 0.5429\n",
      "Epoch 5512/15000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5994 - accuracy: 0.6607 - val_loss: 0.6218 - val_accuracy: 0.6259\n",
      "Epoch 5513/15000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6027 - accuracy: 0.6564 - val_loss: 0.6998 - val_accuracy: 0.5197\n",
      "Epoch 5514/15000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jgalvan/Desktop/Xylella fastidiosa detection/Coding/Main_file/Xylella_detection.ipynb Cell 33\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsalmunia/home/jgalvan/Desktop/Xylella%20fastidiosa%20detection/Coding/Main_file/Xylella_detection.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m n_training_examples \u001b[39m=\u001b[39m X_train_balanced\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsalmunia/home/jgalvan/Desktop/Xylella%20fastidiosa%20detection/Coding/Main_file/Xylella_detection.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Fit data to model    \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bsalmunia/home/jgalvan/Desktop/Xylella%20fastidiosa%20detection/Coding/Main_file/Xylella_detection.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m history \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39;49mfit(X_train_balanced, Y_train_balanced, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsalmunia/home/jgalvan/Desktop/Xylella%20fastidiosa%20detection/Coding/Main_file/Xylella_detection.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m                          validation_data \u001b[39m=\u001b[39;49m (X_val, Y_val), \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsalmunia/home/jgalvan/Desktop/Xylella%20fastidiosa%20detection/Coding/Main_file/Xylella_detection.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m                          batch_size \u001b[39m=\u001b[39;49m n_training_examples, epochs \u001b[39m=\u001b[39;49m num_epochs, verbose\u001b[39m=\u001b[39;49mverbosity)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsalmunia/home/jgalvan/Desktop/Xylella%20fastidiosa%20detection/Coding/Main_file/Xylella_detection.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Generate generalization metrics\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsalmunia/home/jgalvan/Desktop/Xylella%20fastidiosa%20detection/Coding/Main_file/Xylella_detection.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m scores \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39mevaluate(X_val, Y_val, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/xylella_tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/xylella_tf/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.conda/envs/xylella_tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/xylella_tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.conda/envs/xylella_tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.conda/envs/xylella_tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/.conda/envs/xylella_tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.conda/envs/xylella_tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.conda/envs/xylella_tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# K-fold Cross Validation model evaluation\n",
    "ground_acc = 0\n",
    "\n",
    "fold_no = 1\n",
    "for train, validate in kfold.split(X_train, Y_train):\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    classifier = model()\n",
    "    \n",
    "    # Oversample the training set\n",
    "    X_train_balanced, Y_train_balanced = adasyn.fit_resample(X_train[train], Y_train[train])\n",
    "    X_val, Y_val = X_train[validate], Y_train[validate]\n",
    "    n_training_examples = X_train_balanced.shape[0]\n",
    "\n",
    "    \n",
    "    # Fit data to model    \n",
    "    history = classifier.fit(X_train_balanced, Y_train_balanced, \n",
    "                             validation_data = (X_val, Y_val), \n",
    "                             batch_size = n_training_examples, epochs = num_epochs, verbose=verbosity)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = classifier.evaluate(X_val, Y_val, verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {classifier.metrics_names[0]} of {scores[0]}; {classifier.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    if scores[1]>ground_acc:\n",
    "        ground_acc = scores[1]\n",
    "        classifier.save('ann_classifier_best_new.h5')\n",
    "        #file_management.save_lzma(train, 'train_set.lzma', '')\n",
    "        file_management.save_lzma(validate, 'validate_set.lzma', '')\n",
    "        train_set = train\n",
    "        validate_set = validate\n",
    "        \n",
    "        train_acc2 = history.history['accuracy']\n",
    "        val_acc2 = history.history['val_accuracy']\n",
    "        train_loss2 = history.history['loss']\n",
    "        val_loss2 = history.history['val_loss']\n",
    "            \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b76b91d1",
   "metadata": {},
   "source": [
    "Average scores for all folds: (only indices, 15000 epochs)\n",
    "> Accuracy: 77.90514145578656 (+- 1.4814076341552638)\n",
    "> Loss: 0.7443450008119855 (+- 0.1207884071335813)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f9e4f65",
   "metadata": {},
   "source": [
    "Average scores for all folds: (only bands, 15000 epochs)\n",
    "> Accuracy: 76.207948582513 (+- 2.8430736484859094)\n",
    "> Loss: 0.6742679306438991 (+- 0.09772139789920833)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6db9f4eb",
   "metadata": {},
   "source": [
    "Average scores for all folds (5000 epochs):\n",
    "> Accuracy: 59.658717257635935 (+- 1.2219046765570636)\n",
    "> Loss: 0.6586811542510986 (+- 0.00763990732993515)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "994b512d",
   "metadata": {},
   "source": [
    "# Average scores for all folds:\n",
    "> Accuracy: 55.4264451776232 (+- 1.6458214760896448)\n",
    "> Loss: 0.6831462894167218 (+- 0.006606582555030469)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e37c51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T21:39:31.751589Z",
     "start_time": "2022-08-11T21:39:29.925756Z"
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DRAW THE LEARNING CURVES FOR THE BEST K-FOLD\n",
    "# =============================================================================\n",
    "#classifier = model()\n",
    "# history = classifier.fit(X[train_set], Y[train_set], validation_data = (X[test_set], Y[test_set]), batch_size = number_examples, epochs = num_epochs, verbose=verbosity)\n",
    "# train_acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "# train_loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "epochs = np.arange(1, num_epochs+1)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1\n",
    "                               \n",
    "                               ,2, figsize=(7.5, 5), sharex=True)\n",
    "#Draw accuracy curve\n",
    "ax1.plot(epochs, train_acc2, 'r-', label='Training set')\n",
    "ax1.plot(epochs, val_acc2, 'b-', label='Cross-validation set')\n",
    "ax1.axhline(1- sum(Y_train[validate_set])/len(Y_train[validate_set]), label='Negatives ratio', color='k')\n",
    "ax1.set_ylabel('Accuracy', fontsize=12)\n",
    "ax1.set_xlabel('Epochs', fontsize=12)\n",
    "ax1.legend(loc='best', fontsize=12)\n",
    "#Draw cost curve\n",
    "ax2.plot(epochs, train_loss2, 'r-', label='Training set')\n",
    "ax2.plot(epochs, val_loss2, 'b-', label='Cross-validation set')\n",
    "ax2.set_xlabel('Epochs', fontsize=12)\n",
    "ax2.set_ylabel('Loss', fontsize=12)\n",
    "ax2.legend(loc='best', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(classification_path, 'ann_learning_curves3.png'), dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b76f826",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T22:40:11.708785Z",
     "start_time": "2022-08-11T22:40:11.181341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 2ms/step\n",
      "[[1081  324]\n",
      " [ 174  311]]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFUSSION MATRIX FOR THE BEST CLASSIFIER OVER VALIDATION SET\n",
    "# =============================================================================\n",
    "# Load the best classifier\n",
    "best_model_path = 'Classification figures/num_epochs_25000_oversampling_True_dropout_True '\n",
    "best_model = keras.models.load_model(os.path.join(best_model_path, 'ann_classifier_best_new.h5'))\n",
    "\n",
    "#train_set = file_management.load_lzma('train_set.lzma')\n",
    "validate_set = file_management.load_lzma(os.path.join(best_model_path,'validate_set.lzma'))\n",
    "# We evaluate the best classifier on its fold\n",
    "y_pred = best_model.predict(X_train[validate_set])\n",
    "\n",
    "Y_pred = np.round(y_pred)\n",
    "cm=confusion_matrix(Y_train[validate_set],Y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e66d55c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T22:40:13.538022Z",
     "start_time": "2022-08-11T22:40:13.507560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.65%\n",
      "Recall: 64.12%\n",
      "Precision: 48.98%\n",
      "F1-score: 55.54%\n",
      "Proportion of positives: 25.66%\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# OBTAIN ACCURACY, RECALL, PRECISION, F1SCORE FOR BEST MODEL\n",
    "# =============================================================================\n",
    "# Evalute its accuracy over the last kfold\n",
    "accuracy = accuracy_score(Y_train[validate_set], Y_pred)\n",
    "recall = recall_score(Y_train[validate_set], Y_pred)\n",
    "precision = precision_score(Y_train[validate_set], Y_pred)\n",
    "f1score = f1_score(Y_train[validate_set], Y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy*100))\n",
    "print(\"Recall: %.2f%%\" % (recall*100))\n",
    "print(\"Precision: %.2f%%\" % (precision*100))\n",
    "print(\"F1-score: %.2f%%\" % (f1score*100))\n",
    "print(\"Proportion of positives: %.2f%%\" %(100*sum(Y_train[validate_set]/len(Y_train[validate_set]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "805756e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ROC and AUC\n",
    "# =============================================================================\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(Y_train[validate_set], y_pred)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='ANN 1-1 (AUC = {:.2f})'.format(auc_keras))\n",
    "#plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\n",
    "plt.xlabel('False positive rate (specificity)', fontsize=16)\n",
    "plt.ylabel('True positive rate (sensitivity)', fontsize=16)\n",
    "plt.legend(loc='best', fontsize=16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(classification_path, 'roc_curve_validation_ANN11.png'), dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c1e256",
   "metadata": {},
   "source": [
    "## Test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83685325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step\n",
      "[[416 117]\n",
      " [ 62 101]]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFUSSION MATRIX FOR THE BEST CLASSIFIER OVER TEST SET\n",
    "# =============================================================================\n",
    "# Load the best classifier\n",
    "#best_model = keras.models.load_model('ann_classifier_best_new.h5')\n",
    "\n",
    "X_test = file_management.load_lzma('X_test.lzma')\n",
    "Y_test = file_management.load_lzma('Y_test.lzma')\n",
    "\n",
    "# We evaluate the best classifier on its fold\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "Y_test_pred = np.round(y_test_pred)\n",
    "cm=confusion_matrix(Y_test,Y_test_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f38e363",
   "metadata": {},
   "source": [
    "[[390 143]\n",
    " [ 86  77]]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "baa7fd43",
   "metadata": {},
   "source": [
    "[[330 203]\n",
    " [ 58 105]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94ae3fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.28%\n",
      "Recall: 61.96%\n",
      "Precision: 46.33%\n",
      "F1-score: 53.02%\n",
      "Proportion of positives: 23.42%\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# OBTAIN ACCURACY, RECALL, PRECISION, F1SCORE FOR BEST MODEL\n",
    "# =============================================================================\n",
    "# Evalute its metrics\n",
    "accuracy = accuracy_score(Y_test, Y_test_pred)\n",
    "recall = recall_score(Y_test, Y_test_pred)\n",
    "precision = precision_score(Y_test, Y_test_pred)\n",
    "f1score = f1_score(Y_test, Y_test_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy*100))\n",
    "print(\"Recall: %.2f%%\" % (recall*100))\n",
    "print(\"Precision: %.2f%%\" % (precision*100))\n",
    "print(\"F1-score: %.2f%%\" % (f1score*100))\n",
    "print(\"Proportion of positives: %.2f%%\" %(100*sum(Y_test)/len(Y_test)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1fe8975",
   "metadata": {},
   "source": [
    "Accuracy: 67.10%\n",
    "Recall: 47.24%\n",
    "Precision: 35.00%\n",
    "F1-score: 40.21%\n",
    "Proportion of positives: 23.42%"
   ]
  },
  {
   "cell_type": "raw",
   "id": "67dd2a40",
   "metadata": {},
   "source": [
    "Accuracy: 62.50%\n",
    "Recall: 64.42%\n",
    "Precision: 34.09%\n",
    "F1-score: 44.59%\n",
    "Proportion of positives: 23.42%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79b70e5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T22:41:02.150675Z",
     "start_time": "2022-08-11T22:41:01.613756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ROC and AUC\n",
    "# =============================================================================\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(Y_test, y_test_pred)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='ANN 1-1 (AUC = {:.2f})'.format(auc_keras))\n",
    "#plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\n",
    "plt.xlabel('False positive rate (specificity)', fontsize=16)\n",
    "plt.ylabel('True positive rate (sensitivity)', fontsize=16)\n",
    "plt.legend(loc='best', fontsize=16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(classification_path, 'roc_curve_test_ANN11.png'), dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4eb6883",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T22:41:21.452836Z",
     "start_time": "2022-08-11T22:41:13.109341Z"
    }
   },
   "source": [
    "X_test = reducer.transform(X[test_set])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "31ff2829",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T22:41:21.695540Z",
     "start_time": "2022-08-11T22:41:21.456059Z"
    }
   },
   "source": [
    "chart(X_test, Y[test_set])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1ec5a33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-11T22:41:21.928113Z",
     "start_time": "2022-08-11T22:41:21.698784Z"
    }
   },
   "source": [
    "chart(X_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1327243b",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f34294b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T16:29:59.252Z"
    }
   },
   "source": [
    "# =============================================================================\n",
    "# SVM\n",
    "# =============================================================================\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='rbf', gamma=0.0193, C = 100)\n",
    "svclassifier.fit(X[train_set], Y[train_set])\n",
    "\n",
    "y_pred = np.round(svclassifier.predict(X[test_set]))\n",
    "\n",
    "print(confusion_matrix(Y[test_set],y_pred))\n",
    "#### OJO CON COMO DEFINE LA MATRIZ DE CONFUSION PYTHON ####\n",
    "accuracy = accuracy_score(Y[test_set], y_pred)\n",
    "recall = recall_score(Y[test_set], y_pred)\n",
    "precision = precision_score(Y[test_set], y_pred)\n",
    "f1score = f1_score(Y[test_set], y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy*100))\n",
    "print(\"Recall: %.2f%%\" % (recall*100))\n",
    "print(\"Precision: %.2f%%\" % (precision*100))\n",
    "print(\"F1-score: %.2f%%\" % (f1score*100))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1d8684d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T16:29:59.551Z"
    }
   },
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "num_folds = 7\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=0) #fix the divition\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "ground_acc = 0\n",
    "\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(X, Y):\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    svclassifier = SVC(kernel='rbf', gamma=0.0193, C=100, probability=True)\n",
    "    svclassifier.fit(X[train], Y[train])\n",
    "    y_pred = svclassifier.predict_proba(X[test])[:,1]\n",
    "    #y_pred = svclassifier.predict(X[test])\n",
    "    # Generate generalization metrics\n",
    "    acc = accuracy_score(Y[test], np.round(y_pred))\n",
    "    print(f'Score for fold {fold_no}: Accuracy of {acc}')\n",
    "    acc_per_fold.append(acc)\n",
    "    loss_per_fold.append(log_loss(Y[test], y_pred))\n",
    "    if acc>ground_acc:\n",
    "        ground_acc = acc\n",
    "        test_set2 = test\n",
    "        y_pred2 = y_pred\n",
    "        \n",
    "        \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)} (+- {np.std(loss_per_fold)})')\n",
    "print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "128904f7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-08-10T16:29:59.865Z"
    }
   },
   "source": [
    "# =============================================================================\n",
    "# ROC and AUC\n",
    "# =============================================================================\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(Y[test_set2], y_pred2)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='SVM (AUC = {:.2f})'.format(auc_keras))\n",
    "#plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\n",
    "plt.xlabel('False positive rate (specificity)', fontsize=16)\n",
    "plt.ylabel('True positive rate (sensitivity)', fontsize=16)\n",
    "plt.legend(loc='best', fontsize=16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(classification_path, 'roc_curve_SVM.png'), dpi=300, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeffe5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xylella_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
